,index,text,edited_text,cluster_idx
0,0,"387 
Neural Net and Traditional Classifiers  
William Y. Huang and Richard P. Lippmann 
MIT Lincoln Laboratory 
Lexington, MA 02173, USA 
Abstract
Previous work on nets with continuous-valued inputs led to generative 
procedures to construct convex decision regions with two-layer percepttons (one hidden 
layer) and arbitrary decision regions with three-layer percepttons (two hidden layers). 
Here we demonstrate that two-layer perceptton classifiers trained with back propagation 
can form both convex and disjoint decision regions. Such classifiers are robust, train 
rapidly, and provide good performance with simple decision regions. When complex 
decision regions are required, however, convergence time can be excessively long and 
performance is often no better than that of k-nearest neighbor classifiers. Three neural 
net classifiers are presented that provide more rapid training under such situations. 
Two use fixed weights in the first one or two layers and are similar to classifiers that 
estimate probability density functions using histograms. A third ""feature map classifier"" 
uses both unsupervised and supervised training. It provides good performance with 
little supervised training in situations such as speech recognition where much unlabeled 
training data is available. The architecture of this classifier can be used to implement 
a neural net k-nearest neighbor classifier. 
1. INTRODUCTION 
Neural net architectures can be used to construct many different types of classi- 
tiers [7]. In particular, multi-layer perceptron classifiers with continuous valued in- 
puts trained with back propagation are robust, often train rapidly, and provide perfor- 
mance similar to that provided by Gaussian classifiers when decision regions are convex 
[12,7,5,8]. Generative procedures demonstrate that such classifiers can form convex deci- 
sion regions with two-layer perceptrons (one hidden layer) and arbitrary decision regions 
with three-layer perceptrons (two hidden layers) [7,2,9]. More recent work has demon- 
strated that two-layer perceptrons can form non-convex and disjoint decision regions. 
Examples of hand crafted two-layer networks which generate such decision regions are 
presented in this paper along with Monte Carlo simulations where complex decision 
regions were generated using back propagation training. These and previous simula- 
tions [5,8] demonstrate that convergence time with back propagation can be excessive 
when complex decision regions are desired and performance is often no better than that 
obtained with k-nearest neighbor classifiers [4]. These results led us to explore other 
neural net classifiers that might provide faster convergence. Three classifiers called, 
""fixed weight,"" ""hypercube,"" and ""feature map"" classifiers, were developed and eval- 
uated. All classifiers were tested on illustrative problems with two continuous-valued 
inputs and two classes (A and B). A more restricted set of classifiers was tested with 
vowel formant data. 
2. CAPABILITIES OF TWO LAYER PERCEPTRONS 
Multi-layer perceptron classifiers with hard-limiting nonlinearities (node outputs 
of 0 or 1) and continuous-valued inputs can form complex decision regions. Simple 
constructive proofs demonstrate that a three-layer perceptron (two hidden layers) can 
 This work was sponsored by the Defense Advanced Research Projects Agency and the Department 
of the Air Force. The views expressed are those of the authors and do not reflect the policy or position 
of the U.S. Government. 
American Institute of Physics 1988 
388 
b I b2 
Xl x 2 
DECISION REGION FOR CLASS A 
x I bl b2 
 b6 ........ 
-2 
I I 
I 
 I 
I 
o I 2 
3 4 
Xl 
FIG. 1. A two-layer perceptton that forms disjoint decision re9ions for class A (shaded areas). Connec- 
tion weights and node offsets are shown in the left. Hyperplanes formed by all hidden nodes are drawn 
as dashed lines with node labels. Arrows on these lines point to the half plane where the hidden node 
output is ""high"" 
form arbitrary decision regions and a two-layer perceptron (one hidden layer) can form 
single convex decision regions [7,2,9]. Recently, however, it has been demonstrated that 
two-layer perceptrons can form decision regions that are not simply convex [14]. Fig. 1, 
for example, shows how disjoint decision regions can be generated using a two-layer 
perceptron. The two disjoint shaded areas in this Fig. represent the decision region 
for class A (output node has a ""high"" output, y = 1). The remaining area represents 
the decision region for class B (output node has a ""low"" output, y = 0). Nodes in 
this Fig. contain hard-limiting nonlinearities. Connection weights and node offsets are 
indicated in the left diagram. Ten other complex decision regions formed using two-layer 
perceptrons are presented in Fig. 2. 
The above examples suggest that two-layer perceptrons can form decision regions 
with arbitrary shapes. We, however, know of no general proof of this capability. A 
1965 book by Nilson discusses this issue and contains a proof that two-layer nets can 
divide a finite number of points into two arbitrary sets ([10] page 89). This proof 
involves separating M points using at most M - 1 parallel hyperplanes formed by first- 
layer nodes where no hyperplane intersects two or more points. Proving that a given 
decision region can be formed in a two-layer net involves testing to determine whether 
the Boolean representations at the output of the first layer for all points within the 
decision region for class A are linearly separable from the Boolean representations for 
class B. One test for linear separability was presented in 1962 [13]. 
A problem with forming complex decision regions with two-layer percepttons is that 
weights and offsets must be adjusted carefully because they interact extensively to form 
decision regions. Fig. 1 illustrates this sensitivity problem. Here it can be seen that 
weights to one hidden node form a hyperplane which influences decision regions in 
an entire halLplane. For example, small errors in first layer weights that results in a 
change in the slopes of hyperplanes b$ and b6 might only slightly extend the A region 
but completely eliminate the A2 region. This interdependence can be eliminated in 
three layer perceptrons. 
It is possible to train two-layer percepttons to form complex decision regions using 
back propagation and sigmoidal nonlinearities despite weight interactions. Fig. 3, for 
example, shows disjoint decision regions formed using back propagation for the problem 
of Fig. 1. In this and all other simulations, inputs were presented alternately from 
classes A and B and selected from a uniform distribution covering the desired decision 
region. In addition, the back propagation rate of descent term, r/, was set equal to the 
momentum gain term, a and r/= a = .01. Small values for r/and a were necessary to 
guarantee convergence for the difficult problems in Fig. 2. Other simulation details are 
389 
I) ) s) ) I 
FIG. 2. Ten complex decision regions formed by two-layer perceptrons. The numbers assigned to each 
case are the acase""numbers used in the rest of this paper. 
as in [5,8]. Also shown in Fig. 3 are hyperplanes formed by those first-layer nodes with 
the strongest connection weights to the output node. These hyperplanes and weights 
are similar to those in the networks created by hand except for sign inversions, the 
occurrence of multiple similar hyperplanes formed by two nodes, and the use of node 
offsets with values near zero. 
3. COMPARATIVE RESULTS OF TwO-LAYERS VS. THREE-LAYERS 
Previous results [5,8], as well as the weight interactions mentioned above, suggest 
that three-layer percepttons may be able to form complex decision regions faster with 
back propagation than two-layer percepttons. This was explored using Monte Carlo 
simulations for the first nine cases of Fig. 2. All networks have 32 nodes in the first 
hidden layer. The number of nodes in the second hidden layer was twice the number 
of convex regions needed to form the decision region (2, 4, 6, 4, 6, 6, 8, 6 and 6 for 
Cases I through 9 respectively). Ten runs were typically averaged together to obtain 
a smooth curve of percentage error vs. time (number of training trials) and enough 
trials were run (to a limit of 250,000) until the curve appeared to fiatten out with little 
improvement over time. The error curve was then low-pass filtered to determine the 
convergence time. Convergence time was defined as the time when the curve crossed a 
value 5 percentage points above the final percentage error. This definition provides a 
framework for comparing the convergence time of the different classifiers. It, however, is 
not the time after which error rates do not improve. Fig. 4 summarizes results in terms 
of convergence time and final percentage error. In those cases with disjoint decision 
regions, back propagation sometimes failed to form separate regions after 250,000 trials. 
For example, the two disjoint regions required in Case 2 were never fully separated with 
390 
FIG. 3. Decision regions formed using back propagation for Cases  of Fig. . Thick solid lines represent 
decision boundaries. Dashed lines and arrows have the same meaning as in Fig. 1. Only hyperplanes 
for hidden nodes with large weights to the output node are shown. Over 300,000 training trials were 
required to form separate regions. 
a two-layer perceptron but were separated with a three-layer perceptron. This is noted 
by the use of filled symbols in Fig. 4. 
Fig. 4 shows that there is no significant performance difference between two and 
three layer perceptrons when forming complex decision regions using back propagation 
training. Both types of classifiers take an excessively long time (> 100,000 trials) to 
form complex decision regions. A minor difference is that in Cases 2 and 7 the two-layer 
network failed to separate disjoint regions after 250,000 trials whereas the three-layer 
network was able to do so. This, however, is not significant in terms of convergence time 
and error rate. Problems that are difficult for the two-layer networks are also difficult 
for the three-layer networks, and vice versa. 
4. ALTERNATIVE CLASSIFIERS 
Results presented above and previous results [5,8] demonstrate that multi-layer per- 
ceptron classifiers can take very long to converge for complex decision regions. Three 
alternative classifiers were studied to determine whether other types of neural net clas- 
sifiers could provide faster convergence. 
4.1. FIXED WEIGHT CLASSIFIERS 
Fixed weight classifiers attempt to reduce training time by adapting only weights 
between upper layers of multi-layer perceptrons. Weights to the first layer are fixed 
before training and remain unchanged. These weights form fixed hyperplanes which 
can be used by upper layers to form decision regions. Performance will be good if the 
fixed hyperplanes are near the decision region boundaries that are required in a specific 
problem. Weights between upper layers are trained using back propagation as described 
above. Two methods were used to adjust weights to the first layer. Weights were 
adjusted to place hyperplanes randomly or in a grid in the region (-1 < x,x2 < 10). 
All decision regions in Fig. 2 fall within this region. Hyperplanes formed by first layer 
nodes for ""fixed random"" and ""fixed grid"" classifiers for Case 2 of Fig. 2 are shown as 
dashed lines in Fig. 5. Also shown in this Fig. are decision regions (shaded areas) formed 
391 
% 
12 
10 
8 
6 
4 
2 
O 
I I I I i i I i 
[2] 2- layers ERROR KATE 
O 3- layers 
I I I J I I I J 
200000 I I I I I / I I I 
CONVERGENCE TIME 
1OOOOO 
50000 
0 I I I I I I I 
1 2 3 4 5 6 7 8 9 
Case Numbers (see Fig. 2) 
Fro. 4. Perce.taae error (top) a.d co-oer9e.ce time (bottom) for Cases I throu9h 9 of Fi9.  for 
ttvo-and three.layer perceptton classifiers trained usin 9 back propa9ation, Filled syrabois indicate that 
separate disjoint re9ions tvere not formed after 50,000 trials. 
using back propagation to train only the upper network layers. These regions illustrate 
how fixed hyperplanes are combined to form decision regions. It can be seen that decision 
boundaries form along the available hyperplanes. A good solution is possible for the 
fixed grid classifier where desired decision region boundaries are near hyperplanes. The 
random grid classifier provides a poor solution because hyperplanes are not near desired 
decision boundaries. The performance of a fixed weight classifier depends both on the 
placement of hyperplanes and on the number of hyperplanes provided. 
4.2. HYPERCUBE CLASSIFIER 
Many traditional cidsifters estimate probability density functions of input variables 
for different classes using histogram techniques [4]. Hypercube cidsifters use this tech- 
nique by fixing weights in the first two layers to break the input space into hypercubes 
(squares in the case of two inputs). Hypercube classifiers are similar to fixed weight 
classifiers, except weights to the first two layers are fixed, and only weights to output 
nodes are trained. Hypercube classifiers are also similar in structure to the CMAC 
model described by Albus [1]. The output of a second layer node is ""high"" only if the 
input is in the hypercube corresponding to that node. This is illustrated in Fig. 6 for a 
network with two inputs. 
The top layer of a hypercube classifier can be trained using back propagation. A 
maximum likelihood approach, however, suggests a simpler training algorithm which 
consists of counting. The output of second layer node Hi is connected to the output 
node corresponding to that class with greatest frequency of occurrence of training inputs 
in hypercube Hi. That is, if a sample falls in hypercube Hi, then it is classified as class 
O* where 
Ni,o. > Ni,o for all 0  0'. (1) 
In this equation, Ni,o is the number of training tokens in hypercube Hi which belong to 
class O. This will be called maximum likelihood (ML) training. It can be implemented 
by connection second-layer node Hi only to that output node corresponding to class O* 
in Eq. (1). In all simulations hypercubes covered the area (-1 < x, x2 < 10). 
392 
RANDOM 
k r_, ,..W - 4',,;-,- 
/; /l. C'( /it %. 
J ; /  ', b t :' 
,,,.,., ,,? . 
oP,',""' '""  
0 I 2 3 
GRID 
0 1 2 3 4 
Fla. 5. Decision regions formed with 'xed random"" and 'xed grid"" classifiers for Case $ from Fig. 
$ using back propagation training. Lines shown are hIperplanes formed by the first layer nodes. Shaded 
areas represent the decision region for class A. 
A 
I B -1 H2' 1.6 H 
TRAINED 
LAYER 
FIXED 
LAYERS 
FOUR BINS CREATED 
BY FIXED LAYERS 
x 2 
3 
2 
1 
b3 
 jb6 
m j bE 
2 3 
xl x2 
INPUT 
FIG. 6. A hlpercube classifier (left) is a three-lager perceptton with fixed weights to the first two layers, 
and trainable weights to output nodes. Weights are initialized such that outputs of nodes Hi through H4 
(left) are ""high"" onil when the input is in the corresponding hIpercube (right). 
393 
SELECT 
CLASS 
WITH MAJORITY 
IN TOP k 
SELECT TOP 
k EXEMPLARS 
CALCULATE 
CORRELATION 
TO STORED 
EXEMPLARS 
OUTPUT (Only One High) 
Yl 
INPUT 
SUPERVISED 
ASSOCIATIVE 
LEARNING 
UNSUPERVISED 
KOHONEN 
FEATURE MAP 
LEARNING 
x N 
FIG. 7. Feature map classifier. 
4.3. FEATURE MAP CLASSIFIER 
In many speech and image classification problems a large quantity of unlabeled 
training data can be obtained, but little labeled data is available. In such situations 
unsupervised training with unlabeled training data can substantially reduce the amount 
of supervised training required [3]. The feature map classifier shown in Fig. 7 uses com- 
bined supervised/unsupervised training, and is designed for such problems. It is similar 
to histogram classifiers used in discrete observation hidden Markov models [11] and the 
classifier used in [6]. The first layer of this classifier forms a feature map using a self 
organizing clustering algorithm described by Kohonen [6]. In all simulations reported in 
this paper 10,000 trials of unsupervised training were used. After unsupervised train- 
ing, first-layer feature nodes sample the input space with node density proportional to 
the combined probability density of all classes. First layer feature map nodes perform a 
function similar to that of second layer hypercube nodes except each node has maximum 
output for input regions that are more general than hypercubes and only the output of 
the node with a maximum output is fed to the output nodes. Weights to output nodes 
are trained with supervision after the first layer has been trained. Back propag.tion, or 
maximum likelihood training can be used. Maximum likelihood training reqmres Ni,e 
(Eq. 1) to be the number of times first layer node i has maximum output for inputs 
from class 0. In addition, during classification, the outputs of nodes with Ni,e = 0 for 
all 0 (untrained nodes) are not considered when the first-layer node with the maximum 
output is selected. The network architecture of a feature map classifier can be used 
to implement a k-nearest neighbor classifier. In this case, the feedback connections in 
Fig. 7 (large circular summing nodes and triangular integrators) used to select those 
k nodes with the maximum outputs must be slightly modified. K is I for a feature 
map classifier and must be adjusted to the desired value of k for a k-nearest neighbor 
classifier. 
5. COMPARISON BETWEEN CLASSIFIERS 
The results of Monte Carlo simulations using all classifiers for Case 2 are shown in 
Fig. 8. Error rates and convergence times were determined as in Section 3. All alter- 
394 
12 
0 
Trials 
25OO 
2O00 
1500 
1000 
5OO 
0 
Conventional 
I 
GAUSS 
KNN 
Back-Prop 
3- lay 
Percent Correct 
Flxed Welght 
I 
I 
Hypercube 
! ! 
Feature Map 
I I 
! I 
I 
2-lay 
i I I 
KNN GAUSS 32 
Convergence Time 
' ndom 
64K 
3-lay ra 
grid 
I I I I 
36 40 120 440 1680 
Number of Hidden Nodes 
I I 
I I I 
B/4.51 
100 1600 
FIG. 8. Comparative performance of classifiers for Case �. Trainin 9 time of the feature map classifiers 
does not include the 10,000 unsupervised trainin9 trials. 
native classifiers had shorter convergence times than multi-layer perceptron classifiers 
trained with back propagation. The feature map classifier provided best performance. 
With 1,600 nodes, its error rate was similar to that of the k-nearest neighbor classifiers 
but it required fewer than 100 supervised training tokens. The larger fixed weight and 
hypercube classifiers performed well but required more supervised training than the 
feature map classifiers. These classifiers will work well when the combined probability 
density function of all classes varies smoothly and the domain where this function is 
non-zero is known. In this case weights and offsets can be set such that hyperplanes and 
hypercubes cover the domain and provide good performance. The feature map classifier 
automatically covers the domain. Fixed weight ""random"" classifiers performed substan- 
tially worse than fixed weight ""grid"" classifiers. Back propagation training (BP) was 
generally much slower than maximum likelihood training (ML). 
6. VOWEL CLASSIFICATION 
Multi layer perceptron, feature map, and traditional classifiers were tested with 
vowel formant data from Peterson and Barney [11]. These data had been obtained 
by spectrographic analysis of vowels in /hVd/ context spoken by 67 men, women and 
children. First and second formant data of ten vowels was split into two sets, resulting 
in a total of 338 training tokens and 333 testing tokens. Fig. 9 shows the test data 
and the decision regions formed by a two-layer perceptton classifier trained with back 
propagation. The performance of classifiers is presented in Table I. All classifiers had 
similar error rates. The feature map classifier with only 100 nodes required less than 50 
supervised training tokens (5 samples per vowel class) for convergence. The perceptton 
classifier trained with back propagation required more than 50,000 training tokens. The 
first stage of the feature map classifier and the multi-layer perceptton classifier were 
trained by randomly selecting entries from the 338 training tokens after labels had been 
removed and using tokens repetitively. 
395 
4OOO 
2000 
F () 
lOOC 
5oo 
o head 
� hid 
� hod 
 had 
o hawed 
� heard 
o heed 
 hud 
) who'd 
^ hood 
FIG. 9. Decision regions formed by a two-layer network usin9 BP after �00,000 trainin9 tokens from 
Petersoh's steady state vowel data [Peterson, 195�]. Also shown are samples of the testin9 set. Le9end 
show example of the pronunciation of the 10 vowels and the error within each vowel. 
ALGORITHM TRAINING TOKENS-'[ % ERROR 
KNN :338 18.0 
Gaussian "" 338 "" 20.4 
2-L.ayer Pe..r'eptron ,,, 50,000 19.8 
Feature. Map < 50 ..... 22.8 
TABLE I 
Performance of classifiers on steady state vowel data. 
396 
7. CONCLUSIONS 
Neural net architectures form a flexible framework that can be used to construct 
many different types of classifiers. These include Gaussian, k-nearest neighbor, and 
multi-layer perceptton classifiers as well as classifiers such as the feature map classifier 
which use unsupervised training. Here we first demonstrated that two-layer percepttons 
(one hidden layer) can form non-convex and disjoint decision regions. Back propagation 
training, however, can be extremely slow when forming complex decision regions with 
multi-layer perceptrons. Alternative classifiers were thus developed and tested. All 
provided faster training and many provided improved performance. Two were similar to 
traditional classifiers. One (hypercube classifier) can be used to implement a histogram 
classifier, and another (feature map classifier) can be used to implement a k-nearest 
neighbor classifier. The feature map classifier provided best overall performance. It 
used combined supervised/unsupervised training and attained the same error rate as a 
k-nearest neighbor classifier, but with fewer supervised training tokens. Furthermore, 
it required fewer nodes then a k-nearest neighbor classifier. 
REFERENCES 
[1] J. 
[2] D. 
[3] v. 
S. Albus, Brains, Behavior, and Robotics. McGraw-Hill, Petersborough, N.H., 1981. 
J. Burr, ""A neural network digit recognizer,"" in Proceedings of the International Conference 
on Systems, Man, and Cybernetics, IEEE, 1986. 
B. Cooper and J. H. Freeman, ""On the asymptotic improvement in the outcome of supervised 
learning provided by aAditional nonsupervised learning,"" IEEE Transactions on Computers, 
vol. C-19, pp. 1055-63, November 1970. 
[4] R. O. Duda and P. E. Hart, Pattern Classification and Scene Analysis. John-Wiley & Sons, New 
York, 1973. 
[5] W.Y. Huang and R. P. Lippmann, ""Comparisons between conventional and neural net classifiers,"" 
in 1st International Conference on Neural Network, IEEE, June 1987. 
[6] T. 
Kohonen, K. Makisara, and T. Saramaki, ""Phonotopic maps -- insightful representation of 
phonological features for speech recognition,"" in Proceedings of the 7th International Confer- 
ence on Pattern Recognition, IEEE, August 1984. 
[7] R. P. Lippmann, ""An introduction to computing with neural nets,"" IEEE ASSP Magazine, vol. 4, 
pp. 4-22, April 1987. 
[8] R. P. Lippmann and B. Gold, ""Neural classifiers useful for speech recognition,"" in 1st International 
Conference on Neural Network, IEEE, June 1987. 
[g] I.D. Longstaff and J. F. Cross, ""A pattern recognition approach to understanding the multi-layer 
perceptton,"" Mem. 3936, Royal Signals and Radar Establishment, July 1986. 
[10] 
[11] 
[12] r. 
[131 R. 
[14] A. 
N.J. Nilsson, Learning Machines. McGraw Hill, N.Y., 1965. 
T. Paxsons, Voice and Speech Processing. McGraw-Hill, New York, 1986. 
Rosenblurt, Percepttons and the Theory of Brain Mechanisms. Spartan Books, 1962. 
C. Singleton, ""A test for linear separability as applied to self-organizing machines,"" in Self- 
Organization Systems, 196�, (M. C. Yovits, G. T. Jacobi, and G. D. Goldstein, eds.), pp. 503- 
524, Spartan Books, Washington, 1962. 
Wieland and R. Leighton, ""Geometric analysis of neural network capabilities,"" in Ist Interna- 
tional Conference on Neural Networks, IEEE, June 1987. 
", net tradit classifi huang richard lippmann lincoln laboratori usa work net input led gener construct convex decis region perceptton hidden arbitrari decis region perceptton hidden demonstr perceptton classifi train back propag form convex disjoint decis classifi train provid good perform simpl decis complex region converg time excess long often better neighbor three neural classifi present provid rapid train use fix weight first one two layer similar classifi probabl densiti function use third map unsupervis supervis provid good perform supervis train situat speech recognit much unlabel data architectur classifi use implement neural net neighbor introduct net architectur use construct mani differ type perceptron classifi continu valu train back propag often train provid similar provid gaussian classifi decis region convex gener procedur demonstr classifi form convex region perceptron hidden arbitrari decis region perceptron hidden recent work perceptron form disjoint decis hand craft network gener decis region paper along mont carlo simul complex decis gener use back propag previou demonstr converg time back propag excess complex decis region desir perform often better neighbor classifi result led us explor net classifi might provid faster three classifi develop classifi test illustr problem two two class restrict set classifi test formant capabl two layer perceptron perceptron classifi nonlinear output input form complex decis simpl proof demonstr perceptron hidden work sponsor defens advanc research project agenc depart air view express author reflect polici posit institut physic region class bl perceptton form disjoint decis class weight node offset shown hyperplan form hidden node drawn dash line node arrow line point half plane hidden node arbitrari decis region perceptron hidden form convex decis region demonstr perceptron form decis region simpli convex show disjoint decis region gener use two disjoint shade area repres decis region class node remain area repres decis region class node node contain connect weight node offset left ten complex decis region form use present exampl suggest perceptron form decis region arbitrari know gener proof book nilson discuss issu contain proof net finit number point two arbitrari set page proof separ point use parallel hyperplan form node hyperplan intersect two prove given region form net involv test determin whether boolean represent output first layer point within region class linearli separ boolean represent one test linear separ present problem form complex decis region perceptton offset must adjust care interact extens form illustr sensit seen one hidden node form hyperplan influenc decis region entir small error first layer weight result slope hyperplan might slightli extend region complet elimin interdepend elimin layer possibl train perceptton form complex decis region use propag sigmoid nonlinear despit weight show disjoint decis region form use back propag problem input present altern select uniform distribut cover desir decis back propag rate descent set equal gain small valu necessari converg difficult problem simul detail ten complex decis region form number assign use rest also shown hyperplan form node strongest connect weight output hyperplan weight similar network creat hand except sign multipl similar hyperplan form two use node valu near compar result result well weight interact mention suggest perceptton may abl form complex decis region faster propag explor use mont carlo first nine case network node first number node second hidden layer twice number convex region need form decis region ten run typic averag togeth obtain smooth curv percentag error time train enough run limit curv appear fiatten littl error curv filter determin converg time defin time curv cross percentag point final percentag definit provid compar converg time differ time error rate summar result term converg time final percentag case disjoint decis back propag sometim fail form separ region two disjoint region requir case never fulli separ decis region form use back propag case thick solid line repres dash line arrow mean hyperplan hidden node larg weight output node train trial form separ perceptron separ note use fill symbol show signific perform differ two layer perceptron form complex decis region use back propag type classifi take excess long time complex decis minor differ case fail separ disjoint region trial wherea abl signific term converg time error problem difficult network also difficult vice altern classifi present previou result demonstr classifi take long converg complex decis three classifi studi determin whether type neural net could provid faster fix weight classifi weight classifi attempt reduc train time adapt weight upper layer weight first layer fix train remain weight form fix hyperplan use upper layer form decis perform good hyperplan near decis region boundari requir specif weight upper layer train use back propag describ two method use adjust weight first weight place hyperplan randomli grid region decis region fall within hyperplan form first layer classifi case shown line also shown decis region form layer error kate layer time number error time case perceptton classifi train usin back fill syraboi indic disjoint tvere form back propag train upper network region illustr fix hyperplan combin form decis seen decis form along avail good solut possibl grid classifi desir decis region boundari near grid classifi provid poor solut hyperplan near desir perform fix weight classifi depend hyperplan number hyperplan hypercub classifi tradit cidsift estim probabl densiti function input variabl differ class use histogram techniqu hypercub cidsift use fix weight first two layer break input space hypercub case two hypercub classifi similar fix weight except weight first two layer weight output hypercub classifi also similar structur cmac describ albu output second layer node hypercub correspond illustr two top layer hypercub classifi train use back likelihood suggest simpler train algorithm output second layer node hi connect output correspond class greatest frequenc occurr train input hypercub sampl fall hypercub classifi class number train token hypercub hi belong call maximum likelihood implement connect node hi output node correspond class simul hypercub cover area decis region form classifi case use back propag line shown form first layer shade repres decis region class bin creat fix layer classifi perceptton fix weight first two trainabl weight output weight initi output node hi input correspond major top top exemplar store one map featur map featur map classifi mani speech imag classif problem larg quantiti unlabel data littl label data situat train unlabel train data substanti reduc amount supervis train requir featur map classifi shown use design similar histogram classifi use discret observ hidden markov model use first layer classifi form featur map use self cluster algorithm describ kohonen simul report paper trial unsupervis train unsupervis featur node sampl input space node densiti proport combin probabl densiti first layer featur map node perform similar second layer hypercub node except node maximum input region gener hypercub output node maximum output fed output weight output node train supervis first layer back likelihood train maximum likelihood train reqmr number time first layer node maximum output input class output node consid node maximum network architectur featur map classifi use implement neighbor feedback connect circular sum node triangular use select node maximum output must slightli featur classifi must adjust desir valu neighbor comparison classifi result mont carlo simul use classifi case shown error rate converg time determin section lay correct welght map gauss time ra hidden node compar perform classifi case trainin time featur map classifi includ unsupervis classifi shorter converg time perceptron classifi back featur map classifi provid best error rate similar neighbor classifi requir fewer supervis train larger fix weight classifi perform well requir supervis train map classifi work well combin probabl function class vari smoothli domain function case weight offset set hyperplan cover domain provid good featur map classifi cover fix weight classifi perform wors fix weight back propag train much slower maximum likelihood train vowel classif layer featur tradit classifi test formant data peterson barney data obtain spectrograph analysi vowel context spoken women first second formant data ten vowel split two result total train token test show test data decis region form perceptton classifi train back perform classifi present tabl classifi error featur map classifi node requir less train token sampl per vowel perceptton train back propag requir train stage featur map classifi perceptton classifi select entri train token label use token ooc head hid hod haw heard heed hud hood decis region form network bp token steadi state vowel data also shown sampl exampl pronunci vowel error within train error map classifi steadi state vowel conclus net architectur form flexibl framework use construct differ type includ perceptton classifi well classifi featur map classifi use unsupervis first demonstr perceptton hidden form disjoint decis back propag extrem slow form complex decis region altern classifi thu develop faster train mani provid improv two similar one use implement histogram anoth map use implement featur map classifi provid best overal combin train attain error rate neighbor fewer supervis train requir fewer node neighbor neural network digit proceed intern confer cooper asymptot improv outcom supervis provid adit nonsupervis ie transact novemb duda pattern classif scene new huang convent neural net intern confer neural june map insight represent featur speech proceed intern pattern august introduct comput neural ie assp april lippmann classifi use speech intern neural june longstaff pattern recognit approach understand royal signal radar juli learn graw voic speech new perceptton theori brain spartan test linear separ appli spartan analysi neural network ist confer neural june,0
1,1,"1 
CONNECTIVITY VERSUS ENTROPY 
Yaser S. Abu-Mostafa 
California Institute of Technology 
Pasadena, CA 91125 
ABSTRACT 
How does the connectivity of a neural network (number of synapses per 
neuron) relate to the complexity of the problems it can handle (measured by 
the entropy)? Switching theory would suggest no relation at all, since all Boolean 
functions can be implemented using a circuit with very low connectivity (e.g., 
using two-input NAND gates). However, for a network that learns a problem 
from examples using a local learning rule, we prove that the entropy of the 
problem becomes a lower bound for the connectivity of the network. 
INTRODUCTION 
The most distinguishing feature of neural networks is their ability to spon- 
taneously learn the desired function from 'training' samples, i.e., their ability 
to program themselves. Clearly, a given neural network cannot just learn any 
function, there must be some restrictions on which networks can learn which 
functions. One obvious restriction, which is independent of the learning aspect, 
is that the network must be big enough to accommodate the circuit complex- 
ity of the function it will eventually simulate. Are there restrictions that arise 
merely from the fact that the network is expected to learn the function, rather 
than being purposely designed for the function? This paper reports a restriction 
of this kind. 
The result imposes a lower bound on the connectivity of the network (num- 
ber of synapses per neuron). This lower bound can only be a consequence of 
the learning aspect, since switching theory provides purposely designed circuits 
of low connectivity (e.g., using only two-input NAND gates) capable of imple- 
menting any Boolean function [1,2]. It also follows that the learning mechanism 
must be restricted for this lower bound to hold; a powerful mechanism can be 
@ American Institute of Physics 1988 
2 
designed that will find one of the low-connectivity circuits (perhaps by exhaus- 
tive search), and hence the lower bound on connectivity cannot hold in general. 
Indeed, we restrict the learning mechanism to be local; when a training sample 
is loaded into the network, each neuron has access only to those bits carried by 
itself and the neurons it is directly connected to. This is a strong assumption 
that excludes sophisticated learning mechanisms used in neural-network models, 
but may be more plausible from a biological point of view. 
The lower bound on the connectivity of the network is given in terms of 
the entropy of the environment that provides the training samples. Entropy is a 
quantitative measure of the disorder or randomness in an environment or, equiv- 
alently, the amount of information needed to specify the environment. There 
are many different ways to define entropy, and many technical variations of this 
concept [3]. In the next section, we shall introduce the formal definitions and 
results, but we start here with an informal exposition of the ideas involved. 
The environment in our model produces patterns represented by N bits 
x = x... xN (pixels in the picture of a visual scene if you will). Only h different 
patterns can be generated by a given environment, where h < 2 v (the entropy 
is essentially log 2 h). No knowledge is assumed about which patterns the en- 
vironment is likely to generate, only that there are h of them. In the learning 
process, a huge number of sample patterns are generated at random from the 
environment and input to the network, one bit per neuron. The network uses 
this information to set its internal parameters and gradually tune itself to this 
particular environment. Because of the network architecture, each neuron knows 
only its own bit and (at best) the bits of the neurons it is directly connected to 
by a synapse. Hence, the learning rules are local: a neuron does not have the 
benefit of the entire global pattern that is being learned. 
After the learning process has taken place, each neuron is ready to perform 
a function derned by vhat it has larned. The collective interaction of the 
functions of the neurons is what defines the overall function of the network. The 
main result of this paper is that (roughly speaking) if the connectivity of the 
network is less than the entropy of the environment, the network cannot learn 
about the environment. The idea of the proof is to show that if the connectivity 
is small, the final function of each neuron is independent of the environment, 
and hence to conclude that the overall network has accumulated no information 
about the environment it is supposed to learn about. 
FORMAL RESULT 
A neural network is an undirected graph (the vertices are the neurons and the 
edges are the synapses). Label the neurons 1,-.-, N and define K, _c 1,.. -, N 
to be the set of neurons connected by a synapse to neuron n, together with 
neuron n itself. An environment is a subset e __C C0, 1 v (each x  e is a sample 
3 
from the environment). During learning, Zl,-"", zv (the bits of x) are loaded 
into the neurons 1,...,N, respectively. Consider an arbitrary neuron n and 
telabel everything to make K become {1,...,K}. Thus the neuron sees the 
first K coordinates of each x. 
Since our result is asymptotic in N, we will specify K as a function of N; 
K = aN where a = a(N) satifies limN-.,o a(N) = ao (0 < ao < 1). Since the 
result is also statistical, we will consider the ensemble of environments � 
e = {, c I I,I = 
where h = 2 oN and/ =/(N) satifies limN_.oo/(N) = /o (0 < /o < 1). The 
probability distribution on  is uniform; any environmen e G    likely 
occur  any oher. 
The neuron sees only he firs K coordinates of each x generated by he 
environment e. For each e, we define the function : {0,1}   {0,1,2,--.} 
where 
n(a...a) =l{x6e [ z,=a, fork=l,--.,K}l 
and the normalized version 
The function v describes the relative frequency of occurrence for each of the 2 r 
binary vectors a:l -"" zr as x = zl '"" z Jr runs through all h vectors in e. In other 
words, /specifies the projection of e as seen by the neuron. Clearly, v(a) _> 0 
for all a  {0, 1} r and Z&E{O,1}K v(a) = 1. 
Corresponding to two environments el and es, we will have two functions vl 
and bt 2. If//1 is not distinguishable from t/z, the neuron cannot tell the difference 
between ea and es. The distinguishability between btl and t/: can be measured 
by 
1 
d(l/l'l/2) --  Z 
The range of d(t/1,) is 0 <_ d(t/1,) <_ 1, where '0' corresponds to complete 
indistinguishability while '1' corresponds to maximum distinguishability. We 
axe now in a position to state the main result. 
Let e and es be independently selected environments from � according to the 
uniform probability distribution. d(vl, v) is now a random variable, and we are 
interested in the expected value E(d(vl,v2)). The case where E(d(vl,v2)) -- 0 
corresponds to the neuron getting no information about the environment, while 
the case where E(d(Vl,V2)) = I corresponds to the neuron getting maximum 
information. The theorem predicts, in the limit, one of these extremes depending 
on how the connectivity (ao) compares to the entropy (/o). 
4 
Theorem. 
1. If ao > f/o, then limv-.o E (d(Vl, v2)) = 1. 
2. If co < o, then limN._.ooS(d(,,,v2)) =0. 
The proof is given in the appendix, but the idea is easy to illustrate infor- 
mally. Suppose h = 2 K+� (corresponding to part 2 of the theorem). For most 
environments e 6 �, the first K bits of x 6 e go through all 2 K possible val- 
ues approximately 2 � times each as x goes through all h possible values once. 
Therefore, the patterns seen by the neuron are drawn from the fixed ensemble of 
all binary vectors of length K with essentially uniform probability distribution, 
i.e., v is the same for most environments. This means that, statistically, the 
neuron will end up doing the same function regardless of the environment at 
hand. 
What about the opposite case, where h = 2 K-� (corresponding to part 1 of 
the theorem)? Now, with only 2 -� patterns available from the environment, 
the first K bits of x can assume at most 2 K-� values out of the possible 2 g 
values a binary vector of length K can assume in principle. Furthermore, which 
values can be assumed depends on the particular environment at hand, i.e., 
, does depend on the environment. Therefore, although the neuron still does 
not have the global picture, the information it has says something about the 
environment. 
ACKNOWLEDGEMENT 
This work was supported by the Air Force Office of Scientific Research under 
Grant AFOSR-86-0296. 
APPENDIX 
In this appendix we prove the main theorem. We start by discussing some 
basic properties about the ensemble of environments �. Since the probability 
distribution on � is uniform and since [�1-- (2h), we have 
which is equivalent to generating e by choosing h elements x 6 {0, 1} v with 
uniform probability (without replacement). It follows that 
h 
Pr(x6e)= 2 v 
5 
while for x 1  x2, 
h h-1 
Pr(xle, xie) = 2 v x 2 v_l 
and so on. 
The functions  and  are defined on K-bit vectors. 
(a random variable for fixed a) is independent of a 
The statistics of r(a) 
Pr(r(sx) = m) = Pr(r(s) = m) 
which follows from the symmetry with respect to each bit of a. The same holds 
for the statistics of (a). The expected value E(r(a)) = h2 -K (h objects going 
into 2 K cells), hence E((a)) = 2 -. We now restate and prove the theorem. 
Theorem. 
1. If co > o, then limr-.o E (d(l, 2)) = 1. 
2. If ao < o, then limN-o E (d(l, 2)) =0. 
Proof. 
We expand E (d(l, 2)) as follows 
where n and n2 denote nl(0.--0) and n2(0..-0), respectively, and the last step 
follows from the fact that the statistics of nl(a) and n2(a) is independent of a. 
Therefore, to prove the theorem, we evaluate E(Irh- r21) for large N. 
1. Assume ao > fo. Let n denote n(0...0), and consider Pr(n - 0). For r to 
be zero, all 2 N-K strings x of N bits starting with K O's must not be in the 
environment e. Hence 
Pr(r = O) = (1- -- 
h 
2)(1 
h h 
2 r - 1 )'"" (1 - 2 r _ 2r_: + 1 ) 
where the first term is the probability that 0... 00  e, the second term is the 
6 
probability that 0.--O1  e given that 0-.. O0  e, and so on. 
: (1 - h2-m'(1 -- 2-x) -') 
>_ (1 - 
> 1 - 2h2-r2 v-K 
= 1 - 2h2 -K 
2N--K 
Hence, Pr(n, = 0): Pr(n2: 0): Pr(n: 0) _> i - 2h2 -K. However, E(n,) = 
E(n2) = h2 -. Therefore, 
h h 
Z Z Pr(rtl: i, rt2 '-- j)li -- Jl 
i=0 j=O 
h h 
= Z Y] Pr(nl = i)Pr(n2: j)l i - Jl 
i=0 j=0 
h 
_  Pt(hi = 0)Pr(n2 = j)j 
h 
+ Z Pt(hi =/)Pr(n2 = 0)i 
i=0 
which follows by throwing away all the terms where neither i nor j is zero (the 
term where both i an j are zero appears twice for convenience, but this term is 
zero anyway). 
= Pr(nl = 0)E(n2) + Pr(n2 = 0)E(rh) 
> 2(1- 2h2-)h2 - 
Substituting this estimate in the expression for E(d(tl, t2)), we get 
2 K 
E(d(//1,//2)) = 2hE(lnl -- 
_ - x 2(1- 2h2-K)h2 -t 
= 1 - 2h2 -K 
= 1 - 2 x 2 (f-"")v 
Since ao >/o by assumption, this lower bound goes to 1 as N goes to infinity. 
Since 1 is also an upper bound for d(l, 2) (and hence an upper bound for the 
expected value E(d(/�l,/�2))), limv-.oo E(d(/�,/2)) must be 1. 
7 
2. Assume ao < o. Consider 
To evaluate E([n - h2-K[), we estimate the variance of n and use the fact 
that E([n- h2-KI) <_ va, (recall that h2 - = E(n)). Since vat(n) = 
E(n 2) - (E(n)) 2, we need an estimate for E(n2). We write n = Eaei0.1)N- a, 
where 
1, if 0.-.0a 6 e; 
5 = 0, otherwise. 
In this notation, E(n 2) can be written as 
: >- 
&�{0,1} N-I� be{0,1} 
For the 'diagonal' terms (a = b), 
= h2 -/v 
There are 2 N-K such diagonal terms, hence a total contribution of 2 N-K X 
h2 -r = h2 -K to the sum. For the 'off-diagonal' terms (a  b), 
E(5. Sb) = Pr(5. = 1, Sb = 1) 
= Pr(5. = 1)Pr(Sb: l[a = 1) 
h h-1 
-- -- X 
2 r 2 r - I 
There are 2r-(2 v-K - 1) such off-diagonal terms, hence a total contribution of 
2V-(2N-K � h(h-i) < {h,_K2 2 v 
k --'1 ^ 2N(2N--1) -- ,  ] --i to the sum. Putting the contributions 
8 
from the diagonal and off-diagonal terms together, we get 
wr(n) = E(n 2) - (E(n)) 2 
< h2-K + (h2-K)a2v - 1 
1 
= h2-K + (h2-)a 2 N - 1 
h2_  
= h2 -K 1 + 
< 2h2 - 
The last step follows since h2 -K is much smaller than 2 r - 1. Therefore, E(In - 
1 
h2-]) < v < (2h2-)  Substituting this estimate in the expression for 
we get 
Since Cto < f/o by assumption, this upper bound goes to 0 as N goes to infinity. 
Since 0 is also a lower bound for d(yx,ya) (and hence a lower bound for the 
expected value E(d(,x,,a))), limo E(d(,,,a)) must be 0. I 
REFERENCES 
[1] Y. Abu-Mostafa, ""Neural networks for computing?,""AIP Conference Pro- 
ceedings  151, Neural Networks for Computing, J. Denker (ed.), pp. 1-6, 1986. 
[2] Z. Kohavi, Switching and Finite Automata Theory, McGraw-Hill, 1978. 
[3] Y. Abu-Mostafa, ""The complexity of information extraction,""IEEE Trans. 
on Information Theory, vol. IT-32, pp. 513-525, July 1986. 
[4] Y. Abu-Mostafa, ""Complexity in neural systems,""in Analog VLSiand Neural 
Systems by C. Mead, Addison-Wesley, 1988. 
", versu entropi institut technolog ca connect neural network synaps per relat complex problem handl switch theori would suggest relat sinc boolean implement use circuit low connect nand network learn problem exampl use local learn prove entropi becom lower bound connect distinguish featur neural network abil learn desir function abil program given neural network can not learn must restrict network learn one obviou independ learn network must big enough accommod circuit function eventu restrict aris fact network expect learn rather purpos design paper report restrict result impos lower bound connect network synaps per lower bound consequ learn sinc switch theori provid purpos design circuit low connect use nand capabl boolean function also follow learn mechan restrict lower bound power mechan american institut physic find one circuit henc lower bound connect can not hold restrict learn mechan train sampl load neuron access bit carri neuron directli connect strong assumpt exclud sophist learn mechan use may plausibl biolog point lower bound connect network given term entropi environ provid train entropi measur disord random environ amount inform need specifi mani differ way defin mani technic variat next shall introduc formal definit start inform exposit idea environ model produc pattern repres bit pictur visual scene differ gener given entropi essenti log knowledg assum pattern like learn huge number sampl pattern gener random input one bit per network use inform set intern paramet gradual tune network neuron know bit bit neuron directli connect learn rule neuron entir global pattern learn process taken neuron readi perform function dern collect interact neuron defin overal function result paper connect less entropi network can not learn idea proof show connect final function neuron independ henc conclud overal network accumul inform environ suppos learn result neural network undirect graph vertic neuron label neuron defin set neuron connect synaps neuron togeth environ subset sampl bit load neuron consid arbitrari neuron everyth make becom thu neuron see coordin result asymptot specifi function satifi ao ao sinc also consid ensembl environ satifi distribut like neuron see coordin gener defin function normal version function describ rel frequenc occurr vector zl jr run vector project seen two environ el two function vl bt distinguish neuron can not tell differ ea distinguish btl measur rang correspond complet correspond maximum posit state main es independ select environ accord probabl random expect valu case neuron get inform case correspond neuron get maximum theorem one extrem depend connect compar entropi ao proof given idea easi illustr suppos part first bit go possibl approxim time goe possibl valu pattern seen neuron drawn fix ensembl binari vector length essenti uniform probabl mean end function regardless environ opposit part pattern avail first bit assum valu possibl binari vector length assum assum depend particular environ depend although neuron still global inform say someth work support air forc offic scientif research appendix prove main start discuss properti ensembl environ sinc probabl uniform sinc equival gener choos element probabl follow function defin random variabl fix independ statist follow symmetri respect bit hold statist expect valu object go henc restat prove ao expand follow denot last step fact statist independ prove evalu larg assum ao let denot consid string bit start must henc first term probabl second term given jl jl follow throw away term neither zero zero appear twice term estim express get ao lower bound goe goe also upper bound henc upper bound valu must assum ao consid evalu estim varianc use fact sinc need estim write written term diagon henc total contribut term sb henc total contribut put contribut diagon term get last step follow sinc much smaller substitut estim express get cto upper bound goe goe also lower bound henc lower bound valu must network confer neural network denker switch finit automata complex inform inform juli neural analog vlsiand neural,2
2,2,"9 
Stochastic Learning Networks and their Electronic Implementation 
Joshua Alspector*, Robert B. Allen, Victor Hut, and Srinagesh Satyanarayana 
Bell Communications Research, Morristown, NJ 07960 
ABSTRACT
We describe a family of learning algorithms that operate on a recurrent, symmetrically 
connected, neuromorphic network that, like the Boltzmann machine, settles in the 
presence of noise. These networks learn by modifying synaptic connection strengths on 
the basis of correlations seen locally by each synapse. We describe a version of the 
supervised learning algorilhm for a network with analog activation functions. We also 
demonstrate unsupervised competitive learning with this approach, where weight 
saturation and decay play an important role, and describe preliminary experiments in 
reinforcement !earning, where noise is used in the search procedure. We identify the 
above described phenomena as elements that can unify learning techniques at a physical 
microscopic level. 
These algorilhms were chosen for ease of implementation in vlsi. We have designed a 
CMOS test chip in 2 micron rules that can speed up the learning about a millionfold 
over an equivalent simulation on a VAX 11/780. The speedup is due to parallel analog 
computation for summing and multiplying weights and activations, and the use of 
physical processes for generating random noise. The components of the test chip are a 
noise amplifier, a neuron amplifier, and a 300 transistor adaptive synapse, each of which 
is separately testable. These components are also integrated into a 6 neuron and 15 
synapse network. Finally, we point out techniques for reducing the area of the 
electronic correlational synapse both in technology and design and show how the 
algorithm. we study can be implemented naturally in electronic systems. 
1. INTRODUCTION 
Vnere has been significant progress, in recent years, in modeling brain function as the collective 
havior of highly interconnected networks of simple model neurons. This paper focuses on the 
issue of !earning in these networks especially with regard to their implementation in an electronic 
system. Learning phenomena that have been studied include associative memory Ill, supervised 
learning by error correction [21 and by stochastic search 131, competitive learning 141 D! reinforcement 
!earning 16l, and other forms of nnsupervised !earning [71. From the point of view of neural 
plausibility as well as electronic implementation, we particularly like !earning algorithms that 
change synaptic connection strengths asynchronously and are based only on information 
available locally at the synapse. This is illustrated in Fig. 1, where a model synapse uses only the 
correlations of the neurons it connects and perhaps some weak global evaluation signal not 
specific to individual neurons to decide how to adjust its conductance. 
* Address for correspondence: I. Alspector, Bell Communications Research, 2E-378, 435 South St., Morristown, NS 
07960 / (201) 829-4342 / josh@bellcore.corn 
t Permanent address: University of Califomia, Berkeley, EE Department, Co T Hall, Berkeley, CA 94720 
f Permanent address: Columbia University, EE Department, S.W. Mudd Bldg., New York, blY 10027 
@ American Institute of Physics 1988 
10 
s 
S o 
<r> 
Hebb-type learning rule: 
I If Cij increases, 
glob. al scalar (perhaps in the presence of 
evaluation increment w ij 
signal 
r) 
Fig. 1. A local correlational synapse. 
We believe that a stochastic search procedure is most compatible with this viewpoint. Statistical 
procedures based on noise form the communication pathways by which global optimization can 
take place based only on the interaction of neurons. Search is a necessary part of any learning 
procedure as the network attempts to find a connection strength matrix that solves a particular 
problem. Some learning procedures attack the search directly by gradient following through error 
co.,rectionlSl 191 but electronic implementation requires specifying which neurons are input, 
htdden and output in advance and necessitates global control of the error correction 121 procedure 
m a way that requires specific connectivity and synchrony at the neural level. There is also the 
question of how such procedures would work with unsupervised methods and whether they might 
get stuck in local minima. Stochastic processes can also do gradient following but they are better 
at avoiding minima, are compatible with asynchronous updates and local weight adjustments, 
and, as we show in this paper, can generalize well to less supervised learning. 
The phenomena we studied are 1) analog activation, 2) noise, 3) semi-local Hebbian synaptic 
modification, and 4) weight decay and saturation. These techniques were applied to problems in 
supervised, unsupervised, and reinforcement learning. The goal of the study was to see if these 
diverse learning styles can be unified at the microscopic level with a small set of physically 
plausible and electronically implementable phenomena. The hope is to point the way for 
powerful electronic learning systems in the future by elucidating the conditions and the types of 
circuits that may be necessary. It may also be U'ue that the conditions for electronic learning may 
11 
have some bearing on the general principles of biological learning. 
$. LOCAL LEARNING AND STOCHASTIC SEARCH 
$.1 Supervised Learning in Recurrent Networks with Analog Activations 
We have previously shown !!�] how the supervised !earning procedure of the Boltzmann 
machine 131 can be implemented in an electronic system. This system works on a recurrent, 
symmelrically connected network which can be characterized as settling to a minimum in its 
Liapunov function [0il II. While this architecture may stretch our criterion of neural plausibility, it 
does provide for stability and analyzability. The feedback connectivity provides a way for a 
supervised !earning procedure to propagate information back through the network as the 
stochastic search proceeds. More plausible would be a randomly connected network where 
symmetry is a statistical approximation and inhibition damps oscillations, but symmetry is more 
efficient and well matched to our choice of learning rule and search procedure. 
We have extended our electronic model of the Boltzmann machine to include analog activations. 
Fig. 2 shows the model of the neuron we used and its tanh or sigmoid transfer function. The net 
input consists of the usual weighted sum of activations from other neurons but, in the case of 
Boltzmann machine learning, these are added to a noise signal chosen from a variety of 
distributions so that the neuron performs the physical computation: 
activation =f (netl )=f (wlj sj +noise )=tanh(gain*netl ) 
Instead of counting the number of on-on and off-off cooccurrences of neurons which a synapse 
connects, the correlation rule now defines the value of a cooccurrence as: 
Clj=f i * f  
where fi is the activation of neuron i which is a real value from -1 to 1. Note that this rule 
effectively counts both on-on and off-off cooccurrences in the high gain limit. In this limit, for 
Gaussian noise, the cumulative probability distribution for the neuron to have activation +1 (on) 
is close to sigmoidal. The effect of noise ""jitter"" is illustrated at the bottom of the figure. The 
weight change rule is still: 
if Cq + > Cq- then increment wij .... ele decrement 
where the plus phase clamps the output neurons in their desired states while the minus phase 
allows them to run free. 
A' mentioned, we have studied a variety of noise distributions other than those based on the 
Boltzmann distribution. The 2-2-1 XOR problem was selected as a test case since it has been 
shown !�! to be easily caught in local minima. The gain was manipulated in conditions with no 
noise or with noise sampled from one of three distributions. The Gaussian distribution is closest 
to true electronic thermal noise such as used in our implementation, but we also considered a 
cut-off uniform distribution and a Cauchy distribution with long noise tails for comparison. The 
inset to Fig. 3 shows a histogram of samples from the noise distributions used. The noise was 
multiplied by the temperature to 'jitter' the transfer function. Hence, the jitter decreased as the 
mealing schedule proceeded. 
12 
z Vnols e 
f/(: w,,,, + nois 
A Vl n . A rout y transfer function 
- 1.0 
f.(' 
I . 
high gain 
tranlfar function 
wth nola 'Jlttsr' 
 Wij Sj 
J 
Fig. 2. Electronic analog neuron. 
z Vin + z Vnois e 
or z w us +no/se= 
Fig. 3 shows average performance across 100 runs for the last 100 patterns of 2000 training 
pattern presentations. It can be seen that reducing the gain from a sharp step can improve 
learning in a small region of gain, even without noise. There seems to be an optimal gain level. 
However, the addition of noise for any distribution can substantially improve learning at all levels 
Gaussian 
Uniform 
Cauch� 
No Noise 
0.9 
o 
o 
0.8 
0.7 
0.64 
0.5 
-3 
10 
10 10 
Inverse Gain 
Fig. 3. Propordon correct vs. inverse gain. 
1 
lO 
13 
7..2 Stochastic Competitive Le-ning 
We have am how comfitive Ig 14111 c  accplish wi sthastic ! ts. 
ter e preenration of  Mput pattern, e network is led d e weight  Mcrsed 
twn e winning cluster t d e Mput  wMch e on. As shown M Fig. 4 is 
pmach wm nppli to e !e problem of Rumelh d Zipset. A 4x4 pixel may Mput 
yer co to n 2 t comprifive layer wi rent inhibito coections at e not 
ndjmt. e inhibito cofions pride e comfition by mns of a winner-e-all 
s  e netwo settles. e put pae  !  oy two put ts e ed 
 at h pattern prenmti d ey must  physic!y adjacent, eider vertically  
mHy.  s way, e network I aut e coteess of e space d eventually 
vid it Mto two eq! spatial regions wi ch of e cluster ts rndMg only to !es 
m one of e hv. Rmet d Zipset noafid e weighg ter ch pattern and 
picked e winning t as e one wi  Mghest activation. std of explicit noa!ation 
of e weighg, we Mclu a day te prorfion to e weight. e weigh twn e 
Mput layer d cluster layer e Mcrment for onn co,elations, but here ere e no 
temag pes so at even s oss cMony is not necess. de,  small time 
comg e M to e weit utes, no ext! timing should  nded. 
winner-take-all 
duster layer 
inpul layer 
Fig. 4. Competitive learning network for the dipole problem. 
Fig. 5 shows the results of several runs. A 1 at the position of an input unit means that unit I of 
the cluster layer has the larger weight leading to it from that position. A + between two units 
means the dipole from these two units excites unit 1. A 0 and - means that unit 0 is the winner in 
the complementary case. Note that adjacent l's should always have a + between them since both 
weights to unit I are stronger. If, however, there is a I next to a 0, then there is a tension in the 
dipole and a competition for dominance in the cluster layer. We define a figure of merit called 
""surface tension"" which is the number of such dipoles in dispute. The smaller the number, the 
14 
better. Note in Runs A and B, the number is reduced to 4, the minimum possible value, after 
2000 pattern presentations. The space is divided vertically and horizontally, respectively. Run C 
has adopted a less favorable diagonal division with a surface tension of 6. 
Run A 
Run B 
Run C 
Number of dipole pattern presentations 
0 200 800 1400 2000 
0-0-0-0 1+0-0+1 1+1+1+1 1+1+1+1 1+1+1+1 
.... + + + + + + + -- + + + + + + + + 
0-0-0-0 1+1+1+1 1+1+1-0 1+1+1+1 1+1+1+1 
0-0-0-0 1+1-0-0 1-0-0-0 0-0-0-0 0-0-0-0 
.... + ............... 
0-0-0-0 0-0-0-0 0-0-0-0 0-0-0-0 0-0-0-0 
0-0-0-0 0-0-0-0 0-0-0+1 0-0-0-1 0-0-1+1 
....... + --++ ---+ --++ 
0-0-0-0 0-0-0+1 0-0-1+1 0-0-1+1 0-0-1+1 
....... + ----++ ----++ ----++ 
0-0-0-0 1-0-1+1 0-0-1+1 0-0-1+1 0-0-1+1 
.... +-++ --++ --++ --++ 
0-0-0-0 1+0+1+1 0-0+1+1 0-0+1+1 0-0+1+1 
0-0-0-0 0+1+1+1 0+1+1+1 1+1+1+1 1+1+1+1 
..... + + + -- + + + + + + + -- + + + 
0-0-0-0 0-1+1+1 0+1+1+1 0+1+1+1 0-0+1+1 
..... + + + -- + + + -- -- + + - -- + + 
0-0-0-0 0-1+1+1 0-0-0-0 0-0-0-0 0-0-0-1 
................... + 
0-0-0-0 0-0-0-0 0-0-0-0 0-0-0-0 0-0-0-1 
Fig. 5. Results of competitive learning runs on the dipole problem. 
Table 1 shows the result of several competitive algorilhms compared when averaged over 100 
such runs. The deterministic algorilhm of Rumelhart and Zipset gives an average surface tension 
of 4.6 while the stochastic procedure is almost as good. Note that noise is essential in helping the 
competitive layer settle. Without noise the surface tension is 9.8, showing that the winner-take- 
all procedure is not working properly. 
Competitive learning algorithm 
""surface tension"" 
Stochastic net with decay 
- anneal: T=30 ) T=I.0 
- no anneal: 70 @ T=I.0 
4.8 
9.8 
Stochastic net with renormalizafion 
5.6 
Deterministic, winner-take-all 
(Rumelhart & Zipser) 
4.6 
Table 1. Performance of competitive learning algorithms across 100 runs. 
We also tried a procedure where, instead of decay, weights were renormalized. The model is that 
each neuron can support a maximum amount of weight leading into it. Biologically, this might 
be the area that other neurons can form synapses on, so that one synapse cannot increase its 
strength except at the expense of some of the others. Electronically, this can be implemented as 
15 
current emanating from a fixed current source per neuron. As shown in Table 1, this works 
nearly as well as decay. Moreover, preliminary results show that renormalization is especially 
effective when more then two cluster units are employed. 
Both of the stochastic algorithm.% which can be implemented in an electronic synapse in nearly 
the same way as the su,rvised learning algorithm, divide the space just as the deterministic 
normalization procedure 141 does. This suggests that our chip can do both styles of !earning, 
supervised if one includes both phases and unsupervised ff only the procedure of the minus phase 
is used. 
2.3 Reinforcement Learning 
We have tried several approaches to reinforcement !earning using the synaptic model of Fig. 1 
where the evaluation signal is a scalar value available globally that represents how well the 
system performed on each trial. We applied this model to an xor problem with only one output 
unit. The reinforcement was r = 1 for the correct output and r =-1 otherwise. To the network, 
this was similar to supervised learning since for a single unit, the output state is fully specified by 
a scalar value. A major difference, however, is that we do not clamp the output unit in the 
desired state in order to compare plus and minus phases. This feature of supervised learning has 
the effect of adjusting weights to follow a gradient to the desired state. In the reinforcement 
learning described here, there is no plus phase. This has a satisfying aspect in that no overall 
synchrony is necessary to compare phases, but is also much slower at converging to a solution 
because the network has to search the solution space without the guidance of a teacher clamping 
the output units. This situation becomes much worse when there is more than one output unit. In 
that case, the probability of reinforcement goes down exponentially with the number of outputs. 
To test multiple outputs, we chose the simple replication problem whereby the output simply has 
to replicate the input. We chose the number of hidden units equal to the input (or output). 
in the absence of a teacher to clamp the outputs, the network has to find the answer by chance, 
guided only by a ""critic"" which rates its effort as ""better"" or ""worse"". This means the units must 
somehow search the space. We use the same stochastic units as in the supervised or unsupervised 
techniques, but now it is important to have the noise or the annealing temperature set to a proper 
level. ff it is too high, the reinforcement received is random rather than directed by the weights 
in the network. ff it is too low, the available states searched become too small and the probability 
of finding the right solution decreases. We tuned our annealing schedule by looking at a 
volatility measure defined at each neuron which is simply the fraction of the time the neuron 
activation is above zero. We then adjust the final anneal temperature so that this number is 
neither 0 or 1 (noise too low) nor 0.5 (noise too high). We used both a fixed annealing schedule 
for all neurons and a unit-specific schedule where the noise was proportional to the sum of weight 
magnitudes into the unit. A characteristic of reinforcement learning is that the percent correct 
initially increases but then decreases and often oscillates widely. To avoid this, we added a factor 
of (1 - <r >) multiplying the final temperature. This helped to stabilize the learning. 
In keeping with our simple model of the synapse, we chose a weight adjustment technique that 
consisted of correlating the states of the connected neurons with the global reinforcement signal. 
Each synapse measured the quantity R = rsis i for each pattern presented. ff R >0, then wij is 
incremented and it is decremented ff R <0. We later refined this procedure by insisting that the 
reinforcement be greater than a recent average so that R =(r-<r>).isj. This type of procedure 
16 
appears in previous work in a number of forms. !tel !131 For r =:El only, this ""excess 
reinforcement"" is the same as our previous algorithm but differs ff we make a comparison 
between short term and long term averages or use a graded reinforcement such as the negative of 
the sum squared error. Following a suggestion by G. Hinton, we also invesfgated a more 
complex technique whereby each synapse must store a time average of three quantities: <r >, 
<slsi>, and <rsisj>. The definition now is R =<rsisi>-<r><ssj> and the rule is the same as 
before. Statistically, this is the same as ""excess reinforcement"" ff the latter is averaged over 
trials. For the results reported below the values were collected across 10 pattern presentations. A 
variation, which employed a continuous moving average, gave similar results. 
Table 2 summarizes the performance on the xor and the replication task of these reinforcement 
!earning techniques. As the table shows a variety of increasingly sophisticated weight adjustment 
rules were explored; nevertheless we were unable to obtain good results with the techniques 
described for more than 5 output units. In the third column, a small threshold had to be exceeded 
prior to weight adjustment. In the fourth column, unit-specific temperatures dependent on the 
sum of weights, were employed. The last column in the table refers to frequency dependent 
learning where we trained on a single pattern until the network produced a correct answer and 
then moved on to another pattern. This final procedure is one of several possible techniques 
related to 'shaping' in operant learning theory in which difficult patterns are presented more often 
to the network. 
network t=l time-averaged + =0.1 +T-I;W +freq 
xor 
2-4-1 (0.60) 0.64 (0.70) 0.88 (0.76) 0.88 (0.92) 0.99 (0.98) 1.00 
2-2-1 (0.58) 0.57 (0.69) 0.74 (0.96) 1.00 (0.85) 1.00 (0.78) 0.88 
eplication 
2-2-2 (0.94) 0.94 (0.46) 0.46 (0.91) 0.97 (0.87) 0.99 (0.97) 1.00 
3-3-3 (0.15) 0.21 (0.31) 0.33 (0.31) 0.62 (0.37) 0.37 (0.97) 1.00 
4-4-4 - - - (0.75) 1.00 
5-5-5 - - - (0.13) 0.87 
6-6-6 - - - (0.02) 0.03 
Table 2. Proportion correct performance of reinforcement learning 
after (2K) and 10K patterns. 
Our experiments, while incomplete, hint that reinforcement !earning can also be implemented by 
the ame type of,local-global synapse thai characterize the other !earning paradigms. Noise is 
also necessary here for the random search procedure. 
2.4 Summary of Study of Fundamental Learning Parameters 
In summary, we see that the use of noise and our model of a local correlational synapse with a 
non-specific global evaluation signal are two important features in all the learning paradigms. 
Graded activation is somewhat less important. Weight decay seems to be quite important 
although saturation can substitute for it in unsupervised learning. Most interesting from our point 
of view is that all these phenomena are electronically implementable and therefore physically 
17 
plausible. Hopefully this means they are also related to true neural phenomena and therefore 
provide a basis for trollying the various approaches of !earning at a microscopic level. 
3. ELECTRONIC IMPLEMENTATION 
3.1 The Supervised !.arnin Chip 
We have completed the design of the chip previously proposed? �! Its physical style of 
computation speeds up learning a millionfold over a computer simulation. Fig. 6 shows a block 
diagram of the neuron. It is a double differential amplifier. One branch forms a sum of the inputs 
from the differential outputs of all other neurons with connections to it. The other adds noise 
from the noise amplifier. This first stage has low gain to preserve dynamic range at the summing 
nodes. The second stage has high gain and converts to a single ended output. This is fed to a 
switching arrangement whereby either this outpul state or some externally applied desired state is 
fed into the final set of inverter stages which provide for more gain and guaranteed digital 
complementarity. 
v;',, S- S* 
sour.. 
Fig. 6. Block diagram of neuron. 
The noise amplifier is shown schematically in Fig. 7. Thermal noise, with an rms level of tens of 
microvolts, from the channel of an FET is fed into a 3 stage amplifier. Each stage provides a 
potential gain of 100 over the noise bandwidth. Low pass feedback in each stage stabilizes the 
DC output as well as controls gain and bandwidth by means of an externally controlled variable 
resistance for tuning the annealing cycle. 
Fig. 8 shows a block diagram of the synapse. The weight is stored in 5 flip-flops as a sign and 
magnitude binary number. These flip-flops control the conductance from the outputs of neuron i 
to the inputs of neuron j and vice-versa as shown in the figure. The conductance of the FETs are 
in the ratio 1:2:4:8 to correspond to the value of the binary number while the sign bit determines 
whether the true or complementary lines connect. The flip-flops are arranged in a counter which 
is controlled by the correlation logic. ff the plus phase correlations are greater than the minus 
phase, then the counter is incremented by a single unit. ff less, it is decremented. 
18 
Vcontrol 
,T 
J_ 
J_ 
Fig. 7. Block diagram of noise amplifier. 
Sit correlation 
Sj logic 
phmase 
in i or j 
Iniorj 
Sj or i 
Wij or Ji 
Fig. 8. Block diagram of synapse. 
Fig. 9 shows the layout of a test chip. A 6 neuron, 15 synapse network may be seen in the lower 
left comer. Each neuron has attached to it a noise amplifier to assure that the noise is 
uncorrelated. The network occupies an area about 2.5 mm on a side in 2 micron design rules. 
Each 300 transistor synapse occupies 400 by 600 microns. In contrast, a biological synapse 
occupies only about one square micron. The real miracle of biological learning is in the synapse 
where plasticity operates on a molecular level, not in the neuron. We can't hope to compete using 
transistors, howev,er small, especially in the digital domain. Aside from this small network, the 
rest of the chip is occupied with test structures of the various components. 
3.2 Analog Synapse 
Analog circuit techniques can reduce the size of the synapse and increase its functionality. 
Several recent papers 04l [!l have shown how to make a voltage controlled resistor in MOS 
technology. The voltage controlling the conductance representing the synaptic weight can be 
obtained by an analog charge integrator from the correlated activation of the neurons which the 
synapse in question connects. A charge integrator with a ""leaky capacitor"" has a time constant 
19 
which can be used to make comparisons as a continuous time average over the last several trials, 
thereby. adding temporal information. One can envision this lime constant as being adaptive as 
well. The charge integrator directly implements the analog Hebb-type [{6] correlation rules of 
section 2. 
Fig. 9. Chip layout. 
3.3 Technological Improvements for Electronic Neural Networks 
It is still necessary to store the voltage which controls the analog conductance and we propose the 
EPROM U7} or EEPROM device for this. Such a device can hold the value of the weight in the 
same way that flip-flops do in the digital implementation of the synapse H�}. The process which 
creates this device has two polysilicon layers which are useful for making high valued 
capacitances in analog circuilry. In addition, the second polysilicon layer could be used to make 
CCD devices for charge storage and transport. Coupled with the charge storage on a floating 
gale [Is], this forms a compact, low power representation for weight values that aplaroach 
biological values. Another useful addition would be a high valued stable resistive layer U91. One 
20 
could thereby avoid space-wasting long-channel MOSFETs which are currently the only 
reasonable way to achieve high resistance in MOS technology. Lastly, the addition of a diffusion 
step or two creates a Bi-CMOS process which adds high quality bipolar transislors useful in 
analog design. Furthermore, one gets the logarithmic dependence of voltage on curten! in bipolar 
technology in a natural, robust way, thai is not subject to the variations inherent in using 
MOSFEFs in the subthreshold region. This is especially useful in compressing the dynamic 
range in sensory processing I2!. 
CONCLUSION 
We have shown how a simple adaptive synapse which measures correlations can accoun! for a 
variety of !earning styles in stochastic networks. By embellishing the standard CMOS process 
and using analog design techniques, a technology suitable for implementing such a synapse 
electronically can be developed. Noise is an importam elemenl in our formulalion of learning. It 
can help a network settle, interpolate between discrele values of conductance during learning, and 
search a large solution space. Weight decay Cforgelting"") and saturation are also important for 
stability. These phenomena not only unify diverse learning styles but are electronically 
implementable. 
ACKNOWLEDGMENT: 
This work has been influenced by many researchers. We would especially like to thank Andy 
Barto and Geoffrey Hinton for valuable discussions on reinforcement learning, Yannis Tsividis 
for contributing many ideas in analog circuit design, and Joel Gannett for timely releases of his 
vlsi verification software. 
21 
References 
1. .J. Hopfield, ""Neural networks and physical systems wilh emergent collective computational abilities"", Proc. Natl. 
Acad. Sci. USA 79, 2554-2558 (1982). 
2. D.E. Rumel.hart, G.E. Hinton, and RJ. W'dliams, ""Learning internal representations by error propagation"", in 
Parallel Distributed Proce, tsing : Explorations in the Microstructure of Cognition. Vol. 1: Foundations, edited by 
D.E. RumeLhart and J.L. McClelland, (M1T Press, Cambridge, MA, 1986), p. 318. 
3. D.H. Ackley, G.E. Hinton, and T.J. Sejnowski, 'A learning algorithm for Bollzmann machines"", Cognitive Science 
9, 147-169 (1985). 
4. D.E. Rumelhart and D. Zipeer, 'Teamre discovery by competitive learning"", Cognitive Science 9, 75-112 (1985). 
5. S. Grossberg, Adaptive pattern classification and universal recocling: Part I. Parallel development and coding of 
nem'al feature detectors."", Biological Cyhemetics 23, 121-134 (1976). 
6. A.G. Barto, R.S. Sutton, and C.W. Anderson, ""Neuronlike adaptive elements Iat can solve difficult learning 
control problems"", llg.P Trans. Sys. Man Cyber. 13, 835 (1983). 
7. B.A. Peadmutler and G.E. Hinton, ""G-Maximization: An unsupervised learning procedure for discovering 
regulazities"", in Neural Networks for Computing, edited by J.S. Denker, AIP Conference Proceedings 151, 
Americ Inst. of Physics, New Yodr (1986), p.333. 
8. F. Rosenblatt, Principles of Neurodynamics: Percepttons and the Theory of Brain Mechanisms (Spaan Books, 
Washington, D.C., 1961). 
9. G. Widrow and M.E. Hoff, ""Adairire switching ch'cuits"", Inst. of Radio Engineers, Western Electric Show and 
Convention, Convention Record, Part 4, 96-104 (1960). 
10. J. Alspecor and R.B. Allen, ""A neuromorphic vlsi learning system"". in Advanced Research in VLSI: Proceedings 
of the 1987 Stanford Conference. edited by P. Losleben (MJT Press, Cambridge, MA, 1987), pp. 313-349. 
11. M.A. Cohen and S. Grossberg, ""Absolute stability of global pattern formation and parallel memory storage by 
competitive neural networks"", Trans. 1F_,F_,E 13, 815, (1983). 
12. B. Widrow, N.K Gupta, and S. Maitra, ""Punish/Reward: Leaming with a critic in adaptive threshold systems"", 
I.gg Trans. on Sys. Man & Cyber., SMC-3,455 (1973). 
13. R.S. SuUon, 'Temporal credit assignment in reinforcement lea_ming"", unpublished doctoral dissertation, U. Mass. 
Amherst, technical report COINS 84-02 (1984). 
]z. Z. Czamul, ""Deign of voltage-controlled linear transconductance elements with a matched pair of FET 
transistors"", !gF.E Trans. Circ. Sys. 33, 1012, (1986). 
15. M. Banu and Y. Tsividis, ""Floating voltage-controUed resistors in CMOS technology"", Electron. Lett. 18, 678-679 
(1982). 
16. D.O. ttebb, Tae Organization of Behavior (Wiley, NY, 1949). 
17. D. Fmhman-Bentcowsky. I:AMOS - a nw semiconductor charge storage device"", Solid-State Electronics 17, 
517 (1974). 
18. J.P. Sage, K. Thompson, and R.S. Withers, ""An artificial neural network integrated circuit based on MNOS/CCD 
principles"", in Neural Networks for Computing, edited by J.S. Denker, AIP Conference Proceedings 151, 
American Inst. of Physics, New York (1986), p.381. 
19. A.P. Thakoor, J.L. Lamb, A. Moopenn, and . Lambe, ""Binary synaptic connections based on memory switching 
in a-Si:H"", in NeuraiNens,orksfor Computing, edited by J.S. Denker, AIP Conference Proceedings 151, American 
Inst. of Physics, New York (1986), p.426. 
20. M.A. Sivilotti, M.A. Mahowald, and C.A. Mead, ""Real-Time visual computations using analog CMOS processing 
arrays"", in Advanced Research in VLSI: Proceedings of the 1987 Stanford Conference. edited by P. Losleben 
(MIT Press, Cambridge, MA, 1987), pp. 295-312. 
", learn network electron implement robert victor srinagesh commun nj describ famili learn algorithm oper symmetr neuromorph network like boltzmann settl network learn modifi synapt connect strength basi correl seen local describ version learn algorilhm network analog activ also unsupervis competit learn weight decay play import describ preliminari experi nois use search identifi describ phenomena element unifi learn techniqu physic algorilhm chosen eas implement design test chip micron rule speed learn millionfold equival simul vax speedup due parallel analog sum multipli weight use process gener random compon test chip neuron transistor adapt separ compon also integr neuron point techniqu reduc area correl synaps technolog design show studi implement natur electron introduct signific recent model brain function collect highli interconnect network simpl model paper focus network especi regard implement electron learn phenomena studi includ associ memori supervis error correct stochast search competit learn reinforc form nnsupervis point view neural well electron particularli like algorithm synapt connect strength asynchron base inform local illustr model synaps use neuron connect perhap weak global evalu signal individu neuron decid adjust address bell commun south ns perman univers ee co ca perman columbia ee mudd new american institut physic learn cij al scalar presenc increment ij local correl believ stochast search procedur compat statist base nois form commun pathway global optim place base interact search necessari part learn network attempt find connect strength matrix solv particular learn procedur attack search directli gradient follow error sl electron implement requir specifi neuron output advanc necessit global control error correct procedur way requir specif connect synchroni neural also procedur would work unsupervis method whether might stuck local stochast process also gradient follow better avoid compat asynchron updat local weight show gener well less supervis phenomena studi analog hebbian synapt weight decay techniqu appli problem reinforc goal studi see learn style unifi microscop level small set physic electron implement hope point way electron learn system futur elucid condit type may may also condit electron learn may bear gener principl biolog local learn stochast search supervis learn recurr network analog activ previous shown supervis procedur boltzmann implement electron system work connect network character settl minimum function architectur may stretch criterion neural provid stabil feedback connect provid way procedur propag inform back network search plausibl would randomli connect network statist approxim inhibit damp symmetri well match choic learn rule search extend electron model boltzmann machin includ analog show model neuron use tanh sigmoid transfer net consist usual weight sum activ neuron case machin ad nois signal chosen varieti neuron perform physic sj netl count number cooccurr neuron synaps correl rule defin valu cooccurr fi activ neuron real valu note rule count cooccurr high gain cumul probabl distribut neuron activ close effect nois illustr bottom chang rule cq increment wij decrement plu phase clamp output neuron desir state minu phase run studi varieti nois distribut base xor problem select test case sinc easili caught local gain manipul condit nois sampl one three gaussian distribut closest true electron thermal nois use also consid uniform distribut cauchi distribut long nois tail show histogram sampl nois distribut nois temperatur transfer jitter decreas schedul vnol noi vl rout transfer function gain function wij sj electron analog vin vnoi show averag perform across run last pattern train seen reduc gain sharp step improv small region even without seem optim gain addit nois distribut substanti improv learn level nois gain propordon correct invers stochast competit preenrat mput network weight win cluster mput mch shown wm problem pixel may mput comprif layer two pattern must eider vertic network space eventu mto two spatial region cluster mg one zipset weighg pattern win one mghest explicit layer cluster layer even moni small time time layer layer competit learn network dipol show result sever posit input unit mean unit cluster layer larger weight lead two unit dipol two unit excit unit mean unit winner complementari note adjac alway sinc unit next tension competit domin cluster defin figur merit call number dipol smaller note run number reduc minimum possibl pattern space divid vertic run adopt less favor diagon divis surfac tension dipol pattern present result competit learn run dipol show result sever competit algorilhm compar averag determinist algorilhm rumelhart zipset give averag surfac tension stochast procedur almost note nois essenti help layer without nois surfac tension show procedur work learn algorithm net decay net renormalizafion perform competit learn algorithm across also tri procedur instead weight model neuron support maximum amount weight lead might area neuron form synaps one synaps can not increas except expens implement eman fix current sourc per shown tabl work well preliminari result show renorm especi two cluster unit stochast implement electron synaps nearli way learn divid space determinist procedur suggest chip style one includ phase unsupervis ff procedur minu phase reinforc learn tri sever approach reinforc use synapt model evalu signal scalar valu avail global repres well perform appli model xor problem one output reinforc correct output similar supervis learn sinc singl output state fulli specifi scalar major clamp output unit state order compar plu minu featur supervis learn effect adjust weight follow gradient desir reinforc describ plu satisfi aspect overal necessari compar also much slower converg solut network search solut space without guidanc teacher clamp output situat becom much wors one output probabl reinforc goe exponenti number test multipl chose simpl replic problem wherebi output simpli replic chose number hidden unit equal input absenc teacher clamp network find answer rate effort mean unit must search use stochast unit supervis unsupervis import nois anneal temperatur set proper ff reinforc receiv random rather direct weight ff avail state search becom small probabl find right solut tune anneal schedul look measur defin neuron simpli fraction time neuron adjust final anneal temperatur number use fix anneal schedul neuron schedul nois proport sum weight characterist reinforc learn percent correct increas decreas often oscil avoid ad factor multipli final help stabil keep simpl model chose weight adjust techniqu correl state connect neuron global reinforc synaps measur quantiti rsi pattern ff wij decrement ff later refin procedur insist greater recent averag type procedur previou work number previou algorithm differ ff make comparison short term long term averag use grade reinforc neg sum squar follow suggest also invesfg techniqu wherebi synaps must store time averag three definit rule ff latter averag result report valu collect across pattern employ continu move gave similar summar perform xor replic task reinforc tabl show varieti increasingli sophist weight adjust nevertheless unabl obtain good result techniqu output third small threshold exceed weight fourth temperatur depend last column tabl refer frequenc depend train singl pattern network produc correct answer move anoth final procedur one sever possibl techniqu oper learn theori difficult pattern present often proport correct perform reinforc learn hint reinforc also implement type synaps thai character nois necessari random search summari studi fundament learn paramet see use nois model local correl synaps global evalu signal two import featur learn activ somewhat less weight decay seem quit import satur substitut unsupervis interest point view phenomena electron implement therefor physic hope mean also relat true neural phenomena therefor basi trolli variou approach microscop electron implement supervis chip complet design chip previous physic style speed learn millionfold comput show block doubl differenti one branch form sum input differenti output neuron connect add nois nois first stage low gain preserv dynam rang sum second stage high gain convert singl end fed arrang wherebi either outpul state extern appli desir state final set invert stage provid gain guarante digit block diagram nois amplifi shown schemat thermal rm level ten channel fet fed stage stage provid gain nois low pass feedback stage stabil output well control gain bandwidth mean extern control variabl tune anneal show block diagram weight store sign binari control conduct output neuron input neuron shown conduct fet ratio correspond valu binari number sign bit determin true complementari line arrang counter control correl ff plu phase correl greater minu counter increment singl ff block diagram nois correl logic ji block diagram show layout test synaps network may seen lower neuron attach nois amplifi assur nois network occupi area mm side micron design transistor synaps occupi biolog synaps one squar real miracl biolog learn synaps plastic oper molecular hope compet use especi digit asid small chip occupi test structur variou analog synaps circuit techniqu reduc size synaps increas recent paper shown make voltag control resistor mo voltag control conduct repres synapt weight analog charg integr correl activ neuron question charg integr time constant use make comparison continu time averag last sever ad tempor one envis lime constant adapt charg integr directli implement analog correl rule chip technolog improv electron neural network still necessari store voltag control analog conduct propos eeprom devic devic hold valu weight way digit implement synaps process devic two polysilicon layer use make high valu analog second polysilicon layer could use make devic charg storag coupl charg storag float form low power represent weight valu aplaroach anoth use addit would high valu stabl resist layer one therebi avoid mosfet current way achiev high resist mo addit diffus two creat process add high qualiti bipolar transislor use one get logarithm depend voltag bipolar robust thai subject variat inher use subthreshold especi use compress dynam sensori process shown simpl adapt synaps measur correl style stochast embellish standard cmo process use analog design technolog suitabl implement synaps nois importam elemenl formulalion help network interpol discrel valu conduct larg solut weight decay satur also import phenomena unifi divers learn style electron work influenc mani would especi like thank andi geoffrey hinton valuabl discuss reinforc yanni tsividi contribut mani idea analog circuit joel gannett time releas verif network physic system wilh emerg collect comput usa intern represent error distribut tsing explor microstructur edit lhart learn algorithm bollzmann cognit scienc rumelhart discoveri competit cognit scienc pattern classif univers part parallel develop code featur biolog cyhemet adapt element solv difficult learn man peadmutl unsupervis learn procedur discov neural network edit aip confer proceed new yodr principl perceptton theori brain mechan widrow switch radio western electr show convent part neuromorph vlsi learn advanc research proceed stanford edit losleben cohen stabil global pattern format parallel memori storag neural leam critic adapt threshold man credit assign reinforc unpublish doctor technic report coin linear transconduct element match pair fet banu u resistor cmo tae organ behavior semiconductor charg storag electron artifici neural network integr circuit base neural network edit aip confer proceed new york synapt connect base memori switch edit aip confer proceed american new york visual comput use analog cmo process advanc research proceed stanford edit losleben,0
3,3,"22 
LEARNING ON A GENERAL NETWORK 
Amir F. Atiya 
Department of Electrical Engineering 
California Institute of Technology 
Ca 91125 
Abstract 
This paper generalizes the backpropagation method to a general network containing feed- 
back connections. The network model considered consists of interconnected groups of neurons, 
where each group could be fully interconnected (it could have feedback connections, with pos- 
sibly asymmetric weights), but no loops between the groups are allowed. A stochastic descent 
algorithm is applied, under a certain inequality constraint on each intra-group weight matrix 
which ensures for the network to possess a unique equilibrium state for every input. 
Introduction 
It has been shown in the last few years that large networks of interconnected ""neuron""-like 
elements re quite suitable for performing a variety of computational and pattern recognition 
tasks. One of the well-known neural network models is the backpropagation model [1]-[4]. It 
is an elegant way for teaching a layered feedforward network by a set of given input/output 
examples. Neural network models having feedback connections, on the other hand, have lso 
been devised (for example the Hopfield network [5]), and are shown to be quite successful in 
performing some computational tasks. It is important, though, to have a method for learning 
by examples for a feedback network, since this is a general way of design, and thus one can 
avoid using an ad hoc design method for each different computational task. The existence 
of feedback is expected to improve the computational abilities of a given network. This is 
because in feedback networks the state iterates until a stable state is reached. Thus processing 
is performed on several steps or recursions. This, in general allows more processing abilities 
than the ""single step"" feedforward case (note also the fact that a feedforward network is 
a special case of a feedback network). Therefore, in this work we consider the problem of 
developing a general learning algorithm for feedback networks. 
In developing a learning algorithm for feedback networks, one has to pay attention to the 
following (see Fig. I for an example of a configuration of a feedback network). The state of 
the network evolves in time until it goes to equilibrium, or possibly other types of behavior 
such as periodic or chaotic motion could occur. However, we are interested in having a steady 
and and fixed output for every input applied to the network. Therefore, we have the following 
two important requirements for the network. Beginning in any initial condition, the state 
should ultimately go to equilibrium. The other requirement is that we have to have a unique 
American Institute of Physics 1988 
23 
equilibrium state. It is in fact that equilibrium state that determines the final output. The 
objective of the learning algorithm is to adjust the parameters (weights) of the network in small 
steps, so as to move the unique equilibrium state in a way that will result finally in an output 
as close as possible to the required one (for each given input). The existence of more than one 
equilibrium state for a given input causes the following problems. In some iterations one might 
be updating the weights so as to move one of the equilibrium states in a sought direction, while 
in other iterations (especially with different input examples) a different equilibrium state is 
moved. Another important point is that when implementing the network (after the completion 
of learning), for a fixed input there can be more than one possible output. Independently, other 
work appeared recently on training a feedback network [6],[7],[8]. Learning algorithms were 
developed, but solving the problem of ensuring a unique equilibrium was not considered, This 
problem is addressed in this paper and an appropriate network and a learning algorithm are 
proposed. 
outputs 
Fig. 1 
A recurrent network 
The Feedback Network 
Consider a group of n neurons which could be fully inter-connected (see Fig. ! for an 
example). The weight matrix W can be asymmetric (as opposed to the Hopfield network). 
The inputs are also weighted before entering into the network (let V be the weight matrix). 
Let x and y be the input and output vectors respectively. In our model y is governed by the 
following set of differential equations, proposed by Hopfield [5]: 
du 
 d--[ = Wf(u) - u + Vx, y = f(u) (1) 
24 
where f(u) = (f(ux),...,f(ur)) T, W denotes the transpose operator, f is a bounded and 
differentiable function, and r is a positive constant. 
For a given input, we would like the network after a short transient period to give a steady 
and fixed output, no matter what the initial network state was. This means that beginning 
any initial condition, the state is to be attracted towards a unique equilibrium. This leads to 
looking for a condition on the matrix W. 
Theorem: A network (not necessarily symmetric) satisfying 
2 1/max(?)2, 
i j 
exhibits no other behavior except going to a unique equilibrium for a given input. 
Proof: Let u(t) and u2(t) be two solutions of (1). Let 
J(t) = Ilu(t) - u2(t)ll 2 
where [I II is the [wo-norm. Differentiating J with respect to time, one obtains 
dJ(t) _ 2(u(t)-u2(t))r(du(t) du2(t)  
dt dt  1' 
Using (1) , the expression becomes 
dJ(t) 2 2 
dt - r []ul(t) -u2(t))[12 + ;(u(t) -u2(t))""W[f(u(t)) - f(u2(t))]. 
Using Schwarz's Inequality, we obtain 
2 
dJ(t) < _211u(t ) _ u(t)ll  + _11u (t)_ u(t)11. iiW[f(u (t)) _ f(u2(t))] ii. 
dt - r r 
Again, by Schwarz's Inequality, 
w/ [f(u (t)) - f(u(t))] <_ Ilwgll - Ilf(u(t)) - f(u2(t))11 , i = 1,...,n 
where wi denotes the i th row of W. Using the mean value theorem, we get 
[If(u (t)) - f(u2(t)) II < (maxlf'l)llu (t) - u2(t)l I. (3) 
Using (2),(3), and the expression for J(t), we get 
dJ(t) <-aJ(t) (4) 
dt - 
where 
2 2 (maxl f,i)/- jwj.. 
T T i 
(2) 
25 
By hypothesis of the Theorem, a is strictly positive. Multiplying both sides of (4) by exp(at), 
the inequality 
d 0 
- 
results, from which we obtain 
J(t) _< J(0)e 
From that and from the fact that J is non-negative, it follows that J(t) goes to zero as t 
Therefore, any two solutions corresponding to any two initial conditions ultimately approach 
each other. To show that this asymptotic solution is in fact an equilibrium, one simply takes 
u2(t): u(t + T), where T is a constant, and applies the above argument (that J(t) - 0 as 
t --* c), and hence u (t + T) -- u (t) as t --* cw for any T, and this completes the proof. 
For example, if the function f is of the following widely used sigmoid-shaped form, 
1 
f (u) - 1 + e- 
then the sum of the square of the weights should be less than 16. Note that for any function 
f, scaling does not have an effect on the overall results. We have to work in our updating 
scheme subject to the constraint given in the Theorem. In many cases where a large network 
is necessary, this constraint might be too restrictive. Therefore we propose a general network, 
which is explained in the next Section. 
The General Network 
We propose the following network (for an example refer to Fig. 2). The neurons are 
partitioned into several groups. Within each group there are no restrictions on the connections 
and therefore the group could be fully interconnected (i.e. it could have feedback connections). 
The groups are connected to each other, but in a way that there are no loops. The inputs to 
the whole network can be connected to the inputs of any of the groups (each input can have 
several connections to several groups). The outputs of the whole network are taken to be the 
outputs (or part of the outputs) of a certain group, say group f. The constraint given in the 
Theorem is applied on each intra-group weight matrix separately. Let (qa, s,), a = 1, ..., N be 
the input/output vector pairs of the function to be implemented. We would like to minimize 
the sum of the square error, given by 
N 
a----1 
where 
M 
---- --$i) , 
i----1 
and �f is the output vector of group f upon giving input q, and M is the dimension of vector 
s a. The learning process is performed by feeding the input examples q sequentially to the 
network, each time updatg the weights in an attempt to minimize the eor. 
26 
inputa outputs 
Fig. 2 
An example of a general network 
(each group represents a recurrent network) 
Now, consider a single group l. Let W t be the intra-group weight matrix of group l, V 'q 
be the matrix of weights between the outputs of group r and the inputs of group l, and yt be 
I rl 
the output vector of group l. Let the respective elements be wo. , vO. , and Yi- Furthermore, 
let nt be the number of neurons of group l. Assume that the time constant  is sufficiently 
small so s to allow the network to settle quickly to the equilibrium state, which is given by 
the solution of the equation 
yt= f(Wtyt + E VtYr)' (5) 
rAl 
where At is the set of the indices of the groups whose outputs are connected to the inputs of 
group l. We would like each iteration to update the weight matrices W t and V rt so as to move 
the equilibrium in a direction to decrease the error. We need therefore to know the change in 
the error produced by a small change in the weight matrices. Let Oe 
3-Wr, and o�v-r, denote the 
Oe Oe Oea, 
matrices whose (i,j) th element are -,, and respectively. Let 3-fy be the column vector 
whose i th element is . We obtain the following relations: 
aea 
av,,t 
-1 3�a t T 
 = [,_ (w') T] y,(y ) , 
-1 aCa r T 
- ['- (w')q y,(y ) , 
wheee A t is the diagonal matrix whose ita diagonal element is 1/f'( k t t ,q ,- 
for a derivation refer to Appends). The vector  sociaed with group I can be obtaed 
in erms of the vectors  jeBt where Bt is the se of he indices of the groups whose puts 
e connected to the outputs of group l..We get (refer to Appends} 
 = (v')[a -(wq] - 
., aye' () 
The matrix A t - (Wt? ' for any group l can never be singular, so we will not face any 
problem in the updating process. To prove that, let z be a vector satisfying 
[' - (w')],. = 0. 
27 
We can write 
,/maxl.f'l _< -?:,, i= ],..., , 
where z  the i  element of z. Usg Schwarz's Inequity, we obtain 
_ ..., 
Squing both sides and dg the inequalities for i = 1, ..., n, we get 
,,)- (7) 
k i k 
Since the condition 
w' 2 1/max(),)2) 
, 
i k 
is enforced, it follows that (7) cannot be satisfied unless z is the zero vector. Thus, the matrix 
Ai - (Wl) T cannot be singular. 
For each iteration we begin by updating the weights of group f (the group containing 
0e equals simply 2(y{ - s,...,y - sM 0, 0)T). Then 
the final outputs). For that group yy , ..., 
we move backwards to the groups connected to that group and obtain their corresponding 
0e, vectors using (6) update the weights, and proceed in the same manner until we complete 
0y ' 
updating all the groups. Updating the weights is performed using the following stochastic 
descent algorithm for each group, 
O ea 
c9 ea 
AV ----- --aa + adeaR , 
where 1 is a noise matrix whose elements axe characterized by independent zero-mean unity- 
variance Gaussian densities, and the a's are parameters. The purpose of adding noise is to 
allow escaping local minima if one gets stuck in any of them. Note that the control parameter 
is taken to be ea. Hence the variance of the added noise tends to decrease the more we 
approach the ideal zero-error solution. This makes sense because for a large error, i.e. for an 
unsatisfactory solution, it pays more to add noise to the weight matrices in order to escape 
local minima. On the other hand, if the error is small, then we are possibly near the global 
minimum or to an acceptable solution, and hence we do not want too much noise in order 
not to be thrown out of that basin. Note that once we reach the ideal zero-error solution the 
added noise as well as the gradient of e, become zero for all a and hence the increments of the 
weight matrices become zero. If a/ter a certain iteration W happens to violate the constraint 
i.w. _ constant < 1/rnax(f') , then its elements are scaled so as to project it back onto 
the surface of the hypershere. 
Implementation Example 
A pattern recognition example is considered. Fig. $ shows a set of two-dimensional 
training patterns from three classes. It is required to design a neural network recognizer with 
28 
three output neurons. Each of the neurons should be on if a sample of the corresponding class is 
presented, and off otherwise, i.e. we would like to design a ""winner-take-all"" network. A single- 
layer three neuron feedback network is implemented. We obtained 3.3% error. Performing the 
same experiment on a feedforward single-layer network with three neurons, we obtained 20% 
error. For satisfactory results, a feedforward network should be two-layer. With one neuron 
in the first layer and three in the second layer, we got 36.7% error. Finally, with two neurons 
in the first layer and three in the second layer, we got a match with the feedback case, with 
3.3% error. 
2 
3 33 
3 3 
2 
2 
2 
2 
2 2 1 
2 2 1 
2 
2 2 1 
2 
3 
3 
I 1 
1 
33333 3 
3 
3 
3 
1 
I I 
1 
1 
I I 
Fig. 3 
A pattern recognition example 
Conclusion 
A way to extend the backpropagation method to feedback networks has been proposed. 
A condition on the weight matrix is obtained, to insure having only one fixed point, so as 
to prevent having more than one possible output for a fixed input. A general structure for 
networks is presented, in which the network consists of a number of feedback groups connected 
to each other in a feedforward manner. A stochastic descent rule is used to update the weights. 
The method is applied to a pattern recognition example. With a single-layer feedback network 
i obtained good results. On the other hand, the feedforward backpropagation method achieved 
good resuls only for the case of more than one layer, hence also with a larger number of neurons 
than the feedback case. 
29 
Acknowledgement 
The author would like to gratefully acknowledge Dr. Y. Abu-Mostafa for the useful 
discussions. This work is supported by Air Force Office of Scientific Research under Grant 
AFOSR-86-0296. 
Appendix 
Differentiating (5), one obtains 
m tOjm OtOp q- ypSjk), 
Owl, - r(4.)( ' Oy, , 
k, p = 1, ..., nt 
where 
1 ifj=k 
8Y= 0 otherwise, 
and 
l 
Zj = 
I I rl r 
m reA rr 
We can write 
c9yt -- (A t- Wt)-b "" (A- 1) 
where b kv is the nt-dimensional vector whose i tn component is given by 
t ifi=k 
b . p= Yp 
 0 otherwise. 
By the chain rule, 
which, upon substituting from (A 1), can be put in the form  
- Yp o--fy, where g is the ktn 
column of (A t - Wt) -. Finally, we obtain the required expression, which is 
Oea Oea I T 
aw, - ['-(w')]-' W' (Y) ' 
Regarding  it is obtained by differentiating (5) with respect to v t We get similarly 
OVr ' kp' 
Oy  _ (A t - W)-c, 
witere c kp is the nt-dimensional vector whose i tn component is given by 
cp { y[, ff i = k 
i = 0 otherwise. 
3O 
A derivation very similar to the case of  results in the following required expression: 
aea - 1 aea r T 
aW, - ) ' 
Now, finally consider oe o j ay 
-. Let -', jeBt be the matrix whose (k,p) ta element is b'y' The 
elements of  can be obtained by differentiating the equation for the fixed point for group 
j, as follows, 
ag . � 
,,, )' 
Hence, 
ay' - (A'- W')-IV'"" (A- 2) 
Using the chain rule, one can write 
ay, -  (---) ayy' 
We substitute from (A - 2) into the previous equation to complete the derivation by obtaining 
aea 
ae,, _ 
ay  
'B 
References 
[1] P. Werbos, ""Beyond regression: New tools for prediction and analysis in behavioral sci- 
ences"", Harvard University dissertation, 1974. 
[2] D. Parker, ""Learning logic"", MIT Tech Report TR-47, Center for Computational Research 
in Economics and Management Science, 1985. 
[3] Y. Le Cun, ""A learning scheme for asymmetric threshold network"" Proceedings of Cog- 
nitiva, Paris, June 1985. 
[4] D. Rumelhart, G.Hinton, and R. Wilhams, ""earning internal representations by error 
propagation"" in D. Rumelhart, J. McLelland and the PDP research group (Eds.), Parallel 
distributed processing: Explorations in the microstructure of co9nition, Vol. 1, MIT Press, 
Cambridge, MA, 1986. 
[5] J. Hopfield, ""Neurons with graded response have collective computational properties hke 
those of two-state neurons"", Proc. Natl. Acad. Sci. USA, May 1984. 
[6] L. Almeida, ""A learning rule for asynchronous perceptrons with feedback in a combinato- 
rim environment"" Proc. of the First Int. Annual Conf. on Neural Networks, San Diego, 
June 1987. 
[7] R. Rohwer, and B. Forrest, ""Training time-dependence in neural networks"", Proc. of the 
First Int. Annual Conf. on Neural Networks, San Diego, June 1987. 
[8] F. Pineda, ""Generahzation of back-propagation to recurrent neural networks"", Phys. Rev. 
Lett., vol. 59, no. 19, 9 Nov. 1987. 
", gener network atiya electr engin institut technolog paper gener backpropag method gener network contain network model consid consist interconnect group group could fulli interconnect could feedback asymmetr loop group stochast descent certain inequ constraint weight matrix ensur network possess uniqu equilibrium state everi shown last year larg network interconnect quit suitabl perform varieti comput pattern recognit one neural network model backpropag model eleg way teach layer feedforward network set given neural network model feedback devis exampl hopfield network shown quit success comput method learn exampl feedback sinc gener way thu one use ad hoc design method differ comput exist feedback expect improv comput abil given feedback network state iter stabl state thu process perform sever step gener allow process abil feedforward case also fact feedforward network special case feedback work consid problem gener learn algorithm feedback develop learn algorithm feedback one pay attent exampl configur feedback state network evolv time goe possibl type behavior period chaotic motion could interest steadi fix output everi input appli follow import requir begin initi state ultim go requir uniqu institut physic fact equilibrium state determin final learn algorithm adjust paramet network small move uniqu equilibrium state way result final output close possibl requir one given exist one state given input caus follow iter one might updat weight move one equilibrium state sought iter differ input differ equilibrium state anoth import point implement network complet fix input one possibl appear recent train feedback network learn algorithm solv problem ensur uniqu equilibrium address paper appropri network learn algorithm recurr network feedback network group neuron could fulli weight matrix asymmetr oppos hopfield input also weight enter network weight input output vector model govern set differenti propos hopfield denot transpos bound posit given would like network short transient period give steadi fix matter initi network state mean begin initi state attract toward uniqu lead condit matrix network necessarili satisfi behavior except go uniqu equilibrium given let two solut let ii differenti respect one obtain dt express becom obtain ilwgll wi denot th row use mean valu get ii express get hypothesi strictli multipli side inequ obtain fact follow goe zero two solut correspond two initi condit ultim approach show asymptot solut fact one simpli take appli argument henc cw complet function follow wide use sum squar weight less note function scale effect overal work updat subject constraint given mani case larg network constraint might therefor propos gener explain next gener network propos follow network exampl refer neuron sever within group restrict connect therefor group could fulli interconnect could feedback group connect way input whole network connect input group input connect sever output whole network taken part certain say group constraint given appli weight matrix let vector pair function would like minim sum squar given output vector group upon give input dimens vector learn process perform feed input exampl sequenti time weight attempt minim output exampl gener network group repres recurr consid singl group let weight matrix group matrix weight output group input group yt rl output vector group let respect element nt number neuron group assum time constant suffici allow network settl quickli equilibrium given solut equat set indic group whose output connect input would like iter updat weight matric rt move equilibrium direct decreas need therefor know chang error produc small chang weight let denot oe whose th element let column vector th element obtain follow ca diagon matrix whose ita diagon element deriv refer vector group vector bt bt indic group whose connect output group get matrix group never face updat prove let vector satisfi write element obtain side inequ get condit follow can not satisfi unless zero matrix can not iter begin updat weight group group contain equal simpli final group move backward group connect group obtain correspond vector use updat proceed manner complet updat weight perform use follow stochast algorithm ea ea nois matrix whose element axe character independ gaussian purpos ad nois escap local minima one get stuck note control paramet taken henc varianc ad nois tend decreas ideal make sens larg pay add nois weight matric order escap error possibl near global accept henc want much nois order thrown note reach ideal solut nois well gradient becom zero henc increment matric becom certain iter happen violat constraint constant element scale project back onto surfac exampl pattern recognit exampl show set pattern three requir design neural network recogn output neuron sampl correspond class would like design three neuron feedback network obtain perform experi feedforward network three obtain satisfactori feedforward network one neuron first layer three second got two neuron first layer three second got match feedback pattern recognit exampl way extend backpropag method feedback network condit weight matrix insur one fix prevent one possibl output fix gener structur network consist number feedback group connect feedforward stochast descent rule use updat method appli pattern recognit feedback network obtain good feedforward backpropag method achiev resul case one henc also larger number neuron feedback author would like grate acknowledg use work support air forc offic scientif research grant one obtain ojm nt rl write kv vector whose tn compon given yp chain upon substitut put form ktn obtain requir oea obtain differenti respect get similarli kp vector whose tn compon given ff deriv similar case result follow requir aea final consid oe let bt matrix whose ta element obtain differenti equat fix point group chain one write substitut previou equat complet deriv obtain new tool predict analysi behavior harvard univers mit tech report center comput research econom manag le learn scheme asymmetr threshold proceed june intern represent error lelland pdp research group parallel explor microstructur mit grade respons collect comput properti hke may learn rule asynchron perceptron feedback first annual neural san neural annual neural san june recurr neural,0
4,4,"31 
AN ARTIFICIAL NEURAL NETWORK FOR SPATIO- 
TEMPORAL BIPOLAR PATTERNS: APPLICATION TO 
PHONEME CLASSIFICATION 
Toshiteru Homma 
Les E. Atlas 
Robert J. Marks H 
Interactive Systems Design Laboratory 
Department of Electrical Engineering, FT-10 
University of Washington 
Seattle, Washington 98195 
ABSTRACT 
An artificial neural network is developed to recognize spatioqemporal 
bipolar patterns associatively. The function of a formal neuron is generalized by 
replacing multiplication with convolution, weights with transfer functions, and 
thresholding with nonlinear transform following adaptation. The Hebbian learn- 
ing rule and the delta learning rule are generalized accordingly, resulting in the 
learning of weights and delays. The neural network which was first developed 
for spatial patterns was thus generalized for spario-temporal patterns. It was 
tested using a set of bipolar input patterns derived from speech signals, showing 
robust classification of 30 model phonemes. 
1. INTRODUCTION 
Learning spatio-temporal (or dynamic) patterns is of prominent importance in biological 
systems and in artificial neural network systems as well. In biological systems, it relates to such 
issues as classical and operant conditioning, temporal coordination of sensorimotor systems and 
temporal reasoning. In artificial systems, it addresses such real-world tasks as robot control, 
speech recognition, dynamic image processing, moving target detection by sonars or radars, EEG 
diagnosis, and seismic signal processing. 
Most of the processing elements used in neural network models for practical applications 
have been the formal neuron 1 or its variations. These elements lack a memory flexible to tem- 
poral patterns, thus limiting most of the neural network models previously proposed to problems 
of spatial (or static) patterns. Some past solutions have been to convert the dynamic problems to 
static ones using buffer (or storage) neurons, or using a layered network with/without feedback. 
We propose in this paper to use a ""dynamic formal neuron"" as a processing element for 
learning dynamic patterns. The operation of the dynamic neuron is a temporal generalization of 
the formal neuron. As shown in the paper, the generalization is straightforward when the activa- 
tion part of neuron operation is expressed in the frequency domain. Many of the existing learn- 
ing rules for static patterns can be easily generalized for dynamic patterns accordingly. We show 
some examples of applying these neural networks to classifying 30 model phonemes. 
American Institute of Physics 1988 
32 
2. FORMAL NEURON AND DYNAMIC FORMAL NEURON 
The formal neuron is schematically drawn in Fig. l(a), where 
Input 
Activation 
Output 
Transmittance 
Node operator 
Neuron operation 
= [x x2 � � � xt.] r 
Yi, i = 1,2 ..... N 
zi, i = 1,2 ..... N 
= [wi wi2''' w.] r 
where 1(') is a nonlinear memoryless transform 
(2.1) 
Note that a threshold can be implicitly included as a transmittance from a constant input. 
In its original form of formal neuron, xi  {0,1} and '1(') is a unit step function u (-). A 
variation of it is a bipolar formal neuron where xi  {-1,1} and 11(. ) is the sign function sgn('). 
When the inputs and output are converted to frequency of spikes, it may be expressed as 
xi  R and 11(') is a rectifying function r('). Other node operators such as a sigmoidal function 
may be used. 
We generalize the notion of formal neuron so that the input and output are functions of 
time. In doing so, weights are replaced with transfer functions, multiplication with convolution, 
and the node operator with a nonlinear transform following adaptation as often observed in bio- 
logical systems. 
Fig. l(b) shows a schematic diagram of a dynamic formal neuron where 
Input 
Activation 
Output 
Transfer function 
Adaptation 
Node operator 
Neuron operation 
(t) = [Xl(t ) x2(t ) � � � xr(t)] ? 
yi(t), i = 1,2 ..... N 
zi (t), i = 1,2 ..... N 
v(t) = [Wil(t ) Wi2(t ) ''' w.(t)] r 
ai (t) 
11 where '1(') is a nonlinear memoryless transform 
z i (t) = 11 (a i (-t), q (t)T, 2(t )) 
(2.2) 
For convenience, we denote 
with b(0 is equivalent to correlating a(-0 with b(t). 
If the Fourier transforms (f ) = F {(t)}, 
ai Or ) = F {ai (t )} exist, then 
yi O c ) = ai O c) [qOc) cr 
where q (f)cr is the conjugate transpose of /(t). 
� X Wi L Yl = W ZI 
 (a) 
/(f) = F {/(t)}, Yi(f) = F{yi(t)}, 
. as correlation instead of convolution. Note that convolving a(t) 
and 
x,(I) 
X2(I) W (I) w.(t) 
.,,,,,'""''WL() 
x,lt) 
Fig. 1. Formal Neuron and Dynamic Formal Neuron. 
(2.3) 
z(i) 
33 
3. LEARNING FOR FORMAL NEURON AND DYNAMIC FORMAL NEURON 
A number of learning rules for formal neurons has been proposed in the past. In the fol- 
lowing paragraphs, we formulate a learning problem and describe two of the existing learning 
rules, namely, Hebbian learning and delta learning, as examples. 
Present to the neural network M pairs of input and desired output samples 
{k), k)}, k = 1,2 ..... M , in order. Let W () = [t ) 2 () � .. )]r where ?) is the 
transmittance vector at the k-th step of learning. Likewise, let 
_Z () = [z 40 z 4-) � ' ' z4)], and D () = [0) (2) ... ()], 
where 
k) = W(� ), z ) = 1'()), and q(.) = [q(Y0 q(Y2) ' ' ' al(Yv)] r. 
The Hebbian learning rule 2 is described as follows*: 
W (k) = W(-0 + eu() 
The delta learning (or LMS learning) rule 3, 4 is described as follows: 
_w() = _w(k-o _ a{_w(-�) _ 
(3.1) 
(3.2) 
The leaming rules described in the previous section are generalized for the dynamic formal 
neuron by replacing multiplication with correlation. First, the problem is reformulated and then 
the generalized rules are described as follows. 
Present to the neural network M pairs of time-varing input and output samples 
{k)(t), )(t)}, k = 1,2 ..... M , in order. Let W()(t) = [g(t)()(t) ?)(t). � � k)(t)] r 
where ,Vi()(t) is the vector whose elements w?)(t) are transfer functions connecting the input j 
to the neuron i at the k-th step of learning. The Hebbian learning rule for the dynamic neuron is 
then 
W()(t ) = W(-O(t ) + a(-t ), k)(t ), )(t ) r . (3.3) 
The delta learning rule for dynamic neuron is then 
W()(t ) = W(-O(t ) - a(-t ), {W(-0(t ), k)(t ) - )(t )}, )(t )r . (3.4) 
This generalization procedure can be applied to other learning rules in some linear discrim- 
inant systems 5 , the serf-organizing mapping system by Kohonen 6 , the perceptton 7, the back- 
propagation model 3 , etc. When a system includes a nonlinear operation, more careful analysis 
is necesssay as pointed out in the Discussion section. 
4. DELTA LEARNING, PSEUDO INVERSE AND REGULARIZATION 
This section reviews the relation of the delta learning rule to the pseudo-inverse and the 
technique known as regularization. 4, 6, 8, 9, lo 
Consider a minimization problem as described below: Find __W which minimizes 
k 
subject to y(k) = 
A solution by the delta rule is, using a gradient descent method, 
_w() = __w( - ) _ a-R () 
* This interpretation assumes a strong supervising signal at the output while learning. 
(4.1) 
(4.2) 
34 
where R (t') = II t') - ')l[ � The minimum norm solution to the problem, _W*, is unique and 
can Ie expressed as 
IV* = DX t (4.3) 
where/t is the Moore-Penrose pseudo-inverse of/ , i.e., 
X t = lim(XrX + o'2I)-lX T = IinlXT(XX T + o21) -1. (4.4) 
2 
On the condition that 0 < ct <  where  is the maximum eigenvalue of XrX, ') and 
S t') am independent, and IVO,) is uncorrelated with '), 
E {_w* 3 = � {w(')3 (4.5) 
where � {x } denotes the expected value of x. One way to make use of this relation is to calcu- 
late W* for known standard data and refine it by (4.2), thereby saving time in the early stage of 
learning, 
However, this solution results in an ill-conditioned IV often in practice. When the prob- 
lem is ill-posed as such, the technique known as regularization can alleviate the ill-conditioning 
of IV. The problem is reformulated by finding IV which minimizes 
R (o) = llY '�') - ')ll  + o2y'.ll ,ll  (4.6) 
subject to ') = __WX ') where IV = [2 ' ""t] r � 
This reformulation regularizes (4.3) to 
Iv(o) = D_Xr(X_X_ r + o2/) - (4.7) 
which is statistically equivalent to W(') when the input has an additive noise of variance o a 
uncorrelated with '). Interestingly, the leaky LMS algorithm II leads to a statistically 
equivalent solution 
Ivtk) = _ _ (4.8) 
2 
where 0 < 15 < 1 and 0 < ct <  These solutions am related as 
if o a = 1-- when W (t') is uncorrelated with ') .li 
(4.9) 
Equation (4.8) can be generalized for a network using dynamic formal neurons, resulting in 
a equation similar to (3.4). Making use of (4.9), (4.7) can be generalized for a dynamic neuron 
network as 
Iv(t ;(X) = F- {D (f )X_ (f )Cr (x (f )X (f ) cr + (x2/) 43 (4.10) 
where F - denotes the inverse Fourier transform. 
5. SYNTHESIS OF BIPOLAR PHONEME PATTERNS 
This section illustrates the scheme used to synthesize bipolar phoneme patterns and to 
form prototype and test patterns. 
The fundamental and first three formant frequencies, along with their bandwidths, of 
phoneroes provided by Klat0 2 were taken as parameters to synthesize 30 prototype phoneme pat- 
terns. The phoneroes were labeled as shown in Table 1. An array of L (=100) input neurons 
Covered the range of 100 to 4000 Hz. Each neuron had a bipolar state which was +1 only when 
one of the frequency bands in the phoneme presented to the network was within the critical band 
35 
of the neuron and -1 otherwise. The center frequencies (fc) of critical bands were obtained by 
dividing the 100 to 4000 Hz range into a log scale by L. The critical bandwidth was a constant 
100 Hz up to the center frequency fc = 500 Hz and 0.2fc Hz when f >500 Hz. 13 
The parameters shown in Table 1 were used to construct Table 1. Labels of Phoneroes 
30 prototype phoneme patterns. For O, it was constructed as a 
combination of t and 0. F, F 2 ,F s were the first, second, and 
third formants, and B, B 2, and B3. were corresponding 
bandwidths. The fundamental frequency Fo = 130 Hz with B0 = 
10 Hz was added when the phoneme was voiced. For plosives, 
there was a stop before formant traces start. The resulting bipo- 
lar paRems are shown in Fig.2. Each pattern had length of 5 
time units, composed by linearly interpolating the frequencies 
when the formant frequency was gliding. 
A sequence of phonemes converted from a continuous 
pronunciation of digits, {o, zero, one, two, three, four, five, six, 
seven, eight, nine }, was translated into a bipolar pattern, adding 
two time units of transition between two consequtive phonemes 
by interpolating the frequency and bandwidth parameters 
linearly. A flip noise was added to the test pattern and created a 
noisy test pattern. The sign at every point in the original clean 
test pattern was flipped with the probability 0.2. These test pat- 
terns are shown in Fig. 3. 
Label Phoneme 
1 [i y] 
2 [I ] 
3 [eY] 
4 
6 [a] 
7 [o] 
8 
9 [o w] 
lO [u ] 
11 [u TM] 
12 
13 [a y] 
14 [a TM] 
15 [o y] 
16 [w] 
17 [y] 
18 [r] 
19 [1] 
20 (q 
21 [v] 
22 [0] 
23 [] 
24 [s] 
25 [z] 
26 [p] 
27 [t] 
28 (d] 
29 [k] 
30 [n] 
Fig. 2. Prototype Phoneme Patterns. (Thirty phoneme patterns are shown 
in sequence with intervals of two time units.) 
6. SIMULATION OF SPATIO-TEMPORAL FILTERS FOR PHONEME CLASSIFICATION 
The network system described below was simulated and used to classify the prototype 
phoneme patterns in the test patterns shown in the previoius section. It is an example of gen- 
eralizing a scheme developed for static patterns 13 to that for dynamic patterns. Its operation is 
in two stages. The first stage operation is a spatio-temporal filter bank: 
36 
(a) 
Fig. 3. Test Patterns. (a) Clean Test Pattern. (b) Noisy Test Pattern. 
y'(t ) = __W (t ),:(t ) , and '(t ) = _r(a(-t )St(t )) . 
The second stage operation is the ""winner-take-all"" lateral inhibition: 
0'(t) = '(t), and o'(t+a) = r_(A_(-t),(t) - h), 
and 
(6.1) 
(6.2) 
for all f . (6.6) 
This minimizes 
R (o,f 
A_(t) = (1 + )/_.(t) - � (t-nA). (6.3) 
where h  is a constant threshold vector with elements h i = h and (') is the Kronecker delta 
function. This operation is repeated a sufficient number of times, No .13,1n The output is 
O'(t + No-a). 
Two models based on different learning rules were simulated with parameters shown 
below. 
Model 1 (Spario-temporal Matched Filter Bank) 
Let (x(t) = (t), f() =  in (3.3) where F is a unit vector with its elements e/ = 5(k-i). 
___W (t) = X (t)T. (6.4) 
4 1 
h=200, and a(t ) = -(t-n,x). 
n=O  
Model 2 (Spario-temporal Pseudo-inverse Filter) 
Let D =/ in (4.10). Using the alternative expression in (4.4), 
W(t ) = F-I{(x0 e )CTxoe ) + (2I_)-lxCT}. (6.5) 
h =0.05,o 2= 1000.0,and a(t)=(t). 
37 
Because the time and frequency were finite and discrete in simulation, the result of the 
inverse discrete Fourier transform in (6.5) may be aliased. To alleviate the aliasing, the transfer 
functions in the prototype matrix X(t) were padded with zeros, thereby doubling the lengths. 
Further zero-padding the transfer functions did not seem to change teh result significantly. 
The results are shown in Fig. 4(a)-(d). The arrows indicate the ideal response positions at 
the end of a phoneme. When the program was run with different thresholds and adaptation func- 
tion a (t), the result was not very sensitive to the threshold value, but was, nevertheless affected 
by the choice of the adaptation function. The maximum number of iterations for the lateral inhi- 
bition network to converge was observed: for the experiments shown in Fig. 4(a) - (d), the 
numbers were 44, 69, 29, and 47, respectively. Model 1 missed one phoneme and falsely 
responded once in the clean test pattern. It missed three and had one false response in the noisy 
test pattern. Model 2 correctly recognized all phonemes in the clean test pattern, and false- 
alarmed once in the noisy test pattern. 
7. DISCUSSION 
The notion of convolution or correlation used in the models presented is popular in 
engineering disciplines and has been applied extensively to designing filters, control systems, etc. 
Such operations also occur in biological systems and have been applied to modeling neural net- 
works.15,16 Thus the concept of dynamic formal neuron may be helpful for the improvement of 
artificial neural network models as well as the understanding of biological systems. A portion of 
the system described by Tank and Hopfield 17 is similar to the matched filter bank model simu- 
lated in this paper. 
The matched filter bank model (Model 1) performs well when all phonemes (as above) are 
of the same duration. Otherwise, it would perform poorly unless the lengths were forced to a 
maximum length by padding the input and transfer functions with -l's during calculation. The 
pseudo-inverse filter model, on the other hand, should not suffer from this problem. However, 
this aspect of the model (Model 2) has not yet been explicitly simulated. 
Given a spatio-temporal pattern of size L x K, i.e., L spatial elements and K temporal ele- 
ments, the number of calculations required to process the first stage of filtering by both models is 
the same as that by a static formal neuron network in which each neuron is connected to the L x 
K input elements. In both cases, L x K multiplications and additions are necessary to calculate 
one output value. In the case of bipolar patterns, the mutiplication used for calculation of activa- 
tion can be replaced by sign-bit check and addition. A future investigation is to use recursive 
filters or analog filters as transfer functions for faster and more efficient calculation. There are 
various schemes to obtain optimal recursive or analog filters. is, 19 Besides the lateral inhibition 
scheme used in the models, there are a number of alternative procedures to realize a ""winner- 
take-all"" network in analog or digital fashion. 15,2�,21 
As pointed out in the previous section, the Fourier transform in (6.5) requires a precaution 
concerning the resulting length of transfer functions. Calculating the recursive correlation equa- 
tion (3.4) also needs such preprocessing as windowing or truncation. 22 
The generalization of static neural networks to dynamic ones along with their learning 
rules is strainghfforward as shown if the neuron operation and the learning rule are linear. Gen- 
eralizing a system whose neuron operation and/or leaming rule are nonlinear requires more care- 
ful analysis and remains for future work. The system described by Watrous and Shastri 16 is an 
example of generalizing a backpropagation model. Their result showed a good potential of the 
model and a need for more rigorous analysis of the model. Generalizing a system with recurrent 
connections is another task to be pursued. In a system with a certain analytical nonlinearity, the 
signals are expressed by Volterra functionals, for example. A practical learning system can then 
be constructed if higher kernels are neglected. For example, a cubic function can be used instead 
of a sigmoidal function. 
38 
(a) 
3 
Co) 
Fig. 4. Performance of Models. (a) Model 1 with Clean Test Pattern. (b) 
Model 2 with Clean Test Pattern. (c) Model 1 with Noisy Test Pattern. 
(d) Model 2 with Noisy Test Pattern. Arrows indicate the ideal response 
positions at the end of phoneme. 
8. CONCLUSION 
The formal neuron was generalized to the dynamic formal neuron to recognize spario- 
temporal patterns. It is shown that existing learning rules can be generalized for dynamic formal 
neurons. 
An artificial neural network using dynamic formal neurons was applied to classifying 30 
model phonemes with bipolar patterns created by using parameters of formant frequencies and 
their bandwidths. The model operates in two stages: in the first stage, it calculates the correla- 
tion between the input and prototype paRems stored in the transfer function matrix, and, in the 
second stage, a lateral inhibition network selects the output of the phoneme pattern dose to the 
input pattern. 
39 
(c) 
(d) 
Fig. 4 (continued.) 
Two models with different transfer functions were tested. Model 1 was a matched filter 
bank model and Model 2 was a pseudo-inverse filter model. A sequence of phoneme patterns 
corresponding to continuous pronunciation of digits was used as a test pattern. For the test pat- 
tern, Model 1 missed to recognize one phoneme and responded falsely once while Model 2 
correctly recognized all the 32 phonemes in the test pattern. When the flip noise which flips the 
sign of the pattern with the probability 0.2, Model 1 missed three phonemes and falsely 
responded once while Model 2 recognized all the phonemes and false-alarmed once. Both 
models detected the phonems at the correct position within the continuous stream. 
References 
W. S. McCulloch and W. Pitts, ""A logical calculus of the ideas imminent in nervous 
activity,"" Bulletin of Mathematical Biophysics, vol. 5, pp. 115-133, 1943. 
D. O. Hebb, The Organization of Behavior, Wiley, New York, 1949. 
40 
3. D.E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning internal representations by 
error propagation,"" in Parallel Distributed Processing, Vol. 1, MIT, Cambridge, 1986. 
4. B. Widrow and M. E. Hoff, ""Adaptive switching circuits,"" Institute of Radio Engineers, 
Western Electronics Show and Convention, vol. Convention Record Part 4, pp. 96-104, 
1960. 
5. R.O. Duda and P. E. Hart, Pattern Classification and Scene Analysis, Chapter 5, Wiley, 
New York, 1973. 
6. T. Kohonen, Self-organization and Associative Memory, Springer-Verlag, Berlin, 1984. 
7. F. Rosenblatt, Principles of Neurodynamics, Spartan Books, Washington, 1962. 
8. J.M. Varah, ""A practical examination of some numerical methods for linear discrete ill- 
posed problems,"" SIAM Review, vol. 21, no. 1, pp. 100-111, 1979. 
9. C. Koch, J. Marroquin, and A. Yuille, ""Analog neural networks in early vision,"" Proceed- 
ings of the National Academy of Sciences, USA, vol. 83, pp. 4263-4267, 1986. 
10. G.O. Stone, ""An analysis of the delta rule and the learning of statistical associations,"" in 
Parallel Distributed Processing., Vol. 1, MIT, Cambridge, 1986. 
11. B. Widrow and S. D. Steams, Adaptive Signal Processing, Prentice-Hall, Englewood 
Cliffs, 1985. 
12. D.H. Klatt, ""Software for a cascade/parallel formant synthesizer,"" Journal of Acoustical 
Society of America, vol. 67, no. 3, pp. 971-995, 1980. 
13. L.E. Arias, T. Homma, and R. J. Marks II, ""A neural network for vowel classification,"" 
Proceedings International Conference on Acoustics, Speech, and Signal Processing, 1987. 
14. R.P. Lippman, ""An introduction to computing with neural nets,"" IEEE ASSP Magazine, 
April, 1987. 
15. S. Amari and M. A. Arbib, ""Competition and cooperation in neural nets,"" in Systems Neu- 
roscience, ed. J. Metzler, pp. 119-165, Academic Press, New York, 1977. 
16. R.L. Watrous and L. Shastri, ""Learning acoustic features from speech data using connec- 
fionist networks,"" Proceedings of The Ninth Annual Conference of The Cognitive Science 
Society, pp. 518-530, 1987. 
17. D. Tank and J. J. Hopfield, ""Concentrating information in time: analog neural networks 
with applications to speech recognition problems,"" Proceedings of International Confer- 
ence on Neural Netoworks, San Diego, 1987. 
18. J.R. Treichler, C. R. Johnson, Jr., and M. G. Larimore, Theory and Design of Adaptive 
Filters, Chapter 5, Wiley, New York, 1987. 
19. M Schetzen, The Volterra and Wiener Theories of Nonlinear Systems, Chapter 16, Wiley, 
New York, 1980. 
20. S. Grossberg, ""Associative and competitive principles of learning,"" in Competition and 
Cooperation in Neural Nets, ed. M. A. Arbib, pp. 295-341, Springer-Verlag, New York, 
1982. 
21. R.J. Marks II, L. E. Atlas, J. J. Choi, S. Oh, K. F. Cheung, and D.C. Park, ""A perfor- 
mance analysis of associative memories with nonlinearities in the correlation domain,"" 
(submitted to Applied Optics), 1987. 
22. D.E. Dudgeon and R. M. Mersereau, Multidimensional Digital Signal Processing, pp. 
230-234, Prentice-Hall, Englewood Cliffs, 1984. 
", artifici neural network bipolar applic classif homma atla mark system design laboratori electr washington washington artifici neural network develop recogn spatioqempor pattern function formal neuron gener multipl weight transfer nonlinear transform follow hebbian rule delta learn rule gener result weight neural network first develop spatial pattern thu gener use set bipolar input pattern deriv speech show classif model introduct pattern promin import biolog artifici neural network system biolog relat classic oper tempor coordin sensorimotor system artifici address task robot dynam imag move target detect sonar eeg seismic signal process element use neural network model practic applic formal neuron element lack memori flexibl thu limit neural network model previous propos problem spatial past solut convert dynam problem one use buffer use layer network propos paper use formal process element dynam oper dynam neuron tempor gener formal shown gener straightforward part neuron oper express frequenc mani exist rule static pattern easili gener dynam pattern show exampl appli neural network classifi model institut physic formal neuron dynam formal neuron formal neuron schemat drawn oper oper nonlinear memoryless transform threshold implicitli includ transmitt constant origin form formal xi unit step function bipolar formal neuron xi sign function input output convert frequenc may express rectifi function node oper sigmoid function gener notion formal neuron input output function weight replac transfer multipl node oper nonlinear transform follow adapt often observ show schemat diagram dynam formal neuron function oper oper nonlinear memoryless transform denot equival correl fourier transform ai cr conjug transpos wi yl zi correl instead note convolv formal neuron dynam formal learn formal neuron dynam formal neuron number learn rule formal neuron propos formul learn problem describ two exist learn hebbian learn delta neural network pair input desir output sampl let vector step let hebbian learn rule describ delta learn lm rule describ leam rule describ previou section gener dynam formal replac multipl problem reformul gener rule describ neural network pair input output sampl let vector whose element transfer function connect input neuron step hebbian learn rule dynam neuron delta learn rule dynam neuron gener procedur appli learn rule linear system map system kohonen perceptton model system includ nonlinear care analysi necesay point discuss delta pseudo invers regular section review relat delta learn rule known lo minim problem describ find minim solut delta rule use gradient descent interpret assum strong supervis signal output minimum norm solut uniqu express dx condit ct maximum eigenvalu uncorrel denot expect valu one way make use relat known standard data refin therebi save time earli stage solut result iv often techniqu known regular allevi problem reformul find iv minim iv reformul regular statist equival input addit nois varianc leaki lm algorithm ii lead statist solut ct solut relat uncorrel gener network use dynam formal result equat similar make use gener dynam neuron cr denot invers fourier synthesi bipolar phonem pattern section illustr scheme use synthes bipolar phonem pattern prototyp test fundament first three formant along provid taken paramet synthes prototyp phonem phonero label shown tabl array input neuron rang neuron bipolar state frequenc band phonem present network within critic band neuron center frequenc critic band obtain hz rang log scale critic bandwidth constant hz center frequenc fc hz hz paramet shown tabl use construct tabl label phonero prototyp phonem construct correspond fundament frequenc fo hz hz ad phonem stop formant trace result rem shown pattern length compos linearli interpol frequenc formant frequenc sequenc phonem convert continu nine translat bipolar ad time unit transit two consequt phonem interpol frequenc bandwidth paramet flip nois ad test pattern creat test sign everi point origin clean pattern flip probabl test shown phonem prototyp phonem phonem pattern shown sequenc interv two time simul filter phonem classif network system describ simul use classifi prototyp pattern test pattern shown previoiu exampl scheme develop static pattern dynam oper two first stage oper filter test clean test noisi test second stage oper later minim constant threshold vector element kroneck delta oper repeat suffici number output model base differ learn rule simul paramet shown match filter unit vector element use altern express time frequenc finit discret result discret fourier transform may allevi transfer prototyp matrix pad therebi doubl transfer function seem chang teh result result shown arrow indic ideal respons posit end program run differ threshold adapt result sensit threshold nevertheless affect choic adapt maximum number iter later network converg experi shown model miss one phonem fals clean test miss three one fals respons noisi model correctli recogn phonem clean test noisi test discuss notion convolut correl use model present popular disciplin appli extens design control oper also occur biolog system appli model neural thu concept dynam formal neuron may help improv neural network model well understand biolog portion system describ tank hopfield similar match filter bank model match filter bank model perform well phonem would perform poorli unless length forc length pad input transfer function filter suffer aspect model yet explicitli pattern size spatial element tempor number calcul requir process first stage filter model static formal neuron network neuron connect input multipl addit necessari calcul output case bipolar mutipl use calcul replac check futur investig use recurs analog filter transfer function faster effici scheme obtain optim recurs analog besid later inhibit use number altern procedur realiz network analog digit point previou fourier transform requir precaut result length transfer calcul recurs correl also need preprocess window gener static neural network dynam one along learn strainghfforward shown neuron oper learn rule system whose neuron oper leam rule nonlinear requir analysi remain futur system describ watrou shastri gener backpropag result show good potenti need rigor analysi gener system recurr anoth task system certain analyt express volterra practic learn system construct higher kernel cubic function use instead sigmoid perform model clean test clean test model noisi test model noisi test arrow indic ideal respons end conclus formal neuron gener dynam formal neuron recogn shown exist learn rule gener dynam formal artifici neural network use dynam formal neuron appli classifi phonem bipolar pattern creat use paramet formant frequenc model oper two first calcul input prototyp rem store transfer function later inhibit network select output phonem pattern dose model differ transfer function model match filter model model filter sequenc phonem pattern continu pronunci digit use test test model miss recogn one phonem respond fals model recogn phonem test flip nois flip pattern probabl model miss three phonem fals model recogn phonem detect phonem correct posit within continu culloch logic calculu idea immin nervou bulletin mathemat organ new intern represent parallel distribut widrow switch institut radio electron show convent record part duda pattern classif scene chapter associ principl spartan practic examin numer method linear discret siam neural network earli nation academi analysi delta rule learn statist distribut widrow adapt signal englewood formant journal acoust mark neural network vowel intern confer signal introduct comput neural ie assp amari cooper neural system academ new watrou acoust featur speech data use proceed ninth annual confer cognit scienc tank inform analog neural network applic speech recognit proceed intern neural san theori design adapt chapter new volterra wiener theori nonlinear chapter competit principl competit neural new mark analysi associ memori nonlinear correl appli dudgeon multidimension digit signal englewood,0
5,5,"41 
ON PROPERTIES OF NETWORKS 
OF NEURON-LIKE ELEMENTS 
Pierre Baldi* and Santosh S. Venlmtesh I 
15 December 1987 
Abstract 
The complexity and computational capacity of multi-layered, feedforward 
neural networks is examined. Neural networks for special purpose (structured) 
functions are examined from the perspective of circuit complexity. Known re- 
sults in complexity theory are applied to the special instance of neural network 
circuits, and in particular, classes of functions that can be implemented in 
shallow circuits characterised. Some conclusions are also drawn about learning 
complexity, and some open problems raised. The dual problem of determining 
the computational capacity of a class of multi-layered networks with dynamics 
regulated by an algebraic Hamiltoninn is considered. Formal results are pre- 
sented on the storage capacities of programmed higher-order structures, and 
a tradeoff between ease of programming and capacity is shown. A precise de- 
termination is made of the static fixed point structure of random higher-order 
constructs, and phase-transitions (0-1 laws) are shown. 
1 INTRODUCTION 
In this article we consider two aspects of computation with neural networks. Firstly 
we consider the problem of the complexity of the network required to compute classes 
of specified (structured) functions. We give a brief overview of basic known com- 
plexity theorems for readers familiar with neural network models but less familiar 
with circuit complexity theories. We argue that there is considerable computational 
and physiological justification for the thesis that shallow circuits (i.e., networks with 
relatively few layers) are computationally more efficient. We hence concentrate on 
structured (as opposed to random) problems that can be computed in shallow (con- 
stant depth) circuits with a relatively few number (polynomial) of elements, and 
demonstrate classes of structured problems that are amenable to such low cost so- 
lutions. We discuss an allied problem--the complexity of learning--and close with 
some open problems and a discussion of the observed limitations of the theoretical 
approach. 
We next turn to a rigourous classification of how much a network of given 
structure can do; i.e., the computational capacity of a given construct. (This is, in 
*Department of Mathematics, University of California (San Diego), La Jolla, CA 92093 
tMoore School of Electrical Engineering, University of Pennsylvania, Philadelphia, PA 19104 
American Institute of Physics 1988 
42 
a sense, the mirror image of the problem considered above, where we were seeking 
to design a minimal structure to perform a given task.) In this article we restrict 
ourselves to the analysis of higher-order neural structures obtained from polynomial 
threshold rules. We demonstrate that these higher-order networks are a special class 
of layered neural network, and present formal results on storage capacities for these 
constructs. Specifically, for the case of prograznmed interactions we demonstrate 
that the storage capacity is of the order of n d where d is the interaction order. 
For the case of random interactions, a type of phase trartsition is observed in the 
distribution of fixed points as a function of attraction depth. 
2 COMPLEXITY 
There exist two broad classes of constraints on computations. 
1. Physical constraints. These are related to the hardware in which the computa- 
tion is embedded, and include among others time constants, energy limitations, 
volumes and geometrical relations in 3D space, and bandwidth capadties. 
2. Logical constraints: These can be further subdivided into 
� Computability constraints--for instance, there exist unsolvable problems, 
i.e., functions such as the halting problem which are not computable in 
an absolute sense. 
� Complexity constraints--usually giving upper and/or lower bounds on 
the amount of resources such as the time, or the number of gates re- 
quired to compute a given function. As an instance, the assertion ""There 
exists an exponential time algorithm for the Traveling Salesman Prob- 
lem,"" provides a computational upper bound. 
If we view brains as computational devices, it is not unreasonable to think 
that in the course of the evolutionary process, nature may have been faced several 
times by problems related to physical and perhaps to a minor degree logical con- 
straints on computations. If this is the case, then complexity theory in a broad 
sense could contribute in the future to our understanding of parallel computations 
and architectural issues both in natural and synthetic neural systems. 
A simple theory of parallel processing at the macro level (where the elements 
are processors) can be developed based on the ratio of the time spent on com- 
munications between processors [7] for different classes of problems and different 
processor architecture and interconnections. However, this approach does not seem 
to work for parallel processing at the level of circuits, especially if calculations and 
communications are intricately entangled. 
Recent neural or connectionist models are based on a common structure, that 
of highly interconnected networks of linear (or polynomial) threshold (or with sig- 
mold input-output function) units with adjustable interconnection weights. We shall 
therefore review the complexity theory of such circuits. In doing so, it will be some- 
times helpful to contrast it with the similar theory based on Boolean (AND, OR, 
NOT) gates. The presentation will be rather informal and technical complements 
can easily be found in the references. 
43 
Consider a circuit as being on a cyclic oriented graph connecting n Boolean 
inputs to one Boolean output. The nodes of the graph correspond to the gates 
(the n input units, the ""hidden"" units, and the output unit) of the circuit. The 
size of the circuit is the total number of gates and the depth is the length of the 
longest path connecting one input to the output. For a layered, feed-forward circuit, 
the width is the average number of computational units in the hidden (or interior) 
layers of elements. The first obvious thing when comparing Boolean and threshold 
logic is that they are equivalent in the sense that any Boolean function can be 
implemented using either logic. In fact, any such function can be computed in a 
circuit of depth two and exponential size. Simple counting arguments show that 
the fraction of functions requiring a circuit of exponential size approaches one as 
n  oo in both cases, i.e., a random function will in general require an exponential 
size circuit. (Paradoxically, it is very difficult to construct a family of functions 
for which we can prove that an exponential circuit is necessary.) Yet, threshold 
logic is more powerful than Boolean logic. A Boolean gate can compute only one 
function whereas a threshold gate can compute to the order of 2 an2 functions by 
varying the weights with 1/2 _< a _< 1 (see [19] for the lower bound; the upper 
bound is a classical hyperplane counting argument, see for instance [20,30]). It 
would hence appear plausible that there exist wide classes of problems which can be 
computed by threshold logic with circuits substantially smaller than those required 
by Boolean logic. An important result which separates threshold and Boolean logic 
from this point of view has been demonstrated by Yo [31] (see [10,24] for an elegant 
proof). The result is that in order to compute a function such as parity in a circuit 
of constant depth k, at least exp(cn /2k) Boolean gates with unbounded fanin are 
required. As we shall demonstrate shortly, a circuit of depth two and linear size is 
sufficient for the computation of such functions using threshold logic. 
It is not unusual to hear discussions about the tradeoffs between the depth 
and the width of a circuit. We believe that one of the main constributions of 
complexity analysis is to show that this tradeoff is in some sense minimal and that 
in fact there exists a very strong bias in favor of shallow (i.e., constant depth) 
circuits. There are multiple reasons for this. In general, for a fixed size, the number 
of different functions computable by a circuit of small depth exceeds the number 
of those computable by a deeper circuit. That is, if one had no a priori knowledge 
regarding the function to be computed and was given hidden units, then the optimal 
strategy would be to choose a circuit of depth two with the rn units in a single 
layer. In addition, if we view computations as propagating in a feedforward mode 
from the inputs to the output unit, then shallow circuits compute faster. And the 
deeper a circuit, the more difficult become the issues of time delays, synchronisation, 
and precision on the computations. Finally, it should be noticed that given overall 
responses of a few hundred milliseconds and given the known time scales for synaptic 
integration, biological circuitry must be shallow, at least within a ""module"" and 
this is corroborated by anatomical data. The relative slowness of neurons and their 
shallow circuit architecture are to be taken together with the ""analog factor"" and 
""entropy factor"" [1] to understand the necessary high-connectivity requirements of 
neural systems. 
44 
From the previous analysis emerges an important class of circuits in threshold 
logic characterised by polynomial size and shallow depth. We have seen that, in 
general, a random function cannot be computed by such circuits. However, many 
interesting functions--the structured problems--are far from random, and it is then 
natural to ask what is the class of functions computable by such circuits? While 
a complete characterisation is probably difficult, there are several sub-classes of 
structural functions which are known to be computable in shallow poly-size circuits. 
The symmetric functions, i.e., functions which are invaxiant under any per- 
mutation of the n input variables, are an important class of structured problems 
that can be implemented in shallow polynomial size circuits. In fact, any symmet- 
ric function can be computed by a threshold circuit of depth two and linear size; 
(n hidden units and one output unit are always sufficient). We demonstrate the 
validity of this assertion by the following instructive construction. We consider n 
binary inputs, each taking on values -1 and i only, and threshold gates as units. 
Now axray the 2 n possible inputs in n -{- 1 rows with the elements in each row being 
permuted versions of each other (i.e., n-tuples in a row all have the same number 
of -{-1's) and with the rows going monotonically from zero +1's to n +1's. Any 
given symmetric Boolean function clearly assumes the same value for all elements 
(Boolean n-tuples) in a row, so that contiguous rows where the function assumes 
the value +1 form bands. (There axe at most n/2 bands--the worst case occuring 
for the parity function.) The symmetric function can now be computed with 2B 
threshold gates in a single hidden layer with the topmost ""neuron"" being activated 
only if the number of -{-1's in the input exceeds the number of -{-1's in the lower 
edge of the lowest band, and proceeding systematically, the lowest ""neuron"" being 
activated only if the number of -{-1's in the input exceeds the number of -{- 1's in the 
upper edge of the highest band. An input string will be within a band if and only if 
an odd number of hidden neurons are activated starti:g contiguously from the top 
of the hidden layer, and conversely. Hence, a single output unit can compute the 
given symmetric function. 
It is easy to see that arithmetic operations on binary strings can be performed 
with polysize small depth circuits. Reif [23] has shown that for a fixed degree of pre- 
cision, any analytic function such as polynomials, exponentials, and trigonometric 
functions can be approximated with small and shallow threshold circuits. Finally, 
in many situations one is interested in the value of a function only for a vanishingly 
small (i.e., polynomial) fraction of the total number of possible inputs 2 '. These 
functions can be implemented by polysize shallow circuits and one can relate the 
size and depths of the circuit to the cardinal of the interesting inputs. 
So fax we only have been concerned with the complexity of threshold circuits. 
We now turn to the complexity of leaxning, i.e., the problem of finding the weights 
required to implement a given function. Consider the problem of repeating m points 
in ]R t coloured in two colours, using k hyperplanes so that any region contains only 
monochromatic points. If t and k axe fixed the problem can be solved in polynomial 
time. If either t or k goes to infinity, the problem becomes NP-complete [?]. As 
a result, it is not difficult to see that the general learning problem is NP-complete 
(see also [12] for a different proof and [21] for a proof of the fact it is already 
NP-complete in the case of one single threshold gate). 
45 
Some remarks on the limitations of the complexity approach are a propos at 
this juncture: 
While a variety of structured Boolean functions can be implemented at rela- 
tively low cost with networks of linear threshold gates (McCulloch-Pitts neu- 
rons), the extension to different input-output functions and the continuous 
domain is not always straightforward. 
Even restricting ourselves to networks of relatively simple Boolean devices such 
as the linear threshold gate, in many instances, only relatively weak bounds 
axe available for computational cost and complexity. 
o 
o 
Time is probably the single most important ingredient which is completely 
absent from these threshold units and their interconnections [17,14]; there 
axe, in addition, non-biological aspects of connectionist models [8]. 
Finally, complexity results (where available) are often asymptotic in nature 
and may not be meaningful in the range corresponding to a particular appli- 
cation. 
We shall end this section with a few open questions and speculations. One 
problem has to do with the time it takes to learn. Leaxning is often seen as a 
very slow process both in artificial models (cf. back propagation, for instance) and 
biological systems (cf. human acquisition of complex skills). However, if we follow 
the standards of complexity theory, in order to be effective over a wide variety of 
scales, a single learning algorithm should be polynomial time. We can therefore 
ask what is learnable by examples in polynomial time by polynomial size shallow 
threshold circuits? The status of back propagation type of algorithms with respect 
to this question is not very clear. 
The existence of many tasks which are easily executed by biological organisms 
and for which no satisfactory computer program has been found so far leads to the 
question of the specificity of learning algorithms, i.e., whether there exists a com- 
plexity class of problems or functions for which a ""program"" can be found only by 
learning from examples as opposed to by traditional programming. There is some 
circumstantial evidence against such conjecture. As pointed out by Valiant [25], 
cryptography can be seen in some sense as the opposite of learning. The conjectures 
existence of one way function, i.e., functions which can be constructed in polyno- 
mial time but cannot be invested (from examples) in polynomial time suggests that 
learning algorithms may have strict limitations. In addition, for most of the artificial 
applications seen so far, the programs obtained through learning do not outperform 
the best already known software, though there may be many other reasons for that. 
However, even if such a complexity class does not exist, learning algorithm may 
still be very important because of their inexpensiveness and generality. The work of 
Valiant [26,13] on polynomial time learning of Boolean formulas in his ""distribution 
free model"" explores some additional limitations of what can be learned by examples 
without including any additional knowledge. 
Learning may therefore turn out to be a powerful, inexpensive but limited 
family of algorithms that need to be incorporated as ""sub-routines"" of more global 
46 
programs, the structure of which may be 'harder to find. Should evolution be re- 
garded as an ""exponential"" time learning process complemented by the ""polynomial"" time type of learning occurring in the lifetime of organisms? 
3 CAPACITY 
In the previous section the focus of our investigation was on the structure and cost of 
minimal networks that would compute specified Boolean functions. We now consider 
the dual question: What is the computational capacity of a threshold network of 
given structure? As with the issues on complexity, it turns out that for fMrly general 
networks, the capacity results favour shallow (but perhaps broad) circuits [29]. In 
this discourse, however, we shall restrict ourselves to a specified class of higher-order 
networks, and to problems of associative memory. We will just quote the principal 
rigourous results here, and present the involved proofs elsewhere [4]. 
We consider systems of n densely interacting threshold units each of which 
yields an instantaneous state -1 or +1. (This corresponds in the literature to a 
system of n Ising spins, or alternatively, a system of n neural states.) The state 
space is hence the set of vertices of the hypercube. We will in this discussion 
also restrict our attention throughout to symmetric interaction systems wherein the 
interconnections between threshold elements is bidirectional. 
Let Zd be the family of all subsets of cardinality d+ 1 of the set {1, 2,..., n). 
Clearly ]Zd] = ( d + 1 )' For any subset I of {1,2,...,n), and for every state 
u = (-1,1)"", set uz = rl6z 
Definition 1 A homogeneous algebraic threshold network of degree d is a network of 
n 
n threshold elements with interactions specified by a set of ( d + 1 ) real coefficients 
wz indexed by I in Za, and the evolution rule 
16 61 
(1) 
These systems can be readily seen to be natural generalisations to higher- 
order of the familiar case d = i of linear threshold networks. The added degrees of 
freedom in the interaction coefficients can potentially result in enhanced flexibility 
and programming capability over the linear case as has been noted independently 
by several authors recently [2,3,4,5,22,27]. Note that each d-wise product Uz\i is just 
the parity of the corresponding d inputs, and by our earlier discussion, this can be 
computed with d hidden units in one layer followed by a single threshold unit. Thus 
the higher-order network can be realised by a network of depth three, where the first 
hidden layer has d( n n 
d ) units, the second hidden layer has ( d ) units, and there are 
n output units which feedback into the n input units. Note that the weights from 
the input to the first hidden layer, and the first hidden layer to the second are fixed 
47 
(computing the various d-wise products), and the weights from the second hidden 
layer to the output are the coefficients wx which are free parameters. 
These systems can be identified either with long range interactions for higher- 
order spin glasses at zero temperature, or higher-order neural networks. Starting 
from an arbitrary configuration or state, the system evolves asynchronously by a 
sequence of single ""spin"" flips involving spins which are misaligned with the instan- 
taneous ""molecular field."" The dynamics of these symmetric higher-order systems 
are regulated analogous to the linear system by higher-order extensions of the clas- 
sical quadratic Hamiltonian. We define the homogeneous algebraic Hamiltonian of 
degree d by 
Hd(u) =- wxm. 
IEIa 
The algebraic Hamiltonians are functionals akin in behaviour to the classical 
quadratic Hamiltonian as has been previously demonstrated [5]. 
Proposition 1 The functional Hd is non-increasing under the evolution rule 1. 
In the terminology of spin glasses, the state trajectories of these higher-order 
networks can be seen to be following essentially a zero-temperature Monte Carlo 
(or Glauber) dynamics. Because of the monotonicity of the algebraic Hamiltonians 
given by equation 2 under the asynchronous evolution rule 1, the system always 
reaches a stable state (fixed point) where the relation I is satisfied for each of the n 
spins or neural states. The fixed points are hence the arbiters of system dynamics, 
and determine the computational capacity of the system. 
System behaviour and applications are somewhat different depending on 
whether the interactions are random or programmed. The case of random interac- 
tions lends itself to natural extensions of spin glass formulations, while programmed 
interactions yield applications of higher-order extensions of neural network models. 
We consider the two cases in turn. 
3.1 PROGRAMMED INTERACTIONS 
Here we query whether given sets of binary n-vectors can be stored as fixed points 
by a suitable selection of interaction coefficients. If such sets of prescribed vectors 
can be stored as stable states for some suitable choice of interaction coefficients, 
then proposition 1 will ensure that the chosen vectors are at the bottom of ""energy 
wells"" in the state space with each vector exercising a region of attraction around 
it--all characterestics of a physical associative memory. In such a situation the 
dynamical evolution of the network can be interpreted in terms of computations: 
error-correction, nearest neighbour search and associative memory. Of importance 
here is the maximum number of states that can be stored as fixed points for an 
appropriate choice of algebraic threshold network. This represents the maximal 
information storage capacity of such higher-order neural networks. 
Let d represent the degree of the algebraic threshold network. Let u(),..., u (m) 
be the m-set of vectors which we require to store as fixed points in a suitable al- 
gebraic threshold network. We will henceforth refer to these prescribed vectors as 
48 
memories. We define the storage capacity of an algebraic threshold network of de- 
gree d to be the maximal number m of arbitraxily chosen memories which can be 
stored with high probability for appropriate choices of coefficients in the network. 
Theorem 1 The maximal (algorithm independent) storage capacity of a homoge- 
neous algebraic threshold network of degree d is less than or equal to 2 ( n 
d)' 
Generalised Sum of Outer-Products Rule: The classical Hebbiazt rule for the 
lineax case d = i (cf. [11] and quoted references) cazt be naturally extended to 
networks of higher-order. The coefficients w.r, I  Zd axe constructed as the sum of 
generalised Kronecker outer-products, 
m 
a----1 
Theorem 2 The storage capacity of the outer-product algorithm applied to a ho- 
mogeneous algebraic threshold network of degree d is less thazt or equal to nd/2(d + 
1)logn (also cf. [15,27]). 
Generalised Spectral Rule: For d = 1 the spectral rule amounts to iteratively 
projecting states orthogonally onto the lineax space generated by u(),..., u(""0, and 
then taking the dosest point on the hypercube to this projection (cf. [27,28]). This 
approach can be extended to higher-orders as we now describe. 
Let W denote the n x N(,,d) matrix of coefficients wt arranged lexicograph- 
ically; i.e., 
W __ 
Wl,l,2,...,d-1,d Wl,2,3,...,d,d+ l ' ' ' 
W2,1,2,...,d- l,d W2,2,3,...,d,d+ l � �. 
Wn,l,2,...,d-l,d Wn,2,3,...,d,d+l � . . 
Wl,n-d+ l,n-d+ 2,...,n- l,n 
W2,n-d+ l,n-d+ 2,...,n-l,n 
Wn,n-d + l ,n-d+ 2,...,n- l ,n 
Note that the symmetry and the ""zero-diagonal"" nature of the interactions have 
been relaxed to increase capacity. Let U be the n x m matrix of memories. Form 
the extended N(n,a ) x m binary matrix U = [lu() ... u(ra)], where 
.() 
1,2,...,d-1,d 
u () 
lU( ) ._ 1,2,...,d-l,d+l 
u() 
n-dc l,n-d+ 2,...,n- l,n 
Let A'= dg[A0) ... A(m)] be a m x m diagonal matrix with positive diagonal terms. 
A generalisation of the spectral algorithm for choosing coefficients yields 
W = UAU t 
where U t is the pseudo-inverse of U. 
49 
Theorem 3 The storage capacity of the generalised spectral algorithm is at best 
(d). 
3.2 RANDOM INTERACTIONS 
We consider homogeneous algebraic threshold networks whose weights w.r are i.i.d., 
fir(0, 1) random vaxiables. This is a natural generalisation to higher-order of Ising 
spin glasses with Gaussian interactions. We will show an asymptotic estimate for 
the number of fixed points of the structure. Asymptotic results for the usual case 
d = i of linear threshold networks with Gaussian interactions have been reported 
in the literature [6,9,16]. 
For i = 1,...,n set 
$ = ui  w.ru\i . 
I d: i6I 
For each n the random vaxiables S}, i = 1,..., n are identically distributed, jointly 
2 n-1 
Gaussian vaxiables with zero mean, and vaxiance a, = ( 
d )' 
Definition 2 For any given  >_ 0, a state u 6 lB n is S-strongly stable iff S >_ firrs, 
for each i = 1,...,n. 
The case fl = 0 reverts to the usual case of fixed points. The parameter fl is 
essentially a measure of how deep the well of attraction surrounding the fixed point 
is. The following proposition asserts that a 0-1 law (""phase transition"") governs 
the expected number of fixed points which have wells of attraction above a certain 
depth. Let Fd(/) be the expected number of/%strongly stable states. 
Theorem 4 Corresponding to each fixed interaction order d there exists a positive 
constant  such that as n --, oo, 
d 
Fff kd(/) 2 'cd() if/ < 
 kd(/) if/ = ! 
0 if/> , 
where ka(/) > O, and 0 < ca(/) < 1 axe parameters depending solely on/ and the 
interaction order d. 
4 CONCLUSION 
In fine, it appears possible to design shallow, polynomial size threshold circuits 
to compute a wide class of structured problems. The thesis that shallow circuits 
compute more efficiently than deep circuits is borne out. For the paxticulax case of 
5O 
higher-order networks, all the garnered results appear to point in the same direction: 
For neural networks of fixed degree d, the maximal number of programmable states is 
essentially of the order of nd. The total number of fixed points, however, appear to 
be exponential in number (at least for the random interaction case) though almost 
all of them have constant attraction depths. 
References 
[1] Y. S. Abu-Mostafa, ""Number of synapses per neuron,"" in Analog VLSI and 
Neural Systems, ed. C. Mead, Addison Wesley, 1987. 
[2] P. Baldi, II. Some Contributions to the Theory of Neural Networks. Ph.D. The- 
sis, California Insitute of Technology, June 1986. 
[3] P. Baldi and S. S. Venkatesh, ""Number of stable points for spin glasses and 
neural networks of higher orders,"" Phys. Rev. Lett., vol. 58, pp. 913-916, 1987. 
[4] P. Baldi and S.S. Venkatesh, ""Fixed points of algebraic threshold networks,"" 
in prepaxation. 
[5] H. H. Chen, et al, ""Higher order correlation model of associative memory,"" in 
Neural Networks for Computing. New York: AIP Conf. Proc., vol. 151, 1986. 
[6] S. F. Edwards and F. Tanaka, ""Analytical theory of the ground state properties 
of a spin glass: I. ising spin glass,"" Jnl. Phys. F, vol. 10, pp. 2769--2778, 1980. 
[7] G. C. Fox and S. W. Otto, ""Concurrent Computations and the Theory of 
Complex Systems,"" Caltech Concurrent Computation Program, March 1986. 
[8] F. H. Grick and C. Asanuma, ""Certain aspects of the anatomy and physiology 
of the cerebral cortex,"" in Parallel Distributed Processing, vol. 2, eds. D. E. 
Rumelhart and J. L. McCelland, pp. 333-371, MIT Press, 1986. 
[9] D. J. Gross and M. Mezard, ""The simplest spin glass,"" Nucl. Phys., vol. B240, 
pp. 431-452, 1984. 
[10] J. Hasted, ""Almost optimal lower bounds for small depth circuits,"" Proc. 18-th 
ACM STOC, pp. 6-20, 1986. 
[11] J. J. Hopfield, ""Neural networks and physical sytems with emergent collective 
computational abilities,"" Proc. Natl. Acad. Sci. USA, vol. 79, pp. 2554-2558, 
1982. 
[12] J. S. Judd, ""Complexity of connectionist learning with various node functions,"" 
Dept. of Computer and Information Science Technical Report, vol. 87-60, Univ. 
of Massachussetts, Amherst, 1987. 
[13] M. Kearns, M. Li, L. Pitt, and L. Valiant, ""On the learnability of Boolean 
formulae,"" Proc. 19-th ACM STOC, 1987. 
[14] C. Koch, T. Poggio, and V. Torre, ""Retinal ganglion cells: A functional inter- 
pretation of dendritic morphology,"" Phil. Trans. R. Soc. London, vol. B 288, 
pp. 227-264, 1982. 
51 
[15] R. J. McEliece, E. C. Posner, E. R. Rodemich, and $. $. Venkatesh, ""The 
capacity of the Hopfield associative memory,"" IEEE Trans. Inform. Theory, 
vol. IT-33, pp. 461-482, 1987. 
[16] R. J. McEliece and E. C. Posner, ""The number of stable points of an infinite- 
range spin glass memory,"" JPL Telecomre. and Data Acquisition Progress Re- 
port, vol. 42-83, pp. 209-215, 1985. 
[17] C. A. Mead (ed.), Analog VLSI and Neural Systems, Addison Wesley, 1987. 
[18] N. Megiddo, ""On the complexity of polyhedral separability,"" to appear in Jnl. 
Discrete and Computational Geometr7, 1987. 
[19] S. Muroga, ""Lower bounds on the number of threshold functions,"" IEEE Trans. 
Elec. Comp., vol. 15, pp. 805-806, 1966. 
[20] $. Muroga, Threshold Logic and its Applications, Wiley Interscience, 1971. 
[21] V. N. Peled and B. $imeone, ""Polynomial-time algorithms for regular set- 
covering and threshold synthesis,"" Discr. Appl. Math., vol. 12, pp. 57-69, 1985. 
[22] D. Psaltis and C. H. Park, ""Nonlinear discriminant functions and associative 
memories,"" in Neural Networks for Computing. New York: AIP Conf. Proc., 
vol. 151, 1986. 
[23] J. Reif, ""On threshold circuits and polynomial computation,"" preprint. 
[24] R. $molenski, ""Algebraic methods in the theory of lower bounds for Boolean 
circuit complexity,"" Proc. 19-th ACM STOC, 1987. 
[25] L. G. Valiant, ""A theory of the learnable,"" Comm. ACM, vol. 27, pp. 1134-1142, 
1984. 
[26] L. G. Valiant, ""Deductive learning,"" Phil. Trans. R. Soc. London, vol. A 312, 
pp. 441-446, 1984. 
[27] S. S. Venkatesh, Linear Maps with Point Rules: Applications to Pattern Clas- 
siftcation and Associative Memory. Ph.D. Thesis, California Institute of Tech- 
nology, Aug. 1986. 
[28] S. S. Venkatesh and D. Psaltis, ""Linear and logarithmic capacities in associative 
neural networks,"" to appear IEEE Trans. Inform. Theory. 
[29] S. S. Venkatesh, D. Psaltis, and J. Yu, private communication. 
[30] R. O. Winder, ""Bounds on threshold gate realisability,"" IRE Trans. Elec. 
Comp., vol. EC-12, pp. 561-564, 1963. 
[31] A. C. C. Yao, ""Separating the poly-time hierarchy by oracles,"" Proc. 26-th 
IEEE FOCS, pp. 1-10, 1985. 
", properti network element santosh venlmtesh decemb complex comput capac feedforward network neural network special purpos examin perspect circuit known complex theori appli special instanc neural network class function implement circuit conclus also drawn learn open problem dual problem determin comput capac class network dynam algebra hamiltoninn formal result storag capac program tradeoff eas program capac precis made static fix point structur random introduct articl consid two aspect comput neural firstli consid problem complex network requir comput class specifi give brief overview basic known theorem reader familiar neural network model less familiar circuit complex argu consider comput physiolog justif thesi shallow circuit network comput henc concentr oppos problem comput shallow circuit rel number class structur problem amen low cost discuss alli complex close open problem discuss observ limit theoret next turn rigour classif much network given comput capac given depart univers california la ca moor school electr univers pa institut physic mirror imag problem consid seek design minim structur perform given articl restrict analysi neural structur obtain polynomi demonstr network special class layer neural present formal result storag capac case prograznm interact demonstr storag capac order interact case random type phase trartsit observ fix point function attract complex exist two broad class constraint physic relat hardwar includ among other time energi geometr relat bandwidth logic subdivid comput exist unsolv function halt problem comput absolut complex give upper lower bound amount resourc number gate comput given assert exponenti time algorithm travel salesman provid comput upper view brain comput unreason think cours evolutionari natur may face sever problem relat physic perhap minor degre logic complex theori broad could contribut futur understand parallel comput architectur issu natur synthet neural simpl theori parallel process macro level element develop base ratio time spent processor differ class problem differ architectur approach seem work parallel process level especi calcul intric neural connectionist model base common highli interconnect network linear threshold unit adjust interconnect shall review complex theori help contrast similar theori base boolean present rather inform technic complement easili found circuit cyclic orient graph connect boolean one boolean node graph correspond gate input output circuit total number gate depth length path connect one input width averag number comput unit hidden first obviou thing compar boolean threshold equival sens boolean function use either function comput depth two exponenti simpl count argument show fraction function requir circuit exponenti size approach one oo random function gener requir exponenti difficult construct famili function prove exponenti circuit threshold power boolean boolean gate comput one wherea threshold gate comput order function weight lower upper classic hyperplan count see instanc henc appear plausibl exist wide class problem threshold logic circuit substanti smaller requir boolean import result separ threshold boolean logic point view demonstr eleg result order comput function pariti circuit constant depth least boolean gate unbound fanin shall demonstr circuit depth two linear size comput function use threshold unusu hear discuss tradeoff depth width believ one main constribut analysi show tradeoff sens minim fact exist strong bia favor shallow constant multipl reason fix number differ function comput circuit small depth exce number comput deeper one priori knowledg function comput given hidden optim would choos circuit depth two rn unit singl view comput propag feedforward mode input output shallow circuit comput difficult becom issu time precis notic given overal hundr millisecond given known time scale synapt biolog circuitri must least within corrobor anatom rel slow neuron circuit architectur taken togeth understand necessari requir previou analysi emerg import class circuit threshold characteris polynomi size shallow seen random function can not comput mani structur far ask class function comput complet characteris probabl sever function known comput shallow symmetr function invaxi input import class structur problem implement shallow polynomi size function comput threshold circuit depth two linear hidden unit one output unit alway demonstr assert follow instruct consid take valu threshold gate axray possibl input row element row version row number row go monoton zero symmetr boolean function clearli assum valu element contigu row function assum valu form axe worst case occur pariti symmetr function comput gate singl hidden layer topmost activ number input exce number lower lowest proceed lowest number input exce number edg highest input string within band odd number hidden neuron activ contigu top hidden singl output unit comput symmetr easi see arithmet oper binari string perform polys small depth reif shown fix degre analyt function trigonometr approxim small shallow threshold mani situat one interest valu function vanishingli fraction total number possibl input implement polys shallow circuit one relat depth circuit cardin interest fax concern complex threshold turn complex problem find weight implement given consid problem repeat point colour two use hyperplan region contain axe fix problem solv polynomi either goe problem becom difficult see gener learn problem also differ proof proof fact alreadi case one singl threshold remark limit complex approach propo varieti structur boolean function implement low cost network linear threshold gate extens differ function continu alway restrict network rel simpl boolean devic linear threshold mani rel weak bound avail comput cost probabl singl import ingredi complet threshold unit interconnect aspect connectionist model complex result often asymptot natur may meaning rang correspond particular shall end section open question one time take leaxn often seen slow process artifici model back system human acquisit complex follow standard complex order effect wide varieti singl learn algorithm polynomi therefor learnabl exampl polynomi time polynomi size shallow statu back propag type algorithm respect question exist mani task easili execut biolog organ satisfactori comput program found far lead specif learn whether exist class problem function found exampl oppos tradit evid point valiant seen sens opposit conjectur one way function construct time can not invest polynomi time suggest algorithm may strict artifici seen program obtain learn outperform best alreadi known though may mani reason even complex class learn algorithm may import inexpens work polynomi time learn boolean formula explor addit limit learn exampl includ addit may therefor turn inexpens limit algorithm need incorpor global structur may evolut time learn process complement time type learn occur lifetim capac previou section focu investig structur cost network would comput specifi boolean consid dual comput capac threshold network issu turn mrli gener capac result favour shallow perhap circuit shall restrict specifi class problem associ quot princip result present involv proof elsewher consid system dens interact threshold unit instantan state correspond literatur ise system neural state henc set vertic discuss restrict attent throughout symmetr interact system wherein threshold element zd famili subset cardin set subset everi state set uz homogen algebra threshold network degre network threshold element interact specifi set real coeffici index evolut rule system readili seen natur generalis familiar case linear threshold ad degre interact coeffici potenti result enhanc flexibl program capabl linear case note independ sever author recent note product pariti correspond earlier hidden unit one layer follow singl threshold thu network realis network depth first layer second hidden layer output unit feedback input note weight input first hidden first hidden layer second fix variou weight second hidden output coeffici wx free system identifi either long rang interact spin glass zero neural start arbitrari configur system evolv asynchron singl flip involv spin misalign dynam symmetr system regul analog linear system extens quadrat defin homogen algebra hamiltonian algebra hamiltonian function akin behaviour classic hamiltonian previous demonstr function hd evolut rule terminolog spin state trajectori seen follow essenti mont carlo monoton algebra hamiltonian equat asynchron evolut rule system alway stabl state relat satisfi neural fix point henc arbit system determin comput capac behaviour applic somewhat differ depend interact random case random lend natur extens spin glass program yield applic extens neural network consid two case program interact queri whether given set binari store fix point suitabl select interact set prescrib vector store stabl state suitabl choic interact proposit ensur chosen vector bottom state space vector exercis region attract around characterest physic associ situat evolut network interpret term nearest neighbour search associ import maximum number state store fix point choic algebra threshold repres maxim storag capac neural repres degre algebra threshold let vector requir store fix point suitabl threshold henceforth refer prescrib vector defin storag capac algebra threshold network maxim number arbitraxili chosen memori high probabl appropri choic coeffici maxim storag capac algebra threshold network degre less equal sum classic hebbiazt rule case quot cazt natur extend coeffici zd axe construct sum kroneck storag capac algorithm appli algebra threshold network degre less thazt equal spectral spectral rule amount iter state orthogon onto lineax space gener take dosest point hypercub project extend denot matrix coeffici wt arrang symmetri natur interact relax increas let matrix form extend binari matrix diagon matrix posit diagon generalis spectral algorithm choos coeffici yield storag capac generalis spectral algorithm best random interact consid homogen algebra threshold network whose weight random natur generalis ise glass gaussian show asymptot estim number fix point asymptot result usual case linear threshold network gaussian interact report literatur set ui random vaxiabl ident jointli vaxiabl zero vaxianc given state stabl iff case fl revert usual case fix paramet fl measur deep well attract surround fix point follow proposit assert law govern expect number fix point well attract certain let expect number stabl correspond fix interact order exist posit axe paramet depend sole order conclus appear possibl design polynomi size threshold circuit comput wide class structur thesi shallow circuit effici deep circuit born paxticulax case garner result appear point neural network fix degre maxim number programm state order total number fix appear exponenti number least random interact though almost constant attract synaps per analog vlsi addison contribut theori neural california insitut june baldi stabl point spin glass network higher baldi point algebra threshold et order correl model associ network new aip edward theori ground state properti spin ise spin fox comput theori caltech concurr comput march grick aspect anatomi physiolog cerebr parallel distribut mit gross simplest spin optim lower bound small depth network physic sytem emerg collect connectionist learn variou node comput inform scienc technic learnabl boolean acm ganglion function dendrit hopfield associ ie eliec number stabl point spin glass jpl data acquisit progress mead analog vlsi neural addison complex polyhedr appear comput bound number threshold ie threshold logic wiley pele algorithm regular threshold psalti discrimin function associ neural network new aip threshold circuit polynomi method theori lower bound boolean acm theori linear map point applic pattern associ california institut venkatesh logarithm capac associ appear ie privat threshold gate ire hierarchi,2
6,6,"52 
Supervised Learning of Probability Distributions 
by Neural Networks 
Eric B. Baum 
Jet Propulsion Laboratory, Pasadena CA 91109 
Frank Wilczek 
Department of Physics,Harvard University, Cambridge MA 02138 
Abstract: 
We propose that the back propagation algorithm for super- 
vised learning can be generalized, put on a satisfactory conceptual 
footing, and very likely made more efficient by defining the val- 
ues of the output and input neurons as probabilities and varying 
the synaptic weights in the gradient direction of the log likelihood, 
rather than the 'error'. 
In the past thirty years many researchers have studied the 
question of supervised learning in 'neural'-like networks. Recently 
a learning algorithm called 'back propagation '-4 or the 'general- 
ized delta-rule' has been applied to numerous problems including 
the mapping of text to phonemes 5, the diagnosis of illnesses 6 and 
the classification of sonar targets 7. In these applications, it would 
often be natural to consider imperfect, or probabilistic informa- 
tion. We believe that by considering supervised learning from this 
slightly larger perspective, one can not only place back propaga- 
 Permanent address: Institute for Theoretical Physics, Univer- 
sity of California, Santa Barbara CA 93106 
American Institute of Physics 1988 
53 
tion on a more rigorous and general basis, relating it to other well 
studied pattern recognition algorithms, but very likely improve its 
performance as well. 
The problem of supervised learning is to model some mapping 
between input vectors and output vectors presented to us by some 
real world phenomena. To be specific, consider the question of 
medical diagnosis. The input vector corresponds to the symptoms 
of the patient; the i-th component is defined to be 1 if symptom i 
is present and 0 if symptom i is absent. The output vector corre- 
sponds to the illnesses, so that its j-th component is 1 if the j-th 
illness is present and 0 otherwise. Given a data base consisting 
of a number of diagnosed cases, the goal is to construct (learn) a 
mapping which accounts for these examples and can be applied to 
diagnose new patients in a reliable way. One could hope, for in- 
stance, that such a learning algorithm might yield an expert system 
to simulate the performance of doctors. Little expert advice would 
be required for its design, which is advantageous both because ex- 
perts' time is valuable and because experts often have extraodinary 
difficulty in describing how they make decisions. 
A feedforward neural network implements such a mapping be- 
tween input vectors and output vectors. Such a network has a set 
of input nodes, one or several layers of intermediate nodes, and a 
layer of output nodes. The nodes are connected in a forward di- 
rected manner, so that the output of a node may be connected to 
the inputs of nodes in subsequent layers, but closed loops do not 
occur. See figure 1. The output of each node is assumed to be a 
bounded semilinear function of its inputs. That is, if vj denotes 
the output of the j-th node and wij denotes the weight associated 
with the connection of the output of the j-th node to the input of 
54 
the i-th, then the i-th neuron takes value vi = g(]]j. wijvj), where 
g is a bounded, differentiable function called the activation func- 
tion. g(x) = 1/(1 + e-x), called the logistic function, is frequently 
used. Given a fixed set of weights {wij}, we set the input node 
values to equal some input vector, compute the value of the nodes 
layer by layer until we compute the output nodes, and so generate 
an output vector. 
Figure 1: A 5 layer network. Note bottleneck at layer 3. 
55 
Such networks have been studied because of analogies to neu- 
robiology, because it may be easy to fabricate them in hardware, 
and because learning algorithms such as the Perceptron learning 
algorithm s, Widrow- Hoff �, and backpropagation have been able 
to choose weights wij that solve interesting problems. 
Given a set of input vectors s, together with associated target 
values tq back propagation attempts to adjust the weights so as 
$' 
to minimize the error E in achieving these target values, defined as 
(1) 
' is the output of the j-th node when s ' is presented as 
where oa. 
input. Back propagation starts with randomly chosen wid and 
then varies in the gradient direction of E until a local minimum 
is obtained. Although only a locally optimal set of weights is ob- 
tained, in a number of experiments the neural net so generated 
has performed surprisingly well not only on the training set but on 
subsequent data. 4-� This performance is probably the main reason 
for widespread interest in backpropagation. 
It seems to us natural, in the context of the medical diagnosis 
problem, the other real world problems to which backpropagation 
has been applied, and indeed in any mapping problem where one 
desires to generalize from a limited and noisy set of examples, to 
interpret the output vector in probabilistic terms. Such an inter- 
pretation is standard in the literature on pattern classification. m 
Indeed, the examples might even be probabilistic themselves. That 
is to say it might not be certain whether symptom i was present 
in case/ or not. 
Let s� represent the probability symptom i is present in case 
' represent the probability disease j ocurred in case 
/% and let tj 
56 
/a. Consider for the moment the case where the t. are 1 or 0, 
so that the cases are in fact fully diagnosed. Let fj(�,$) be our 
prediction of the probability of disease j given input vector �, where 
 is some set of parameters determined by our learning algorithm. 
In the neural network case, the  are the connection weights and 
Now lacking a priori knowledge of good 0, the best one can do 
is to choose the parameters  to maximize the likelihood that the 
given set of examples should have occurred. i� The formula for this 
likelihood, p, is immediate: 
or 
log(p) --  [  log( f j ( ', ) ) +  
log(1- fj(�u,))] 
The extension of equation (2), and thus equation (3) to the 
case where the � are probabilities, taking values in [0, 1], is straight- 
57 
forward '1 and yields 
(4) 
Expressions of this sort often arise in physics and information the- 
ory and are generally interpreted as an entropy. TM 
We may now vary the {} in the gradient direction of the en- 
tropy. The back propagation algorithm generalizes immediately 
from minimizing 'Error' or 'Energy' to maximizing entropy or log 
likelihood, or indeed any other function of the outputs and the 
inputs TM. Of course it remains true that the gradient can be com- 
puted by back propagation with essentially the same number of 
computations as are required to compute the output of the net- 
work. 
A backpropagation algorithm based on log-likelihood is not 
only more intuitively appealing than one based on an ad-hoc def- 
inition of error, but will make quite different and more accurate 
predictions as well. Consider e.g. training the net on an exam- 
ple which it already understands fairly well. Say t] = 0, and 
fj(s �) = e. Now, from eqn(1) OE/Ofj = 2e, so using 'Error' as a 
* We may see this by constructing an equivalent larger set of 
examples with the  taking only values 0 or i with the appropriate 
frequency. Thus assume the tj are rational numbers with denomi- 
 and let p IIt,,j  What we mean by 
t, and numerator nj 
nator dj -- dj. 
the set of examples {t  �/ -- 1, ..., M} can be represented by con- 
ru=0 
sidering a set of N = Mp examples {} where for each/, tj 
'), and r, = 1 
for p(/- 1) < y <_ p/ and I <_ ymod(d) <_ (d - nj tj 
otherwise. Now applying equation (3) gives equation (4), up to an 
overall normalization. 
58 
criterion the net learns very little from this example, whereas, us- 
ing eqn(3), Olog(p)/Ofj = 1/(1 -), so the net continues to learn 
and can in fact converge to predict probabilities near 1. Indeed 
because backpropagation using the standard 'Error' measure can 
not converge to generate outputs of 1 or 0, it has been custom- 
ary in the literature 4 to round the target values so that a target 
of i would be presented in the learning algorithm as some ad hoc 
number such as .8, whereas a target of 0 would be presented as .2. 
In the context of our general discussion it is natural to ask 
whether using a feedforward network and varying the weights is in 
fact the most effective alternative. Anderson and Abrahams 3 have 
discussed this issue from a Bayesian viewpoint. From this point of 
view, fitting output to input using normal distributions and varying 
the means and covariance matrix may seem to be more logical. 
Feedforward networks do however have several advantages for 
complex problems. Experience with neural networks has shown the 
importance of including hidden units wherein the network can form 
an internal representation of the world. If one simply uses normal 
distributions, any hidden variables included will simply integrate 
out in calculating an output. It will thus be necessary to include at 
least third order correlations to implement useful hidden variables. 
Unfortunately, the number of possible third order correlations is 
very large, so that there may be practical obstacles to such an 
approach. Indeed it is well known folklore in curve fitting and 
pattern classification that the number of parameters must be small 
compared to the size of the data set if any generalization to future 
cases is expected. � 
In feedforward nets the question takes a different form. There 
can be bottlenecks to information flow. Specifically, if the net is 
59 
constructed with an intermediate layer which is not bypassed by 
any connections (i.e. there are no connections from layers preceding 
to layers subsequent), and if furthermore the activation functions 
are chosen so that the values of each of the intermediate nodes 
tend towards either i or 0 '2, then this layer serves as a bottleneck 
to information flow. No matter how many input nodes, output 
nodes, or free parameters there are in the net, the output will be 
constrained to take on no more than 2  different patterns, where 
I is the number of nodes in the bottleneck layer. Thus if I is 
small, some sort of 'generalization' must occur even if the number 
of weights is large. One plausible reason for the success of back 
propagation in adequately solving tasks, in spite of the fact that 
it finds only local minima, is its ability to vary a large number of 
parameters. This freedom may allow back propagation to escape 
from many putative traps and to find an acceptable solution. 
A good expert system, say for medical diagnosis, should not 
only give a diagnosis based on the available information, but should 
be able to suggest, in questionable cases, which lab tests might be 
performed to clarify matters. Actually back propagation inher- 
ently has such a capability. Back propagation involves calculation 
of Olog(p)/Owij. This information allows one to compute immedi- 
ately Olog(p)/Osj. Those input nodes for which this partial deriva- 
tive is large correspond to important experiments. 
In conclusion, we propose that back propagation can be gen- 
eralized, put on a satisfactory conceptual footing, and very likely 
made more efficient, by defining the values of the output and in- 
� 2 Alternatively when necessary this can be enforced by adding 
an energy term to the log-likelihood to constrain the parameter 
variation so that the neuronal values are near either I or 0. 
6O 
put neurons as probabilities, and replacing the 'Error' by the log- 
likelihood. 
Acknowledgement: E. B. Baum was supported in part by DARPA 
through arrangement with NASA and by NSF grant DMB-840649, 
802. F. Wilczek was supported in part by NSF grant PHY82-17853 
References 
(1)Werbos,P,""Beyond Regression: New Tools for Prediction and 
Analysis in the Behavioral Sciences"", Harvard University Disserta- 
tion (1974) 
(2)Parker D. B.,""Learning Logic"",MIT Tech Report TR-47, Center 
for Computationl Research in Economics and Management Science, 
MIT, 1985 
(3)Le Cun, Y., Proceedings of Cognitiva 85,p599-604, Paris (X9S5) 
(4)Rumelhart, D. E., Hinton, G. E., Williams, G. E., ""Learning 
Internal Representations by Error Propagation"", in ""Parallel Dis- 
tributed Processing"", vol 1, eds. Rumelhart, D. E., McClelland, J. 
L., MIT Press, Cambridge MA,(1986) 
(5)Sejnowski, T. J., Rosenberg, C. R., Complex Systems, v 1, pp 
145-168 (1987) 
(6)LeCun, Y., Address at 1987 Snowbird Conference on Neural 
Networks 
(7)Gorman, P., Sejnowski, T. J.,""Learned Classification of Sonar 
Targets Using a Massively Parallel Network"", in ""Workshop on 
Neural Network Devices and Applications"", JPLD-4406, (1987) 
pp224-237 
(8)Rosenblatt, F.,""Principles of Neurodynamics: Perceptrons and 
61 
the theory of brain mechanisms"", Spartan Books, Washington DC 
(1962) 
(9)Widrow, B., HolT, M. E., 1960 IRE WESCON Cony. Record, 
Part 4, 96-104 (1960) 
(10)Duda, R. O., Hart, P. E., ""Pattern Classification and Scene 
Analysis"", John Wiley and Sons, N.Y., (1973) 
(11)Guiasu, S., ""Information Theory with Applications"", McGraw 
Hill, NY, (1977) 
(12)Baum,E.B.,""Generalizing Back Propagation to Computation"", 
in ""Neural Networks for Computing"", AIP Conf. Proc. 151, Snow- 
bird UT (1986)pp47-53 
(13)Anderson, C.H., Abrahams, E.,""The Bayes Connection"", Pro- 
ceedings of the IEEE International Conference on Neural Networks, 
San Diego,(1987) 
", learn probabl distribut neural network baum propuls pasadena ca cambridg propos back propag algorithm learn put satisfactori conceptu like made effici defin output input neuron probabl vari synapt weight gradient direct log past thirti year mani research studi supervis learn recent learn algorithm call propag appli numer problem includ map text phonem diagnosi ill classif sonar target would natur consid probabilist believ consid supervis learn larger one place back perman institut theoret santa barbara ca institut physic rigor gener relat well pattern recognit like improv problem supervis learn model map input vector output vector present us world consid question input vector correspond symptom compon defin symptom present symptom output vector compon present given data base consist number diagnos goal construct account exampl appli new patient reliabl one could learn algorithm might yield expert system simul perform littl expert advic would requir advantag time valuabl expert often extraodinari describ make feedforward neural network implement map input vector output network set input one sever layer intermedi output node connect forward output node may connect input node subsequ close loop see figur output node assum semilinear function vj denot output node wij denot weight associ connect output node input neuron take valu vi differenti function call activ call logist frequent given fix set weight set input node equal input comput valu node layer comput output gener output layer note bottleneck layer network studi analog may easi fabric learn algorithm perceptron learn hoff backpropag abl choos weight wij solv interest set input vector togeth associ target tq back propag attempt adjust weight minim error achiev target defin output node present back propag start randomli chosen wid vari gradient direct local minimum although local optim set weight number experi neural net gener perform surprisingli well train set perform probabl main reason widespread interest seem us context medic diagnosi real world problem backpropag inde map problem one gener limit noisi set output vector probabilist standard literatur pattern exampl might even probabilist say might certain whether symptom present repres probabl symptom present case repres probabl diseas ocur case let tj consid moment case case fact fulli let probabl diseas given input vector set paramet determin learn neural network connect weight lack priori knowledg good best one choos paramet maxim likelihood set exampl formula extens equat thu equat take valu yield sort often aris physic inform gener interpret tm may vari gradient direct back propag algorithm gener immedi minim maxim entropi log inde function output cours remain true gradient back propag essenti number requir comput output backpropag algorithm base intuit appeal one base make quit differ accur consid train net alreadi understand fairli say use may see construct equival larger set take valu appropri thu assum tj ration number let mean numer nj dj set exampl repres set mp exampl tj nj tj appli equat give equat net learn littl net continu learn fact converg predict probabl near inde backpropag use standard measur converg gener output literatur round target valu target would present learn algorithm ad hoc wherea target would present context gener discuss natur ask use feedforward network vari weight effect anderson abraham issu bayesian point fit output input use normal distribut vari mean covari matrix may seem network howev sever advantag experi neural network shown includ hidden unit wherein network form intern represent one simpli use normal hidden variabl includ simpli integr calcul thu necessari includ third order correl implement use hidden number possibl third order correl may practic obstacl inde well known folklor curv fit classif number paramet must small size data set gener futur feedforward net question take differ bottleneck inform net intermedi layer bypass connect connect layer preced layer furthermor activ function chosen valu intermedi node toward either layer serv bottleneck inform matter mani input output free paramet output take differ number node bottleneck thu sort must occur even number weight one plausibl reason success back adequ solv spite fact find local abil vari larg number freedom may allow back propag escap mani put trap find accept good expert say medic give diagnosi base avail abl question lab test might clarifi actual back propag back propag involv calcul inform allow one comput input node partial larg correspond import propos back propag put satisfactori conceptu like defin valu output altern necessari enforc ad energi term constrain paramet neuron valu near either neuron replac baum support part darpa arrang nasa nsf grant wilczek support part nsf grant new tool predict behavior harvard univers tech report center computationl research econom manag proceed cognitiva pari represent error vol mit cambridg complex pp address snowbird confer neural classif sonar use massiv parallel network devic perceptron theori brain spartan washington dc ire wescon classif scene john wiley theori graw back propag network aip ut bay ie intern confer neural,0
7,7,"62 
Centric Models of the Orientation Map in Primary Visual Cortex 
William Baxter 
Department of Computer Science, S.U.N.Y. at Buffalo, NY 14620 
Bruce Dow 
Department of Physiology, S.U.N.Y. at Buffalo, NY 14620 
Abstract 
In the visual cortex of the monkey the horizontal organization of the preferred 
orientations of orientation-selective cells follows two opposing rules: 1) neighbors tend 
to have similar orientation preferences, and 2) many different orientations are observed 
in a local region. Several orientation models which satisfy these constraints are found 
to differ in the spacing and the topological index of their singularities. Using the rate 
of orientation change as a measure, the models are compared to published experimental 
results. 
Introduction 
It has been known for some years that there exist orientation-sensitive neurons in 
the visual cortex of cats and monkeys . These cells react to highly specific patterns of 
light occurring in narrowly circumscribed regions of the visual field, i.e, the cell's 
receptive field. The best patterns for such cells are typically not diffuse levels of 
illumination, but elongated bars or edges oriented at specific angles. An individual cell 
responds maximally to a bar at a particular orientation, called the preferred orienta- 
tion. Its response declines as the bar or edge is rotated away from this preferred orien- 
tation. 
Orientation-sensitive cells have a highly regular organi?ation in primary cortex 3. 
Vertically, as an electrode proceeds into the depth of the cortex, the column of tissue 
contains cells that tend to have the same preferred orientation, at least in the upper 
layers. Horizontally, as an electrode progresses across the cortical surface, the preferred 
orientations change in a smooth, regular manner, so that the recorded orientations 
appear to rotate with distance. It is this horizontal structure we are concerned with, 
hereafter referred to as the orientation map. An orientation map is defined as a two- 
dimensional surface in which every point has associated with it a preferred orientation 
ranging from 0 � � -- 180 �. In discrete versions, such as the army of cells in the cortex or 
the discrete simulations in this paper, the orientation map will be considered to be a 
sampled version of the underlying continuous surface. The investigations of this paper 
are confined to the upper layers of macaque striate cortex. 
Detailed knowledge of the two-dimensional layout of the orientation map has 
implications for the architecture, development, and function of the visual cortex. The 
organization of orientation-sensitive cells reflects, to some degree, the organization of 
intracortical connections in striate cortex. Plausible orientation maps can be generated 
by models with lateral connections that are uniformly exhibited by all cells in the 
layer 4, or by models which presume no specific intracortical connections, only 
appropriate patterns of afferent input 6. In this paper, we examine models in which 
intracortical connections produce the orientation map but the orientation-controlling 
circuitry is not displayed by all cells. Rather, it derives from localized ""centers"" which 
are distributed across the cortical surface with uniform spacing ?,8,9. 
American Institute of Physics 1988 
63 
The orientation map also represents a deformation in the retinotopy of primary 
visual cortex. Since the early sixties it has been known that V1 reflects a topographic 
map of the retina and hence the visual field �. There is some global distortion of this 
mapping ,2,s, but generally spatial relations between points in the visual field are 
maintained on the cortical surface. This well-known phenomenon is only accurate for 
a medium-grain description of V1, however. At a finer cellular level there is consider- 
able scattering of receptive fields at a given cortical location TM. The notion of the hyper- 
column s proposes that such scattering permits each region of the visual field to be 
analyzed by a population of cells consisting of all the necessary orientations and with 
inputs from both eyes. A quantitative description of the orientation map will allow 
prediction of the distances between iso-orientation zones of a particular orientation, 
and suggest how much cortical machinery is being brought to bear on the analysis of a 
given feature at a given location in the visual field. 
Models of the Orientation Map 
Hubel and Wiesel's Parallel Stripe Model 
The classic model of the orientation map is the parallel stripe model first pub- 
lished by Hubel and Wiesel in 1972 s. This model has been reproduced several times in 
their publications 3,s.7 and appears in many textbooks. The model consists of a series of 
parallel slabs, one slab for each orientation, which are postulated to be orthogonal to 
the ocular dominance stripes. The model predicts that a microelectrode advancing 
tangentially (i.e., horizontally) through the 
orientations. The rate of change, which is 
determined by the angle of the electrode 
stripes. 
tissue should encounter steadily changing 
also called the orientation drift rate 8, is 
with respect to the array of orientation 
The parallel stripe model does not account for several phenomena reported in 
long tangential penetrations through striate cortex in macaque monkeys ?,9. First, as 
pointed out by Swindale 2�, the model predicts that some penetrations will have flat or 
very low orientation drift rates over lateral distances of hundreds of micrometers. 
This is because an electrode advancing horizontally and perpendicular to the ocular 
dominance stripes (and therefore parallel to the orientation stripes) would be expected 
to remain within a single orientation column over a considerable distance with its 
orientation drift rate equal to zero. Such results have never been observed. Second, 
reversals in the direction of the orientation drift, from clockwise to counterclockwise 
or vice versa, are commonly seen, yet this phenomenon is not addressed by the parallel 
stripe model. Wavy stripes in the ocular dominace system  do not by themselves 
introduce reversals. Third, there should be a negative correlation between the orienta- 
tion drift rate and the ocularity ""drift rate"". That is, when orientation is changing 
rapidly, the electrode should be confined to a single ocular dominance stripe (low ocu- 
larity drift rate), whereas when ocularity is changing rapidly the electrode should be 
confined to a single orientation stripe (low orientation drift rate). This is clearly not 
evident in the recent studies of Livingstone and Hubel ? (see especially their figs. 3b, 
21 & 23), where both orientation and ocularity often have high drift rates in the same 
electrode track, i.e, they show a positive correlation. Anatomical studies with 2- 
deoxyglucose also fail to show that the orientation and ocular dominance column sys o 
tems are orthogonal 2. 
64 
Centric Models and the Topological Index 
Another model, proposed by Braitenberg and Braitenberg in 19797, has the orien- 
tations arrayed radially around centers like spokes in a wheel The centers are spaced at 
distances of about 0.Sram. This model produces reversals and also the sinusoidal pro- 
gressions frequently encountered in horizontal penetrations. However this approach 
suggests other possibilities, in fact an entire class of centtic models. The organizing 
centers form discontinuities in the otherwise smooth field of orientations. Different 
topological types of discontinuity are possible, characterized by their topological 
index 23. The topological index is a parameter computed by taking a path around a 
discontinuity and recording the rotation of the field elements (figure 1). The value of 
the index indicates the amount of rotation; the sign indicates the direction of rotation. 
An index of 1 signifies that the orientations rotate through 360�; an index of 1/2 
signifies a 180 � rotation. A positive index indicates that the orientations rotate in the 
same sense as a path taken around the singularity; a negative index indicates the 
reverse rotation. 
Topological singularities are stable under orthogonal transformations, so that if 
the field elements are each rotated 90 � the index of the singularity remains unchanged. 
Thus a +1 singularity may have orientations radiating out from it like spokes from a 
wheel, or it may be at the center of a series of concentric circles. Only four types of 
discontinuities are considered here, +1, -1, +1/2, -1/2, since these are the most stable, i.e., 
their neighborhoods are characterized by smooth change. 
I I I I I I 
// I 
% 
/ i I I , 
/ / / \ \ 
+1 +1/2 -1 
figure 1. Topological singularities. A positive index indicates that the orientations rotate 
in the same direction as a path taken around the singularity; a negative index indicates 
the reverse rotation. Orientations rotate through 360 � around +1 centers, 180 � around 
/2 centers. 
Cytochrome Oxidase Puffs 
At topological singularities the change in orientation is discontinuous, which 
violates the structure of a smoothly changing orientation map; modeHers try to 
minimize discontinuities in their models in order to satisfy the smoothness constraint. 
Interestingly, in the upper layers of striate cortex of monkeys, zones with little or no 
orientation selectivity have been discovered. These zones are notable for their high 
cytochrome oxidase reactivity 24 and have been referred to as cytochrome oxidase puffs, 
dots, spots, patches or blob 17252627. We will refer to them as puffs. If the organizing 
centers of centtic models are located in the cytochrome oxidase puffs then the discon- 
tinuities in the orientation map are effectively eliminated (but see below). Braitenberg 
has indicated 2s that the +1 centers of his model should correspond to the puffs. Dow 
and Bauer proposed a model s with +1 and -1 centers in alternating puffs. Gotz proposed 
a similar model 9 with alternating +1/2 and -1/2 centers in the puffs. The last two 
models manage to eliminate all discontinuities from the interpuff zones, but they 
65 
assume a perfect rectangular lattice of cytochrome oxidase puffs. 
A Set of Centric Models 
There are two parameters for the models considered here. (1) Whether the posi- 
tive singularities are placed in every puff or in alternate puffs; and (2) whether the 
singularities are +l's or a/2's. This gives four centric models (figure 2): 
E1 : +1 centers in puffs, -1 centers in the interpuff zones. 
A1 : both +1 and -1 centers in the puffs, interdigitated in a checkerboard fashion. 
E1/2 : +1/2 centers in the puffs, -1/2 centers in the interpuff zones 
A1/2 : both +1/2 and -1/2 centers in the puffs, as in A1. 
The E1 model corresponds to the Braitenberg model transposed to a rectangular array 
rather than an hexagonal one, in accordance with the observed organization of the 
cytochrome oxidase regions 27. In fact, the rectangular version of the Braitenberg model 
is pictured in figure 49 of 27. The A1 model was originally proposed by Dow and 
Bauer s and is also pictured in an article by Mitchison 29. The A1/2 model was proposed 
by Gotz 9. It should be noted that the E1 and A1 models are the same model rotated 
and scaled a bit; the E1/2 and A1/2 have the same relationship. 
E1 
E� 
A1 
A� 
figure 2. The four centric models. Dark ellipses represent cytochrome oxidase puffs. 
Dots in interpuff zones of E1 & E1/2 indicate singularities at those points. 
66 
Simulo. tions 
Simulated horizontal electrode recordings were made in the four models to com- 
pare their orientation drift rates with those of published recordings. In the computer 
simulations (figure 2) the interpuff distances were chosen to correspond to histological 
measuremen 27. Puff centers are separated by 500 along their long axes, 350 along 
the short axes. The density of the arrays was chosen to approximate the sampling fre- 
quency observed in Hubel and Wiesel's horizontal electrode recording experiments 9, 
about 20 cells per millimeter. Therefore the cell density of the simulation arrays was 
about six times that shown in the figure. 
All of the models produce simulated electrode data that qualitatively resemble 
the published recording results, e.g., they contain reversals, and runs of constantly 
changing orientations. The orientation drift rate and number of reversals vary in the 
different models. 
The models of figure 2 are shown in perfectly rectangular arrays. Some impor- 
tant characteristics of the models, such as the absence of discontinuites in interpuff 
zones, are dependent on this regularity. However, the real arrangement of cytochrome 
oxidase puffs is somewhat irregular, as in Horton's figure 327. A small set of puffs from 
the parafoveal region of Horton's figure was enlarged and each of the centtic models 
was embedded in this irregular array. The E1 model and a typical simulal electrode 
track are shown in figure 3. Several problems are encountered when models developed 
in a regular lattice are implemented in the irregular lattice of the real system; the 
models have appreciably different properties. The -1 singularities in �1's interpuff 
zones have been reduced to -�2�s; the A1 and A1/2 models now have some interpuff 
discontinuities where before they had none. 
Quantitative Comparisons 
Measurement of the Orientation Drift Rate 
There are two sets of centtic models in the computer simulations: a set in the per- 
fectly rectangular array (figure 2) and a set in the irregular puff array (as in figure 3). 
At this point we can generate as many tracks in the simulation arrays as we wish. 
How can this information be compared to the published records? The orientation drift 
rate, or slope, is one basis for distinguishing between models. In real electrode tracks 
however, the data are rather noisy, perhaps from the measuring process or from 
inherent unevenness of the orientation map. The typical approach is to fit a straight 
line and use the slope of this line. Reversals in the tracks require that lines be fit piece- 
wise, the approach used by Hubel and Wiesel 9. Because of the unevenness of the data 
it is not always clear what constitutes a reversal. Livingstone and Hubel 7 report that 
the track in their figure 5 has only two reversals in 5 millimeters. Yet there seem to be 
numerous microreversals between the 1st and 3rd millimeter of their track. At what 
point is a change in slope considered a true reversal rather than just noise? 
The approach used here was to use a local slope measure and ignore the problem 
of reversals - this permitted the fast calculation of slope by computer. A single elec- 
trode track, usually several millimeters long, was assigned a single slope, the average 
of the derivative taken at each point of the track. Since these are discrete samples, the 
local derivative must be approximated by taking measurements over a small neighbor- 
hood. How large should this neighborhood be? If too small it will be susceptible to 
noise in the orientation measures, if too large it will ""fiatten out"" true reversals. Slope 
67 
E1 
rlrq 
figure 3. A centric model in a realistic puff array (from2?). A simulated electrode track 
and resulting data are shown. Only the E1 model is shown here, but other models 
were similarly embedded in this array. 
68 
measures using neighborhoods of several sizes were applied to six published horizontal 
electrode tracks from the foveal and parafoveal upper layers of macaque striate cortex: 
figures 5,6,7 from ?, figure 16 from 3, figure 1 from 3�. A neighborhood of 0.1ram, 
which attempts to fit a line between virtually every pair of points, gave abnormally 
high slopes. Larger neighborhoods tended to give lower slopes, especially to those 
tracks which contained reversals. The smallest window that gave consistent measures 
for all six tracks was 0.2mm; therefore this window was chosen for comparisons 
between published data and the centric models. This measure gave an average slope of 
285 degrees per millimeter in the six published samples of track data, compared to 
Hubel & Wiesel's measure of 281 deg/mm for the penetrations in their 1974 pape r9. 
Slope measures of the centtic models 
The slope measure was applied to several thousand tracks at random locations 
and angles in the simulation arrays, and a slope was computed for each simulated elec- 
trode track. Average slopes of the models are shown in Table I. Generally, models 
with �1 centers have higher slopes than those with a/2 centers; models with centers 
in every puff have higher slopes than the alternate puff models. Thus E1 showed the 
highest orientation drift rate, A1/2 the lowest, with A1 and EV2 having intermediate 
rates. The E1 model, in both the rectangular and irregular arrays, produced the most 
realistic slope values. 
TABLE I Average slopes of the centric models 
Rectangular Irregular 
array array 
312 289 
216 216 
198 202 
117 144 
E1 
A1 
El/2 
A1/2 
Numbers are in degrees/mm. Slope measure (window = 0.2mm) applied 
to 6 published records yielded an average slope of 285 degrees/mm. 
Discussion 
Constraints on the Orientation Map 
Our original definition of the orientation map permits each cell to have an orien- 
tation preference whose angle is completely independent of its neighbors. But this is 
much too general. Looking at the results of tangential electrode penetrations, there are 
two striking constraints in the data. The first of these is reflected in the smoothness of 
the graphs. Orientation changes in a regular manner as the electrode moves horizon- 
tally through the upper layers: neighboring cells have similar orientation preferences. 
Discontinuities do occur but are rare. The other constraint is the fact that the orienta- 
tion is always changing with distance, although the rate of change may vary. 
Sequences of constant orientation are very rare and when they do occur they never 
carry on for any appreciable distance. This is one of the major reasons why the paral- 
lel stripe model is untenable. The two major constraints on the orientation map may 
be put informally as follows: 
69 
1. The smoothness constraint: neighboring points have similar orientation 
preferences. 
2. The heterogeneity constraint: all orientations should be represented 
within a small region of the cortical surface. 
This second constraint is a bit stronger than the data imply. The experimental results 
only show that the orientations change regularly with distance, not that all orienta- 
tions must be present within a region. But this constraint is important with respect to 
visual processing and the notion of hypercolumns 3. 
These are opposing constraints: the first tends to minimize the slope, or orienta- 
tion drift rate, while the second tends to maximize this rate. Thus the organization of 
the orientation map is analogous to physical systems that exhibit ""frustration"", that is, 
the elements must satisfy conflicting constraints 3. One of the properties of such sys- 
tems is that there are many near-optimal solutions, no one of which is significantly 
better than the others. As a result, there are many plausible orientation maps: any map 
that satisfies these two constraints will generate qualitatively plausible simulated elec- 
trode tracks. This points out the need for quantitative comparisons between models 
and experimental results. 
Centric models and the two constraints 
What are some possible mechanisms of the constraints that generate the orienta- 
tion map? Smoothness is a local property and could be attributed to the workings of 
individual cells. It seems to be a fundamental property of cortex that adjacent cells 
respond to similar stimuli. The heterogeneity requirement operates at a slightly larger 
scale, that of a hypercolumn rather than a minicolumn. While the first constraint may 
be modeled as a property of individual cells, the second constraint is distributed over a 
region of cells. How can such a collection of cells insure that its members cycle 
through all the required orientations? The topological singularities discussed earlier, by 
definition, include all orientations within a restricted region. By distributing these 
centers across the surface of the cortex, the heterogeneity constraint may be satisfied. In 
fact, the amount of orientation drift rate is a function of the density of this distribu- 
tion (i.e., more centers per unit area give higher drift rates). 
It has been noted that the E1 and the A1 organizations are the same topological 
model, but on different scales; the low drift rates of the A1 model may be increased by 
increasing the density of the +1 centers to that of the E1 model. The same relationship 
holds for the El/2 and A1/2 models. It is also possible to obtain realistic orientation drift 
rates by increasing the density of +1/2 centers, or by mixing +l's and +1/2's. However, 
these alternatives increase the number of interpuff singularities. And given the possible 
combinations of centers, it may be more than coincidental that a set of +1 centers at 
just the spacing of the cytochrome oxidase regions results in realistic orientation drift 
rates. 
Cortical Architecture and Types of Circuitry 
Thus far, we have not addressed the issue of how the preferred orientations are 
generated. The mechanism is presently unknown, but attempts to depict it have tradi- 
tionally been of a geometric nature, alluding to the dendritic morphologf '282. More 
recently, computer simulations have shown that orientation-sensitive units may be 
obtained from asymmetries in the receptive fields of afferents 6, or developed using 
7O 
simple Hebbian rules for altering synaptic weights 5. That is, given appropriate net- 
work parameters, orientation tuning arises an as inherent property of some neural net- 
works. Centtic models propose a quite different approach in which an originally 
untuned cell is ""programmed"" by a center located at some distance to respond to a 
specific orientation. So, for an individual cell, does orientation develop locally, or is it 
""imposed from without""? Both of these mechanisms may be in effect, acting synergisti- 
cally to produce the final orientation map. The map may spontaneously form on the 
embryonic cortex, but with cells that are nonspecific and broadly tuned. The organiza- 
tion imposed by the centers could have two effects on this incipient map. First, the 
additional influence from centers could ""tighten up"" the tuning curves, making the 
cells more specific. Second, the spacing of the centers specifies a distinct and uniform 
scale for the heterogeneity of the map. An unsupervised developing orientation map 
could have broad expanses of iso-orientation zones mixed with regions of rapidly 
changing orientations. The spacing of the puffs, hence the architecture of the cortex, 
insures that there is an appropriate variety of feature sensitive cells at each location. 
This has implications for cortical functioning: given the distances of lateral connec- 
tivity, for a cell of a given orientation, we can estimate how many other iso- 
orientation zones of that same orientation the cell may be communicating with. For a 
given orientation, the E1 model has twice as many iso-orientation zones per unit area 
as A1. 
Ever since the discovery of orientation-specific cells in visual cortex there have 
been attempts to relate the distribution of cell selectivities to architectural features of 
the cortex. Hubel and Wiesel originally suggested that the orientation slabs followed 
the organization of the ocular dominance slabs s. The Braitenbergs suggested in their 
original model ? that the centers might be identified with the giant cells of Meynert. 
Later centric models have identified the centers with the cytochrome oxidase regions, 
again relating the orientation map to the ocular dominance array, since the puffs them- 
selves are closely related to this array. 
While biologists have habitually related form to function, workers in machine 
vision have traditionally relied on general-purpose architectures to implement a 
variety of algorithms related to the processing of visual information 33. More recently, 
many computer scientists designing artificial vision systems have turned their atten- 
tion towards connectionist systems and neural networlm There is great interest in 
how the sensitivities to different features and how the selectivities to different values 
of those features may be embedded in the system architecture 34sa6. Linsker has pro- 
posed (this volume) that the development of feature spaces is a natural concomitance 
of layered networks, providing a generic organizing principle for networks. Our work 
deals with more specific cortical architectonics, but we are convinced that the study of 
the cortical layout of feature maps will provide important insights for the design of 
artificial systems. 
References 
1. D. Hubel & T. Wiesel, J. Physid. (Lond.) 160, 106 (1962). 
2. D. Hubel & T. Wiesel, J. Physiol. (Lond.) 195, 225 (1968). 
3. D. Hubel & T. Wiesel, Proc. Roy. Soc. Lond. B 198, 1 (1977). 
4. N. Swindale, Proc. Roy. $oc. Ionel. B 215, 211 (1982). 
5. R.Linsker, Proc. Natl. Acad. $ci. USA 83, 8779 (1986). 
6. R. Soodak, Proc. Natl. Acad. $ci. USA 84, 3936 (1987). 
71 
7. V. Braitenberg & C. Braitenberg, Biol. Cyber. 33, 179 (1979). 
8. B. Dow & R. Bauer, Biol. Cyber. 49, 189 (1984). 
9. K. Gotz, Biot. Cyber. 56, 107 (1987). 
10. P. Daniel & D. Whitteridge, J. Physiol. (Lond.) 159, 302 (1961). 
11. B. Dow, R. Vautin & R. Bauer, J. Neurosci. 5, 890 (1985). 
12. R.B. Tootell, M.S. Silverman, E. Switkes & R. DeValois, Science 218, 902 (1982). 
13. D.C. Van Essen, W.T. Newsome & J.H. Maunsell, Vision Research 24, 429 (1984). 
14. D. Hubel & T. Wiesel, J. Comp. Neurol. 158, 295 (1974). 
15. D. Hubel & T. Wiesel, J. Comp. Neurol. 146, 421 (1972). 
16. D. Hubel, Nature 299, 515 (1982). 
17. M. Livingstone & D. Hubel, J. Neurosci. 4, 309 (1984). 
18. R. Bauer, B. Dow, A. Snyder & R. Vautin, Exp. Brain Res. 50, 133 (1983). 
19. D. Hubel & T. Wiesel, J. Comp. Neurol. 158, 267 (1974). 
20. N. Swindale, in Models of the Visual Cortex, D. Rose & V. Dobson, eds., 
(Wiley, 1985), p. 452. 
21. S. LeVay, D. Hubel, & T. Wiesel, J. Comp. Neurol. 159, 559 (1975). 
22. D. Hubel, T. Wiesel & M. Stryker, J. Comp. Neurol. 177, 361 (1978). 
23. T. Elsdale & F. Wasoff, Wilhelm Roux's Archives 180, 121 (1976). 
24. M.T. Wong-Riley, Brain Res. 162, 201 (1979). 
25. A. Humphrey & A. Hendrickson, J. Neurosci. 3, 345 (1983). 
26. E. Carroll & M. Wong-Riley, J. Comp. Neurol. 222, 1 (1984). 
27. J. Horton, Proc. Roy. Soc. Lond. B 304, 199 (1984). 
28. V. Braitenberg, in Models of the Visual Cortex, p. 479. 
29. G. Mitchison, in Models of the Visual Cortex, p. 443. 
30. C. Michael, Vision Research 25 415 (1985). 
31. S. Kirkpatrick, M. Gelart & M. Vecchi, Science 220, 671 (1983). 
32. S. Tieman & H. Hirsch, in Models of the Visual Cortex, p. 432. 
33. D. Ballard & C. Brown Computer Vision (Prentice-Hall, N.J., 1982). 
34. D. Ballard, G. Hinton, & T. Sejnowski, Nature 306, 21 (1983). 
35. D. Ballard, Behar. and Brain Sc/. 9, 67 (1986). 
36. D. Walters, Proc. First Int. Conf. on Neural Networks (June 1987). 
", model orient map primari visual cortex baxter comput ny dow ny visual cortex monkey horizont organ prefer cell follow two oppos neighbor tend similar orient mani differ orient observ local sever orient model satisfi constraint found differ space topolog index use rate orient chang model compar publish experiment known year exist neuron visual cortex cat monkey cell react highli specif pattern occur narrowli circumscrib region visual best pattern cell typic diffus level elong bar edg orient specif individu cell maxim bar particular call prefer respons declin bar edg rotat away prefer cell highli regular primari cortex electrod proce depth column tissu cell tend prefer least upper electrod progress across cortic prefer chang regular record orient rotat horizont structur concern refer orient orient map defin surfac everi point associ prefer orient discret armi cell cortex discret simul orient map consid version underli continu investig paper confin upper layer macaqu striat knowledg layout orient map function visual cell organ connect striat plausibl orient map gener model later connect uniformli exhibit cell model presum specif intracort pattern affer input examin model connect produc orient map display deriv local distribut across cortic surfac uniform space institut physic orient map also repres deform retinotopi primari sinc earli sixti known reflect topograph retina henc visual field global distort gener spatial relat point visual field cortic phenomenon accur descript finer cellular level scatter recept field given cortic locat notion propos scatter permit region visual field popul cell consist necessari orient quantit descript orient map allow distanc zone particular suggest much cortic machineri brought bear analysi featur given locat visual orient map parallel stripe model classic model orient map parallel stripe model first hubel wiesel model reproduc sever time public appear mani model consist seri one slab postul orthogon ocular domin model predict microelectrod advanc rate angl electrod encount steadili chang call orient drift rate respect array orient parallel stripe model account sever phenomena report tangenti penetr striat cortex macaqu monkey swindal model predict penetr flat low orient drift rate later distanc hundr electrod advanc horizont perpendicular ocular stripe therefor parallel orient would expect remain within singl orient column consider distanc drift rate equal result never direct orient clockwis counterclockwis vice commonli yet phenomenon address parallel wavi stripe ocular dominac system neg correl drift rate ocular orient chang electrod confin singl ocular domin stripe drift wherea ocular chang rapidli electrod singl orient stripe orient drift clearli recent studi livingston hubel especi orient ocular often high drift rate show posit anatom studi also fail show orient ocular domin column sy orthogon model topolog index propos braitenberg braitenberg array radial around center like spoke wheel center space model produc revers also sinusoid frequent encount horizont howev approach fact entir class centtic organ form discontinu otherwis smooth field differ type discontinu character topolog topolog index paramet comput take path around record rotat field element valu index indic amount sign indic direct index signifi orient rotat index posit index indic orient rotat sens path taken around neg index indic singular stabl orthogon field element rotat index singular remain singular may orient radiat like spoke may center seri concentr four type consid sinc neighborhood character smooth topolog posit index indic orient rotat direct path taken around neg index indic revers orient rotat around around oxidas puff topolog singular chang orient structur smoothli chang orient tri discontinu model order satisfi smooth upper layer striat cortex zone littl select zone notabl high oxidas reactiv refer cytochrom oxidas patch refer organ centtic model locat cytochrom oxidas puff orient map effect elimin see braitenberg indic center model correspond dow bauer propos model center altern gotz propos similar model altern center last two manag elimin discontinu interpuff perfect rectangular lattic cytochrom oxidas set centric model two paramet model consid whether singular place everi puff altern whether give four centric model center center interpuff center interdigit checkerboard center center interpuff center model correspond braitenberg model transpos rectangular array hexagon accord observ organ oxidas region rectangular version braitenberg model pictur figur model origin propos dow also pictur articl mitchison model propos gotz note model model rotat scale four centric dark ellips repres cytochrom oxidas interpuff zone indic singular tion horizont electrod record made four model orient drift rate publish comput interpuff distanc chosen correspond histolog puff center separ along long along short densiti array chosen approxim sampl observ hubel horizont electrod record experi cell per therefor cell densiti simul array six time shown model produc simul electrod data qualit resembl publish record contain run constantli orient drift rate number revers vari model figur shown perfectli rectangular characterist absenc discontinuit interpuff depend real arrang cytochrom puff somewhat figur small set puff parafov region figur enlarg centtic model embed irregular model typic electrod shown figur sever problem encount model develop regular lattic implement irregular lattic real appreci differ singular interpuff reduc model interpuff comparison orient drift rate two set centtic model comput set rectangular array set irregular puff array figur point gener mani track simul array inform compar publish orient drift one basi distinguish real electrod track data rather perhap measur process uneven orient typic approach fit straight use slope revers track requir line fit approach use hubel wiesel uneven data alway clear constitut livingston hubel report track figur two revers yet seem microrevers millimet chang slope consid true revers rather approach use use local slope measur ignor problem revers permit fast calcul slope singl usual sever millimet assign singl averag deriv taken point sinc discret deriv must approxim take measur small larg neighborhood small suscept orient larg true slope centric model realist puff array simul electrod track result data model shown model similarli embed use neighborhood sever size appli six publish horizont track foveal parafov upper layer macaqu striat figur figur neighborhood attempt fit line virtual everi pair gave abnorm larger neighborhood tend give lower especi contain smallest window gave consist measur six track therefor window chosen comparison publish data centric measur gave averag slope degre per millimet six publish sampl track compar measur penetr pape measur centtic model slope measur appli sever thousand track random locat angl simul slope comput simul averag slope model shown tabl model center higher slope model center everi puff higher slope altern puff thu show orient drift intermedi rectangular irregular produc slope averag slope centric model irregular array slope measur appli publish record yield averag slope orient map origin definit orient map permit cell prefer whose angl complet independ look result tangenti electrod strike constraint first reflect smooth orient chang regular manner electrod move upper neighbor cell similar orient occur constraint fact alway chang although rate chang may constant orient rare occur never appreci one major reason stripe model two major constraint orient map may put inform smooth neighbor point similar orient heterogen orient repres small region cortic second constraint bit stronger data experiment result show orient chang regularli must present within constraint import respect process notion hypercolumn oppos first tend minim drift second tend maxim thu organ orient map analog physic system exhibit element must satisfi conflict constraint one properti mani one significantli mani plausibl orient map satisfi two constraint gener qualit plausibl simul point need quantit comparison model experiment model two constraint possibl mechan constraint gener smooth local properti could attribut work seem fundament properti cortex adjac cell similar heterogen requir oper slightli larger hypercolumn rather first constraint may model properti individu second constraint distribut collect cell insur member cycl requir topolog singular discuss includ orient within restrict distribut across surfac heterogen constraint may amount orient drift rate function densiti center per unit area give higher drift note organ topolog differ low drift rate model may increas densiti center relationship also possibl obtain realist orient drift increas densiti mix altern increas number interpuff given possibl may coincident set center space cytochrom oxidas region result realist orient drift architectur type circuitri address issu prefer orient mechan present attempt depict geometr allud dendrit morphologf comput simul shown unit may asymmetri recept field affer develop use hebbian rule alter synapt weight given appropri orient tune aris inher properti neural centtic model propos quit differ approach origin cell center locat distanc respond individu orient develop mechan may act produc final orient map may spontan form cell nonspecif broadli impos center could two effect incipi influenc center could tune make space center specifi distinct uniform heterogen unsupervis develop orient map broad expans zone mix region rapidli space henc architectur appropri varieti featur sensit cell implic cortic given distanc later cell given estim mani zone orient cell may commun model twice mani zone per unit area sinc discoveri cell visual cortex attempt relat distribut cell select architectur featur hubel wiesel origin suggest orient slab follow organ ocular domin slab braitenberg suggest model center might identifi giant cell centric model identifi center cytochrom oxidas relat orient map ocular domin sinc puff close relat biologist habitu relat form worker machin tradit reli architectur implement algorithm relat process visual inform comput scientist design artifici vision system turn toward connectionist system neural networlm great interest sensit differ featur select differ valu featur may embed system architectur linsker develop featur space natur concomit layer provid gener organ principl work specif cortic convinc studi cortic layout featur map provid import insight design hubel hubel hubel usa usa braitenberg dow daniel vautin switk scienc van newsom vision research hubel hubel natur livingston snyder brain hubel model visual rose wiesel elsdal wilhelm archiv brain humphrey carrol model visual model visual vision research gelart scienc tieman model visual ballard brown comput vision natur brain first neural network,1
8,8,"72 
ANALYSIS AND COMPARISON OF DIFFERENT LEARNING 
ALGORITHMS FOR PATTERN ASSOCIATION PROBLEMS 
J. Bernasconi 
Brown Boveri Research Center 
CH-5405 Baden, Switzerland 
ABSTRACT 
We investigate the behavior of different learning algorithms 
for networks of neuron-like units. As test cases we use simple pat- 
tern association problems, such as the XOR-problem and symmetry de- 
tection problems. The algorithms considered are either versions of 
the Boltzmann machine learning rule or based on the backpropagation 
of errors. We also propose and analyze a generalized delta rule for 
linear threshold units. We find that the performance of a given 
learning algorithm depends strongly on the type of units used. In 
particular, we observe that networks with �1 units quite generally 
exhibit a significantly better learning behavior than the correspon- 
ding 0,1 versions. We also demonstrate that an adaption of the 
weight-structure to the symmetries of the problem can lead to a 
drastic increase in learning speed. 
INTRODUCTION 
In the past few years, a number of learning procedures for 
neural network models with hidden units have been proposed 1'2 They 
can all be considered as strategies to minimize a suitably chosen 
error measure. Most of these strategies represent local optimization 
procedures (e.g. gradient descent) and therefore suffer from all the 
problems with local minima or cycles. The corresponding learning 
rates, moreover, are usually very slow. 
The performance of a given learning scheme may depend critical- 
ly on a number of parameters and implementation details. General 
analytical results concerning these dependences, however, are prac- 
tically non-existent. As a first step, we have therefore attempted 
to study empirically the influence of some factors that could have a 
significant effect on the learning behavior of neural network sys- 
tems. 
Our preliminary investigations are restricted to very small 
networks and to a few simple examples. Nevertheless, we have made 
some interesting observations which appear to be rather general and 
which can thus be expected to remain valid also for much larger and 
more complex systems. 
NEURAL NETWORK MODELS FOR PATTERN ASSOCIATION 
An artificial neural network consists of a set of interconnec- 
ted units (formal neurons). The state of the i-th unit is described 
by a variable So which can be discrete (e.g. So = 0,1 or So = �1) or 
1 
continuous (e.g . 0 < So < 1 or -1 < So < +1) , and each connection 
j+i carries a weighW  hich can be oitive, zero, or negative 
x3 
American Institute of Physics 1988 
The dynamics of the network is determined by a local update 
rule, 
Si(t+l ) = f(l Wij So(t)) (1) 
j  ' 
where f is a nonlinear activation function, specifically a threshold 
function in the case of discrete units and a sigmoid-type function, 
e.g. 
f(x) = 1/(l+e -x) (2) 
or 
f(x) = (1-e-X)/(l+e -x) , (3) 
respectively, in the case of continuous units. The individual units 
can be given different thresholds by introducing an extra unit which 
always has a value of 1. 
If the network is supposed to perform a pattern association 
task, it is convenient to divide its units into input units, output 
units, and hidden units. Learning then consists in adjusting the 
weights in such a way that, for a given input pattern, the network 
relaxes (under the prescribed dynamics) to a state in which the 
output units represent the desired output pattern. 
Neural networks learn from examples (input/output pairs) which 
are presented many times, and a typical learning procedure can be 
viewed as a strategy to minimize a suitably defined error function 
F. In most cases, this strategy is a (stochastic) gradient descent 
method: To a clamped input pattern, randomly chosen from the lear- 
ning examples, the network produces an output pattern {Oi}. This is 
compared with the desired output, say {T.}, and the error F({Oi} , 
1 . 
{Ti}) is calculated. Subsequently, each wetght is changed by an 
amount proportional to the respective gradient of F, 
F 
awij = -"" ' (4) 
and the procedure is repeated for a new learning example until F is 
minimized to a satisfactory level. 
In our investigations, we shall consider two different types of 
learning schemes. The first is a deterministic version of the Boltz- 
mann machine learning rule 1 and has been proposed by Yann Le Cun . 
It applies to networks with symmetric weights, Wij = Wji , so that an 
energy 
E(S) = - W.. S.S. (5) 
- (i,j) x3 x 3 
can be associated with each state S = {S:}. If X refers to the net- 
work state when only the input units areXclampe and Y to the state 
when both the input and output units are clamped, the error function 
74 
is defined as 
F = E(_Y) - E(X) 
(6) 
and the gradients are simply given by 
F 
aw.. - Y' Y' -x.x. (7) 
� 3 � 3 
The second scheme, called backpropagation or generalized delta 
rule 1'3, probably represents the most widely used learning algorithm. 
In its original form, it applies to networks with feedforward connec- 
tions only, and it uses gradient descent to minimize the mean squared 
error of the output signal, 
oi )2 
F =  Y (T i - (8) 
1 
For a weight W.o from an (input or hidden) unit j to an output 
unit i, we simply hv 
F 
- (T - O.)f'(Y Wik Sk)S (9) 
8Wij i  k J ' 
where f' is the derivative of the nonlinear activation function 
introduced in Eq. (1), and for weights which do not connect to an 
output unit, the gradients can successively be determined by apply- 
ing the chain rule of differentiation. 
In the case of discrete units, f is a threshold function, so 
that the backpropagation algorithm described above cannot be applied. 
We remark, however, that the perceptron learning rule 4, 
AWi3 = s(T. - O )Sj (10) 
� x i ' 
is nothing else than Eq. (9) with f' replaced by a constant s. 
Therefore, we propose that a generalized delta rule for linear 
threshold units can be obtained if f' is replaced by a constant g in 
all the backpropagation expressions for 3F/3W... This generalization 
of the perceptron rule is, of course, not nque. In layered net- 
works, e.g., the value of the constant which replaces f' need not be 
the same for the different layers. 
ANALYSIS OF LEARNING ALGORITHMS 
The proposed learning algorithms suffer from all the problems 
of gradient descent on a complicated landscape. If we use small 
weight changes, learning becomes prohibitively slow, while large 
weight changes inevitably lead to oscillations which prevent the 
algorithm from converging to a good solution. The error surface, 
moreover, may contain many local minima, so that gradient descent is 
not guaranteed to find a global minimum. 
There are several ways to improve a stochastic gradient descent 
procedure. The weight changes may, e.g., be accumulated over a 
number of learning examples before the weights are actually changed. 
Another often used method consists in smoothing the weight changes 
by overrelaxation, 
F +  AWoo(k) , (11) 
AWij (k+l) = - Wo. 3 
z0 
where AW.o(k) refers to the weight change after the presentation of 
the k-thearning example (or group of learning examples, respecti- 
vely). The use of a weight decay term, 
� = 
AWi 3 8W.. 3 ' 
x3 
prevents the algorithm from generating very large weights which may 
create such high barriers that a solution cannot be found in reason- 
able time. 
Such smoothing methods suppress the occurrence of oscillations, 
at least to a certain extent, and thus allow us to use higher lear- 
ning rates. They cannot prevent, however, that the algorithm may 
become trapped in bad local minimum. An obvious way to deal with the 
problem of local minima is to restart the algorithm with different 
initial weights or, equivalently, to randomize the weights with a 
certain probability p during the learning procedure. More sophisti- 
cated approaches involve, e.g., the use of hill-climbing methods. 
The properties of the error-surface over the weight space not 
only depend on the choice of the error function F, but also on the 
network architecture, on the type of units used, and on possible 
restrictions concerning the values which the weights are allowed to 
a s s u/e. 
The performance of a learning algorithm thus depends on many 
factors and parameters. These dependences are conveniently analyzed 
in terms of the behavior of an appropriately defined learning curve. 
For our small examples, where the learning set always consists of 
all input/output cases, we have chosen to represent the performance 
of a learning procedure by the fraction of networks that are 
""perfect"" after the presentation of N input patterns. (Perfect net- 
works are networks which for every input pattern produce the correct 
output). Such learning curves give us much more detailed information 
about the behavior of the system than, e.g., averaged quantities 
like the mean learning time. 
RESULTS 
In the following, we shall present and discuss some represen- 
tative results of our empirical study. All learning curves refer to 
a set of 100 networks that have been exposed to the same learning 
procedure, where we have varied the initial weights, or the sequence 
76 
of learning examples, or both. With one exception (Figure 4), the 
sequences of learning examples are always random. 
A prototype pattern association problem is the exclusive-or 
(XOR) problem. Corresponding networks have two input units and one 
output unit. Let us first consider an XOR-network with only one 
hidden unit, but in which the input units also have direct connec- 
tions to the output unit. The weights are symmetric, and we use the 
deterministic version of the Boltzmann learning rule (see Eqs. (5) 
to (7)). Figure 1 shows results for the case of tabula rasa initial 
conditions, i.e. the initial weights are all set equal to zero. If 
the weights are changed after every learning example, about 2/3 of 
the networks learn the problem with less than 25 presentations per 
pattern (which corresponds to a total number of 4 x 25 = 100 presen- 
tations). The remaining networks (about 1/3), however, never learn 
to solve the XOR-problem, no matter how many input/output cases are 
presented. This can be understood by analyzing the corresponding 
evolution-tree in weight-space which contains an attractor consis- 
ting of 14 ""non-perfect"" weight-configurations. The probability to 
become trapped by this attractor is exactly 1/3. If the weight 
changes are accumulated over 4 learning examples, no such attractor 
too 
v, 80- 
o 
 80- 
J 0- 
0- 
o 
0 
o 
I I I I 
o o o 
o 
o o 
 oooo 
� o o 
� o 
� o o 
e o � 
� o 
o 
o 
i I I I 
20 40 60 80 100 
PRESENTATIONS/PATTERN 
Fig. 1. Learning curves for an XOR-network with one hidden unit 
(deterministic Boltzmann learning, discrete �1 units, initial 
weights zero). Full circles: weights changed after every learning 
example; open circles: weight changes accumulated over 4 learning 
examples. 
?? 
seems to exist (see Fig. 1), but for some networks learning at least 
takes an extremely long time. The same saturation effect is observed 
with random initial weights (uniformly distributed between -1 and 
+1), see Fig. 2. 
Figure 2 also exhibits the difference in learning behavior 
between networks with �1 units and such with 0,1 units. In both 
cases, weight randomization leads to a considerably improved lear- 
ning behavior. A weight decay term, by the way, has the same effect. 
The most striking observation, however, is that �1 networks learn 
much faster than 0,1 networks (the respective average learning times 
differ by about a factor of 5). In this connection, we should mention 
that  = 0.1 is about optimal for 0,1 units and that for �1 networks 
the learning behavior is practically independent of the value of . 
It therefore seems that �1 units lead to a much more well-behaved 
error-surface than 0,1 units. One can argue, of course, that a 
discrete 0,1 model can always be translated into a �1 model, but 
this would lead to an energy function which has a considerably more 
complicated weight dependence than Eq. (5). 
too 
8o 
6o 
4o 
2o 
o 
2 
5 to 2o 50 1oo 200 t000 
PRESENTATIONS / PATTERN 
Fig. 2. Learning curves for an XOR-network with one hidden unit 
(deterministic Boltzmann learning, initial weights random, weight 
changes accumulated over 5 learning examples). Circles: discrete �1 
units,  = 1; triangles: discrete 0,1 units,  = 0.1; broken curves: 
without weight randomization; solid curves: with weight randomiza- 
tion (p = 0.025). 
78 
Figures 3 and 4 refer to a feedforward XOR-network with 3 
hidden units, and to backpropagation or generalized delta rule 
learning. In all cases we have included an overrelaxation (or momen- 
tum) term with  = 0.9 (see Eq. (11)). For the networks with contin- 
uous units we have used the activation functions given by Eqs. (2) 
and (3), respectively, and a network was considered ""perfect"" if for 
all input/output cases the error was smaller than 0.1 in the 0,1 
case, or smaller than 0.2 in the �1 case, respectively. 
In Figure 3, the weights have been changed after every learning 
example, and all curves refer to an optimal choice of the only 
remaining parameter,  or Q, respectively. For discrete as well as 
for continuous units, the �1 networks again perform much better than 
their 0,1 counterparts. In the continuous case, the average learning 
times differ by about a factor of 7, and in the discrete case the 
discrepancy is even more pronounced. In addition, we observe that in 
�1 networks learning with the generalized delta rule for discrete 
units is about twice as fast as with the backpropagation algorithm 
for continuous units. 
too 
I I I 
v 80 
o 
 60 
a 40 
' 20' 
0 I 
,5 10 20 ,50 t00 200 .500 1000 
PRESENTATIONS / PATTERN 
Fig. 3. Learning curves for an XOR-network with three hidden units 
(backpropagation/generalized delta rule, initial weights random, 
weights changed after every learning example). Open circles: discre- 
te �1 units, g = 0.05; open triangles: discrete 0,1 units, g = 0.025; 
full circles: continuous �1 units, Q = 0.125; full triangles; contin- 
uous 0,1 units, Q = 0.25. 
79 
In Figure 4, the weight changes are accumulated over all 4 
input/output cases, and only networks with continuous units are 
considered. Also in this case, the �1 units lead to an improved 
learning behavior (the optimal q-values are about 2.5 and 5.0, 
respectively). They not only lead to significantly smaller learning 
times, but �1 networks also appear to be less sensitive with respect 
to a variation of q than the corresponding 0,1 versions. 
The better performance of the �1 models with continuous units 
can partly be attributed to the steeper slope of the chosen activa- 
tion function, Eq. (3). A comparison with activation functions that 
have the same slope, however, shows that the networks with �1 units 
still perform significantly better than those with 0,1 units. If the 
weights are updated after every learning example, e.g., the reduc- 
tion in learning time remains as large as a factor of 5. In the case 
of backpropagation learning, the main reason for the better perfor- 
mance of �1 units thus seems to be related to the fact that the 
algorithm does not modify weights which emerge from a unit with 
value zero. Similar observations have been made by Stornetta and 
Huberman, s who further find that the discrepancies become even more 
pronounced if the network size is increased. 
1oo 
,, 80 
o 
 60 
u 40 
70 
I 
W=2.5 W=5.0 
2.5 
o I 
0 50 100 150 2.00 2.50 
PRESENTATIONS / PATTERN 
Fi. 4. Learning curves for an XOR-network with three hidden units 
(backpropagation, initial weights random, weight changes accumulated 
over all 4 input/output cases). Circles: continuous �1 units; 
triangles: continuous 0,1 units. 
8O 
In Figure 5, finally, we present results for a network that 
learns to detect mirror symmetry in the input pattern. The network 
consists of one output, one hidden, and four input units which are 
also directly connected to the output unit. We use the deterministic 
version of Boltzmann learning and change the weights after every 
presentation of a learning pattern. If the weights are allowed to 
assume arbitrary values, learning is rather slow and on average 
requires almost 700 presentations per pattern. We have observed, 
however, that the algorithm preferably seems to converge to solu- 
tions in which geometrically symmetric weights are opposite in sign 
and almost equal in magnitude (see also Ref. 3). This means that the 
symmetric input patterns are automatically treated as equivalent, as 
their net input to the hidden as well as to the output unit is zero. 
We have therefore investigated what happens if the weights are 
forced to be antisymmetric from the beginning. (The learning proce- 
dure, of course, has to be adjusted such that it preserves this 
antisymmetry). Figure 5 shows that such a problem-adapted weight- 
structure leads to a dramatic decrease in learning time. 
too 
 80- 
- 60- 
u_ 40- 
M 
I I I ' 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
� 
I I I I 
o 
o 
o 
o 
� 
� 
� o 
o 
� o 
1o 20 
o 
o 
o 
o 
o 
o 
o 
o 
I 
o 
o 
o 
0 I I I I 
2_ 5 50 100 2_00 500 2_000 
PRESENTATIONS / PATTERN 
Fig. 5. Learning curves for a symmetry detection network with 4 
input units and one hidden unit (deterministic Boltzmann learning, 
q = 1, discrete �1 units, initial weights random, weights changed 
after every learning example). Full circles: symmetry-adapted 
weights; open circles: arbitrary weights, weight randomization 
(p = 0.05). 
81 
CONCLUSIONS 
The main results of our empirical study can be summarized as 
follows: 
- Networks with �1 units quite generally exhibit a significantly 
faster learning than the corresponding 0,1 versions. 
- In addition, �1 networks are often less sensitive to parameter va- 
riations than 0,1 networks. 
- An adaptation of the weight-structure to the symmetries of the 
problem can lead to a drastic improvement of the learning behavior. 
Our qualitative interpretations seem to indicate that the ob- 
served effects should not be restricted to the small examples consi- 
dered in this paper. It would be very valuable, however, to have 
corresponding analytical results. 
REFERENCES 
1. ""Parallel Distributed Processing: Explorations in the Microstruc- 
ture of Cognition"", vol. 1: ""Foundations"", ed. by D.E. Rumelhart 
and J.L. McClelland (MIT Press, Cambridge), 1986, Chapters 7 & 8. 
2. Y. le Cun, in ""Disordered Systems and Biological Organization"", 
ed. by E. Bienenstock, F. Fogelman Souli, and G. Weisbuch (Sprin- 
ger, Berlin), 1986, pp. 233-240. 
3. D.E. Rumelhart, G.E. Hinton, and R.J. Williams, Nature 323, 533 
(1986). 
4. M.L. M�nsky and S. Papeft, ""Percepttons"" (IT Press, Cambr�dge), 
1969. 
5. W.S. Stornetta and B.A. Huberman, IEEE Conference on ""Neural Net- 
works"", San D�ego, Cal�forn�a, 21-24 3une 1987. 
", comparison differ learn pattern associ problem bernasconi boveri research center switzerland investig behavior differ learn algorithm network test case use simpl associ symmetri algorithm consid either version boltzmann machin learn rule base backpropag also propos analyz gener delta rule threshold find perform given algorithm depend strongli type unit observ network unit quit gener significantli better learn behavior also demonstr adapt symmetri problem lead increas learn past number learn procedur network model hidden unit propos consid strategi minim suitabl chosen strategi repres local optim gradient therefor suffer local minima correspond learn usual perform given learn scheme may depend number paramet implement gener result concern first therefor attempt studi empir influenc factor could effect learn behavior neural network preliminari investig restrict small simpl made interest observ appear rather gener thu expect remain valid also much larger complex network model pattern associ artifici neural network consist set unit state unit describ variabl discret connect carri neg institut physic dynam network determin local updat wij nonlinear activ specif threshold case discret unit case continu individu unit given differ threshold introduc extra unit valu network suppos perform pattern associ conveni divid unit input output hidden learn consist adjust way given input network prescrib state unit repres desir output network learn exampl present mani typic learn procedur strategi minim suitabl defin error function strategi gradient descent clamp input randomli chosen network produc output pattern desir say error wetght chang proport respect gradient procedur repeat new learn exampl satisfactori shall consid two differ type first determinist version machin learn rule propos yann le cun appli network symmetr wij wji associ state refer state input unit state input output unit error function defin gradient simpli given second call backpropag gener delta probabl repres wide use learn origin appli network feedforward use gradient descent minim mean squar output weight unit output simpli wik deriv nonlinear activ function weight connect gradient success determin chain rule case discret threshold backpropag algorithm describ can not perceptron learn rule noth els replac constant propos gener delta rule linear unit obtain replac constant backpropag express gener perceptron rule layer valu constant replac need differ learn algorithm propos learn algorithm suffer problem gradient descent complic use small learn becom prohibit larg chang inevit lead oscil prevent converg good error may contain mani local gradient descent guarante find global sever way improv stochast gradient descent weight chang accumul learn exampl weight actual often use method consist smooth weight chang refer weight chang present exampl group learn use weight decay algorithm gener larg weight may high barrier solut can not found smooth method suppress occurr least certain thu allow us use higher can not algorithm may trap bad local obviou way deal local minima restart algorithm differ weight random weight probabl learn approach use properti weight space depend choic error function also type unit possibl concern valu weight allow perform learn algorithm thu depend mani depend conveni analyz term behavior appropri defin learn small learn set alway consist chosen repres perform learn procedur fraction network present input network everi input pattern produc correct learn curv give us much detail inform behavior system averag quantiti mean learn shall present discuss result empir learn curv refer set network expos learn vari initi sequenc learn one except learn exampl alway prototyp pattern associ problem correspond network two input unit one let us first consid one input unit also direct output weight use version boltzmann learn rule figur show result case tabula rasa initi initi weight set equal weight chang everi learn network learn problem less present per correspond total number remain network never learn solv matter mani case understood analyz correspond contain attractor probabl trap attractor exactli weight accumul learn attractor learn curv one hidden unit boltzmann discret initi full weight chang everi learn open weight chang accumul learn exist network learn least extrem long satur effect observ random initi weight distribut see also exhibit differ learn behavior network unit weight random lead consider improv weight decay strike network learn faster network respect averag learn time factor mention optim unit network learn behavior practic independ valu therefor seem unit lead much one model alway translat would lead energi function consider weight depend pattern learn curv one hidden unit boltzmann initi weight weight accumul learn discret discret broken weight solid weight refer feedforward backpropag gener delta rule case includ overrelax term network unit use activ function given network consid case error smaller smaller figur weight chang everi learn curv refer optim choic discret well continu network perform much better continu averag learn differ factor discret case even observ network learn gener delta rule discret twice fast backpropag algorithm continu pattern learn curv three hidden unit delta initi weight chang everi learn open open discret continu full figur weight chang accumul network continu unit also unit lead improv behavior optim lead significantli smaller learn network also appear less sensit respect variat correspond better perform model continu unit partli attribut steeper slope chosen comparison activ function show network unit perform significantli better updat everi learn learn time remain larg factor case backpropag main reason better unit thu seem relat fact modifi weight emerg unit similar observ made stornetta find discrep becom even network size pattern learn curv three hidden unit initi weight weight chang accumul continu continu figur present result network detect mirror symmetri input network one one four input unit directli connect output use determinist boltzmann learn chang weight everi learn weight allow arbitrari learn rather slow averag almost present per algorithm prefer seem converg geometr symmetr weight opposit sign almost equal magnitud also mean input pattern automat treat net input hidden well output unit therefor investig happen weight antisymmetr learn adjust preserv figur show lead dramat decreas learn pattern learn curv symmetri detect network unit one hidden unit boltzmann discret initi weight weight chang everi learn full open arbitrari weight random main result empir studi summar network unit quit gener exhibit significantli learn correspond network often less sensit paramet adapt symmetri lead drastic improv learn qualit interpret seem indic effect restrict small exampl would analyt distribut explor rumelhart clelland chapter le system biolog fogelman weisbuch natur stornetta ie confer san,0
9,9,"82 
SIMULATIONS SUGGEST 
INFORMATION PROCESSING ROLES 
FOR THE DIVERSE CURRENTS IN 
HIPPOCAMPAL NEURONS 
Lyle J. Borg-Graham 
Harvard-MIT Division of Health Sciences and Technology and 
Center for Biological Information Processing, 
Massachusetts Institute of Technology, Cambridge, Massachusetts 02139 
ABSTRACT 
A computer model of the hippocampal pyramidal cell (HPC) is described 
which integrates data from a variety of sources in order to develop a con- 
sistent description for this cell type. The model presently includes descrip- 
tions of eleven non-linear somatic currents of the HPC, and the electrotonic 
structure of the neuron is modelled with a soma/short-cable approximation. 
Model simulations qualitatively or quantitatively reproduce a wide range of 
somatic electrical behavior ii HPCs, and demonstrate possible roles for the 
various currents in information processing. 
1 The Computational Properties of Neurons 
There are several substrates for neuronal computation, including connec- 
tivity, synapses, morphometrics of dendritic trees, linear parameters of cell 
membrane, as well as non-linear, time-varying membrane conductances, also 
referred to as currents or channels. In the classical description of neuronal 
function, the contribution of membrane channels is constrained to that of 
generating the action potential, setting firing threshold, and establishing the 
relationship between (steady-state) stimulus intensity and firing frequency. 
However, it is becoming clear that the role of these channels may be much 
more complex, resulting in a variety of novel ""computational operators"" that 
reflect the information processing occurring in the biological neural net. 
American Institute of Physics 1988 
83 
2 Modelling Hippocampal Neurons 
Over the past decade a wide variety of non-linear ion channels, have been 
described for many excitable cells, in particular several kinds of neurons. 
One such neuron is the hippocampal pyramidal cell (HPC). HPC chan- 
nels are marked by their wide range of temporal, voltage-dependent, and 
chemical-dependent characteristics, which results in very complex behavior 
or responses of these stereotypical cortical integrating cells. For example, 
some HPC channels are activated (opened) transiently and quickly, thus pri- 
marily affecting the action potential shape. Other channels have longer ki- 
netics, modulating the response of HPCs over hundreds of milliseconds. The 
measurement these channels is hampered by various technical constraints, 
including the small size and extended electrotonic structure of HPCs and the 
diverse preparations used in experiments. Modelling the electrical behavior 
of HPCs with computer simulations is one method of integrating data from 
a variety of sources in order to develop a consistent description for this cell 
type. 
In the model referred to here putative mechanisms for voltage-dependent 
and calcium-dependent channel gating have been used to generate simula- 
tions of the somatic electrical behavior of HPCs, and to suggest mechanisms 
for information processing at the single cell level. The model has also been 
used to suggest experimental protocols designed to test the validity of sim- 
ulation results. Model simulations qualitatively or quantitatively reproduce 
a wide range of somatic electrical behavior in HPCs, and explicitly demon- 
strate possible functional roles for the various currents [1]. 
The model presently includes descriptions of eleven non-linear somatic 
currents, including three putative Na + currents - INa-t-ig, INa-rep, and 
INa-t,it; six K + currents that have been reported in the literature - IDa 
(Delayed Rectifier), IA, Ic, 1.4Hp (After-hyperpolarization), IM, and IQ; 
and two Ca 2+ currents, also reported previously - Ic, and 
The electrotonic structure of the HPC is modelled with a soma/short- 
cable approximation, and the dendrites are assumed to be linear. While the 
conditions for reducing the dendritic tree to a single cable are not met for 
HPC (the so-called Rail conditions [3]), the Zi, of the cable is close to that 
of the tree. In addition, although HPC dendrites have non-linear membrane, 
it assumed that as a first approximation the contribution of currents from 
this membrane may be ignored in the somatic response to somatic stimulus. 
Likewise, the model structure assumes that axon-soma current under these 
conditions can be lumped into the soma circuit. 
84 
In part this paper will address the following question: if neural nets 
are realizable using elements that have simple integrarive all-or-nothing re- 
sponses, connected to each other with regenerative conductors, then what 
is the function for all the channels observed experimentally in real neurons? 
The results of this HPC model study suggest some purpose for these com- 
plexities, and in this paper we shall investigate some of the possible roles of 
non-linear channels in neuronal information processing. However, given the 
speculative nature of many of the currents that we have presented in the 
model, it is important to view results based on the interaction of the many 
model elements as preliminary. 
3 
Defining Neural Information Coding is the First 
Step in Describing Biological Computations 
Determination of computational properties of neurons requires a priori as- 
sumptions as to how information is encoded in neuronal output. The clas- 
sical description assumes that information is encoded as spike frequency. 
However, a single output variable, proportional to firing frequency, ignores 
other potentially information-rich degrees of freedom, including: 
� Relative phase of concurrent inputs. 
� Frequency modulation during single bursts. 
� Cessation of firing due to intrinsic mechanisms. 
� Spike shape. 
Note that these variables apply to patterns of repetitive firing 1. The 
relative phase of different inputs to a single cell is very important at low 
firing rates, but becomes less so as firing frequency approaches the time 
constant of the postsynaptic membrane or some other rate-limiting process 
in the synaptic transduction (e.g. neurotransmitter release or post synap- 
tic channel activation/deactivation kinetics). Frequency modulation during 
bursts/spike trains may be important in the interaction of a given axon's 
output with other inputs at the target neuron. Cessation of firing due to 
mechanisms intrinsic to the cell (as opposed to the end of input) may be 
Single spikes may be considered as degenerate cases of repetitive firing responses. 
85 
important, for example, in that cell's transmission function. Finally, modu- 
lation of spike shape may have several consequences, which will be discussed 
later. 
4 Physiological Modulation of HPC Currents 
In order for modulation of HPC currents to be considered as potential in- 
formation processing mechanisms in vivo, it is necessary to identify physio- 
logical modulators. For several of the currents described here such factors 
have been identified. For example, there is evidence that IM is inhibited 
by muscarinic (physiologically, cholinergic) agonists [2], that 1,4 is inhib- 
ited by acetylcholine [6], and that 1.4HP is inhibited by noradrenaline [5]. 
In fct, the list of neurotransmitters which are active non-synaptically is 
growing rapidly. It remains to be seen whether there are as yet undiscov- 
ered mechanisms for modulating other HPC currents, for example the three 
Na + currents proposed in the present model. Some possible consequences 
of such mechanisms will be discussed later. 
5 HPC Currents and Information Processing 
The role of a given channel on the HPC electrical response depends on its 
temporal characteristics as a function of voltage, intracellular messengers, 
and other variables. This is complicated by the fact that the opening and 
closing of channels is equivalent to varying conductances, allowing both lin- 
ear and non-linear operations (e.g. [4] and [7]). In particular, a current 
which is activated/deactivated over a period of hundreds of milliseconds 
will, to a first approximation, act by slowly changing the time constant of 
the membrane. At the other extreme, currents which activate/deactivate 
with sub-millisecond time constants act by changing the trajectory of the 
membrane voltage in complicated ways. The classic example of this is the 
role of Na + currents underlying the action potential. 
To investigate how the different HPC currents may contribute to the 
information processing of this neuron, we have looked at how each current 
shapes the HPC response to a simple repertoire of inputs. At this stage 
in our research the inputs have been very basic - short somatic current 
steps that evoke single spikes, long lasting somatic current steps that evoke 
spike trains, and current steps at the distal end of the dendritic cable. By 
examining the response to these inputs the functional roles of the HPC 
86 
Current [[ Spike Shape Spike Threshold tin/Frequency-Intensity 
IN- t,.ig + -]--]-+ - 
INa-rep + ++ +++ 
ICa -(++) -(+) q- (+-t-q-) 
IDR ++ + ++ 
1.4 + ++ ++ 
Ic + - +++ 
IAHP - q-q- +q-q- 
IM - q- q- 
Table 1: Putative functional roles of HPC somatic currents. Entries in 
parentheses indicate secondary role, e.g. Ca 2+ activation of K + current. 
currents can be tentatively grouped into three (non-exclusive) categories: 
� Modulation of spike shape. 
� Modulation of firing threshold, both for single and repetitive spikes. 
� Modulation of semi-steady-state membrane time constant. 
� Modulation of repetitive firing, specifically the relationship between 
strength of tonic input and frequency of initial burst and later ""steady 
state"" spike train. 
Table I summarizes speculative roles for some of the HPC currents as 
suggested by the simulations. Note that while all four of the listed char- 
acteristics are interrelated, the last two are particularly so and are lumped 
togetler in Table 1. 
5.1 Possible Roles for Modulation of F! Characteristic 
Again, it has been traditionally assumed that neural information is encoded 
by (steady-state) frequency modulation, e.g. the number of spikes per second 
over some time period encodes the output information of a neuron. For 
example, muscle fiber contraction is approximately proportional to the spike 
frequency of its motor neuron 2 If the physiological inhibition of a specific 
2In fact, where action potential propagation is a stereotyped phenomena, such as in 
long axons, then the timing of spikes is the only parameter that may be modulated. 
87 
Stimulus Intensity (Constant Current) 
Figure 1: Classical relation between total neuronal input (typically tonic 
current stimulus) and spike firing frequency [solid line] and (qualitative) 
biological relationships [dashed and dotted lines]. The dotted line applies 
when INa-rp is blocked. 
current changes the FI characteristic, this allows one way to modulate that 
neuron's information processing by various agents. 
Figurel contrasts the classical input-output relation of a neuron and 
more biological input-output relations. The relationships have several fea- 
tures which can be potentially modulated either physiologically or patho- 
logically, including saturation, threshold, and shape of the curves. Note in 
particular the cessation of output with increased stimulation, as the alepo- 
larizing stimulus prevents the resetting of the transient inward currents. 
For the HPC, simulations show (Figure 2 and Figure 3) that blocking the 
putative INa-rep has the effect of causing the cell to ""latch-up"" in response 
to tonic stimulus that would otherwise elicit stable spike trains. Both de- 
polarizing currents and repolarizing currents play a role here. First, spike 
upstroke is mediated by both IN-p and the lower threshold IN-tig; at 
high stimuli repolarization between spikes does not get low enough to reset 
INa-trig. Second, spikes due to only one of these Na + currents are weaker 
and as a result do not activate the repolarizing K + currents as much as 
normal because a) reduced time at depolarized levels activates the voltage- 
dependent K + currents less and b) less Ca 2+ influx with smaller spikes 
reduces the Ca2+-dependent activation of some K + currents. The net re- 
sult is that repolarization between spikes is weaker and, again, does not reset 
INa-trig, 
Although the current being modulated here (IN-ep) is theoretical, the 
88 
99.9 
2 n $tnulus Hornml  
olta9e (nV) Tne (sec) ( 1.Be-3) 
ta9e (nV) Ttne (sec) (M 1.Be-3) 
Figure 2: Simulation of repetitive firing in response to constant current 
injection into the soma. In this series, with the ""normal"" cell, a stimulus 
of about 8 nA (not shown) will cause to cell to fire a short burst and then 
cease firing. 
possibility of selective blocking of INa-?ep allows a mechanism for shifting 
the saturation of the neuron's response to the left and, as can be seen by 
comparing Figures 2 and 3, making the FI curve steeper over the response 
range. 
5.2 Possible Roles for Modulation of Spike Threshold 
The somatic firing threshold determines the minimal input for eliciting a 
spike, and in effect change the sensitivity of a cell. As a simple example, 
blocking INa-t?ig in the HPC model raises threshold by about 10 millivolts. 
This could cause the cell to ignore input patterns that would otherwise 
generate action potentials. 
There are two aspects of the firing ""threshold"" for a cell - static and 
dynamic. Thus, the rate at which the soma membrane approaches thresh- 
old is important along with the magnitude of that threshold. In general 
the threshold level rises with a slower depolarization for several reasons, in- 
cluding partial inactivation of inward currents (e.g. INa-trig) and partial 
activation of outward currents (e.g. IA [8]) at subthreshold levels. 
89 
Time (sec) ( 1.Be-3) 
2 n8 Stimulus, u/o I-Ha-ReD 
I o.ba9e (mY) Time (sec) ( 1.Be-3) 
I"" ' ?' ' ' 2' 
4 n8 Stimuluss w/o I-Na-Rep 
tm9e (mV) Time (sec) 
6 nFt Stimulus, w/o I-lm-Rep 
Figure 3: Blocking one of the putative Na + currents (IN,-r,p) causes the 
HPC repetitive firing response to fail at lower stimulus than ""normal"". This 
corresponds to the leftward shift in the saturation of the response curve 
shown in Figure 1. 
Thus it is possible, for example, that I helps to distinguish tonic den- 
dritic distal synaptic input from proximal input. For input that eventually 
will supply the same depolarizing current at the soma, dendritic input will 
have a slower onset due to the cable properties of the dendrites. This slow 
onset could allow I to delay the onset of the spike or spikes. A simi- 
lar depolarizing current applied more proximally would have a faster onset. 
Sub-threshold activation of I on the depolarizing phase would then be in- 
sufficient to delay the spike. 
5.3 Possible Roles for Modulation of Somatic Spike Shape 
How important is the shape of an individual spike generated at the soma? 
First, we can assume that spike shape, in particular spike width, is unimpor- 
tant at the soma spike-generating membrane - once the soma fires, it fires. 
However, the effect of the spike beyond the soma may or may not depend 
on the spike shape, and this is dependent on both the degree which spike 
propagation is linear and on the properties of the pre-synaptic membrane. 
Axon transmission is both a linear and non-linear phenomena, and the 
shorter the axon's electrotonic length, the more the shape of the somatic 
9O 
action potential will be preserved at the distal pre-synaptic terminal. At 
one extreme, an axon could transmit the spike a purely non-linear fashion 
- once threshold was reached, the classic ""all-or-nothing"" response would 
transmit a stereotyped action potential whose shape would be independent 
of the post-threshold soma response. At the other extreme, i.e. if the axonal 
membrane were purely linear, the propagation of the somatic event at any 
point down the axon would be a linear convolution of the somatic signal 
and the axon cable properties. It is likely that the situation in the brain lies 
somewhere between these limits, and will depend on the wavelength of the 
spike, the axon non-linearities and the axon length. 
What role could be served by the somatic action potential shape modu- 
lating the pre-synaptic terminal signal? There are at least three possibilities. 
First, it has been demonstrated that the release of transmitter at some pre- 
synaptic terminals is not an ""all-or-nothing"" event, and in fact is a function 
of the pre-synaptic membrane voltage waveform. Thus, modulation of the 
somatic spike width may determine how much transmitter is released down 
the line, providing a mechanism for changing the effective strength of the 
spike as seen by the target neuron. Modulation of somatic spike width could 
be equivalent to a modulation of the ""loudness"" of a given neuron's message. 
Second, pyramidal cell axons often project collateral branches back to the 
originating soma, forming axo-somatic synapses which result in a feedback 
loop. In this case, modulation of the somatic spike could affect this feedback 
in complicated ways, particularly since the collaterals are typically short. 
Finally, somatic spike shape may also play a role in the transmission of 
spikes at axonal branch points. For example, consider a axonal branch point 
with an impedance mismatch and two daughter branches, one thin and one 
thick. Here a spike that is too narrow may not be able to alepolarize the 
thick branch sufficiently for transmission of the spike down that branch, with 
the spike propagating only down the thin branch. Conversely, a wider spike 
may be passed by both branches. Modulation of the somatic spike shape 
could then be used to direct how a cell's output is broadcast, some times 
allowing transmission to all the destinations of an HPC, and at other times 
inhibiting transmission to a limited set of the target neurons. 
For HPCs much evidence has been obtained which implicate the roles 
of various HPC currents on modulating somatic spike shape, for example 
the 'a2+-dependent K + current Ic [9]. Simulations which demonstrate 
the effect of Ic on the shape of individual action potentials are shown in 
Figure 4. 
91 
Uoltage ('nU) 'Volt'9 e' (nU') ......... 
line (sec) (x 1.0e-8) line (sec) (x 
_--80.8 -88.0 
Current (nR) o., ICurrent (nR)F, 
lie!(�) i..ee-) lie (ec) (-...ee-) 
. .e ?_? 2.'e-.,_.__-:,5.e .e .p. ,3.e ,.e ,5.e 
19 9 .-19.9 I-Ha-Trig 
� I-DR 
Figure 4: Role of Ic during repolarization of spike. In the simulation on the 
left, Ic is the largest repolarizing current. In the simulation on the right, 
blocking Ic results in an wider spike. 
6 
The Assumption of Somatic Vs. Non-Somatic 
Currents 
In this research the somatic response of the HPC has been modelled under 
the assumption that the data on HPC currents reflect activity of channels 
localized at the soma. However, it must be considered that all channel pro- 
teins, regardless of their final functional destination, are manufactured at 
the soma. Some of the so-called somatic channels may therefore be ves- 
tiges of channels intended for dendritic, axonal, or pre-synaptic membrane. 
For example, if the spike-shaping channels are intended to be expressed for 
pre-synaptic membrane, then modulation of these channels by endogenous 
factors (e.g. ACh) takes place at target neuron. This may seem disarlvan- 
tageous if a factor is to act selectively on some afferent tract. On the other 
hand, in the dendritic field of a given neuron it is possible only some affer- 
ents have certain channels, thus allowing selective response to modulating 
agents. These possibilities further expand the potential roles of membrane 
channels for computation. 
92 
7 
Other Possible Roles of Currents for Modulat- 
ing HPC Response 
There are many other potential ways that HPC currents may modulate the 
HPC response. For example, the relationship between intracellular Ca 2+ 
and the Ca2+-dependent K + currents, Ic and IAHp, may indicate possible 
information processing mechanisms. 
Intracellular Ca 2+ is an important second messenger for several intracel- 
lular processes, for example muscular contraction, but excessive [Ca2+]in is 
noxious. There are at least three negative feedback mechanisms for limiting 
the flow of Ca 2+: voltage-dependent inactivation of Ca 2+ currents; reduc- 
tion of Eta (and thus the Ca 2+ driving force) with Ca 2+ influx; and the just 
mentioned Ca2+-mediation of repolarizing currents. A possible information 
processing mechanism could be by modulation of IAHp, which plays an im- 
portant role in limiting repetitive firing 3. Simulations suggest that blocking 
this current causes Ic to step in and eventually limit further repetitive fir- 
ing, though after many more spikes in a train. Blocking both these currents 
may allow other mechanisms to control repetitive firing, perhaps ones that 
operate independently of [Ca2]i n. Conceivably, this could put the neuron 
into quite a different operating region. 
8 
Populations of Neurons Vs. Single Cells: Im- 
plications for Graded Modulation of HPC Cur- 
rents 
In this paper we have considered the all-or-nothing contribution of the var- 
ious channels, i.e. the entire population of a given channel type is either 
activated normally or all the channels are disabled/blocked. This descrip- 
tion may be oversimplified in two ways. First, it is possible that a blocking 
mechanism for a given channel may have a graded effect. For example, it is 
possible that cholinergic input is not homogeneous over the soma membrane, 
or that at a given time only a portion of these afferents are activated. In 
either case it is possible that only a portion of the cholinergic receptors are 
bound, thus inhibiting a portion of channels. Second, the result of channel 
inhibition by neuromodulatory projections must consider both single cell 
3The slowing down of the spike trains in Figure 2 and Figure 3 is mainly due to the 
buildup of [Ca2+]i,, which progressively activates more IAHr. 
93 
response and population response, the size of the population depending on 
the neuro-architecture of a cortical region and the afferents. For example, 
activation of a cholinergic tract which terminates in a localized hippocampal 
region may effect thousands of HPCs. Assuming that the IM of individual 
HPCs in the region may be either turned on or off completely with some 
probability, the behavior of the population will be that of a graded response 
of IM inhibition. This graded response will in turn depend on the strength 
of the cholinergic tract activity. 
The key point is that the information processing properties of isolated 
neurons may be reflected in the behavior of a population, and vica-versa. 
While it is likely that removal of a single pyramidal cell from the hippocam- 
pus will have zero functional effect, no neuron is an island. Understand- 
ing the central nervous system begins with the spectrum of behavior in its 
functional units, which may range from single channels, to specific areas of 
a dendritic tree, to the single cell, to cortical or nuclear subfields, on up 
through the main subsystems of CNS. 
References 
[1] L. Borg-Graham. Modelling the Somatic Electrical Behavior of Hip- 
pocampal Pyramidal Neurons. Master's thesis, Massachusetts Institute 
of Technology, 1987. 
[2] J. Halliwell and P. Adams. Voltage clamp analysis of muscarinic excita- 
tion in hippocampal neurons. Brain Research, 250:71-92, 1982. 
[3] J. J. B. Jack, D. Noble, and R. W. Tsien. Electric Current Flow In 
Excitable Cells. Clarendon Press, Oxford, 1983. 
[4] C. Koch and T. Poggio. Biophysics of computation: neurons, synapses 
and membranes. C.B. LP. Paper, (008), 1984. Center for Biological 
Information Processing, MIT. 
[5] D. Madison and R. Nicoll. Noradrenaline blocks accommodation of pyra- 
midal cell discharge in the hippocampus. Nature, 299:, Oct 1982. 
[6] Y. Nakajuma, S. Nakajima, R. Leonard, and K. Yamaguchi. Actetyl- 
choline inhibits a-current in dissociated cultured hippocampal neurons. 
Biophysical Journal, 49:575a, 1986. 
94 
[7] T. Poggio and V. Torre. Theoretical Approaches to Complex Systems, 
Lecture Notes in Biomathematics, pages 28-38. Volume 21, Springer 
Verlag, Berlin, 1978. A New Approach to $ynaptic Interaction. 
[8] J. Storm. A-current and ca-dependent transient outward current control 
the initial repetitive firing in hippocampal neurons. Biophysical Journal, 
49:369a, 1986. 
[9] J. Storm. Mechanisms of action potential repolarization and a fast after- 
hyperpolarization in rat hippocampal pyramidal cells. Journal of Phys- 
iology, 1986. 
", suggest process role divers current neuron divis health scienc technolog biolog inform institut massachusett comput model hippocamp pyramid cell describ integr data varieti sourc order develop descript cell model present includ eleven somat current electroton neuron model simul qualit quantit reproduc wide rang electr behavior demonstr possibl role current inform comput properti neuron sever substrat neuron includ morphometr dendrit linear paramet cell well membran also current classic descript neuron contribut membran channel constrain action set fire establish stimulu intens fire becom clear role channel may much result varieti novel inform process occur biolog neural institut physic model hippocamp neuron past decad wide varieti ion mani excit particular sever kind neuron hippocamp pyramid cell hpc mark wide rang result complex behavior respons stereotyp cortic integr hpc channel activ transient thu affect action potenti channel longer modul respons hpc hundr channel hamper variou technic small size extend electroton structur hpc prepar use model electr behavior hpc comput simul one method integr data varieti sourc order develop consist descript cell model refer put mechan channel gate use gener somat electr behavior suggest mechan inform process singl cell model also suggest experiment protocol design test valid model simul qualit quantit reproduc wide rang somat electr behavior explicitli possibl function role variou current model present includ descript eleven somat includ three put na current six current report literatur ida two ca also report previous electroton structur hpc model dendrit assum reduc dendrit tree singl cabl met rail condit cabl close although hpc dendrit assum first approxim contribut current membran may ignor somat respons somat model structur assum current lump soma part paper address follow neural net realiz use element simpl integrar connect regen function channel observ experiment real result hpc model studi suggest purpos paper shall investig possibl role channel neuron inform given natur mani current present import view result base interact mani element neural inform code first describ biolog comput comput properti neuron requir priori inform encod neuron descript assum inform encod spike singl output proport fire ignor potenti degre rel phase concurr frequenc modul singl cessat fire due intrins spike variabl appli pattern repetit fire phase differ input singl cell import low becom less fire frequenc approach time postsynapt membran process synapt transduct neurotransmitt releas post channel frequenc modul train may import interact given input target cessat fire due intrins cell oppos end may spike may consid degener case repetit fire transmiss spike shape may sever discuss physiolog modul hpc current order modul hpc current consid potenti process mechan necessari identifi sever current describ factor evid im inhibit muscarin agonist acetylcholin inhibit noradrenalin list neurotransmitt activ remain seen whether yet mechan modul hpc exampl three current propos present possibl consequ mechan discuss hpc current inform process role given channel hpc electr respons depend characterist function intracellular complic fact open channel equival vari allow oper current period hundr millisecond first act slowli chang time constant current time constant act chang trajectori voltag complic classic exampl na current underli action investig differ hpc current may contribut process look current hpc respons simpl repertoir stage research input basic short somat current evok singl long last somat current step evok current step distal end dendrit respons input function role hpc spike shape spike threshold put function role hpc somat entri indic secondari ca activ tent group three modul spike modul fire singl repetit modul membran time modul repetit specif relationship tonic input frequenc initi burst later spike summar specul role hpc current note four list last two particularli lump tabl possibl role modul characterist tradit assum neural inform encod frequenc number spike per second time period encod output inform muscl fiber contract approxim proport spike motor neuron physiolog inhibit specif action potenti propag stereotyp time spike paramet may intens classic relat total neuron input tonic spike fire frequenc relationship dot dot line appli chang fi allow one way modul inform process variou contrast classic relat neuron biolog relationship sever potenti modul either physiolog includ shape note cessat output increas stimulu prevent reset transient inward simul show figur block effect caus cell respons tonic stimulu would otherwis elicit stabl spike current repolar current play role spike mediat lower threshold stimuli repolar spike get low enough reset spike due one na current weaker result activ repolar current much reduc time depolar level activ current less less ca influx smaller spike activ net repolar spike weaker reset current modul hornml ttne simul repetit fire respons constant current stimulu caus cell fire short burst select block allow mechan shift satur respons left seen figur make fi curv steeper respons possibl role modul spike threshold somat fire threshold determin minim input elicit effect chang sensit simpl hpc model rais threshold could caus cell ignor input pattern would otherwis action two aspect fire cell static rate soma membran approach import along magnitud gener threshold level rise slower depolar sever partial inactiv inward current partial outward current ia subthreshold time stimuluss time ft block one put na current caus repetit fire respons fail lower stimulu leftward shift satur respons curv figur help distinguish tonic distal synapt input proxim input eventu suppli depolar current dendrit input slower onset due cabl properti slow could allow delay onset spike depolar current appli proxim would faster activ depolar phase would delay possibl role modul somat spike shape import shape individu spike gener assum spike particular spike soma membran soma effect spike beyond soma may may depend spike depend degre spike linear properti transmiss linear electroton shape somat potenti preserv distal axon could transmit spike pure fashion threshold classic respons would stereotyp action potenti whose shape would independ soma axon pure propag somat event axon would linear convolut somat signal axon cabl like situat brain lie depend wavelength axon axon role could serv somat action potenti shape termin least three demonstr releas transmitt termin fact function membran voltag modul spike width may determin much transmitt releas provid mechan chang effect strength seen target modul somat spike width could equival modul given pyramid cell axon often project collater branch back form synaps result feedback modul somat spike could affect feedback complic particularli sinc collater typic somat spike shape may also play role transmiss axon branch consid axon branch point imped mismatch two daughter one thin one spike narrow may abl alepolar branch suffici transmiss spike spike propag thin wider spike pass modul somat spike shape use direct output time transmiss destin time transmiss limit set target hpc much evid obtain implic role variou hpc current modul somat spike exampl current ic simul demonstr effect ic shape individu action potenti shown line icurr role ic repolar simul ic largest repolar simul ic result wider assumpt somat research somat respons hpc model assumpt data hpc current reflect activ channel must consid channel regardless final function manufactur somat channel may therefor channel intend channel intend express modul channel endogen take place target may seem factor act select affer dendrit field given neuron possibl certain thu allow select respons modul possibl expand potenti role membran possibl role current hpc respons mani potenti way hpc current may modul relationship intracellular ca ic may indic possibl process ca import second messeng sever exampl muscular excess least three neg feedback mechan limit flow ca inactiv ca eta thu ca drive ca repolar possibl inform mechan could modul play role limit repetit fire simul suggest block current caus ic step eventu limit repetit though mani spike block current allow mechan control repetit perhap one independ could put neuron quit differ oper neuron singl grade modul hpc paper consid contribut entir popul given channel type either normal channel may oversimplifi two possibl block given channel may grade cholinerg input homogen soma given time portion affer case possibl portion cholinerg receptor thu inhibit portion result channel neuromodulatori project must consid singl cell slow spike train figur figur mainli due progress activ popul size popul depend cortic region cholinerg tract termin local hippocamp may effect thousand assum im individu region may either turn complet behavior popul grade respons im grade respons turn depend strength cholinerg tract key point inform process properti isol may reflect behavior like remov singl pyramid cell zero function neuron central nervou system begin spectrum behavior may rang singl specif area dendrit singl cortic nuclear main subsystem model somat electr behavior pyramid massachusett institut halliwel voltag clamp analysi muscarin hippocamp brain electr current flow clarendon koch biophys synaps center biolog madison noradrenalin block accommod cell discharg oct inhibit dissoci cultur hippocamp poggio theoret approach complex note page volum springer new approach transient outward current control initi repetit fire hippocamp biophys mechan action potenti repolar fast rat hippocamp pyramid journal,0
10,10,"95 
OPTIMAL NEURAL SPIKE CLASSIFICATION 
Amir F. Atiya(*) and Ja,nes M. Bower(**) 
(*) Dept. of Electrical Engineering 
(**) Division of Biology 
California Institute of Technology 
Ca 91125 
Abstract 
Being able to record the electrical activities of a number of neurons simultaneously is likely 
to be important in the study of the functional organization of networks of real neurons. Using 
one extracellular microelectrode to record from several neurons is one approach to studying 
the response properties of sets of adjacent and therefore likely related neurons. However, to 
do this, it is necessary to correctly classify the signals generated by these different neurons. 
This paper considers this problem of classifying the signals in such an extracellular recording, 
based upon their shapes, and specifically considers the classification of signals in the case when 
spikes overlap temporally. 
Introduction 
How single neurons in a network of neurons interact when processing information is likely 
to be a fundamental question central to understanding how real neural networks compute,. 
In the mammalian nervous system we know that spatially adjacent neurons are, in general, 
more hkely to interact, as well as receive common inputs. Thus neurobiologists are interested 
in devising techniques that allow adjacent groups of neurons to be sampled simultaneously. 
Unfortunately, the small scale of real neural networks makes inserting one recording electrode 
per cell impractical. Therefore, one is forced to use single electrodes designed to sample neu- 
ral signals evoked by several cells at once. While this approach provides the multi-neuron 
recordings being sought, it also presents a rather serious waveform classification problem be- 
cause the actual temporal sequence of action potentials in each individual neuron must be 
deciphered. This paper describes a method for classifying the activities of several individual 
neurons recorded simultaneously using a single electrode. 
Description of the Problem 
Over the last two decades considerable attention 1'8 has been devoted to the problem of 
classification of action potentials in multi-neuron recordings. These action potentials (also 
referred to as ""spikes"") are the extracellularly recorded signal produced by a single neuron 
when it is passing information to other neurons (Fig. 1). Fortunately, spikes recorded from the 
same cell are more or less similar in shape, while spikes coming from different neurons usually 
have somewhat different shapes, depending on the neuron type, electrode characteristics, the 
distance between the electrode and the neuron, and the intervening medium. Fig. I illustrates 
some representative variations in spike shapes. It is our objective to detect and classify different 
spikes based on their shapes. However, relying entirely on the shape of the spikes presents 
difficulties. For example spikes from different neurons can overlap temporally producing novel 
waveforms (see Fig. 2 for an example of an overlap). To deal with these overlaps, one has first 
to detect the occurrence of an overlap, and then estimate the constituent spikes. Unfortunately, 
only a few of the available spike separation algorithms consider these events, even though they 
are potentially very important in understanding neural networks. Those few tend to rely 
American Institute of Physics 1988 
96 
on heuristic rules and subtractive methods to resolve overlap cases. No currently published 
method we are aware of attempts to use knowledge of the likelihood of overlap events for 
detecting them, which is at the basis of the method we will describe. 
Fig. 1 
An example of a multi-neuron recording 
overlapping spikes 
Fig. 2 
An example of a temporal overlap of action potentials 
General Approach 
The first step in classifying neural waveforms is obviously to identify the typical spike 
shapes occurring in a particular recording. To do this we have applied a learning algorithm 
on the beginning portion of the recording, which in an unsupervised fashion (i.e. without the 
intervention of a human operator) estimates the shapes. After the learning stage we have 
the classification stage, which is applied on the remaining portion of the recording. A new 
classification method is proposed, which gives minimum probability of error, even in case of the 
occurrence of overlapping spikes. Both the learning and the classification algorithms require 
a preprocessing step to detect the position of the spike candidate in the data record. 
Detectior: For the first task of detection most researchers use a simple level detecting 
algorithm, that signals a spike when recorded voltage levels cross a certain voltage threshold. 
However, variations in recording position due to natural brain movements during recording 
(e.g. respiration) can cause changes in relative height of the positive to the negative peak. 
Thus, a level detector (using either a positive or a negative threshold) can miss some spikes. 
Alternatively, we have chosen to detect an event by sliding a window of fixed length until a 
time when the peak to peak value within the window exceeds a certain threshold. 
Learning: Learning is performed on the beginning portion of the sampled data using 
the Isodata clustering algorithm 9. The task is to estimate the number of neurons n whose 
spikes are represented in the waveform and learn the different shapes of the spikes of the 
various neurons. For that purpose we apply the clustering algorithm choosing only one feature 
97 
from the spike, the peak to peak value which we have found to be quite an effective feature. 
Note that using the peak to peak value in the learning stage does not necessitate using it for 
classification (one might need additional or different features, especially for tackling the case 
of spike overlap). 
The Optimal Classification Rule: Once we have identified the number of different events 
present, the classification stage is concerned with estimating the identities of the spikes in the 
recording, based on the typical spike shapes obtained in the learning stage. In our classification 
scheme we make use of the information given by the shape of the detected spike as well 
as the firing rates of the different neurons. Although the shape plays in general the most 
important role in the classification, the rates become a more significant factor when dealing 
with overlapping events. This is because in general overlap is considerably less frequent than 
single spikes. The shape information is given by d set of features extracted from the waveform. 
Let x be the feature vector of the detected spike (e.g. the samples of the spike waveform). Let 
N, ..., N,, represent the different neurons. The detection algorithm tells us only that at least 
one spike occurred in the narrow interval (t - T, t + T) (= say I) where t is the instant of 
the peak of the detected spike, T and Tg are constants chosen subjectively according to the 
smallest possible time separation between two consecutive spikes, identifiable as two separate 
(nonoverlapping) spikes. By definition, if more than one spike occurs in the interval I, then 
we have an overlap. As a matter of convention, the instant of the occurrence of a spike  
taken to be that of the spike peak. For simplicity, we will consider the case of two possibly 
overlapping spikes, though the method can be extended easily to more. The classification rule 
which results in minimum probability of error is the one which chooses the neuron (or pair of 
neurons in case of overlap) which has the maximum likelihood. We have therefore to compare 
the Pi's and the Py's, defined as 
= p(N, fed in Ix, A), 
i ---- 1, ..., n 
as = P(N and NS fired in/Ix, A), 
l,j=l,...,n, 
where A represents the event that one or two spikes occurred in the interval I. In other words 
Pi the probability that what has been detected is a single spike from neuron i, whereas 
is the probability that we have two overlapping spikes from neurons I and j (note that spikes 
from the same neuron never overlap). Henceforth we will use f to denote probability density. 
For the purpose of abbreviation let Bi(t) mean ""neuron Ni fired at t"". The classification 
problem can be reduced to comparing the following likelihood functions: 
ft+ T2 
Li = f(Bi(t))a,_r ' f(xlBi(t,))dZ,, i= 1,...,r (la) 
t + T: ft + T: 
= f(xlBt(tx),Bs(t=))dt,dt= , l,j= 1,...,n, j < I (lb) 
(for a derDation refer to AppendN). Let fi be the density of the inter-spe interval d ri be 
the most recent firg instant of neuron Ni. ff we e given the ft that neuron Ni h been 
idle for at let a period of duration t - ri, we get 
= 
(2} 
A disadvantage of using (2) is that the available fi's and ri's are only estimates, which depend 
on the previous classification results, Further, for reliable estimation of the densities fi, one 
needs a large number of spikes and therefore a long learning period since we are estimating a 
98 
whole function. Therefore, we have not used this form, but instead have used the following two 
schemes. In the first one, we ignore the knowledge about the previous firing pattern except 
for the estimated firing rates ,l, ...,An of the different neurons N1, ...,Nn respectively. Then 
the probability of a spike coming from neuron Ni in an interval of duration dt is simply Aidt. 
Hence 
i(B(0) = (3) 
In the second scheme we do not use any previous knowledge except for the total firing rate (of 
all neurons), say a. Then 
f(Bi(t)) = --. (4) 
n 
Although the second scheme does not use as much of the information about the firing 
pattern as the first scheme does, it has the advantage of obtaining and using a more reliable 
estimate of the firing rate, because in general the overall firing rate changes less with time than 
the individual rates and because the estimate of a does not depend on previous classification 
results. However, it is useful mostly when the firing rates of the different neurons do not vary 
much, otherwise the firt scheme is preferred. 
In real recording situations, sometimes one encounters voltage signals which are much 
different than any of the previously learned typical spike shapes or their pairwise overlaps. 
This can happen for example due to a falsely detected noise event, a spike from a class not 
encountered in the learning stage, or to the overlap of three or more spikes. To cope with 
these cases we use the reject option. This means that we refuse to classify the detected spike 
because of the unlikeliness of the assumed event A. The reject option is therefore employed 
whenever P(Atx ) is smaller than a certain threshold. We know that 
P(AIx ) = f(A,x)/[f(A,x)+ f(A,x)] 
where A c is the complement of the event A. The density f(AC,x) can be approximated as 
uniform (over the possible values of x) because a large variety of cases are covered by the event 
A c. It follows that one can just compare f(A,x) to a threshold. Hence the decision strategy 
becomes finally: Reject if the sum of the likelihood functions is less than a threshold. Otherwise 
choose the neuron (or pair of neurons) corresponding to the largest likelihood functions. Note 
that the sum of the likelihood functions equals f(A,x) (refer to Appendix). 
Now, let us evaluate the integrals in (1). Overlapping spikes are assumed to add linearly. 
Since we intend to handle the overlap case, we have to use a set of features xm which obeys 
the following. Given the features of two of the waveforms, then one can compute those of their 
overlap. A good such candidate is the set of the samples of the spike (or possibly also just 
part of the samples). The added noise, partly thermal noise from the electrode and partly 
due to firings from distant neurons, can usually be approximated as white Gaussian. Let the 
variance be cr 2. The integrals in the likelihood functions can be approximated as summations 
(note in fact that we have samples available, not a continuous waveform). Let �i represent the 
typical feature vector (template) associated with neuron Ni, with the rn th component being 
i 
y,,. Then 
1 exp [- 1 i 2 
m=l 
M 
i exp[-- i t 
-- Ym-kx 
i(xl,(kl), - 
rl,---- ! 
- y' 
rr--k ] J 
99 
where x, is the rn t component of x, and M is the dimension ofx. This leads to the following 
likelihood functions 
 1 i 2 
kl=-M m=l 
-- -- Ym-kx -- m-kl J 
kl=-Mlk:-M1 
where k  the spike stant, and the interval from -M to M2 corresponds to the inteal I 
defined at the beginning of the Section. 
Implementation 
The techniques we have just described were tested in the following way. For the first 
experiment we identified two spike classes in a recording from the rat cerebellum. A signal 
is created, composed of a number of spikes from the two classes at random instants, plus 
noise. To make the situation as realistic as possible, the added noise is taken from idle periods 
(i.e. non-spiking) of a real recording. The reason for using such an artificially generated 
signal is to be able to know the class identities of the spikes, in order to test our approach 
quantitatively. We implement the detection and classification techniques on the obtained 
signal, with various values of noise amplitude. In our case the ratio of the peak to peak values 
of the telnplates turns out to be 1.375. Also, the spike rate of one of the clases is twice that of 
the other class. Fig.3a shows the results with applying the first scheme (i.e. using Eq. 3). The 
overall percentage correct classification for all spikes (solid curve) and the percentage correct 
classification for overlapping spikes (dashed curve) are plotted versus the standard deviation 
of the noise cr normalized with respect to the peak h of the large template. Notice that the 
overall classification accuracy is near 100% for cr/h less than 0.15, which is actually the range 
of noise amplitudes we mostly encountered in our work with real recordings. Observe also 
the good results for classifying overlapping events. We have applied also the second scheme 
(i.e. using Eq. 4) and obtained similar results. We wish to mention that the thresholds for 
detection and for the reject option are set up so as to obtain no more than 3% falsely detected 
spikes. 
A similar experiment is performed with three waveforms (three classes), where two of the 
waveforms are the same as those used in the first experiment. The third is the average of 
the first two. All the three neurons have the same spike rate (i.e. ,l : -2 = ,3). Hence 
both classification schemes are equivalent in this case. Fig. 3b shows the overall as well as 
the sub-category of overlap classification results. One observes that the results are worse than 
those for the two-class case. This is because the spacings between the templates are in general 
smaller. Notice also that the accuracy in resolving overlapping events is now tangibly less 
than the overall accuracy. However, one can say that the results are acceptable in the range 
of cr/h less than 0.1. The following experiment is also performed using the same data. We 
would like to investigate the importance of the information given by the (overall) firing rate on 
the problem of classifying overlapping events. In our method the summation in the likelihood 
functions for single spikes is multiplied by o/n, while that for overlapping spikes is multiplied 
by (c/n) 2. Usually ot/n is considerably less than one. Hence we have a factor which gives less 
weight for overlapping events. Now, consider the case of ignoring completely the information 
given by the firing rate and relying solely on shape information. We assume that overlapping 
spikes from any two given classes represent ""new"" class of waveforms and that each of these 
overlap classes has the same rate as that of a single-spike class. In that case we can obtain 
expressions for the likelihood functions as consisting just the summations, i.e. free of the rate 
100 
l. 1.148 I.l% 1.24t I.l 
a 
If. Ill 
III.III 
II.III 
I, 1.848 1.1% 1.14 1.1 1.711 
otlel/ 
Fig. 3 
a) Overall (solid curve) and overlap (dashed curve) 
classification accuracy for a two class case 
b) Overall (solid curve) and overlap (dashed curve) 
classification accuracy for a three class case 
Percent of incorrect classification of single spikes as overlap 
solid curve: scheme utilzing the spike rate 
dashed curve: scheme not utilizing the spike rate 
factor / (refer to Appendix). An experiment is performed using that scheme (on the same 
three class data). One observes that the method classifies a number of single spikes wrongly 
as overlaps, much more than our original scheme does (see Fig. 3c), especially for the large 
noise case. On the other hand, the number of overlaps which are classified wrongly as single 
spikes is near zero for both schemes. 
Finally, in the last experiment the techniques re implemented on real recordings from the 
rat cerebellum. The recorded signal is band-pass-filtered in the frequency range 300 Hz - 10 
KH% then sampled with a rate of 20KH.. For classification, we take 20 samples per spike as 
features. Fig. 4 shows the results of the proposed method, using the first scheme (Eq. 3). The 
number of neurons whose spikes are represented in the waveform is estimated to be four. The 
lol 
detection threshold is set up so that spikes which are too small are disregarded, because they 
come from several neurons far away from the electrode and are hard to distinguish. Notice 
the overlap of classes 1 and 2, which was detected. We used the second scheme also on the 
same portion and it gave similar results as those of the first scheme (only one of the spikes is 
classified differently). Overall, the discrepancies between classifications done by the proposed 
method and an experienced human observer were found to be small. 
3 
1 
3 3 
2 
I I 
3 
14 
1,2 3 
I I 
1 
3 2 
1 
1 
Fig. 4 
Classification results for a recording from the rat cerebellum 
Conclusion 
Many researchers have considered the problem of spike classification in multi-neuron 
recordings, but only few have tackled the case of spike overlap, which could occur frequently, 
particularly if the group of neurons under study is stimulated. In this work we propose a 
method for spike classification, which can also aid in detecting and classifying overlapping 
spikes. By taking into account the statistical properties of the discharges of the neurons sam- 
pied, this method minimizes the probability of classification error. The application of the 
method to artificial as well as real recordings confirm its effectiveness. 
Appendix 
Consider first Py. We can write 
102 
We can also obtain 
f+Tf+T= 
V, s = f(x' AIB'(t)' Bs(t2)) 
Now, consider the two events Bt(t) d Bi(t2 ). In the absense of any formation about thek 
dependence, we sume that they e independent. We get 
f(Bt(t),Bi(t2)) =/(Bt(t))/(By(t2)). 
Within the interval I, both /(Bt(t)) and /(Bs(t2)) hardly vy because the duration of 
I 2 very small comped to a typical inter-spe teal. Therefore we get the foowing 
approx ation: 
/(SS(*))  /(SS(*))' 
The expression for S becomes 
Notice that the term A was omitted from the gument of the density inside the integral, 
because the occuence of two spikes at t d t2eI implies the occurrence of A. A 
derivation for  results  
The erm f(x, A)  common o all he PU's and [he Pi's. Hence one can sply compare [he 
following lelood functions: 
= 
Acknowledgement 
Our thanks to Dr. Yaser Abu-Mostafa for his assistance with this work. This project was 
supported by the Caltech Program of Advanced Technology (sponsored by Aerojet,GM,GTE, 
and TRW), and the Joseph Drown Foundation. 
References 
[1] M. Abeles and M. Goldstein, Proc. IEEE, 65, pp.762-773, 1977. 
[2] G. Dinning and A. Sanderson, IEEE Trans. Bio- Med. Eng., BME-28, pp. 804-812, 
1981. 
[3] E. D'Hollander and G. Orban, IEEE Trans. Bio-Med. Eng., BME-26, pp. 279-284, 1979. 
[4] D. Mishelevich, IEEE Trans. Bio-Med. Eng., BME-17, pp. 147-150, 1970. 
[5] V. Prochazka and H. Kornhuber, Electroenceph. clin. Neurophysiol., 32, pp. 91-93, 1973. 
[6] W. Roberts, Biol. Cybernet., 35, pp. 73-80, 1979. 
[7] W. Roberts and D. Hartline, Brain Res., 94, pp. 141-149, 1975. 
[8] E. Schmidt, J. Neurosci. Methods, 12, pp. 95-111, 1984. 
[9] R. Duda and P. Hart, Pattern Classification and Scene Analysis, John Wiley, 1973. 
", neural spike classif electr engin divis biolog institut technolog abl record electr activ number neuron simultan like import studi function organ network real use extracellular microelectrod record sever neuron one approach studi respons properti set adjac therefor like relat necessari correctli classifi signal gener differ paper consid problem classifi signal extracellular upon specif consid classif signal case overlap singl neuron network neuron interact process inform like fundament question central understand real neural network mammalian nervou system know spatial adjac neuron hkeli well receiv common thu neurobiologist interest devis techniqu allow adjac group neuron sampl small scale real neural network make insert one record electrod cell one forc use singl electrod design sampl signal evok sever cell approach provid also present rather seriou waveform classif problem actual tempor sequenc action potenti individu neuron must paper describ method classifi activ sever individu record simultan use singl problem last two decad consider attent devot problem action potenti action potenti extracellularli record signal produc singl neuron pass inform neuron spike record cell less similar spike come differ neuron usual somewhat differ depend neuron electrod electrod interven illustr repres variat spike object detect classifi differ base reli entir shape spike present exampl spike differ neuron overlap tempor produc novel exampl deal one first detect occurr estim constitu avail spike separ algorithm consid even though potenti import understand neural tend reli institut physic heurist rule subtract method resolv overlap current publish awar attempt use knowledg likelihood overlap event basi method exampl record spike exampl tempor overlap action potenti approach first step classifi neural waveform obvious identifi typic spike occur particular appli learn algorithm begin portion unsupervis fashion without human estim learn stage classif appli remain portion new method give minimum probabl even case overlap learn classif algorithm requir preprocess step detect posit spike candid data first task detect research use simpl level detect signal spike record voltag level cross certain voltag variat record posit due natur brain movement record caus chang rel height posit neg level detector either posit neg miss chosen detect event slide window fix length peak peak valu within window exce certain learn perform begin portion sampl data use isodata cluster algorithm task estim number neuron whose repres waveform learn differ shape spike purpos appli cluster algorithm choos one featur peak peak valu found quit effect use peak peak valu learn stage necessit use might need addit differ especi tackl case spike optim classif identifi number differ event classif stage concern estim ident spike base typic spike shape obtain learn classif make use inform given shape detect spike well fire rate differ although shape play gener role rate becom signific factor deal overlap gener overlap consider less frequent shape inform given set featur extract featur vector detect spike sampl spike let repres differ detect algorithm tell us least spike occur narrow interv say instant peak detect tg constant chosen subject accord possibl time separ two consecut identifi two separ one spike occur interv matter instant occurr spike spike consid case two possibl though method extend easili classif rule result minimum probabl error one choos neuron pair case maximum therefor compar defin fed ns fire repres event one two spike occur interv word probabl detect singl spike neuron wherea probabl two overlap spike neuron spike neuron never henceforth use denot probabl purpos abbrevi let mean ni fire classif reduc compar follow likelihood ft dation refer let fi densiti interv ri recent instant neuron ff given neuron ni period durat get disadvantag use avail depend previou classif reliabl estim densiti one larg number spike therefor long learn period sinc estim use instead use follow two first ignor knowledg previou fire pattern except estim fire rate differ neuron probabl spike come neuron ni interv durat dt simpli second scheme use previou knowledg except total fire rate say second scheme use much inform fire first scheme advantag obtain use reliabl fire gener overal fire rate chang less time individu rate estim depend previou classif use mostli fire rate differ neuron vari otherwis firt scheme real record sometim one encount voltag signal much previous learn typic spike shape pairwis happen exampl due fals detect nois spike class learn overlap three cope case use reject mean refus classifi detect spike unlikeli assum event reject option therefor employ smaller certain know complement event densiti approxim possibl valu larg varieti case cover event follow one compar henc decis strategi reject sum likelihood function less otherwis neuron pair correspond largest likelihood note sum likelihood function equal let us evalu integr overlap spike assum add intend handl overlap use set featur xm obey given featur two one comput good candid set sampl spike possibl also ad partli thermal nois electrod partli fire distant usual approxim white let cr integr likelihood function approxim summat fact sampl continu let repres featur vector associ neuron rn th compon exp rn compon dimens lead follow function spike interv correspond begin techniqu describ test follow first identifi two spike class record rat signal compos number spike two class random plu make situat realist ad nois taken idl period real reason use artifici gener abl know class ident order test approach implement detect classif techniqu obtain variou valu nois case ratio peak peak valu telnplat turn spike rate one clase twice show result appli first scheme use percentag correct classif spike percentag correct overlap spike plot versu standard deviat nois cr normal respect peak larg notic classif accuraci near less actual rang nois amplitud mostli encount work real observ also good result classifi overlap appli also second scheme use obtain similar wish mention threshold reject option set obtain fals detect similar experi perform three waveform two use first third averag first three neuron spike rate henc classif scheme equival show overal well overlap classif one observ result wors space templat gener notic also accuraci resolv overlap event tangibl less overal one say result accept rang less follow experi also perform use like investig import inform given fire rate problem classifi overlap method summat likelihood singl spike multipli overlap spike multipli usual consider less henc factor give less overlap consid case ignor complet inform fire rate reli sole shape assum overlap two given class repres class waveform class rate case obtain likelihood function consist free rate ill overal overlap accuraci two class case overal overlap accuraci three class case incorrect classif singl spike overlap scheme utilz spike rate scheme util spike rate experi perform use scheme class one observ method classifi number singl spike wrongli much origin scheme especi larg number overlap classifi wrongli singl near zero last experi techniqu implement real record record signal frequenc rang hz sampl rate take sampl per spike show result propos use first scheme neuron whose spike repres waveform estim threshold set spike small sever neuron far away electrod hard notic overlap class use second scheme also portion gave similar result first scheme one spike discrep classif done propos experienc human observ found result record rat cerebellum research consid problem spike classif case spike could occur group neuron studi work propos spike also aid detect classifi overlap take account statist properti discharg neuron method minim probabl classif applic artifici well real record confirm first write also obtain consid two event absens thek get interv hardli durat small typic therefor get express becom term omit densiti insid two spike impli occurr result common henc one compar thank yaser assist project caltech program advanc technolog joseph drown abel din ie ie ie prochazka robert brain duda pattern classif scene john,1
11,11,"103 
NEURAL NETWORKS FOR TEMPLATE MATCHING: 
APPLICATION TO REAL-TIME CLASSIFICATION 
OF THE ACTION POTENTIALS OF REAL NEURONS 
Yiu-fai Wong, Jashojiban Banik]. and James M. Bower$ 
]'Division of Engineering and Applied Science 
$Division of Biology 
California Institute of Technology 
Pasadena, CA 91125 
ABSTRACT 
Much experimental study of real neural networks relies on the proper classification of 
extracellulary sampled neural signals (i.e. action potentials) recorded from the brains of ex- 
perimental animals. In most neurophysiology laboratories this classification task is simplified 
by limiting investigations to single, electrically well-isolated neurons recorded one at a time. 
However, for those interested in sampling the activities of many single neurons simultaneously, 
waveform classification becomes a serious concern. In this paper we describe and constrast 
three approaches to this problem each designed not only to recognize isolated neural events, 
but also to separately classify temporally overlapping events in real time. First we present two 
formulations of waveform classification using a neural network template matching approach. 
These two formulations are then compared to a simple template matching implementation. 
Analysis with real neural signals reveals that simple template matching is a better solution to 
this problem than either neural network approach. 
INTRODUCTION 
For many years, neurobiologists have been studying the nervous system by 
using single electrodes to serially sample the electrical activity of single neu- 
rons in the brain. However, as physiologists and theorists have become more 
aware of the complex, nonlinear dynamics of these networks, it has become 
apparent that serial sampling strategies may not provide all the information 
necessary to understand functional organization. In addition, it will likely be 
necessary to develop new techniques which sample the activities of multiple 
neurons simultaneously 1. Over the last several years, we have developed two 
different methods to acquire multineuron data. Our initial design involved 
the placement of many tiny microelectrodes individually in a tightly packed 
pseudo-floating configuration within the brain 2. More recently we have been 
developing a more sophisticated approach which utilizes recent advances in 
silicon technology to fabricate multi-ported silicon based electrodes (Fig. 1). 
Using these electrodes we expect to be able to readily record the activity pat- 
terns of larger number of neurons. 
As research in multi-single neuron recording techniques continue, it has be- 
come very clear that whatever technique is used to acquire neural signals from 
many brain locations, the technical difficulties associated with sampling, data 
compressing, storing, analyzing and interpreting these signals largely dwarf the 
development of the sampling device itself. In this report we specifically consider 
the need to assure that neural action potentials (also known as ""spikes"") on 
each of many parallel recording channels are correctly classified, which is just 
one aspect of the problem of post-processing multi-single neuron data. With 
more traditional single electrode/single neuron recordings, this task usually in- 
American Institute of Physics 1988 
104 
volves passing analog signals through a Schmidt trigger whose output indicates 
the occurence of an event to a computer, at the same time as it triggers an 
oscilloscope sweep of the analog data. The experimenter visually monitors the 
oscilloscope to verify the accuracy of the discrimination as a well-discriminated 
signal from a single neuron will overlap on successive oscilloscope traces (Fig. 
lc). Obviously this approach is impractical when large numbers of channels 
are recorded at the same time. Instead, it is necessary to automate this classifi- 
cation procedure. In this paper we will describe and contrast three approaches 
we have developed to do this. 
layer 
Traces 
on lower 
layer 
., ,, ; 
0 1 
2 3 4 
me (mc) 
Receding site b. 
75 sq 
Fig. 1. Silicon probe being developed in our lababoratory for multi-single unit recording 
in cerebellax cortex. a) a complete probe; b) surface view of one recording tip; c) several 
superhnposed neuronal action potentials recorded from such a silicon electrode in cerebellax 
cortex. 
While our principal design objective is the assurance that neural waveforms 
are adequately discriminated on multiple channels, technically the overall ob- 
jective of this research project is to sample from as many single neurons as 
possible. Therefore, it is a natural extention of our effort to develop a neural 
waveform classification scheme robust enough to allow us to distinguish activi- 
ties arising from more than one neuron per recording site. To do this, however, 
we now not only have to determine that a particular signal is neural in origin, 
but also from which of several possible neurons it arose (see Fig. 2a). While 
in general signals from different neurons have different waveforms aiding in 
the classification, neurons recorded on the same channel firing simultaneously 
or nearly simultaneously will produce novel combination waveforms (Fig. 2b) 
which also need to be classified. It is this last complication which particularly 
105 
bedevils previous efforts to classify neural signals (For review see 5, also see 
3-4). In summary, then, our objective was to design a circuit that would: 
1. distinguish different waveforms even though neuronal discharges tend 
to be quite similar in shape (Fig. 2a); 
2. recognize the same waveform even though unavoidable movements 
such as animal respiration often result in periodic changes in the amplitude 
of a recorded signal by moving the brain relative to the tip of the electrode; 
3. be considerably robust to recording noise which variably corrupts all 
neural recordings (Fig. 2); 
4. resolve overlapping waveforms, which are likely to be particularly in- 
teresting events from a neurobiological point of view; 
5. provide real-time performance allowing the experimenter to detect 
problems with discrimination and monitor the progress of the experiment; 
6. be implementable in hardware due to the need to classify neural sig- 
nals on many channels simultaneously. Simply duplicating a software-based 
algorithm for each channel will not work, but rather, multiple, small, in- 
dependent, and programmable hardware devices need to be constructed. 
1 1 
signal recorded 
2 2 
t 5o v 
electrode 
a. 
Fig. 2. a) Schematic diagram of an electrode recording from two neuronal cell bodies b) An 
actual multi-neuron recording. Note the similarities in the two waveforms and the overlapping 
event. c) and d) Synthesized data with different noise levels for testing classification algorithms 
(c: 0.3 NSR; d: 1.1 NSR). 
106 
METHODS 
The problem of detecting and classifying multiple neural signals on sin- 
gle voltage records involves two steps. First, the waveforms that are present 
in a particular signal must be identified and the templates be generated; 
second, these waveforms must be detected and classified in ongoing data 
records. To accomplish the first step we have modified the principal com- 
ponent analysis procedure described by Abeles and Goldstein 3 to automat- 
ically extract templates of the distinct waveforms found in an initial sam- 
ple of the digitized analog data. This will not be discussed further as it is 
the means of accomplishing the second step which concerns us here. Specif- 
ically, in this paper we compare three new approaches to ongoing wave- 
form classification which deal explicitly with overlapping spikes and vari- 
ably meet other design criteria outlined above. These approaches consist of 
a modified template matching scheme, and two applied neural network im- 
plementations. We will first consider the neural network approaches. On 
a point of nomenclature, to avoid confusion in what follows, the real neu- 
rons whose signals we want to classify will be referred to as ""neurons"" while 
computing elements in the applied neural networks will be called ""Hopons."" 
Neural Network Approach -- Overall, the problem of classifying neural 
waveforms can best be seen as an optimization problem in the presence of 
noise. Much recent work on neural-type network algorithms has demonstrated 
that these networks work quite well on problems of this sort 6-8. In particular, 
in a recent paper Hopfield and Tank describe an A/D converter network and 
suggest how to map the problem of template matching into a similar context 8. 
The energy functional for the network they propose has the form: 
where T/j = connectivity between Hopon i and Hopon j, V/ = voltage output 
of Hopon i, Ii = input current to Hopon i and each Hopon has a sigmoid 
input-output characteristic V -- g(u) = 1/(1 + exp(-au)). 
If the equation of motion is set to be: 
dui/dt = -OE/OV =  TsV  + I 
(la) 
then we see that dE/dt = -(j TiVj + Ii)dV/dt - -(du/dt)(dV/dt) = 
-g'(u)(du/dt) 2 50. Hence E will go to to a minimum which, in a network 
constructed as described below, will correspond to a proposed solution to a 
particular waveform classification problem. 
Template Matching using a Hopfield-type Neural Net -- We have 
taken the following approach to template matching using a neural network. For 
simplicity, we initially restricted the classification problem to one involving two 
waveforms and have accordingly constructed a neural network made up of two 
groups of Hopons, each concerned with discriminating one or the other wave- 
form. The classification procedure works as follows: first, a Schmidt trigger 
107 
is used to detect the presence of a voltage on the signal channel above a set 
threshold. When this threshold is crossed, implying the presence of a possible 
neural signal, 2 msecs of data around the crossing are stored in a buffer (40 
samples at 20 KHz). Note that biophysical limitations assure that a single real 
neuron cannot discharge more than once in this time period, so only one wave- 
form of a particular type can occur in this data sample. Also, action potentials 
are of the order of i msec in duration, so the 2 msec window will include the full 
signal for single or overlapped waveforms. In the next step (explained later) 
the data values are correlated and passed into a Hopfield network designed to 
minimize the mean-square error between the actual data and the linear com- 
bination of different delays of the templates. Each Hopon in the set of Hopons 
concerned with one waveform represents a particular temporal delay in the 
occurrence of that waveform in the buffer. To express the network in terms of 
an energy function formulation: Let x(t) - input waveform amplitude in the 
ttn time bin, sj(t) -- amplitude of the jtn template, Vj denote if sj(t- k)(j n 
template delayed by k time bins)is present in the input waveform. Then the 
appropriate energy function is: 
1 2 
t j,k 
i ,. V.(Vj _ 1)s(t- k) 
2 
+q 
j,kl <k2 
(2) 
The first term is designed to minimize the mean-square error and specifies 
the best match. Since V C [0, 1], the second term is minimized only when each 
Vj assumes values 0 or 1. It also sets the diagonal elements T/j to 0. The 
third term creates mutual inhibition among the processing nodes evaluating 
the same neuronal signal, which as described above can only occur once per 
sample. 
Expanding and simplifying expression (2), the connection matrix is: 
T(j,),(j2,) = { 
--  'jl (t - k)sia(t - k2) - '5 
t (3a) 
0 ifj=j2, k=k 
and the input current 
i (t-k) 
I. :  x(t)si(t - k) -   sl 
t t 
(3b) 
As it can be seen, the inputs are the correlations between the actual data and 
the various delays of the templates subtracting a constant term. 
Modified Hopfield Network -- As documented in more detail in Fig. 
3-4, the above full Hopfield-type network works well for temporally isolated 
spikes at moderate noise levels, but for overlapping spikes it has a local minima 
problem. This is more severe with more than two waveforms in the network. 
108 
Further, we need to build our network in hardware and the full Hopfield net- 
work is difficult to implement with current technology (see below). For these 
reasons, we developed a modified neural network approach which significantly 
reduces the necessary hardware complexity and also has improved performance. 
To understand how this works, let us look at the information contained in the 
quantities Ti5 and Ii5 (eq. 3a and 3b ) and make some use of them. These 
quantities have to be calculated at a pre-processing stage before being loaded 
into the Hopfield network. If after calculating these quantities, we can quickly 
rule out a large number of possible template combinations, then we can sig- 
nificantly reduce the size of the problem and thus use a much smaller (and 
hence more efficient) neural network to find the optimal solution. To make the 
derivation simple, we define slightly modified versions of T/i and Ii5 (eq. 4a 
and 4b) for two-template case. 
Ti5 = Z sl(t - i)s.(t - j) (4a) 
t 
[ 1 1 1 
Iff =  x(t) s(t - i) + s2(t - j)] -   s(t - i) -   s(t - j) (4b) 
t t t 
In the case of overlaping spikes the T/i's are the cross-correlations between s (t) 
and s2 (t) with different delays and Iis's are the cross-correlations between input 
x(t) and weighted combination of s(t) and s(t). Now if x(t) = s(t- i) + 
s. (t - j) (i.e. the overlap of the first template with i time bin delay and the 
second template with j time bin delay), then Ai5 = ITi- Iii]: 0. However 
in the presence of noise, Aij will not be identically zero, but will equal to the 
noise, and if A,i > AT/ (where AT/i = IT/5 - Tvi, I for i  i  and j  j) this 
simple algorithm may make unacceptable errors. A solution to this problem 
for overlapping spikes will be described below, but now let us consider the 
problem of classifying non-overlapping spikes. In this case, we can compare 
the input cross-correlation with the auto-correlations (eq. 4c and 4d). 
7[: . s(t- i); T[' = '. s(t - i) (4c) 
t t 
I:  x(t)s(t - i); I'=  x(t)s2(t - i) 
t t 
(4d) 
So for non-overlapping cases, if x(t) = s(t- i), then A; = IT[ - 11 = 0. If 
x(t): s=(t - i), then A:': IT['- IJ' I = 0. 
In the absence of noise, then the minimum of AiS, A'i and A{ represents the 
correct classification. However, in the presence of noise, none of these quantities 
will be identically zero, but will equal the noise in the input x(t) which will 
give rise to unacceptible errors. Our solution to this noise related problem is 
to choose a few minima (three have chosen in our case) instead of one. For 
each minimum there is either a known corresponding linear combination of 
templates for overlapping cases or a simple template for non-overlapping cases. 
A three neuron Hopfield-type network is then programmed so that each neuron 
corresponds to each of the cases. The input x(t) is fed to this tiny network to 
resolve whatever confusion remains after the first step of %ross-correlation"" 
comparisons. (Note: Simple template matching as described below can also be 
used in the place of the tiny Hop field type network.) 
109 
Simple Template Matching -- To evaluate the performances of these 
neural network approaches, we decided to implement a simple template match- 
ing scheme, which we will now describe. However, as documented below, this 
approach turned out to be the most accurate and require the least complex 
hardwaxe of any of the three approaches. The first step is, again, to fill a buffer 
with data based on the detection of a possible neural signal. Then we calculate 
the difference between the recorded waveform and all possible combinations of 
the two previously identified templates. Formally, this consists of calculating 
the distances between the input x(m) and all possible cases generated by all 
the combinations of the two templates. 
= Ix(t) - {s(t - i) + s(t - 
t 
di- -.[x(t)- i)l; d'[ = lx(t)- i)l 
t t 
d,i, -' rnin( dij, d' i, d',') 
d,i, gives the best fit of all possible combinations of templates to the actual 
voltage signal. 
TESTING PROCEDURES 
To compare the performance of each of the three approaches, we devised a 
common set of test data using the following procedures. First, we used the prin- 
cipal component method of Abeles and Goldstein 3 to generate two templates 
from a digitized analog record of neural activity recorded in the cerebellum 
of the rat. The two actual spike waveform templates we decided to use had 
a peak-to-peak ratio of 1.375. From a second set of analog recordings made 
from a site in the cerebellum in which no action potential events were evident, 
we determined the spectral characteristics of the recording noise. These two 
components derived from real neural recordings were then digitally combined, 
the objective being to construct realistic records, while also knowing absolutely 
what the correct solution to the template matching problem was for each oc- 
curring spike. As shown in Fig. 2c and 2d, data sets corresponding to different 
noise to signal ratios were constructed. We also carried out simulations with 
the amplitudes of the templates themselves varied in the synthesized records to 
simulate waveform changes due to brain movements often seen in real record- 
ings. In addition to two waveform test sets, we also constructed three waveform 
sets by generating a third template that was the average of the first two tem- 
plates. To further quantify the comparisons of the three diffferent approaches 
described above we considered non-overlapping and overlapping spikes sepa- 
rately. To quantify the performance of the three different approaches, two 
standards for classification were devised. In the first and hardest case, to be 
judged a correct classification, the precise order and timing of two waveforms 
had to be reconstructed. In the second and looser scheme, classification was 
judged correct if the order of two waveforms was correct but timing was al- 
lowed to vary by 100 secs(i.e. +2 time bins) which for most neurobiological 
applications is probably sufficient resolution. Figs. 3-4 compare the perfor- 
mance results for the three approaches to waveform classification implemented 
as digital simulations. 
11o 
PERFORMANCE COMPARISON 
Two templates - non-overlapping waveforms: As shown in Fig. 3a, at 
low noise-to-signal ratios (NSRs below .2) each of the three approaches were 
comparable in performance reaching close to 100% accuracy for each criterion. 
As the ratio was increased, however the neural network implementations did 
less and less well with respect to the simple template matching algorithm with 
the full Hop field type network doing considerably worse than the modified 
network. In the range of NSR most often found in real data (.2 - .4) simple 
template matching performed considerably better than either of the neural 
network approaches. Also it is to be noted that simple template matching 
gives an estimate of the goodness of fit betwwen the waveform and the closest 
template which could be used to identify events that should not be classified 
(e.g. signals due to noise). 
.Z .4 .G .8 
noise level: 3a/peak amplitude 
.2 .4 .6 .B 
noise level: 3(r/peak amplitude 
degrees of overlap 
light line -- absolute criteria 
heavy line -- less stringent criteria 
simple template matching 
Hopfield network 
modified Hop field network 
Fig. 3. Comparisons of the three approaches detecting two non-overlapping (a), and over- 
lapping (b) waveforms, c) compares the performances of the neural network approaches for 
different degrees of waveform overlap. 
Two' templates - overlapping waveforms: Fig. 3b and 3c compare perfor- 
mances when waveforms overlapped. In Fig. 3b the serious local minima prob- 
lem encountered in the full neural network is demonstrated as is the improved 
performance of the modified network. Again, overall performance in physi- 
111 
ological ranges of noise is clearly best for simple template matching. When 
the noise level is low, the modified approach is the better of the two neural 
networks due to the reliability of the correlation number which reflects the 
resemblence between the input data and the template. When the noise level 
is high, errors in the correlation numbers may exclude the right combination 
from the smaller network. In this case its performance is actually a little worse 
than the larger Hopfield network. Fig. 3c documents in detail which degrees 
of overlap produce the most trouble for the neural network approaches at av- 
erage NSR levels found in real neural data. It can be seen that for the neural 
networks, the most serious problem is encountered when the delays between 
the two waveforms are small enough that the resulting waveform looks like the 
larger waveform with some perturbation. 
Three templates - overlappin9 and non-overlappin9: In Fig. 4 are shown 
the comparisons between the full Hopfield network approach and the simple 
template matching approach. For nonoverlapping waveforms, the performance 
of these two approaches is much more comparable than for the two waveform 
case (Fig. 4a), although simple template matching is still the optimal method. 
In the overlapping waveform condition, however, the neural network approach 
fails badly (Fig. 4b and 4c). For this particular application and implementa- 
tion, the neural network approach does not scale well. 
ao 
Co 
2 
bo 
.2 .4 .6 .8 1. 
noise level: 3a/peak amplitude 
.2 .4 .fi .11 I.B 
noise level: 3a/peak amplitude 
O .2 .4 .& .8 
noise level: 3r/peak amplitude 
Hopfield network 
simple template matching 
light line -- absolute criteria 
heavy line -- less stringent criteria 
rr = variance of the noise 
Fig. 4. Comparisons of performance for three waveforms. a) nonoverlapping waveforms; b) 
two waveforms overlapping; c) three waveforms overlapping. 
HARDWARE COMPARISONS 
As described earlier, an important design requirement for this work was the 
ability to detect neural signals in analog records in real-time originating from 
112 
many simultaneously active sampling electrodes. Because it is not feasible to 
run the algorithms in a computer in real time for all the channels simultane- 
ously, it is necessary to design and build dedicated hardware for each channel. 
To do this, we have decided to design VLSI implementations of our circuitry. 
In this regard, it is well recognized that large modifiable neural networks need 
very elaborate hardware implementations. Let us consider, for example, im- 
plementing hardwaxes for a two-template case for comparisons. Let n = no. 
of neurons per template (one neuron for each delay of the template), rn = 
no. of iterations to reach the stable state (in simulating the discretized dif- 
ferential equation, with step size = 0.05), l = no. of samples in a template 
tj(rn). Then, the number of connections in the full Hopfield network will be 
4n 2. The total no. of synaptic calculations = 4rnn . So, for two templates 
and n = 16, rn = 100, 4rnn  = 102,400. Thus building the full Hopfield-type 
network digitally requires a system too large to be put in a single VLSI chip 
which will work in real time. If we want to build an analog system, we need 
to have many (O(4n2)) easily modifiable synapses. As yet this technology is 
not available for nets of this size. The modified Hopfield-type network on the 
other hand is less technically demanding. To do the preprocessing to obtain 
the minimum values we have to do about n 2 = 256 additions to find all possible 
Iijs and require 256 subtractions and comparisons to find three minima. The 
costs associated with doing input cross-correlations are the same as for the full 
neural network (i.e. 2nl = 768(/ = 24) multiplications). The saving with the 
modified approach is that the network used is small and fast (120 multiplica- 
tions and 120 additions to construct the modifiable synapses, no. of synaptic 
calculations = 90 with m = 10, n = 3). 
In contrast to the neural networks, simple template matching is simple 
indeed. For example, it must perform about n2l + n'= 10, 496 additions and 
n 2 = 256 comparisons to find the minimum dii. Additions are considerably less 
costly in time and hardware than multiplications. In fact, because this method 
needs only addition operations, our preliminary design work suggests it can be 
built on a single chip and will be able to do the two-template classification 
in as little as 20 microseconds. This actually raises the possibility that with 
switching and buffering one chip might be able to service more than one channel 
in essentially real time. 
CONCLUSIONS 
Template matching using a full Hopfield-type neural network is found to 
be robust to noise and changes in signal waveform for the two neural waveform 
classification problem. However, for a three-waveform case, the network does 
not perform well. Further, the network requires many modifiable connections 
and therefore results in an elaborate hardware implementation. The overall 
performance of the modified neural network approach is better than the full 
Hopfield network approach. The computation has been reduced largly and 
the hardware requirements are considerably less demanding demonstrating the 
value of designing a specific network to a specified problem. However, even the 
modified neural network performs less well than a simple template-matching 
algorithm which also has the simplest hardware implementation. Using the 
simple template matching algorithm, our simulations suggest it will be pos- 
sible to build a two or three waveform classifier on a single VLSI chip using 
CMOS technology that works in real time with excellent error characteristics. 
Further, such a chip will be able to accurately classify variably overlapping 
113 
neural signals. 
REFERENCES 
[1] G. L. Gerstein, M. J. Bloom, I. E. Espinosa, S. Evanczuk & M. R. Turner, 
IEEE Trans. Sys. Cyb. Man., SMC-13,668(1983). 
2 J.M. Bower & R. Llinas, Soc. Neurosci. Abst., 9, 607(1983). 
3 M. Abeles & M. H. Goldstein, Proc. IEEE, 65, 2(1977). 
W. M. Roberts & D. K. Hartline, Brain Res.-94, 141(1976). 
E.M. Schmidt, J. of Neurosci. Methods, 12, 95(1984). 
J. J. Hopfield, Proc. Natl. Acad. Sci.(USA), 81, 3088(1984). 
J. J. Hopfield & D. W. Tank, Biol. Cybern., 52, 141(1985). 
D. W. Tank & J. J. Hopfield, IEEE Trans. Circuits Syst., CAS-33, 
533(1986). 
ACKNOWLEDGEMENTS 
We would like to acknowledge the contribution of Dr. Mark Nelson to the intellectual 
development of these projects and the able assistance of Herb Adams, Mike Walshe and John 
Powers in designing and constructing support equipment. This work was supported by NIH 
grant NS22205, the Whitaker Foundation and the Joseph Drown Foundation. 
", network templat classif action potenti real neuron jashojiban jame engin appli scienc biolog institut technolog ca experiment studi real neural network reli proper classif sampl neural signal action record brain neurophysiolog laboratori classif task simplifi limit investig electr neuron record one interest sampl activ mani singl neuron classif becom seriou paper describ constrast approach problem design recogn isol neural also separ classifi tempor overlap event real first present two waveform classif use neural network templat match two formul compar simpl templat match real neural signal reveal simpl templat match better solut problem either neural network mani neurobiologist studi nervou system singl electrod serial sampl electr activ singl physiologist theorist becom nonlinear dynam becom serial sampl strategi may provid inform understand function like develop new techniqu sampl activ multipl simultan last sever develop two method acquir multineuron initi design involv placement mani tini microelectrod individu tightli pack configur within brain recent sophist approach util recent advanc technolog fabric silicon base electrod electrod expect abl readili record activ larger number research neuron record techniqu clear whatev techniqu use acquir neural signal brain technic difficulti associ data analyz interpret signal larg dwarf sampl devic report specif consid need assur neural action potenti known mani parallel record channel correctli aspect problem neuron tradit singl neuron task usual institut physic pass analog signal schmidt trigger whose output indic occur event time trigger sweep analog experiment visual monitor verifi accuraci discrimin singl neuron overlap success oscilloscop trace obvious approach impract larg number channel record necessari autom paper describ contrast three approach develop lower site sq silicon probe develop lababoratori unit record cerebellax complet surfac view one record sever neuron action potenti record silicon electrod cerebellax princip design object assur neural waveform adequ discrimin multipl technic overal research project sampl mani singl neuron natur extent effort develop neural classif scheme robust enough allow us distinguish aris one neuron per record determin particular signal neural also sever possibl neuron aros gener signal differ neuron differ waveform aid neuron record channel fire simultan nearli simultan produc novel combin waveform also need last complic particularli previou effort classifi neural signal review see also see object design circuit distinguish differ waveform even though neuron discharg tend quit similar shape recogn waveform even though unavoid movement anim respir often result period chang amplitud record signal move brain rel tip consider robust record nois variabl corrupt record resolv overlap like particularli event neurobiolog point provid perform allow experiment detect discrimin monitor progress implement hardwar due need classifi neural mani channel simpli duplic channel programm hardwar devic need record schemat diagram electrod record two neuron cell bodi note similar two waveform overlap synthes data differ nois level test classif algorithm problem detect classifi multipl neural signal voltag record involv two waveform present particular signal must identifi templat waveform must detect classifi ongo data accomplish first step modifi princip analysi procedur describ abel goldstein extract templat distinct waveform found initi digit analog discuss mean accomplish second step concern us paper compar three new approach ongo classif deal explicitli overlap spike meet design criteria outlin approach consist modifi templat match two appli neural network first consid neural network point avoid confus real whose signal want classifi refer element appli neural network call network approach problem classifi neural best seen optim problem presenc much recent work network algorithm demonstr network work quit well problem sort recent paper hopfield tank describ convert network map problem templat match similar context energi function network propos connect hopon hopon voltag output hopon ii input current hopon hopon sigmoid characterist equat motion set see henc go minimum network describ correspond propos solut waveform classif match use neural net follow approach templat match use neural initi restrict classif problem one involv two accordingli construct neural network made two concern discrimin one classif procedur work schmidt trigger use detect presenc voltag signal channel set threshold impli presenc possibl msec data around cross store buffer note biophys limit assur singl real can not discharg time one particular type occur data action potenti order msec msec window includ full singl overlap next step data valu correl pass hopfield network design error actual data linear differ delay hopon set hopon one waveform repres particular tempor delay waveform express network term energi function let input waveform amplitud time amplitud jtn denot delay time present input energi function first term design minim error specifi best sinc second term minim assum valu also set diagon element term creat mutual inhibit among process node evalu neuron describ occur per simplifi express connect matrix input current sl input correl actual data variou delay templat subtract constant hopfield network document detail full network work well tempor isol moder nois overlap spike local minima sever two waveform need build network hardwar full hopfield difficult implement current technolog develop modifi neural network approach significantli necessari hardwar complex also improv understand let us look inform contain make use calcul stage load hopfield calcul quickli larg number possibl templat reduc size problem thu use much smaller neural network find optim make defin slightli modifi version case overlap spike differ delay input weight combin overlap first templat time bin delay templat time bin howev presenc aij ident equal algorithm may make unaccept solut problem overlap spike describ let us consid classifi compar input absenc minimum repres presenc none quantiti ident equal nois input rise unaccept solut nois relat problem choos minima chosen instead minimum either known correspond linear combin overlap case simpl templat three neuron network program neuron input fed tini network whatev confus remain first step simpl templat match describ also place tini hop field type templat match evalu perform network decid implement simpl templat document turn accur requir least complex three first step fill buffer data base detect possibl neural calcul differ record waveform possibl combin two previous identifi consist calcul distanc input possibl case gener combin two give best fit possibl combin templat actual procedur compar perform three devis set test data use follow use compon method abel goldstein gener two templat digit analog record neural activ record cerebellum two actual spike waveform templat decid use ratio second set analog record made site cerebellum action potenti event determin spectral characterist record two deriv real neural record digit object construct realist also know absolut correct solut templat match problem shown data set correspond differ signal ratio also carri simul amplitud templat vari synthes record waveform chang due brain movement often seen real addit two waveform test also construct three waveform gener third templat averag first two quantifi comparison three difer approach consid overlap spike quantifi perform three differ two classif first hardest correct precis order time two waveform second looser classif correct order two waveform correct time vari time neurobiolog probabl suffici compar result three approach waveform classif implement digit comparison templat shown ratio three approach perform reach close accuraci ratio howev neural network implement less well respect simpl templat match algorithm full hop field type network consider wors modifi rang nsr often found real data simpl match perform consider better either neural also note simpl templat match estim good fit betwwen waveform closest could use identifi event classifi signal due amplitud amplitud overlap line absolut criteria line less stringent criteria templat match network hop field network comparison three approach detect two compar perform neural network approach degre waveform templat overlap compar waveform seriou local minima encount full neural network demonstr improv modifi overal perform rang nois clearli best simpl templat nois level modifi approach better two neural due reliabl correl number reflect input data nois level error correl number may exclud right combin smaller case perform actual littl wors larger hopfield document detail degre overlap produc troubl neural network approach nsr level found real neural seen neural seriou problem encount delay two waveform small enough result waveform look like waveform templat shown comparison full hopfield network approach simpl match nonoverlap perform two approach much compar two waveform although simpl templat match still optim overlap waveform neural network approach badli particular applic neural network approach scale amplitud amplitud amplitud network templat match line absolut criteria line less stringent criteria varianc nois comparison perform three nonoverlap waveform three waveform comparison describ import design work detect neural signal analog record origin simultan activ sampl feasibl algorithm comput real time channel necessari design build dedic hardwar decid design vlsi implement well recogn larg modifi neural network need elabor hardwar let us hardwax case let neuron per templat neuron delay rn iter reach stabl state simul discret step size sampl templat number connect full hopfield network total synapt calcul two templat rn thu build full digit requir system larg put singl vlsi chip work real want build analog need mani easili modifi yet technolog avail net modifi network hand less technic preprocess obtain minimum valu addit find possibl requir subtract comparison find three associ input full network save approach network use small fast addit construct modifi synapt contrast neural simpl templat match simpl must perform addit comparison find minimum addit consider less time hardwar method addit preliminari design work suggest singl chip abl classif littl actual rais possibl buffer one chip might abl servic one channel essenti real match use full neural network found robust nois chang signal waveform two neural waveform network perform network requir mani modifi connect therefor result elabor hardwar overal modifi neural network approach better full network comput reduc largli hardwar requir consider less demand demonstr design specif network specifi even neural network perform less well simpl also simplest hardwar use templat match simul suggest build two three waveform classifi singl vlsi chip use technolog work real time excel error chip abl accur classifi variabl overlap evanczuk bower abel robert brain hopfield tank ie circuit would like acknowledg contribut mark nelson intellectu project abl assist herb mike walsh john design construct support work support nih whitak foundat joseph drown,0
12,12,"114 
A Computer Simulation of Olfactory Cortex With Functional Implications for 
Storage and Retrieval of Olfactory Information 
Matthew A. Wilson and James M. Bower 
Computation and Neural Systems Program 
Division of Biology, California Institute of Technology, Pasadena, CA 91125 
ABSTRACT 
Based on anatomical and physiological data, we have developed a computer simulation of piri- 
form (olfactory) cortex which is capable of reproducing spatial and temporal patterns of actual 
cortical activity under a variety of conditions. Using a simple Hebb-type learning rule in conjunc- 
tion with the cortical dynamics which emerge from the anatomical and physiological organiza- 
tion of the model, the simulations are capable of establishing cortical representations for differ- 
ent input patterns. The basis of these representations lies in the interaction of sparsely distribut- 
ed, highly divergent/convergent interconnections between modeled neurons. We have shown that 
different representations can be stored with minimal interference, and that following learning 
these representations are resistant to input degradation, allowing reconstruction of a representa- 
tion following only a partial presentation of an original training stimulus. Further, we have 
demonstrated that the degree of overlap of cortical representations for different stimuli can 
also be modulated. For instance similar input patterns can be induced to generate distinct cortical 
representations (discrimination), while dissimilar inputs can be induced to generate overlapping 
representations (accommodation). Both features are presumably important in classifying olfacto- 
ry stimuli. 
INTRODUCTION 
Piriform cortex is a primary olfactory cerebral cortical structure which receives 
second order input from the olfactory receptors via the olfactory bulb (Fig. 1). It 
is believed to play a significant role in the classification and storage of olfactory 
information L2,3. For several years we have been using computer simulations as a 
tool for studying information processing within this cortex 4,5. While we are ulti- 
mately interested in higher order functional questions, our first modeling objective 
was to construct a computer simulation which contained sufficient neurobiological 
detail to reproduce experimentally obtained cortical activity patterns. We believe 
this first step is crucial both to establish correspondences between the model and 
the cortex, and to assure that the model is capable of generating output that can 
be compared to data from actual physiological experiments. In the current case, 
having demonstrated that the behavior of the simulation at least approximates 
that of the actual cortex n (Fig. 3), we are now using the model to explore the 
types of processing which could be carded out by this cortical structure. In partic- 
ular, in this paper we will describe the ability of the simulated cortex to store and 
recall cortical activity patterns generated by stimulus various conditions. We 
believe this approach can be used to provide experimentally testable hypotheses 
concerning the functional organization of this cortex which would have been diffi- 
cult to deduce solely from neurophysiological or neuroanatomical data. 
American Institute of Physics 1988 
115 
Receptors 
Olfactory 
Bulb 
Piriform Cortex 
and Other 
Olfactory Structures 
Hippocampus I 
Entorhinal 
Cortex 
LOT 
Fig. 1. Simplified block diagram of the olfactory system and closely related structures. 
MODEL DESCRIPTION 
This model is largely instructed by the neurobiology of piriform cortex 3. Axon- 
al conduction velocities, time delays, and the general properties of neuronal inte- 
gration and the major intrinsic neuronal connections approximate those currently 
described in the actual cortex. However, the simulation reduces both the number 
and complexity of the simulated neurons (see below). As additional information 
concerning the these or other important features of the cortex is obtained it will be 
incorporated in the model. Bracketed numbers in the text refer to the relevent 
mathematical expressions found in the appendix. 
Neurons. The model contains three distinct populations of intrinsic cortical 
neurons, and a fourth set of cells which simulate cortical input from the olfactory 
bulb (Fig. 2). The intrinsic neurons consist of an excitatory population of pyrami- 
dal neurons (which are the principle neuronal type in this cortex), and two popula- 
tions of inhibitory intemeurons. In these simulations each population is modeled 
as 100 neurons arranged in a 10x10 array (the actual piriform cortex of the rat 
contains on the order of 10 6 neurons). The output of each modeled cell type con- 
sists of an all-or-none action potential which is generated when the membrane 
potential of the cell crosses a threshold [2.3]. This output reaches other neurons 
after a delay which is a function of the velocity of the fiber which connects them 
and the cortical distance from the originating neuron to each target neuron [2.0, 
2.4]. When an action potential arrives at a destination cell it triggers a conduc- 
tance change in a particular ionic channel type in that cell which has a characteris- 
tic time course, amplitude, and waveform [2.0, 2.1]. The effect of this conductance 
change on the transmembrane potential is to drive it towards the equilibrium 
potential of that channel. Na +, CI-, and K + channels are included in the model. 
These channels are differentially activated by activity in synapses associated with 
different cell types (see below). 
116 
LOT Afferent FIIxr 
C;udlly Olrected 
Local 
Aoclatlon 
Fiber 
Rtrally Drect�l 
AssOClltlon Fiber 
I.1 Feedback Inhibition 
C.udally Directed 
A/aoclMIon Fiber 
Fig. 2. Schematic diagram of phiform cortex showing an excitatory pyramidal cell and two 
inhibitory intemeurons with their local interactions. Circles indicate sites of synapfic modifia- 
bility. 
Connection Patterns. In the olfactory system, olfactory receptors project to the 
olfactory bulb which, in turn, projects directly to the piriform cortex and other olfac- 
tory structures (Fig. 1). The input to the piriform cortex from the olfactory bulb is 
delivered via a fiber bundle known as the lateral olfactory tract (LOT). This fiber 
tract appears to make sparse, non-topographic, excitatory connections with pyra- 
midal and feedforward inhibitory neurons across the extent of the cortex 3,6. In the 
model this input is simulated as 100 independent cells each of which make ran- 
dom connections (p--0.05) with pyramidal and feedforward inhibitory neurons 
(Fig. 1 and 2). 
In addition to the input connections from the olfactory bulb, there is also an 
extensive set of connections between the neurons intrinsic to the cortex (Fig. 2). 
For example, the association fiber system arises from pyramidal cells and makes 
sparse, distributed excitatory connections with other pyramidal cells all across the 
cortex 7'8'9 . In the model these connections are randomly distributed with 0.05 
probability. In the model and in the actual cortex, pyramidal cells also make exci- 
tatory connections with nearby feedforward and feedback inhibitory cells. These 
intemeurons, in turn, make reciprocal inhibitory connections with the group of 
nearby pyramidal cells. The primary effect of the feedback inhibitory neurons is to 
inhibit pyramidal cell firing through a C1- mediated current shunting mecha- 
nism ]�,1],12. Feedforward interneurons inhibit pyramidal cells via a long latency, 
long duration, K + mediated hyperpolarizing potential 12.13. Pyramidal cell axons 
also constitute the primary output of both the model and the actual piriform cor- 
tex7.14. 
117 
$ynaptic Properties and Modification Rules. In the model, each synaptic con- 
nex:tion has an associated weight which determines the peak amplitude of the con- 
ductance change induced in the postsynaptic cell following presynaptic activity 
[2.0]. To study learning in the model, synaptic weights associated with some of 
the fiber systems are modifiable in an activity-dependent fashion (Fig. 2). The 
basic modification rule in each case is Hebb-like; i.e. change in synaptic strength 
is proportional to presynaptic activity multiplied by the offset of the postsynapfic 
membrane potential from a baseline potential. This baseline potential is set 
slightly more positive than the CI' equilibrium potential associated with the shunt- 
ing feedback inhibition. This means that synapses activated while a destination 
cell is in a depolarized or excited state are strengthened, while those activated 
during a period of inhibition are weakened. In the model, synapses which follow 
this rule include the association fiber connections between excitatory pyramidal 
neurons as well as the connections between inhibitory neurons and pyramidal neu- 
rons. Whether these synapses are modifiable in this way in the actual cortex is a 
subject of active research in our lab. However, the model does mimic the actual 
synaptic properties associated with the input pathway (LOT) which we have 
shown to undergo a transient increase in synaptic strength following activation 
which is independent of postsynapfic potential 15. This increase is not permanent 
and the synaptic strength subsequently returns to its baseline value. 
Generation of Physiological Responses. Neurons in the model are represented 
as first-order ""leaky"" integrators with multiple, time-varying inputs [1.0]. During 
simulation runs, membrane potentials and currents as well as the time of 
occurence of action potentials are stored for comparison with actual data. An 
explicit compartmental model (5 compartments) of the pyramidal cells is used to 
generate the spatial current distributions used for calculation of field potentials 
(evoked potentials, EEGs) [3.0, 4.0]. 
Stimulus Characteristics. To compare the responses of the model to those of 
the actual cortex, we mimicked actual experimental stimulation protocols in the 
simulated cortex and contrasted the resulting intracellular and extracellular 
records. For example, shock stimuli applied to the LOT are often used to elicit 
characteristic cortical evoked potentials in vivo 16'17'18. In the model we simulated 
this stimulus paradigm by simultaneously activating all 100 input fibers. Another 
measure of cortical activity used most successfully by Freeman and colleagues 
involves recording EEG activity from piriform cortex in behaving animals 19,2�. 
These odor-like responses were generated in the model through steady, random 
stimulation of the input fibers. 
To study learning in the model, once physiological measures were established, 
it was required that we use more refined stimulation procedures. In the absence of 
any specific information about actual input activity patterns along the LOT, we 
constructed each stimulus out of a randomly selected set of 10 out of the 100 input 
118 
fibers. Each stimulus episode consisted of a burst of activity in this subset of 
fibers with a duration of 10 msec at 25 msec intervals to simulate the 40 Hz peri- 
oclicity of the actual olfactory bulb input. This pattern of activity was repeated in 
trials of 200 msec duration which roughly corresponds to the theta rhythm period- 
icity of bulbar activity and respiration 21,22. Each trial was then presented 5 times 
for a total exposure time of 1 second (cortical time). During this period the Hebb- 
type learning rule could be used to modify the connection weights in an activity- 
dependent fashion. 
Output Measure for Learning. Given that the sole output of the cortex is in the 
form of action potentials generated by the pyramidal cells, the output measure of 
the model was taken to be the vector of spike frequency for all pyramidal neurons 
over a 200 msec trial, with each element of the vector corresponding to the firing 
frequency of a single pyramidal cell. Figures 5 through 8 show the 10 by 10 array 
of pyramidal cells. The size of the box placed at each cell position represents the 
magnitude of the spike frequency for that cell. To evaluate learning effects, overlap 
comparisons between response pairs were made by taking the normalized dot 
product of their response vectors and expressing that value as a percent overlap 
(Fig. 4). 
Simulated 
Actual 
Fig. 3. Simulated physiological responses of the model compared with actual conical respons- 
es. Upper:. Simulated intracellular response of a single cell to paired stimulation of the input 
system (LOT) (left) compared with actual response (right) (Habefiy & Bower,'84). Middle: 
Simulated extracellular response recorded at the conical surface to stimulation of the LOT 
(left), compared with actual response (right) (Haberly,'73b). Lower: Stimulated EEG 
response recorted at the cortical surface to odor-like input (left), for actual EEG see Freeman 
1978. 
119 
Computational Requirements. All simulations were carried out on a Sun 
Microsystems 3/260 model microcomputer equipped with 8 Mbytes of memory and 
a floating point accelerator. Average time for a 200 msec simulation was 3 cpu 
minutes. 
RESULTS 
Physiological Responses 
As described above, our initial modeling objective was to accurately simulate 
a wide range of activity patterns recorded, by ourselves and others, in piriform 
cortex using various physiological procedures. Comparisons between actual and 
simulated records for several types of response are shown in figure 3. In general, 
the model replicated known physiological responses quite well (Wilson et al in 
preparation describes, in detail, the analysis of the physiological results). For 
example in response to shock stimulation of the input pathway (LOT), the model 
reproduces the principle characteristics of both the intracellular and location- 
dependent extracellular waveforms recorded in the actual cortex 9,17,18 (Fig. 3). 
Percent Overlap 
with 
Final Response 
Pattern 
100 
60 
0 5 
Number of Trials 
Fig. 4. Convergence of the conical response during training with a single stimulus with synaptic 
modification. 
56% overlap 
� mml mm 
II [] � 
n [] nl 
m [] [] � 
[] mm 
[] � [] 
m. m 
� � m 
m � 
� � . 
[] 
[] m 
[] � 
m m 
� � 
Full Stimulus 50% Simulus 
Before Training 
[] mm 
mm-- 
[] m 
[] � m 
[] � 
mm 
mm � 
� m 
� 
[] [] 
80% overlap 
� � 
� � 
� 
Full Stimulus 
50% Simulus 
After Training 
Fig. 5. Reconstruction of cortical response patterns with partially degraded stimuli. Left: 
Response, before training, to the full stimulus (left) and to the same stimulus with 50% of the 
input fibers inactivated (right). There is a 44% degradation in the response. Right: Response 
after aining, to the full stimulus (left), and to the same stimulus with 50% of the input 
fibers inactivated (right). As a result of aining, the degradation is now only 20%. 
120 
Trained on A 
nln 
� � 
� 
� 
I I � 
� � 
[ 
Trained on B 
� 
� 
� � 
� 
� 
� w � 
� � 
Retains A Response 
� � 
� 
� 
� � � 
� 
I I � 
� � 
Fig. 6. Storage of multiple patterns. Left: Response to stimulus A after training. Middle: 
Response to stimulus B after training on A followed by training on B. Right: Response to 
stimulus A after training on A followed by training on B. When compared with the original 
response (left) there is an 85% congruence. 
Further, in response to odor-like stimulation the model exhibits 40 Hz oscillations 
which are characteristic of the EEG activity in olfactory cortex in awake, behaving 
animals 19. Although beyond the scope of the present paper, the simulation also 
duplicates epileptiform 9 and damped oscillatory 16 type activity seen in the cortex 
under special stimulus or pharmacological conditions n. 
Learning 
Having simulated characteristic physiological responses, we wished to 
explore the capabilities of the model to store and recall information. Learning in 
this case is defined as the development of a consistent representation in the activ- 
ity of the cortex for a particular input pattern with repeated stimulation and synap- 
tic modification. Figure 4 shows how the network converges, with training, on a 
representation for a stimulus. Having demonstrated that, we studied three proper- 
ties of learned responses - the reconstruction of trained cortical response patterns 
with partially degraded stimuli, the simultaneous storage of separate stimulus 
response patterns, and the modulation of cortical response patterns independent 
of relative stimulus characteristics. 
Reconstruction of Learned Cortical Response Patterns with Partially Degrad- 
ed Stimuli. We were interested in knowing what effect training would have on the 
sensitivity of cortical responses to fluctuations in the input signal. First we pre- 
sented the model with a random stimulus A for one trial (without synaptic modifi- 
cation). On the next trial the model was presented with a degraded version of A 
in which half of the original 10 input fibers were inactivated. Comparison of the 
responses to these two stimuli in the naive cortex showed a 44% variation. Next, 
the model was trained on the full stimulus A for 1 second (with synaptic modifica- 
tion). Again, half of the input was removed and the model was presented with the 
degraded stimulus for 1 trial (without synaptic modification). In this case the dif- 
121 
27% overlap 
46% overlap 
ibm 
mm 
� � 
� mm 
� � 
� 
� 
� � 
� 
Stimulus A Stimulus B 
Before Training 
Stimulus A Stimulus B 
After Training 
Fig. 7. Results of merging conical response pattems for dissimilar stimuli. Left: Response to 
stimulus A and stimulus B before Ixaining. Stimuli A and B do not activate any input fibers in 
common but still have a 27% overlap in conical response patterns. Right: Response to stimu- 
lus A and stimulus B after training in the presence of a common modulatory input El. The 
overlap in conical response patterns is now 46%. 
ference between cortical responses was only 20% (Fig. 5) showing that training 
increased the robustness of the response to degradation of the stimulus. 
Storage of Two Patterns. The model was first trained on a random stimulus A 
for 1 second. The response vector for this case was saved. Then, continuing with 
the weights obtained during this training, the model was trained on a new non- 
overlapping (i.e. different input fibers activated) stimulus B. Both stimulus A and 
stimulus B alone activated roughly 25% of the cortical pyramidal neurons with 25% 
overlap between the two responses. Following the second mining period we 
assessed the amount of interference in recalling A introduced by mining with B 
by presenting stimulus A again for a single trial (without synaptic modification). 
The variation between the response to A following additional training with B and 
the initially saved reponse to A alone was less than 15% (Fig. 6) demonstrating 
that learning B did not substantially interfere with the ability to recall A. 
Modulation of Cortical Response Patterns. It has been previously demon- 
strated that the stimulus evoked response of olfactory cortex can be modulated by 
factors not directly tied to stimulus qualities, such as the behavioral state of the 
animal 1,2�,23. Accordingly we were interested in knowing whether the representa- 
tions stored in the model could be modulated by the influence of such a ""state"" 
input. 
One potential role of a ""state"" input might be to merge the cortical response 
patterns for dissimilar stimuli; an effect we refer to as accomodation. To test this 
in the model, we presented it with a random input stimulus A for 1 trial. It was 
then presented with a random input stimulus B (non-overlapping input fibers). 
The amount of overlap in the cortical responses for these untrained cases was 
27%. Next, the model was trained for 1 second on stimulus A in the presence of an 
additional random ""state"" stimulus E1 (activity in a set of 10 input fibers distinct 
122 
77% overlap 
45% overlap 
Im � 
�� 
� � 
� 
Stimulus A Stimulus B Stimulus A Stimulus B 
Before Training After Training 
Fig. 8. Results of differentiating cortical response patterns for similar stimuli. Left: 
Response to stimulus A and stimulus B before aining. Stimuli A and B activate 75% of 
their input fibers in common and have a 77% overlap in cortical response patterns. Right: 
Response to stimulus A and stimulus B after training A in the presence of modulatory input 
E1 and training B with a different modulatory input E2. The overlap in cortical response pat- 
terns is now 45%. 
from both A and B). The model was then trained on stimulus B in the presence of 
the same ""state"" stimulus El. After training, the model was presented with stim- 
ulus A alone for 1 trial and stimulus B alone for 1 trial. Results showed that now, 
even without the coincident E1 input, the amount of overlap between A and B 
responses was found to have increased to 46% (Fig 7). The role of E1 in this case 
was to provide a common stimulus component during learning which reinforced 
shared components of the responses to input stimuli A and B. 
To test the ability of a state stimulus to induce differentiation of cortical 
response patterns for similar stimuli, we presented the model with a random input 
stimulus A for 1 trial, followed by 1 trial of a random input stimulus B (75% of the 
input fibers overlapping). The amount of overlap in the cortical responses for these 
untrained cases was 77%. Next, the model was trained for a period of 1 second on 
stimulus A in the presence of an additional random ""state"" stimulus E1 (a set of 
10 input fibers not overlapping either A or B). It was then trained on input stimu- 
lus B in the presence of a different random ""state"" stimulus E2 (10 input fibers not 
overlapping either A, B, or El) After this training the model was presented with 
stimulus A alone for 1 trial and stimulus B alone for 1 trial. The amount of overlap 
was found to have decreased to 45% (Fig 8). In this situation E1 and E2 provided 
a differential signal during learning which reinforced distinct components of the 
responses to input stimuli A and B. 
DISCUSSION 
Physiological Responses. Detailed discussion of the mechanisms underlying 
the simulated patterns of physiological activity in the cortex is beyond the scope 
of the current paper. However, the model has been of value in suggesting roles for 
123 
specific features of the cortex in generating physiologically recorded activity. For 
example, while actual input to the cortex from the olfactory bulb is modulated into 
40 Hz bursts 24, continuous stimulation of the model allowed us to demonstrate 
the model's capability for intrinsic periodic activity independent of the comple- 
mentary pattern of stimulation from the olfactory bulb. While a similar ability has 
also been demonstrated by models of Freeman 25, by studying this oscillating 
property in the model we were able to associate these oscillatory characteristics 
with specific interactions of local and distant network properties (e.g. inhibitory 
and excitatory time constants and trans-cortical axonal conduction velocities). 
This result suggests underlying mechanisms for these oscillatory patterns which 
may be somewhat different than those previously proposed. 
Learning. The main subject of this paper is the examination of the learning 
capabilities of the cortical model. In this model, the apparently sparse, highly dis- 
tributed pattern of connectivity characteristic of piriform cortex is fundamental to 
the way in which the model learns. Essentially, the highly distributed pattern of 
connections allows the model to develop stimulus-specific cortical response pat- 
terns by extracting correlations from randomly distributed input and association 
fiber activity. These correlations are, in effect, stored in the synaptic weights of 
the association fiber and local inhibitory connections. 
The model has also demonstrated robustness of a learned cortical response 
against degradation of the input signal. A key to this property is the action of 
sparsely distributed association fibers which provide reinforcment for previously 
established patterns of cortical activity. This property arises from the modification 
of synaptic weights due to correlations in activity between intra-cortical associa- 
tion fibers. As a result of this modification the activity of a subset of pyramidal 
neurons driven by a degraded input drives the remaining neurons in the response. 
In general, in the model, similar stimuli will map onto similar cortical respons- 
es and dissimilar stimuli will map onto dissimilar cortical responses. However, a 
presumably important function of the cortex is not simply to store sensory infor- 
mation, but to represent incoming stimuli as a function of the absolute stimulus 
qualities and the context in which the stimulus occurs. The fact that many of the 
structures that piriform cortex projects to (and receives projections from) may be 
involved in multimodal ""state"" generation TM is circumstantial evidence that such 
modulation may occur. We have demonstrated in the model that such a modulato- 
ry input can modify the representations generated by pairs of stimuli so as to 
push the representations of like stimuli apart and pull the representations of dis- 
similar stimuli together. It should be pointed out that this modulatory input was 
not an ""instructive"" signal which explicitly directed the course of the representa- 
tion, but rather a ""state"" signal which did not require a priori knowledge of the 
representational structure. In the model, this modulatory phenomenon is a simple 
consequence of the degree of overlap in the combined (odor stimulus + modulator) 
stimulus. Both cases approached approximately 50% overlap in cortical responses 
reflecting the approximately 50% overlap in the combined stimuli for both cases. 
124 
Of interest was the use of the model's reconstructive capabilities to maintain the 
modulated response to each input stimulus even in the absence of the modulatory 
input. 
CAVEATS AND CONCLUSIONS 
Our approach to studying this system involves using computer simulation to 
investigate mechanisms of information processing which could be implemented 
given what is known about biological constraints. The significance of results pre- 
sented here lies primarily in the finding that the structure of the model and the 
parameter settings which were appropriate for the reproduction of physiological 
responses were also appropriate for the proper convergence of a simple, biologi- 
cally plausible learning rule under various conditions. Of course, the model we 
have developed is only an approximation to the actual cortex limited by our knowl- 
edge of its organization and the computing power available. For example, the 
actual piriform cortex of the rat contains on the order of 10 6 cells (compared with 
102 in the simulations) with a sparsity of connection on the order of p=0.001 
(compared with p=0.05 in the simulations). Our continuing research effort will 
include explorations of the scaling properties of the network. 
Other assumptions made in the context of the current model include the 
assumption that the representation of information in pitiform cortex is in the form 
of spatial distributions of rate-coded outputs. Information contained in the spatio- 
temporal patterns of activity was not analyzed, although preliminary observation 
suggests that this may be of significance. In fact, the dynamics of the model itself 
suggest that temporally encoded information in the input at various time scales 
may be resolvable by the cortex. Additionally, the output of the cortex was 
assumed to have spatial uniformity, i.e. no differential weighting of information 
was made on the basis of spatial location in the cortex. But again, observation of 
the dynamics of the model, as well as the details of known anatomical distribution 
patterns for axonal-connections, indicate that this is a major oversimplification. 
Preliminary evidence from the model would indicate that some form of hierarchical 
structuring of information along rostral/caudal lines may occur. For example it 
may be that cells found in progressively more rostral locations would have 
increasingly non-specific odor responses. 
Further investigations of learning within the model will explore each of these 
issues more fully, with attempts to correlate simulated findings with actual record- 
ings from awake, behaving animals. At the same time, new data pertaining to the 
structure of the cortex will be incorporated into the model as it emerges. 
ACKNOWLEDGEMENTS 
We wish to thank Dr. Lewis Haberly and Dr. Joshua Chover for their roles in 
the development and continued support of the modeling effort. We also wish to 
thank Dave Bilitch for his technical assistance. This work was supported by NIH 
grant NS22205, NSF grant EET-8700064, the Lockheed Corporation, and a fel- 
lowship from the ARCS foundation. 
125 
APPENDIX 
Somatic Integration 
v , _L IX,,.,/ ( t ) +  
dt = cn 
li (t ) = [ �tt-Vi(t )]git (t ) 
E,-V, (t ) ] 
rt 
(1.o) 
(1.1) 
.ny. = number of input types 
v(t) = membrane potential of i th cell 
I a (t) = current into cell i due to input type k 
E k = equilibrium potential associated with input type k 
E r = resting potential 
r/ = membrane leakage resistance 
c, = membrane capacitance 
ga(t) = conductance due to input type k m cell i 
g,,(t)=Y. [OdX)Aok w o Sj(t -X- -tDd. 
j=l Vk 
(2.0) 
Spike Propagation 
and Synaptic Input 
F (t ) = te(1- ) [(1-U (t--,r) ) + U (t--,r) cos [. (t"") ] ] 
x (d--x) 
Aij  - + 
, x=yd (2.1) 
(2.2) 
S(e) = {10 
V](t)>T], SO.)=O for X=t..t-at, 
otherwise (2.3) 
Lq = li - j lAx 
(2.4) 
nctt s = number of ceils in the simulation 
Ax = distance between adjacent cells 
d, = duration of conductance change due to input type k 
v, = velocity of signals for input type k 
e = latency for input type k 
p = spatial attenuation factor for input type k 
p = minimum spatial attenuation for input type k 
At, = refractory period 
= threshold for cell j 
= distance from cell i to ceil j 
 = distribution of synaptic density for input type k 
= synaptic weight from cell j to cell i 
ga (t) = conductance due to input type k in cell i 
Fx(t) = conductance waveform for input type k 
(t) = spike output of cell j at time t 
(t) unit step function 
Field Potentials 
n=! 
l,(t ) 
1 
[(Ztlec-Zn)2 + (x1-x,)2 ] ""2'- 
(3.0) 
nee m = number of ceils in the simulation 
nseg s = number of segments in the compartmental model 
V (t) = approximate extracellular field potential at cell j 
lt ) = membrane current for segment n m cell i 
Dendritic Model 
"" =  [/F(t) +l+(t) + -- 
dt cm n 
/ -(t ) = 
Vn_l(t) -Vn(t) 
r-i + rt 
zeec = depth of re:ording site 
zn = depth of segment n 
e= x location of the jth cell 
= extracellular resistance per unit length 
�,-V, (t) '- ] 
+  [Ec-Vn(t)]gnc(t) 
(4.0) 
v,d(t) - v,(t) 
,, (4.1) 
!an+(t) = r +1 + r, 
126 
Ig(t) = tan-O) + lan*(t) 
(4.2) 
l I 
r = � el, + R i 
g m 
� c =C,,,lndn (4.3) 
ncan = number of different channels per segment 
V n (t) = membrane potential of n th segment 
c = membrane capacitance for segment n 
ra n = axial resistance for segment n 
rm n = membrane resistance for segment n 
gnc(t) = conductance of channel c in segment n 
E c = equilibrium potential associated with channel c 
l�(t) = axial current between segment n+l and n 
ln(t) = membrane current for segment n 
I. = length of segment n 
d n = diameter of segment n 
R,. = membrane resistivity 
R i = intraceHular resistivity per unit length 
R e = exu'acellular resistance per unit length 
C,. = capacitance per unit surface axea 
REFERENCES 
1. W.J. Freeman, J. Neurophysiol., 23, 111 (1960). 
2. T. Tanabe, M. Iino, and S. F. Takagi, J. Neurophysiol., 38,1284 (1975). 
3. L.B. Haberly, Chemical Senses, 10, 219 (1985). 
4. M. Wilson, J. M. Bower, J. Chover, and L. B. Haberly, Soc. Neuro. Abs., 11, 
317 (1986). 
5. M. Wilson andJ. M. Bower, Soc. Neurosci. Abs., 12, 310 (1987). 
6. M. Devor, J. Comp. Neur., 166, 31 (1976). 
7. L.B. Haberly andJ. L. Price, J. Comp. Neurol., 178, 711 (1978a). 
8. L.B. Haberly and S. Presto, J. Comp. Neur., 248,464 (1986). 
9. L.B. Haberly and J. M. Bower, J. Neurophysiol., 51, 90 (1984). 
10. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 193 (1969). 
11. M. A. Biedenbach and C. F. Stevens, J. Neurophysiol., 32, 204 (1969). 
12. M. Satou, K. Mori, Y. Tazawa, and S. F. Takagi, J. Neurophysiol., 48, 1157 
(1982). 
13. G. F. Tseng and L. B. Haberly, Soc. Neurosci. Abs. 12, 667 (1986). 
14. L. B. Luskin and J. L. Price, J. Comp. Neur., 216, 264 (1983). 
15. J. M. Bower and L. B", comput simul olfactori cortex function implic retriev olfactori inform wilson jame bower neural system program california institut ca anatom physiolog develop comput simul cortex capabl reproduc spatial tempor pattern actual activ varieti use simpl learn rule cortic dynam emerg anatom physiolog simul capabl establish cortic represent input basi represent lie interact spars highli interconnect model shown represent store minim follow learn represent resist input allow reconstruct follow partial present origin train degre overlap cortic represent differ stimuli instanc similar input pattern induc gener distinct cortic dissimilar input induc gener overlap featur presum import classifi cortex primari olfactori cerebr cortic structur receiv order input olfactori receptor via olfactori bulb believ play signific role classif storag olfactori sever year use comput simul studi inform process within cortex interest higher order function first model object construct comput simul contain suffici neurobiolog reproduc experiment obtain cortic activ believ first step crucial establish correspond model assur model capabl gener output compar data actual physiolog current demonstr behavior simul least approxim actual cortex use model explor process could card cortic paper describ abil simul cortex store cortic activ pattern gener stimulu variou approach use provid experiment testabl hypothes function organ cortex would deduc sole neurophysiolog neuroanatom institut physic cortex structur simplifi block diagram olfactori system close relat descript model larg instruct neurobiolog piriform cortex conduct time gener properti neuron major intrins neuron connect approxim current actual simul reduc number complex simul neuron addit inform import featur cortex obtain bracket number text refer relev express found model contain three distinct popul intrins cortic fourth set cell simul cortic input olfactori intrins neuron consist excitatori popul neuron principl neuron type two inhibitori simul popul model neuron arrang array actual piriform cortex rat order output model cell type action potenti gener membran cell cross threshold output reach neuron delay function veloc fiber connect cortic distanc origin neuron target neuron action potenti arriv destin cell trigger chang particular ionic channel type cell time waveform effect conduct transmembran potenti drive toward equilibrium na channel includ channel differenti activ activ synaps associ cell type affer fiixr oclltlon fiber feedback inhibit direct mion fiber schemat diagram phiform cortex show excitatori pyramid cell two intemeuron local circl indic site synapf olfactori olfactori receptor project bulb project directli piriform cortex structur input piriform cortex olfactori bulb via fiber bundl known later olfactori tract fiber appear make excitatori connect feedforward inhibitori neuron across extent cortex input simul independ cell make connect pyramid feedforward inhibitori neuron addit input connect olfactori also set connect neuron intrins cortex associ fiber system aris pyramid cell make distribut excitatori connect pyramid cell across model connect randomli distribut model actual pyramid cell also make connect nearbi feedforward feedback inhibitori make reciproc inhibitori connect group pyramid primari effect feedback inhibitori neuron pyramid cell fire mediat current shunt feedforward interneuron inhibit pyramid cell via long mediat hyperpolar potenti pyramid cell axon constitut primari output model actual piriform properti modif synapt associ weight determin peak amplitud chang induc postsynapt cell follow presynapt activ studi learn synapt weight associ fiber system modifi fashion modif rule case chang synapt strength proport presynapt activ multipli offset postsynapf potenti baselin baselin potenti set posit equilibrium potenti associ feedback mean synaps activ destin depolar excit state activ period inhibit synaps follow rule includ associ fiber connect excitatori pyramid well connect inhibitori neuron pyramid whether synaps modifi way actual cortex activ research model mimic actual properti associ input pathway undergo transient increas synapt strength follow activ independ postsynapf potenti increas perman synapt strength subsequ return baselin physiolog neuron model repres integr input membran potenti current well time action potenti store comparison actual compartment model pyramid cell use spatial current distribut use calcul field potenti compar respons model actual mimick actual experiment stimul protocol cortex contrast result intracellular extracellular shock stimuli appli lot often use elicit cortic evok potenti vivo model simul stimulu paradigm simultan activ input anoth cortic activ use success freeman colleagu record eeg activ piriform cortex behav anim respons gener model random input studi learn physiolog measur requir use refin stimul absenc specif inform actual input activ pattern along stimulu randomli select set input stimulu episod consist burst activ subset durat msec msec interv simul hz actual olfactori bulb pattern activ repeat msec durat roughli correspond theta rhythm bulbar activ respir trial present time total exposur time second period learn rule could use modifi connect weight measur given sole output cortex action potenti gener pyramid output measur model taken vector spike frequenc pyramid neuron msec element vector correspond fire singl pyramid figur show array pyramid size box place cell posit repres spike frequenc evalu learn overlap respons pair made take normal dot respons vector express valu percent overlap simul physiolog respons model compar actual conic simul intracellular respons singl cell pair stimul input compar actual respons extracellular respons record conic surfac stimul lot compar actual respons stimul eeg recort cortic surfac input actual eeg see freeman simul carri sun model microcomput equip mbyte memori float point averag time msec simul cpu respons describ initi model object accur simul wide rang activ pattern piriform use variou physiolog comparison actual record sever type respons shown figur model replic known physiolog respons quit well et al analysi physiolog respons shock stimul input pathway model principl characterist intracellular extracellular waveform record actual cortex overlap respons trial converg conic respons train singl stimulu synapt overlap mml mm nl mm stimulu simulu train mm overlap stimulu simulu train reconstruct cortic respons pattern partial degrad full stimulu stimulu fiber inactiv degrad respons full stimulu stimulu input inactiv result degrad respons storag multipl respons stimulu stimulu train follow train respons train follow train compar origin respons stimul model exhibit hz oscil characterist eeg activ olfactori cortex behav although beyond scope present simul also epileptiform damp oscillatori type activ seen cortex special stimulu pharmacolog condit simul characterist physiolog wish capabl model store recal learn case defin develop consist represent cortex particular input pattern repeat stimul figur show network demonstr studi three learn respons reconstruct train cortic respons pattern partial degrad simultan storag separ stimulu modul cortic respons pattern independ rel stimulu learn cortic respons partial interest know effect train would cortic respons fluctuat input first model random stimulu one trial synapt next trial model present degrad version half origin input fiber comparison two stimuli naiv cortex show model train full stimulu second synapt half input remov model present stimulu trial synapt case overlap overlap mm stimulu train stimulu train result merg conic respons pattem dissimilar respons stimulu stimuli activ input fiber still overlap conic respons respons stimulu train presenc common modulatori input conic respons pattern cortic respons show train robust respons degrad two model first train random stimulu respons vector case continu weight obtain model train new differ input fiber stimulu stimulu alon activ roughli cortic pyramid neuron two follow second mine period amount interfer recal introduc mine present stimulu singl trial synapt variat respons follow addit train initi save repons alon less demonstr learn substanti interfer abil recal cortic respons previous stimulu evok respons olfactori cortex modul directli tie stimulu behavior state accordingli interest know whether store model could modul influenc potenti role input might merg cortic respons dissimilar effect refer test present random input stimulu present random input stimulu input amount overlap cortic respons untrain case model train second stimulu presenc random stimulu set input fiber distinct overlap overlap stimulu stimulu stimulu train train result differenti cortic respons pattern similar stimulu stimulu stimuli activ input fiber common overlap cortic respons stimulu stimulu train presenc modulatori input train differ modulatori input overlap cortic respons model train stimulu presenc stimulu model present alon trial stimulu alon result show without coincid amount overlap found increas role case provid common stimulu compon learn reinforc compon respons input stimuli test abil state stimulu induc differenti cortic pattern similar present model random input follow trial random input stimulu fiber amount overlap cortic respons case model train period second presenc addit random stimulu set input fiber overlap either train input presenc differ random stimulu input fiber either train model present alon trial stimulu alon amount overlap found decreas situat provid differenti signal learn reinforc distinct compon input stimuli detail discuss mechan underli simul pattern physiolog activ cortex beyond scope current model valu suggest role featur cortex gener physiolog record actual input cortex olfactori bulb modul hz burst continu stimul model allow us demonstr capabl intrins period activ independ pattern stimul olfactori similar abil demonstr model freeman studi oscil model abl associ oscillatori characterist specif interact local distant network properti inhibitori excitatori time constant axon conduct result suggest underli mechan oscillatori pattern somewhat differ previous main subject paper examin learn cortic appar highli pattern connect characterist piriform cortex fundament way model highli distribut pattern allow model develop cortic respons extract correl randomli distribut input associ correl store synapt weight associ fiber local inhibitori model also demonstr robust learn cortic respons degrad input key properti action distribut associ fiber provid reinforc previous pattern cortic properti aris modif synapt weight due correl activ result modif activ subset pyramid driven degrad input drive remain neuron similar stimuli map onto similar cortic dissimilar stimuli map onto dissimilar cortic import function cortex simpli store sensori repres incom stimuli function absolut stimulu context stimulu fact mani piriform cortex project receiv project may multimod gener tm circumstanti evid may demonstr model input modifi represent gener pair stimuli represent like stimuli apart pull represent stimuli point modulatori input signal explicitli direct cours rather signal requir priori knowledg modulatori phenomenon simpl degre overlap combin stimulu case approach approxim overlap cortic respons approxim overlap combin stimuli interest use reconstruct capabl maintain respons input stimulu even absenc modulatori conclus approach studi system involv use comput simul mechan inform process could implement known biolog signific result lie primarili find structur model set appropri reproduct physiolog also appropri proper converg plausibl learn rule variou model develop approxim actual cortex limit organ comput power piriform cortex rat contain order cell sparsiti connect order continu research effort explor scale properti assumpt made context current model includ represent inform pitiform cortex form spatial distribut inform contain pattern activ although preliminari observ may dynam model tempor encod inform input variou time scale resolv output cortex spatial differenti weight inform made basi spatial locat observ dynam well detail known anatom distribut indic major evid model would indic form hierarch inform along line may exampl cell found progress rostral locat would odor investig learn within model explor attempt correl simul find actual behav new data pertain cortex incorpor model wish thank lewi haberli joshua chover role develop continu support model also wish dave bilitch technic work support nih nsf grant lockhe arc integr number input type membran potenti th cell current cell due input type equilibrium potenti associ input type rest potenti membran leakag resist membran capacit conduct due input type cell vk propag synapt input co li ax number ceil simul distanc adjac cell durat conduct chang due input type veloc signal input type latenc input type spatial attenu factor input type minimum spatial attenu input type refractori period threshold cell distanc cell ceil distribut synapt densiti input type synapt weight cell cell conduct due input type cell conduct waveform input type spike output cell time unit step function potenti number ceil simul number segment compartment model approxim extracellular field potenti cell membran current segment cell model cm rt depth site depth segment locat jth cell extracellular resist per unit length number differ channel per segment membran potenti th segment membran capacit segment axial resist segment membran resist segment conduct channel segment equilibrium potenti associ channel axial current segment membran current segment length segment diamet segment membran resist hular resist per unit length resist per unit length capacit per unit surfac axea chemic wilson haberli haberli haberli biedenbach biedenbach tseng luskin bower,1
13,13,"127 
Neural Network Implementation Approaches 
for the 
Connection Machine 
Nathan H. Brown, Jr. 
MRJ/Perkin Elmer, 10467 White Granite Dr. (Suite 304), Oakton, Va. 22124 
ABSTRACT 
The SIMD parallelism of the Connection Machine (CM) allows the construction of 
neural network simulations by the use of simple data and control structures. Two 
approaches are described which allow parallel computation of a model's nonlinear 
functions, parallel modification of a model's weights, and parallel propagation of a 
model's activation and error. Each approach also allows a model's interconnect 
structure to be physically dynamic. A Hopfield model is implemented with each 
approach at six sizes over the same number of CM processors to provide a performance 
comparison. 
INTRODUCTION 
Simulations of neural network models on digital computers perform various 
computations by applying linear or nonlinear functions, defined in a program, to 
weighted sums of integer or real numbers retrieved and stored by array reference. The 
numerical values are model dependent parameters like time averaged spiking frequency 
(activation), synaptic efficacy (weight), the error in error back propagation models, and 
computational temperature in thermodynamic models. The interconnect structure of a 
particular model is implied by indexing relationships between arrays defined in a 
program. On the Connection Machine (CM), these relationships are expressed in 
hardware processors interconnected by a 16-dimensional hypercube communication 
network. Mappings are constructed to define higher dimensional interconnectivity 
between processors on top of the fundamental geometry of the communication 
network. Parallel transfers are defined over these mappings. These mappings may be 
dynamic. CM parallel operations transform array indexing from a temporal succession 
of references to memory to a single temporal reference to spatially distributed 
processors. 
Two alternative approaches to implementing neural network simulations on the CM 
are described. Both approaches use ""data parallelism"" 1 provided by the *Lisp virtual 
machine. Data and control structures associated with each approach and performance 
data for a Hopfield model implemented with each approach are presented. 
DATA STRUCTURES 
The functional components of a neural network model implemented in *Lisp are 
stored in a uniform parallel variable (pvar) data structure on the CM. The data structure 
may be viewed as columns of pvars. Columns are given to all CM virtual processors. 
Each CM physical processor may support 16 virtual processors. In the first approach 
described, CM processors are used to represent the edge set of a models graph 
structure. In the second approach described, each processor can represent a unit, an 
outgoing link, or an incoming link in a model's structure. Movement of activation (or 
error) through a model's interconnect structure is simulated by moving numeric values 
American Institute of Physics 1988 
128 
over the CM's hypercube. Many such movements can result from the execution of a 
single CM macroinstruction. The CM transparently handles message buffering and 
collision resolution. However, some care is required on the part of the user to insure 
that message traffic is distributed over enough processors so that messages don't stack 
up at certain processors, forcing the CM to sequentially handle large numbers of 
buffered messages. Each approach requires serial transfers of model parameters and 
states over the communication channel between the host and the CM at certain times in a 
simulation. 
The fh'st approach, ""the edge list approach,"" distributes the edge list of a network 
graph to the CM, one edge per CM processor. Interconnect weights for each edge are 
stored in the memory of the processors. An array on the host machine stores the 
current activation for all units. This approach may be considered to represent abstract 
synapses on the CM. The interconnect structure of a model is described by product 
sets on an ordered pair of identification (id) numbers, rid and sid. The rid is the id of 
units receiving activation and sid the id of units sending activation. Each id is a unique 
integer. In a hierarchical network, the ids of input units are never in the set of rids and 
the ids of output units are never in the set of sids. Various set relations (e.g. inverse, 
reflexive, symmetric, etc.) defined over id ranges can be used as a high level 
representation of a network's interconnect structure. These relations can be translated 
into pvar columns. The limits to the interconnect complexity of a simulated model are 
the virtual processor memory limits of the CM configuration used and the stack space 
Rveuired by functions used to compute the weighted sums of activation. Fig. 1 shows a 
-> R 2 -> R 4 interconnect structure and its edge list representation on the CM. 
6 7 8 9 
I 2 3 
CMPROCESSOR 0 I 2 3 4 5 6 7 8 g 10111213 
PACT (ai) 4 4 4 5 5 5 6 6 7 7 8 8 9 9 
SACT (aj) I 2 3 1 2 3 4 5 4 5 4 5 4 5 
Fig. 1. Edge List Representation of a R3-> R 2 -> R 4 Interconnect Structure 
This representation can use as few as six pvars for a model with Hebbian 
adaptation: rid (i), sid (j), interconnect weight (wij), ract (ai) , sact (aj), and learn rate 
(1). Error back propagation requires the addition of: error (ei), old interconnect 
weight (wij(t- 1)), and the momentum term (ix). The receiver and sender unit 
identification pvars are described above. The interconnect weight pvar stores the 
weight for the interconnect. The activation pvar, sact, stores the current activation, aj, 
transfered to the unit specified by rid from the unit specified by sid. The activation 
pvar, ract, stores the current weighted activation ajwij. The error pvar stores the error 
for the unit specified by the sid. A variety of proclaims (e.g. integer, floating point, 
boolean, and field) exist in *Lisp to define the type and size of pvars. Proclaims 
conserve memory and speed up execution. Using a small number of pvars limits the 
129 
amount of memory used in each CM processor so that maximum virtualization of the 
hardware processors can be realized. Any neural model can be specified in this fashion. 
Sigma-pi models require multiple input activation pvars be specified. Some edges may 
have a different number of input activation pvars than others. To maintain the uniform 
data structure of this approach a tag pvar has to be used to determine which input 
activation pvars are in use on a particular edge. 
The edge list approach allows the structure of a simulated model to ""physically"" 
change because edges may be added (up to the virtual processor limit), or deleted at any 
time without affecting the operation of the control structure. Edges may also be placed 
in any processor because the subselection (on rid or sid) operation performed before a 
particular update operation insures that all processors (edges) with the desired units are 
selected for the update. 
The second simulation approach, ""the composite approach,"" uses a more 
complicated data structure where units, incoming links, and outgoing links are 
represented. Update routines for this approach use parallel segmented scans to form 
the weighted sum of input activation. Parallel segmented scans allow a MIMD like 
computation of the weighted sums for many units at once. Pvar columns have unique 
values for unit, incoming link, and outgoing link representations. The data structures 
for input units, hidden units, and output units are composed of sets of the three pvar 
column types. Fig. 2 shows the representation for the same model as in Fig. 1 
implemented with the composite approach. 
1 
o 1 
c--. I Cl c-...q 
I I I 
' I 
I II 
I II 
2 3 4 5 6 7 8 9 
2 3 4 5 6 7 8 9 101112 1314151617181920212223242526272829303132333435 
[o 
Fig. 2. Composite Representation of a R 3 -> R 2 -> R 4 Interconnect Structure 
In Fig. 2, CM processors acting as units, outgoing links, and incoming links are 
represented respectively by circles, triangles, and squares. CM cube address pointers 
used to direct the parallel transfer of activation are shown by arrows below the 
structure. These pointers def'me the model interconnect mapping. Multiple sets of 
these pointers may be stored in seperate pvars. Segmented scans are represented by 
operation-arrow icons above the structure. A basic composite approach pvar set for a 
model with Hebbian adaptation is: forward B, forward A, forward transfer address, 
interconnect weight (wij), act-1 (ai), act-2 (aj), threshold, learn rate (/1), current unit id 
(i), attached unit id (j), level, and column type. Back progagation of error requires the 
addition of: backward B, backward A, backward transfer address, error (ei), previous 
interconnect weight (wij(t-1)), and the momentum term ((x). The forward and 
backward boolean pvars control the segmented scanning operations over unit 
constructs. Pvar A of each type controls the plus scanning and pvar B of each type 
controls the copy scanning. The forward transfer pvar stores cube addresses for 
130 
forward (ascending cube address) parallel transfer of activation. The backward transfer 
pvar stores cube addresses for backward (descending cube address) parallel transfer of 
error. The interconnect weight, activation, and error pvars have the same functions as 
in the edge list approach. The current unit id stores the current unit's id number. The 
attached unit id stores the id number of an attached unit. This is the edge list of the 
network's graph. The contents of these pvars only have meaning in link pvar columns. 
The level pvar stores the level of a unit in a hierarchical network. The type pvar stores 
a unique arbitrary tag for the pvar column type. These last three pvars are used to 
subselect processor ranges to reduce the number of processors involved in an 
operation. 
Again, edges and units can be added or deleted. Processor memories for deleted 
units are zeroed out. A new structure can be placed in any unused processors. The 
level, column type, current unit id, and attached unit id values must be consistent with 
the desired model interconnectivity. 
The number of CM virtual processors required to represent a given model on the 
CM differs for each approach. Given N units and N(N-1) non-zero interconnects (e.g. 
a symmetric model), the edge list approach simply distributes N(N-1) edges to N(N-1) 
CM virtual processors. The composite approach requires two virtual processors for 
each interconnect and one virtual processor for each unit or N+2 N(N-1) CM virtual 
processors total. The difference between the number of processors required by the two 
approaches is N 2. Table I shows the processor and CM virtualization requirements for 
each approach over a range of model sizes. 
TABIE I Model Sizes and CM Processors Required 
Run No. Grid Size Number of Units Edge List Quart CM Virt. Procs. Virt. Level 
N(N-1) 
1 82 64 4032 8192 0 
2 92 81 6480 8192 0 
3 112 121 14520 16384 0 
4 132 169 28392 32768 2 
5 162 256 65280 65536 4 
6 192 361 129960 131072 8 
Run No. Grid Size Number of Units Composite Quart CM Virt. Procs. Virt. Level 
N+2N(N-1) 
7 82 64 8128 8192 0 
8 92 81 13041 16384 0 
9 112 121 29161 32768 2 
10 132 169 56953 65536 4 
11 162 256 130816 131072 8 
12 192 361 260281 262144 16 
131 
CONTROL STRUCTURES 
The control code for neural network simulations (in *Lisp or C*) is stored and 
executed sequentially on a host computer (e.g. Symbolics 36xx and VAX 86xx) 
connected to the CM by a high speed communication line. Neural network simulations 
executed in *Lisp use a small subset of the total instruction set: processor selection 
reset (*all), processor selection (*when), parallel content assignment (*set), global 
summation (*sum), parallel multiplication (*!!), parallel summation (+! !), parallel 
exponentiation (exp! !), the parallel global memory references (*pset) and (pref! !), and 
the parallel segmented scans (copy!! and +! !). Selecting CM processors puts them in a 
""list of active processors"" (loap) where their contents may be arithmetically manipulated 
in parallel. Copies of the list of active processors may be made and used at any time. A 
subset of the processors in the loap may be ""subselected"" at any time, reducing the loap 
contents. The processor selection reset clears the current selected set by setting all 
processors as selected. Parallel content assignment allows pvars in the currently 
selected processor set to be assinged allowed values in one step. Global summation 
executes a tree reduction sum across the CM processors by grid or cube address for 
particular pvars. Parallel multiplications and additions multiply and add pvars for all 
selected CM processors in one step. The parallel exponential applies the function, e x, to 
the contents of a specified pvar, x, over all selected processors. Parallel segmented 
scans apply two functions, copy!! and +!!, to subsets of CM processors by scanning 
across grid or cube addresses. Scanning may be forward or backward (i.e. by 
ascending or descending cube address order, respectively). 
Figs. 3 and 4 show the edge list approach kernels required for Hebbian learning for 
a R 2 -> R 2 model. The loop construct in Fig. 3 drives the activation update 
ai(t+l)=F[Zwij(t+l)aj(t)] 
operation. The usual loop to compute each weighted sum for a particular unit has been 
replaced by four parallel operations: a selection reset (*all), a subselection of all the 
processors for which the particular unit is a receiver of activation (*when (= !! rid (!! 
(1 + u)))), a parallel multiplication (*!! weight sact), and a tree reduction sum (*sum 
...). Activation is spread for a particular unit, to all others it is connected to, by: 
storing the newly computed activation in an array on the host, then subselecting the 
processors where the particular unit is a sender of activation (*when (=!! sid (!! (1+ 
u)))), and broadcasting the array value on the host to those processors. 
(dotimes (u 4) 
(*all (*when (=!! rid (!! (1+ u))) 
(setf (aref activation u) 
(some-nonlinearity (*sum (*!! weight sact)))) 
(*set ract (!! (aref activation u))) 
(*all (*when (=!! sid (!! (1+ u))) 
(*set sact (!! (aref activation u)))))) 
Fig. 4 shows 
Fig. 3. Activation Update Kernel for the Edge Lst Approach. 
the Hebbian weight update kernel 
132 
wij (t+ 1)--11 ai(t+ 1)aj (t+ 1 ). 
(*all 
(*set weight 
(*!! learn-rate ract sact)))) 
(2) 
Fig. 4. Hebbian Weight Modification Kemel for the Edge List Approach 
The edge list activation update kernel is essentially serial because the steps involved can 
only be applied to one unit at a time. The weight modification is parallel. For error 
back propagation a seperate loop for computing the errors for the units on each layer of 
a model is required. Activation update and error back propagation also require transfers 
to and from arrays on the host on every iteration step incurring a concomitant overhead. 
Other common computations used for neural networks can be computed in parallel 
using the edge list approach. Fig. 5 shows the code kernel for parallel computation of 
Lyapunov engergy equations 
E= - 1/2y. Ni;jwijaiaj + IgNi=llia i 
(3) 
where i= 1 to number of units (N). 
(+ (* -.5 (*sum (*!! weight ract sact))) (*sum (*!! input sact))) 
Fig. 5. Kernel for Computation of the Lyapunov Energy Equation 
Although an input pvar, input, is defined for all edges, it is only non-zero for those 
edges associated with input units. Fig. 6 shows the pvar structure for parallel 
computation of a Hopfield weight prescription, with segmented scanning to produce the 
weights in one step, 
wij: Y. Sr: 1 (2ari- 1)(2a- 1) (4) 
where wii=0, wij=wji , and r=l to the number of patterns, S, to be stored. 
seg t n n t n n 
ract vl 1 v21 ... vS 1 vll v21 ... vS 1 ... 
sact v12 v22 . .. vS2 v13 v23 . .. vS 3 ... 
weight w 12 w 13 
Fig. 6. Pvar Structure for Parallel Computation of Hopfield Weight Prescription 
Fig. 7 shows the *Lisp kernel used on the pvar structure in Fig. 6. 
(set weight 
(scan %!! (*!! (-!! (*!! ract (!! 2)) (!! 1)) (-!! (*!! sact (!! 2)) (!! 1)))) 
:segment-pvar seg :include-self t) 
Fig. 7. Parallel Computation of Hopfield Weight Prescription 
133 
The inefficiencies of the edge list activation update are solved by the updating 
method used in the composite approach. Fig. 8 shows the *Lisp kernel for activation 
update using the composite approach. Fig. 9 shows the *Lisp kernel for the Hebbian 
learning operation in the composite approach. 
(*all 
(*when (=!! level (!! 1)) 
(*set act (scan!! act-1 'copy!! :segment-pvar forwardb :include-self t)) 
(*set act (*!! act-1 weight)) 
(*when (=!! type (!! 2)) (*pset :overwrite act-1 act-1 ftransfer))) 
(*when (=! ! level (!! 2)) 
(*set act (scan!! act-1 '+!! :segment-pvar forwarda :include-self t)) 
(*when (=!! type (!! 1)) (some-nonlinearity!! act-1)))) 
Fig. 8. Activation Update Kernel for the Composite Approach 
(*all 
(*set act- 1 (scan! ! act- 1 'copy ! ! :segment-pvar forwardb 
:include-self t)) 
(*when (=!! type (!! 2)) 
(*set act-2 (pref!! act- 1 btransfer))) 
(*set weight 
(+! ! weight 
(* !! learn-rate act- 1 act-2))))) 
Fig. 9. Hebbian Weight Update Kernel for the Composite Approach 
It is immediately obvious that no looping is invloved. Any number of interconnects 
may be updated by the proper subselection. However, the more subselection is used 
the less efficient the computation becomes because less processors are invloved. 
COMPI F. XITY ANALYSIS 
The performance results presented in the next section can be largely anticipated 
from an analysis of the space and time requirements of the CM implementation 
approaches. For simplicity I use a R n -> R n model with Hebbian adaptation. The 
oder of magnitude requirements for activation and weight updating are compared for 
both CM implementation approaches and a basic serial matrix arithmetic approach. 
Fr the given model. the space requirements on a conventional serial machine are 
2n+n locations or O(n2). The growth of the space requirement is dominated by the 
nxn weight matrix defining the system interconnect structure. The edge list approach 
uses six pvars for each processor and uses nxn processors for the mapping, or 6n z 
locations or O(n2). The composite approach uses 11 pvars. There are 2n processors 
for units and 2n z processors for interconnects in the given model. The composite 
approach uses 1 l(2n+2n 2) locations or O(n2). The CM implementations take up 
roughly the same space as the serial implementation, but the space for the serial 
implementation is composed of passive memory whereas the space for the CM 
implementations is composed of interconnected processors with memory. 
The time analysis for the approaches compares the time order of magnitudes to 
compute the activation update (1) and the Hebbian weight update (2). On a serial 
134 
machine, the n weighted sums computed for the activation update require n 2 
multiplications,and n(n-1) additions. There are 2n2-n operations or time order of ,, 
magnitude O(nZ),. The time order of magnitude for the weight matrix update is O(n z) 
since there are n z weight matrix elements. 
The edge list approach forms n weighted sums by performing a parallel product of 
all of the weights and activations in the model, (*!! weight sact), and then a tree 
reduction sum, (*sum ...), of the products for the n unit (see Fig. 4). There are 
l+n(nlog2 n) operations or time order of magnitude O(n ). This is the same order of 
magnitude as obtained on a serial machine. Further, the performance of the activation 
update is a function of the number of interconnects to be processed. 
The composite approach forms n weighted sums in nine steps (see Fig. 8): five 
selection operations; the segmented copy scan before the parallel multiplication; the 
parallel multiplication; the parallel transfer of the products; and the segmented plus 
scan, which forms the n sums in one step. This gives the composite activation update a 
time order of magnitude O(1). Performance is independent of the number of 
interconnects processed. The next section shows that this is not quite true. 
The n 2 weights in the model can be updated in three parallel steps using the edge 
list approach (see Fig. 4). The n 2 weights in the model can be updated in eight parallel 
steps using the composite approach (see Fig. 9). In either case, the weight update 
operation has a time order of magnitude O(1). 
The time complexity results obtained for the composite approach apply to 
computation of the Lyaponov energy equation (3) and the Hopfield weighting 
prescription (4), given that pvar structures which can be scanned (see Figs. 1 and 6) are 
used. The same operations performed serially are time order of magnitude O(n2). 
The above operations all incur a one time overhead cost for generating the addresses 
in the pointer pvars, used for parallel transfers, and arranging the values in segments 
for scanning. What the above analysis shows is that time complexity is traded for 
space complexity. The goal of CM programming is to use as many processors as 
possible at every step. 
PERFORMANCE COMPARISON 
Simulations of a Hopfield spin-glass model 2 were run for six different model sizes 
over the same number (16,384) of physical CM processors to provide a performance 
comparison between implementation approaches. The Hopfield network was chosen 
for the performance comparison because of its simple and well known convergence 
dynamics and because it uses a small set of pvars which allows a wide range of 
network sizes (degrees of virtualization) to be run. Twelve treaments are run. Six with 
the edge list approach and six with the composite approach. Table 3-1 shows the 
model sizes run for each treatment. Each treatment was run at the virtualization level 
just necessary to accomodate the number of processors required for each simulation. 
Two exemplar patterns are stored. Five test patterns are matched against the two 
exemplars. Two test patterns have their centers removed, two have a row and column 
removed, and one is a random pattern. Each exemplar was hand picked and tested to 
insure that it did not produce cross-talk. The number of rows and columns in the 
exemplars and patterns increase as the size of the networks for the treatments increases. 
135 
Since the performance of the CM is at issue, rather than the performance of the network 
model used, a simple model and a simple pattern set were chosen to minimize 
consideration of the influence of model dynamics on performance. 
Performance is presented by plotting execution speed versus model size. Size is 
measured by the number of interconnects in a model. The execution speed metric is 
interconnects updated per second, N*(N-1)/t, where N is the number of units in a 
model and t is the time used to update the activations for all of the units in a model. All 
of the units were updated three times for each pattern. Convergence was determined 
by the output activation remaining stable over the f'mal two updates. The value of t for 
a treatment is the average of 15 samples of ix Fig. 10 shows the activation update cycle 
time for both approaches. Fig. 11 shows the interconnect update speed plots for both 
approaches. The edge list approach is plotted in black. The composite approach is 
plotted in white. The performance shown excludes overhead for interpretation of the 
*Lisp instructions. The model size categories for each plot correspond to the model 
sizes and levels of CM virtualization shown in Table I. 
Activation Update Cycle Time vs Model Size 
1.6 
1.4 
1.2 
1 
secs O. 8 
0.6 
0.4 
0.2 
0 
� $ o 
 n, ,o , 
3 4 5 6 
Model Size 
Fig. 10. Activation Update Cycle Times 
i.p.S. 
Interconnect Update Speed Comparison 
Edge List Approach vs. Composite Approach 
2000000. 
1500000' 
1000000' 
500000 
oe 
1 
o 
o 
o 
o 
o 
2 3 4 5 6 
Model Size 
Fig. 11. Edge List Interconnect Update Speeds 
Fig. 11 shows an order of magnitude performance difference between the 
approaches and a roll off in performance for each approach as a function of the number 
of virtual processors supported by each physical processor. The performance tum 
around is at 4x virtualization for the edge list approach and 2x virtualization for the 
composite approach. 
136 
CONCLUSIONS 
Representing the interconnect structure of neural network models with mappings 
defined over the set of fine grain processors provided by the CM architecture provides 
good performance for a modest programming effort utilizing only a small subset of the 
instructions provided by *Lisp. Further, the performance will continue to scale up 
linearly as long as not more than 2x virtualization is required. While the complexity 
analysis of the composite activation update suggests that its performance should be 
independent of the number of interconnects to be processed, the performance results 
show that the performance is indirectly dependent on the number of interconnects to be 
processed because the level of virtualization required (after the physical processors are 
exhausted) is dependent on the number of interconnects to be processed and 
virtualization decreases performance linearly. The complexity analysis of the edge list 
activation update shows that its performance should be roughly the same as serial 
implementations on comparable machines. The results suggest that the composite 
approach is to be prefered over the edge list approach but not be used at a virtualization 
level higher than 2x. 
The mechanism of the composite activation update suggest that hierarchical 
networks simulated in this fashion will compare in performance to single layer 
networks because the parallel transfers provide a type of pipeline for activation for 
synchronously updated hierarchical networks while providing simultaneous activation 
transfers for asynchronously updated single layer networks. Researchers at Thinking 
Machines Corporation and the M.I.T. AI Laboratory in Cambridge Mass. use a similar 
approach for an implementation of NETtalk. Their approach overlaps the weights of 
connected units and simultaneously pipelines activation forward and error backward. 3 
Performance better than that presented can be gained by translation of the control 
code from interpreted *Lisp to PARIS and use of the CM2. In addition to not being 
interpreted, PARIS allows explicit control over important registers that aren't 
accessable through *Lisp. The CM2 will offer a number of new features which will 
enhance performance of neural network simulations: a *Lisp compiler, larger 
processor memory (64K), and floating point processors. The complier and floating 
point processors will increase execution speeds while the larger processor memories 
will provide a larger number of virtual processors at the performance turn around points 
allowing higher performance through higher CM utilization. 
REFERENCES 
1. ""Introduction to Data Level Parallelism,"" Thinking Machines Technical Report 
86.14, (April 1986). 
2. Hopfield, J. J., ""Neural networks and physical systems with emergent collective 
computational abilities,"" Proc. Nail. Acad, $ci,, Vol. 79, (April 1982), pp. 2554-2558. 
3. Blelloch, G. and Rosenberg, C. Netwcrk Learning on the Connection Machine, 
M.I.T. Technical Report, 1987. 
", network implement approach machin white granit simd parallel connect machin allow construct network simul use simpl data control two describ allow parallel comput nonlinear parallel modif parallel propag activ approach also allow interconnect physic hopfield model implement six size number cm processor provid perform neural network model digit comput perform variou appli linear nonlinear defin sum integ real number retriev store array valu model depend paramet like time averag spike frequenc synapt efficaci error error back propag temperatur thermodynam interconnect structur model impli index relationship array defin connect machin relationship express processor interconnect hypercub commun map construct defin higher dimension interconnect processor top fundament geometri commun parallel transfer defin map may cm parallel oper transform array index tempor success refer memori singl tempor refer spatial distribut altern approach implement neural network simul cm approach use provid lisp virtual data control structur associ approach perform hopfield model implement approach structur function compon neural network model implement lisp uniform parallel variabl data structur data structur view column column given cm virtual cm physic processor may support virtual first approach cm processor use repres edg set model graph second approach processor repres incom link movement activ interconnect structur simul move numer valu institut physic mani movement result execut cm cm transpar handl messag buffer care requir part user insur messag traffic distribut enough processor messag stack certain forc cm sequenti handl larg number approach requir serial transfer model paramet commun channel host cm certain time edg list distribut edg list network one edg per cm interconnect weight edg memori array host machin store activ approach may consid repres abstract interconnect structur model describ product order pair identif rid rid id receiv activ sid id unit send id uniqu hierarch id input unit never set rid id output unit never set variou set relat defin id rang use high level interconnect relat translat pvar limit interconnect complex simul model virtual processor memori limit cm configur use stack space function use comput weight sum show interconnect structur edg list represent edg list represent interconnect structur represent use six pvar model hebbian rid sid interconnect weight ract sact learn rate error back propag requir addit error old interconnect momentum term receiv sender unit pvar describ interconnect weight pvar store activ store current unit specifi rid unit specifi activ store current weight activ error pvar store error unit specifi varieti proclaim float exist lisp defin type size proclaim memori speed use small number pvar limit memori use cm processor maximum virtual processor neural model specifi model requir multipl input activ pvar edg may differ number input activ pvar maintain uniform structur approach tag pvar use determin input pvar use particular edg list approach allow structur simul model edg may ad virtual processor delet without affect oper control edg may also place processor subselect rid oper perform updat oper insur processor desir unit second simul composit use data structur incom outgo link updat routin approach use parallel segment scan form weight sum input parallel segment scan allow mimd like weight sum mani unit pvar column uniqu incom outgo link data structur input hidden output unit compos set three pvar show represent model composit ii ii composit represent interconnect structur cm processor act outgo incom link respect cm cube address pointer direct parallel transfer activ shown arrow pointer model interconnect multipl set pointer may store seper segment scan repres icon basic composit approach pvar set hebbian adapt forward forward forward transfer weight learn rate current unit id attach unit id column back progag error requir backward backward backward transfer error previou weight momentum term forward boolean pvar control segment scan oper unit pvar type control plu scan pvar type copi forward transfer pvar store cube address cube parallel transfer backward transfer store cube address backward cube parallel transfer interconnect error pvar function edg list current unit id store current id unit id store id number attach edg list content pvar mean link pvar level pvar store level unit hierarch type pvar store uniqu arbitrari tag pvar column last three pvar use processor rang reduc number processor involv edg unit ad processor memori delet zero new structur place unus column current unit attach unit id valu must consist desir model number cm virtual processor requir repres given model differ given unit interconnect symmetr edg list approach simpli distribut edg virtual composit approach requir two virtual processor interconnect one virtual processor unit cm virtual differ number processor requir two tabl show processor cm virtual requir approach rang model model size cm processor requir grid size number unit edg list quart cm level grid size number unit composit quart cm level structur control code neural network simul lisp store sequenti host comput symbol vax cm high speed commun neural network simul lisp use small subset total instruct processor select processor select parallel content assign global parallel multipl parallel summat parallel parallel global memori refer parallel segment scan select cm processor put activ content may arithmet manipul copi list activ processor may made use processor loap may reduc loap processor select reset clear current select set set parallel content assign allow pvar current processor set assing allow valu one global summat tree reduct sum across cm processor grid cube address parallel multipl addit multipli add pvar cm processor one parallel exponenti appli content specifi select parallel segment appli two subset cm processor scan grid cube scan may forward backward descend cube address show edg list approach kernel requir hebbian learn loop construct drive activ updat usual loop comput weight sum particular unit four parallel select reset subselect particular unit receiv activ rid parallel multipl weight tree reduct sum sum activ spread particular other connect newli comput activ array subselect particular unit sender activ sid broadcast array valu host rid activ sum weight set ract activ sid set sact activ show activ updat kernel edg lst hebbian weight updat kernel set weight ract hebbian weight modif kemel edg list approach edg list activ updat kernel essenti serial step involv appli one unit weight modif error propag seper loop comput error unit layer model activ updat error back propag also requir transfer array host everi iter step incur concomit common comput use neural network comput parallel edg list show code kernel parallel comput engergi equat number unit sum weight ract sum input kernel comput lyapunov energi equat input defin associ input show pvar structur parallel hopfield weight segment scan produc one number vl vll pvar structur parallel comput hopfield weight prescript show lisp kernel use pvar structur weight ract sact seg parallel comput hopfield weight prescript ineffici edg list activ updat solv updat use composit show lisp kernel activ use composit show lisp kernel hebbian oper composit level set act forwardb set act type pset level set act forwarda type activ updat kernel composit approach set forwardb type set set weight weight hebbian weight updat kernel composit approach immedi obviou loop number interconnect updat proper subselect use less effici comput becom less processor xiti analysi perform result present next section larg anticip analysi space time requir cm implement simplic use model hebbian magnitud requir activ weight updat compar cm implement approach basic serial matrix arithmet given space requir convent serial machin locat growth space requir domin weight matrix defin system interconnect edg list approach six pvar processor use nxn processor composit approach use processor unit processor interconnect given composit use locat cm implement take space serial space serial compos passiv memori wherea space cm compos interconnect processor time analysi approach compar time order magnitud activ updat hebbian weight updat serial weight sum comput activ updat requir oper time order time order magnitud weight matrix updat weight matrix edg list approach form weight sum perform parallel product weight activ weight tree sum product oper time order magnitud order obtain serial perform activ function number interconnect composit approach form weight sum nine step five segment copi scan parallel parallel transfer segment plu form sum one give composit activ updat order magnitud perform independ number next section show quit weight model updat three parallel step use edg approach weight model updat eight parallel use composit approach either weight updat time order magnitud time complex result obtain composit approach appli lyaponov energi equat hopfield weight given pvar structur scan oper perform serial time order magnitud oper incur one time overhead cost gener address pointer use parallel arrang valu segment analysi show time complex trade goal cm program use mani processor everi comparison hopfield model run six differ model size number physic cm processor provid perform implement hopfield network chosen perform comparison simpl well known converg use small set pvar allow wide rang size twelv treament six edg list approach six composit tabl show size run treatment run virtual level necessari accomod number processor requir exemplar pattern five test pattern match two two test pattern center two row column one random exemplar hand pick test produc number row column pattern increas size network treatment perform cm rather perform network simpl model simpl pattern set chosen minim influenc model dynam present plot execut speed versu model size number interconnect execut speed metric updat per number unit time use updat activ unit unit updat three time converg determin output activ remain stabl two valu treatment averag sampl ix show activ updat cycl show interconnect updat speed plot edg list approach plot composit approach perform shown exclud overhead interpret lisp model size categori plot correspond model level cm virtual shown tabl updat cycl time vs model size size activ updat cycl time updat speed comparison list approach composit approach size edg list interconnect updat speed show order magnitud perform differ roll perform approach function number virtual processor support physic perform tum virtual edg list approach virtual interconnect structur neural network model map set fine grain processor provid cm architectur provid perform modest program effort util small subset provid perform continu scale long virtual complex composit activ updat suggest perform number interconnect perform result perform indirectli depend number interconnect level virtual requir physic processor depend number interconnect process decreas perform complex analysi edg list updat show perform roughli serial compar result suggest composit prefer edg list approach use virtual higher mechan composit activ updat suggest hierarch simul fashion compar perform singl layer parallel transfer provid type pipelin activ updat hierarch network provid simultan activ asynchron updat singl layer research think corpor ai laboratori cambridg use similar implement approach overlap weight unit simultan pipelin activ forward error better present gain translat control lisp pari use addit pari allow explicit control import regist offer number new featur perform neural network lisp larger memori float point complier float processor increas execut speed larger processor memori provid larger number virtual processor perform turn around point higher perform higher cm data level think machin technic report network physic system emerg collect learn connect technic,2
14,14,"137 
On the 
Power of Neural Networks for 
Solving Hard Problems 
Jehoshua Bruck 
Joseph W. Goodman 
Information Systems Laboratory 
Department of Electrical Engineering 
Stanford University 
Stanford, CA 94305 
Abstract 
This paper deals with a neural network model in which each neuron 
performs a threshold logic function. An important property of the model 
is that it always converges to a stable state when operating in a serial 
mode [2,5]. This property is the basis of the potential applications of the 
model such as associative memory devices and combinatorial optimization 
[3,6]. 
One of the motivations for use of the model for solving hard combinatorial 
problems is the fact that it can be implemented by optical devices and 
thus operate at a higher speed than conventional electronics. 
The main theme in this work is to investigate the power of the model for 
solving NP-hard problems [4,8], and to understand the relation between 
speed of operation and the size of a neural network. In particular, it will 
be shown that for any NP-hard problem the existence of a polynomial 
size network that solves it implies that NP=co-NP. Also, for Traveling 
Salesman Problem (TSP), even a polynomial size network that gets an 
e-approximate solution does not exist unless P=NP. 
The above results are of great practical interest, because right now it is 
possible to build neural networks which will operate fast but are limited 
in the number of neurons. 
I Background 
The neural network model is a discrete time system that can be represented by 
a weighted and undirected graph. There is a weight attached to each edge of 
the graph and a threshold value attached to each node (neuron) of the graph. 
� American Institute of Physics 1988 
138 
The order of the network is the number of nodes in the corresponding graph. 
Let N be a neural network of order n; then N is uniquely defined by (W, T) 
where: 
� W is an n x n symmetric matrix, Wij is equal to the weight attached to 
edge (i, j). 
� T is a vector of dimension n, Ti denotes the threshold attached to node i. 
Every node (neuron) can be in one of two possible states, either 1 or -1. The 
state of node i at time t is denoted by V/(t). The state of the neural network at 
time t is the vector V(t). 
The next state of a node is computed by: 
V/(t + 1) = sgn(Hi(t)) = { 
where 
1 if Hi(t) _> 0 (1) 
-1 otherwise 
The next state of the network, i.e. V(t + 1), is computed from the current 
state by performing the evaluation (1) at a subset of the nodes of the network, 
to be denoted by $. The modes of operation are determined by the method 
by which the set '$ is selected in each time interval. If the computation is 
performed at a single node in any time interval, i.e. ] $ I= 1, then we will say 
that the network is operating in a serial mode; if I $1= n then we will say that 
that the network is operating in a fully parallel mode. All the other cases, i.e. 
I <l $1< n will be called parallel modes of operation. The set $ can be chosen 
at random or according to some deterministic rule. 
A state V(t) is called stable iff V(t) = sgn(WV(t)- T), i.e. there is no 
change in the state of the network no matter what the mode of operation is. 
One of the most important properties of the model is the fact that it always 
converges to a stable state while operating in a serial mode. The main idea in 
the proof of the convergence property is to define a so called energy function 
and to show that this energy function is nondecreasing when the state of the 
network changes. The energy function is: 
E(t) = vT(t)WV(t) - 2vT(t)T 
(2) 
An important note is that originally the energy function was defined such that 
it is nonincreasing [5]; we changed it such that it will comply with some known 
graph problems (e.g. Min Cut). 
A neural network will always get to a stable state which corresponds to a 
local maximum in the energy function. This suggests the use of the network as a 
139 
device for performing a local search algorithm for finding a maximal value of the 
energy function [6]. Thus, the network will perform a local search by operating 
in a random and serial mode. It is also known [2,9] that maximization of E 
associated with a given network N in which T - 0 is equivalent to finding 
the Minimum Cut in N. Actually, many hard problems can be formulated as 
maximization of a quadratic form (e.g. TSP [6]) and thus can be mapped to a 
neural network. 
2 The Main Results 
The set of stable states is the set of possible final solutions that one will get 
using the above approach. These final solutions correspond to local maxima of 
the energy function but do not necessarily correspond to global optima of the 
corresponding problem. The main question is: suppose we allow the network to 
operate for a very long time until it converges; can we do better than just getting 
some local optimum? i.e., is it possible to design a network which will always 
find the exact solution (or some guaranteed approximation) of the problem? 
Definition: Let X be an instance of problem. Then I X I denotes the size of 
X, that is, the number of bits required to represent X. For example, for X 
being an instance of TSP, I X I is the number of bits needed to represent the 
matrix of the distances between cities. 
Definition: Let N be a neural network. Then I N I denotes the size of the 
network N. Namely, the number of bits needed to represent W and T. 
Let us start by defining the desired setup for using the neural network as a 
model for solving hard problems. 
Consider an optimization problem L, we would like to have for every instance 
X of L a neural network Nx with the following properties: 
� Every local maximum of the energy function associated with Nx corre- 
sponds to a global optimum of X. 
� The network Nx is small, that is, I Nx I is bounded by some polynomial 
inlXl. 
Moreover, we would like to have an algorithm, to be denoted by AL, which given 
an instance X E L, generates the description for Nx in polynomial (in I X I) 
time. 
Now, we will define the desired setup for using the neural network as a model 
for finding approximate solutions for hard problems. 
Definition: Let Egto be the global maximum of the energy function. Let Etoc 
140 
be a local maximum of the energy function. We will say that a local maximum 
is an e-approximate of the global iff: 
Ealo -- Eloc 
<e 
Ealo -- 
The setup for finding approximate solutions is similar to the one for finding 
exact solutions. For e->_ 0 being some fixed number. We would like to have a 
network Nx, in which every local maximum is an e-approximate of the global 
and that the global corresponds to an optimum of X. The network Nx should 
be small, namely, I Nx, I should be bounded by a polynomial in I X I. Also, 
we would like to have an algorithm AL,, such that, given an instance X E L, it 
generates the description for Nx in polynomial (in IX I) time. 
Note that in both the exact case and the approximate case we do not put any 
restriction on the time it takes the network to converge to a solution (it can be 
exponential). 
At this point the reader should convince himself that the above description is 
what he imagined as the setup for using the neural network model for solving 
hard problems, because that is what the following definition is about. 
Definition: We will say that a neural network for solving (or finding an e- 
approximation of) a problem L exists if the algorithm At (or At) which gen- 
erates the description of Nx (or Nx,) exists. 
The main results in the paper are summarized by the following two propo- 
sitions. The first one deals with exact solutions of NP-hard problems while the 
second deals with approximate solutions to TSP. 
Proposition I Let L be an NP-hard problem. Then the existence of a neural 
network for solving L implies that NP - co-NP. 
Proposition 2 Let e >_ 0 be some fixed number. The existence of a neural 
network for finding an e-approximate solution to TSP implies that P=NP. 
Both (P=NP) and (NP=co-NP) are believed to be false statements, hence, 
we can not use the model in the way we imagine. 
The key observation for proving the above propositions is the fact that a 
single iteration in a neural network takes time which is bounded by a polynomial 
in the size of the instance of the corresponding problem. The proofs of the above 
two propositions follow directly from known results in complexity theory and 
should not be considered as new results in complexity theory. 
141 
3 The Proofs 
Proof of Proposition 1: The proof follows from the definition of the classes 
NP and co-NP, and Lemma 1. The definitions and the lemma appear in Chap- 
ters 15 and 113 in [8] and also in Chapters 2 and 7 in [4]. 
Lemma I If the complement of an NP-complete problem is in NP, 
then NP=co-NP. 
Let L be an NP-hard problem. Suppose there exists a neural network that solves 
L. Let L be an NP-complete problem. By definition, L can be polynomialy 
reduced to L. Thus, for every instance X E L, we have a neural network such 
that from any of its global maxima we can efficiently recognize whether X is a 
'yes' or a 'no' instance of L. 
We claim that we have a nondeterministic polynomial time algorithm to decide 
that a given instance X E L is a 'no' instance. Here is how we do it: for X  L 
we construct the neural network that solves it by using the reduction to L. We 
then check every state of the network to see if it is a local maximum (that is 
done in polynomial time). In case it is a local maximum, we check if the instance 
is a 'yes' or a 'no' instance (this is also done in polynomial time). 
Thus, we have a nondeterministic polynomial time algorithm to recognize any 
'no' instance of L. Thus, the complement of the problem L is in NP. But L is 
an NP-complete problem, hence, from Lemma 1 it follows that NP=co-NP. [] 
Proof of Proposition 2: The result is a corollary of the results in [7], the 
reader can refer to it for a more complete presentation. 
The proof uses the fact that the Restricted HamiltonJan Circuit (RHC) is an 
NP-complete problem. 
Definiton of RHC: Given a graph G = (V, E) and a HamiltonJan path in G. 
The question is whether there is a HamiltonJan circuit in G? 
It is proven in [7] that RHC is NP-complete. 
Suppose there exists a polynomial size neural network for finding an 
e-approximate solution to TSP. Then it can be shown that an instance X 
RHC can be reduced to an instance f(  TSP, such that in the network 
the following holds: if the Hamiltonian path that is given in X corresponds to a 
local maximum in N2 then X is a 'no' instance; else, if it does not correspond 
to a local maximum in N2 then X is a 'yes' instance. Note that we can check 
for locality in polynomial time. 
Hence, the existence of N2, for all (  TSP implies that we have a polynomial 
time algorithm for RHC. [] 
142 
4 
Concluding Remarks 
In Proposition 1 we let I W I and I T I be arbitrary but bounded by a 
polynomial in the size of a given instance of a problem. If we assume 
that I W I and I T I are fixed for all instances then a similar result to 
Proposition 1 can be proved without using complexity theory; this result 
appears in [1]. 
The network which corresponds to TSP, as suggested in [6], can not solve 
the TSP with guaranteed quality. However, one should note that all the 
analysis in this paper is a worst case type of analysis. So, it might be that 
there exist networks that have good behavior on the average. 
Proposition 1 is general to all NP-hard problems while Proposition 2 is 
specific to TSP. Both propositions hold for any type of networks in which 
an iteration takes polynomial time. 
Clearly, every network has an algorithm which is equivalent to it, but an 
algorithm does not necessarily have a corresponding network. Thus, if we 
do not know of an algorithmic solution to a problem we also will not be able 
to find a network which solves the problem. If one believes that the neural 
network model is a good model (e.g. it is amenable to implementation with 
optics), one should develop techniques to program the network to perform 
an algorithm that is known to have some guaranteed good behavior. 
Acknowledgement: Support of the U.S. Air Force Office of Scientific Research 
is gratefully acknowledged. 
References 
[1] 
Y. Abu Mostafa, Neural Networks for Computing? in Neural Networks 
for Computing, edited by J. Denker (AIP Conference Proceedings no. 151, 
1986). 
[2] J. Bruck and J. Sanz, A Study on Neural Networks, IBM Tech Rep, RJ 
5403, 1986. To appear in International Journal of Intelligent Systems, 1988. 
[3] J. Bruck and J. W. Goodman, A Generalized Convergence Theorem for 
Neural Networks and its Applications in Combinatorial Optimization, IEEE 
First ICNN, San-Diego, June 1987. 
[4] M. R. Garey and D. S. Johnson, Computers and Intractability: A Guide to 
the Theory ofNP-Completeness, W. H. Freeman and Company, 1979. 
143 
[5] 
[6] 
[7] 
[8] 
[9] 
J. J. Hopfield, Neural Networks and Physical Systems with Emergent Col- 
lective Computational Abilities, Proc. Nat. Acad. Sci.. USA, Vol. 79, pp. 
2554-2558, 1982. 
J. J. Hopfield and D. W. Tank, Neural Computations of Decisions in Op- 
timization Problems, Biol. Cybern. 52, pp. 141-152, 1985. 
C. H. Papadimitriou and K. Steiglitz, On the Complexity of Local Search 
for the Traveling Salesman Problem, SIAM J. on Comp., Vol. 6, No. 1, pp. 
76-83, 1977. 
C. H. Papadimitriou and K. Steiglitz, Combinatorial Optimization: Algo: 
rithms and Complexity, Prentice-Hall, Inc., 1982. 
J. C. Picard and H. D. Ratlift, Minimum Cuts and Related Problems, Net- 
works, Vol 5, pp. 357-370, 1974. 
", neural network hard problem bruck goodman system laboratori electr engin univers ca paper deal neural network model neuron threshold logic import properti model alway converg stabl state oper serial properti basi potenti applic associ memori devic combinatori optim motiv use model solv hard combinatori fact implement optic devic oper higher speed convent main theme work investig power model problem understand relat oper size neural shown problem exist polynomi network solv impli travel problem even polynomi size network get solut exist unless result great practic right build neural network oper fast limit number background neural network model discret time system repres weight undirect weight attach edg graph threshold valu attach node american institut physic order network number node correspond neural network order uniqu defin symmetr wij equal weight attach vector dimens ti denot threshold attach node node one two possibl either node time denot state neural network vector next state node comput otherwis next state comput current perform evalu subset node denot mode oper determin method set select time comput singl node time say network oper serial say network oper fulli parallel call parallel mode set chosen random accord determinist state call stabl iff state network matter mode oper import properti model fact alway stabl state oper serial main idea proof converg properti defin call energi function show energi function nondecreas state energi function import note origin energi function defin nonincreas chang compli known problem min neural network alway get stabl state correspond maximum energi suggest use network perform local search algorithm find maxim valu function network perform local search oper random serial also known maxim given network equival find minimum cut mani hard problem formul quadrat form tsp thu map main result set stabl state set possibl final solut one get final solut correspond local maxima energi function necessarili correspond global optima main question suppos allow network long time better get local possibl design network alway exact solut guarante let instanc denot size number bit requir repres instanc number bit need repres distanc let neural denot size number bit need repres us start defin desir setup use neural network solv hard optim problem would like everi instanc neural network nx follow everi local maximum energi function associ nx global optimum network nx nx bound polynomi would like denot given instanc gener descript nx polynomi defin desir setup use neural network model find approxim solut hard let egto global maximum energi let etoc local maximum energi say local maximum global eloc setup find approxim solut similar one find fix would like everi local maximum global global correspond optimum network bound polynomi would like algorithm given instanc descript polynomi ix exact case approxim case put time take network converg solut point reader convinc descript imagin setup use neural network model solv follow definit say neural network solv find problem exist algorithm descript nx main result paper summar follow two first one deal exact solut problem deal approxim solut let exist neural solv impli np let fix exist neural find solut tsp impli believ fals use model way key observ prove proposit fact iter neural network take time bound polynomi size instanc correspond proof proposit follow directli known result complex theori consid new result complex proof proposit proof follow definit class lemma definit lemma appear also chapter complement problem suppos exist neural network solv let polynomiali everi instanc neural network maxima effici recogn whether instanc claim nondeterminist polynomi time algorithm decid given instanc construct neural network solv use reduct check everi state network see local maximum polynomi case local check instanc instanc also done polynomi nondeterminist polynomi time recogn instanc complement problem lemma follow proposit result corollari result refer complet proof use fact restrict jan circuit given graph jan path question whether jan circuit proven rhc exist polynomi size neural network find solut shown instanc reduc instanc network follow hamiltonian path given correspond maximum correspond local maximum note check local polynomi exist tsp impli polynomi algorithm remark proposit let arbitrari bound size given instanc assum fix instanc similar result prove without use complex result network correspond suggest solv tsp guarante one note paper worst case type might exist network good behavior gener problem proposit proposit hold type network iter take polynomi everi network algorithm equival necessarili correspond know algorithm solut problem also abl find network solv one believ neural model good model amen implement one develop techniqu program network perform algorithm known guarante good support air forc offic scientif research grate abu neural network neural network edit denker confer proceed bruck studi neural ibm tech rj appear intern journal intellig bruck gener converg theorem network applic combinatori ie june garey comput guid theori freeman neural network physic system emerg comput hopfield neural comput decis papadimitri complex local search travel salesman siam papadimitri combinatori picard minimum cut relat vol,2
15,15,"144 
SPEECH RECOGNITION EXPERIMENTS 
WITH PERCEPTRONS 
D. J. Burr 
Bell Communications Research 
Morristown, NJ 07960 
ABSTRACT 
Artificial neural networks (ANNs) are capable of accurate recognition of 
simple speech vocabularies such as isolated digits [1]. This paper looks at two 
more difficult vocabularies, the alphabetic E-set and a set of polysyllabic 
words. The E-set is difficult because it contains weak discriminants and 
polysyllables are difficult because of timing variation. Polysyllabic word 
recognition is aided by a time pre-alignment technique based on dynamic pro- 
gramming and E-set recognition is improved by focusing attention. Recogni- 
tion accuracies are better than 98% for both vocabularies when implemented 
with a single layer perceptron. 
INTRODUCTION 
Artificial neural networks perform well on simple pattern recognition 
tasks. On speaker trained spoken digits a layered network performs as accu- 
rately as a conventional nearest neighbor classifier trained on the same tokens 
[1]. Spoken digits are easy to recognize since they are for the most part 
monosyllabic and are distinguished by strong vowels. 
It is reasonable to ask whether artificial neural networks can also solve 
more difficult speech recognition problems. Polysyllabic recognition is difficult 
because multi-syllable words exhibit large timing variation. Another difficult 
vocabulary, the alphabetic E-set, consists of the words B, C, D, E, G, P, T, V, 
and Z. This vocabulary is hard since the distinguishing sounds are short in 
duration and low in energy. 
We show that a simple one-layer perceptron [7] can solve both problems 
very well if a good input representation is used and sufficient examples are 
given. We examine two spectral representations -- a smoothed FFT (fast 
Fourier transform) and an LPC (linear prediction coefficient) spectrum. A 
time stabilization technique is described which pre-aligns speech templates 
based on peaks in the energy contour. Finally, by focusing attention of the 
artificial neural network to the beginning of the word, recognition accuracy of 
the E-set can be consistently increased. 
A layered neural network, a relative of the earlier perceptton [7], can be 
trained by a simple gradient descent process [8]. Layered networks have been 
American Institute of Physics 1988 
145 
applied successfully to speech recognition [1], handwriting recognition [2], and 
to speech synthesis [11]. A variation of a layered network [3] uses feedback to 
model causal constraints, which can be useful in learning speech and language. 
Hidden neurons within a layered network are the building blocks that are used 
to form solutions to specific problems. The number of hidden units required is 
related to the problem [1,2]. Though a single hidden layer can form any map- 
ping [12], no more than two layers are needed for disjunctive normal form [4]. 
The second layer may be useful in providing more stable learning and 
representation in the presence of noise. Though neural nets have been shown 
to perform as well as conventional techniques[1,5], neural nets may do better 
when classes have outliers [5]. 
PERCEPTRONS 
A simple perceptron contains one input layer and one output layer of 
neurons directly connected to each other (no hidden neurons). This is often 
called a one-layer system, referring to the single layer of weights connecting 
input to output. Figure 1. shows a one-layer perceptron configured to sense 
speech patterns on a two-dimensional grid. The input consists of a 04-point 
spectrum at each of twenty time slices. Each of the 1280 inputs is connected 
to each of the output neurons, though only a sampling of connections are 
shown. There is one output neuron corresponding to each pattern class. Neu- 
rons have standard linear-weighted inputs with logistic activation. 
C(1) C(2) C(N-1) C(N) 
64 units 
Figure 1. A single layer perceptron sensing a time-frequency array of sample 
data. Each output neuron C(i) (IiN) corresponds to a pattern class and 
is full connected to the input array (for clarity only a few connections are 
shown). 
An input word is fit to the grid region by applying an automatic endpoint 
detection algorithm. The algorithm is a variation of one proposed by Rabiner 
and Sambur [9] which employs a double threshold successive approximation 
146 
method. Endpoints are determined by first detecting threshold crossings of 
energy and then of zero crossing rate. In practice a level crossing other than 
zero is used to prevent endpoints from being triggered by background sounds. 
INPUT REPRESENTATIONS 
Two different input representations were used in this study. The first is a 
Fourier representation smoothed in both time and frequency. Speech is sam- 
pled at 10 KHz a.nd Hamming windowed at a number of sample points. A 
128-point FFT spectrum is computed to produce a template of 64 spectral 
samples at each of twenty time frames. The template is smoothed twice with a 
time window of length three and a frequency window of length eight. 
For comparison purposes an LPC spectrum is computed using a tenth 
order model on 300-sample Hamming windows. Analysis is performed using 
the autocorrelation method with Durbin recursion [6]. The resulting spectrum 
is smoothed over three time frames. 
Sample spectra for the utterance ""neural-nets"" is shown in Figure 2. 
Notice the relative smoothness of the LPC spectrum which directly models 
spectral peaks. 
FFT LPC 
Figure 2. FFT and LPC time-frequency plots for the utterance ""neural nets"". 
Time is toward the left, and frequency, toward the right. 
DYNAMIC TIME ALIGNMENT 
Conventional speech recognition systems often employ a time normaliza- 
tion technique based on dynamic programming [10]. It is used to warp the 
time scales of two utterances to obtain optimal alignment between their spec- 
tral frames. We employ a variation of dynamic programming which aligns 
energy contours rather than spectra. A reference energy template is chosen 
for each pattern class, and incoming patterns are warped onto it. Figure 3 
shows five utterances of ""neural-nets"" both before and after time alignment. 
Notice the improved alignment of energy peaks. 
147 
Figure 3. (a) Superimposed energy plots of five different utterances of ""neural 
nets"". (b). Same utterances after dynamic time alignment. 
POLYSYLLABLE RE COGNITION 
Twenty polysyllabic words containing three to five syllables were chosen, 
and five tokens of each were recorded by a single male speaker. A variable 
number of tokens were used to train a simple perceptron to study the effect of 
training set size on performance. Two performance measures were used: 
classification accuracy, and an RMS error measure. Training tokens were per- 
muted to obtain additional experimental data points. 
Figure 4. Output responses of a perceptron trained with one token per class 
(left) and four tokens per class (right). 
148 
Figure 4 shows two representative perspective plots of the output of a 
perceptron trained on one and four tokens respectively per class. Plots show 
network response (z-coordinate) as a function of output node (left axis) and 
test word index (right axis). Note that more training tokens produce a more 
ideal map - a map should have ones along the diagonal and zeroes everywhere 
else. 
Table 1 shows the results of these experiments for three different 
representations: (1) FFT, (2) LPC and (3) time aligned LPC. This table lists 
classification accuracy as a function of number of training tokens and input 
representation. The perceptton learned to classify the unseen patterns per- 
fectly for all cases except the FFT with a single training pattern. 
Table 1. Polysyllabic Word Recognition Accuracr 
Number Training Tokens I 2 3 4 
FFT 98.7% 100% 100% 100% 
LPC 100% 100% 100% 100% 
Time Aligned LPC 100% 100% 100% 100% 
Permuted Trials 400 300 200 100 
A different performance measure, the RMS error, evaluates the degree to 
which the trained network output responses R- k approximate the ideal targets 
Tik. The measure 'is evaluated over the N non-trained tokens and M output 
nodes of the network. Tjk equals I for j=k and 0 for 
RMS Error = 
j=l k=l 
MN 
Figure 5 shows plots of RMS error as a function of input representation 
and training patterns. Note that the FFT representation produced the highest 
error, LPC was about 40% less, and time-aligned LPC only marginally better 
than non-aligned LPC. In a situation where many choices must be made (i.e. 
vocabularies much larger than 20 words) LPC is the preferred choice, and 
time alignment could be useful to disambiguate similar words. Increased 
number of training tokens results in improved performance in all cases. 
149 
 I I I I 
1.0 2.0 3.0 
Number Training Tokens 
4.0 
Figure 5. RMS error versus number of training tokens for various input 
representations. 
E-SET VOCABULARY 
The E-Set vocabulary consists of the nine E-words of the English alpha- 
bet -- B, C, D, E, G, P, T, V, Z. Twenty tokens of each of the nine classes 
were recorded by a single male speaker. To maximize the sizes of training and 
test sets, half were used for training and the other half for testing. Ten per- 
mutations produced a total of 000 separate recognition trials. 
Figure 6 shows typical LPC templates for the nine classes. Notice the 
double formant ridge due to the 'E"" sound, which is common to all tokens. 
Another characteristic feature is the F0 ridge - the upward fold on the left of 
all tokens which characterizes voicing or pitched sound. 
150 
Figure 6. LPC time-frequency plots for representative tokens of the E-set 
words. 
Figure 7. Time-frequency plots of weight values connected to each output 
neuron through in a trained perceptron. 
151 
Figure 7 shows similar plots illustrating the weights learned by the net- 
work when trained on ten tokens of each class. These are plotted like spectra, 
since one weight is associated with each spectral sample. Note that the pat- 
terns have some formant structure. A recognition accuracy of 01.4% included 
perfect scores for classes C, E, and G. 
Notice that weights along the F0 contour are mostly small and some are 
slightly negative. This is a response to the voiced ';"" sound common to all 
classes. The network has learned to discount ""voicing"" as a discriminator for 
this vocabulary. 
Notice also the strong ""hilly"" terrain near the beginning of most tem- 
plates. This shows where the network has decided to focus much of its 
discriminating power. Note in particular the hill-valley pair at the beginning 
of '?"" and ""T"". These are near to formants F2/F3 and could conceivably be 
formant onset detectors. Note the complicated detector pattern for the 
sound. 
The classes that are easy to discriminate (C, E, G) produce relatively flat 
and unintere. sting weight spaces. A highly convoluted weight space must 
therefore be correlated with difficulty in discrimination. It makes little sense 
however that the network should be working hard in the late time ('"" sound) 
portion of the utterance. Perhaps additional training might reduce this 
activity, since the network would eventually find little consistent difference 
there. 
A second experiment was conducted to help the network to focus atten- 
tion. The first k frames of each input token were averaged to produce an aver- 
age spectrum. These average spectra were then used in a simple nearest 
neighbor recognizer scheme. Recognition accuracy was measured as a function 
of k. The highest performance was for k=8, indicating that the first 40% of 
the word contained most of the ""action"". 
B C D E G P T V Z 
96 0 1 0 0 0 0 1 0 
0 100 0 0 0 0 0 0 0 
0 0 98 0 0 2 0 0 0 
0 0 0 100 0 0 0 0 0 
0 0 0 0 100 0 0 0 0 
0 0 3 0 0 93 4 0 0 
0 0 0 0 0 0 100 0 0 
2 0 0 0 0 2 0 98 0 
0 0 0 0 0 0 0 I 90 
Figure 8. Confusion matrix of the E-set focused on the first 40% of each 
word. 
152 
All words were resampled to concentrate 20 time frames into the first 
40% of the word. LPC spectra were recomputed using a 16th order model 
and the network was trained on the new templates. Performance increased 
from 91.4% to 98.2%. There were only 16 classification errors out of the 900 
recognition tests. The confusion matrix is shown in Figure 8. Learning times 
for all experiments consisted of about ten passes through the training set. 
When weights mere primed with average spectral values rather than random 
values, learning time decreased slightly. 
CONCLUSIONS 
Artificial neural networks are capable of high performance in pattern 
recognition applications, matching or exceeding that of conventional 
classifiers. We have shown that for difficult speech problems such as time 
alignment and weak discriminability, artificial neural networks perform at 
high accuracy exceeding 98%. One-layer perceptrons learn these difficult tasks 
almost effortlessly -- not in spite of their simplicity, but because of it. 
REFERENCES 
1. D. J. Burr, ""A Neural Network Digit Recognizer"", Proceedings of IEEE 
Conference on Systems, Man, and Cybernetics, Atlanta, GA, October, 1986, 
pp. 1621-1625. 
2. D. J. Burr, 'xperiments with a Connectionist Text Reader,"" IEEE Inter- 
national Conference on Neural Networks, San Diego, CA, June, 1987. 
3. M. I. Jordan, ""Serial Order: A Parallel Distributed Processing Approach,"" 
ICS Report 8604, UCSD Institute for Cognitive Science, La Jolla, CA, May 
1986. 
4. S. J. Hanson, and D. J. Burr, 'Vhat Connectionist Models Learn: Toward 
a Theory of Representation in Multi-Layered Neural Networks,"" submitted for 
publication. 
5. W. Y. Huang and R. P. Lippmann, ""Comparisons Between Neural Net and 
Conventional Classifiers,"" IEEE International Conference on Neural Networks, 
San Diego, CA, June 21-23, 1987. 
6. J. D. Markel and A. H. Gray, Jr., Linear Prediction of Speech, Springer- 
Verlag, New York, 1976. 
7. M. L. Minsky and S. Papert, Perceptrons, MIT Press, Cambridge, Mass., 
1969. 
153 
8. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, 'earning Internal 
Representations by Error Propagation,"" in Parallel Distributed Processing, 
Vol. 1, D. E. Rumelhart and J. L. McClelland, eds., MIT Press, 1986, pp. 318- 
362. 
9. L. R. Rabiner and M. R. Sambur, ""An Algorithm for Determining the End- 
points of Isolated Utterances,"" BSTJ, Vol. 54, 207-315, Feb. 1975. 
10. H. Sakoe and S. Chiba, 'T)ynamic Programming Optimization for Spoken 
Word Recognition,"" IEEE Trans. Acoust., Speech, Signal Processing, Vol. 
ASSP-26, No. 1, 43-49, Feb. 1978. 
11. T. J. Sejnowski and C. R. Rosenberg, ""NETtalk: A Parallel Network that 
Learns to Read Aloud,"" Technical Report JHU/EECS-S6/01, Johns Hopkins 
University Electrical Engineering and Computer Science, 1986. 
12. A. Wieland and R. Leighton, ""Geometric Analysis of Neural Network 
Capabilities,"" IEEE International Conference on Neural Networks, San Deigo, 
CA, June 21-24, 1087. 
", recognit experi perceptron burr commun research nj neural network capabl accur recognit speech vocabulari isol digit paper look two difficult alphabet set polysyllab difficult contain weak discrimin difficult time polysyllab word aid time techniqu base dynam recognit improv focus accuraci better vocabulari implement singl layer neural network perform well simpl pattern recognit speaker train spoken digit layer network perform convent nearest neighbor classifi train token spoken digit easi recogn sinc part distinguish strong reason ask whether artifici neural network also solv difficult speech recognit polysyllab recognit difficult word exhibit larg time anoth difficult alphabet consist word vocabulari hard sinc distinguish sound short low show simpl perceptron solv problem well good input represent use suffici exampl examin two spectral represent smooth fft lpc predict stabil techniqu describ speech templat peak energi focus attent neural network begin recognit accuraci consist layer neural rel earlier perceptton simpl gradient descent process layer network institut physic success speech recognit handwrit recognit speech synthesi variat layer network use feedback causal use learn speech neuron within layer network build block use form solut specif number hidden unit requir problem though singl hidden layer form two layer need disjunct normal form second layer may use provid stabl learn presenc though neural net shown perform well convent neural net may better class outlier simpl perceptron contain one input layer one output layer directli connect hidden often refer singl layer weight connect figur show perceptron configur sens pattern input consist twenti time input connect output though sampl connect one output neuron correspond pattern standard input logist unit singl layer perceptron sens array sampl output neuron correspond pattern class full connect input array clariti connect input word fit grid region appli automat endpoint algorithm variat one propos rabin sambur employ doubl threshold success approxim endpoint determin first detect threshold cross zero cross practic level cross use prevent endpoint trigger background represent differ input represent use first represent smooth time speech khz ham window number sampl fft spectrum comput produc templat spectral twenti time templat smooth twice window length three frequenc window length comparison purpos lpc spectrum comput use tenth model ham analysi perform use autocorrel method durbin recurs result spectrum smooth three time spectra utter shown figur rel smooth lpc spectrum directli model lpc fft lpc plot utter toward toward time align speech recognit system often employ time techniqu base dynam program use warp scale two utter obtain optim align employ variat dynam program align contour rather refer energi templat chosen pattern incom pattern warp onto figur five utter time improv align energi superimpos energi plot five differ utter utter dynam time cognit polysyllab word contain three five syllabl five token record singl male variabl token use train simpl perceptron studi effect set size two perform measur rm error train token obtain addit experiment data output respons perceptron train one token per class four token per class show two repres perspect plot output train one four token respect per plot show respons function output node word index note train token produc map map one along diagon zero everywher show result experi three differ lpc time align tabl list accuraci function number train token input perceptton learn classifi unseen pattern case except fft singl train polysyllab word recognit train token align lpc trial differ perform rm evalu degre train network output respons approxim ideal target measur evalu token output tjk equal error show plot rm error function input represent train note fft represent produc highest lpc lpc margin better situat mani choic must made much larger lpc prefer align could use disambigu similar increas train token result improv perform train token rm error versu number train token variou input vocabulari vocabulari consist nine english twenti token nine class record singl male maxim size train half use train half ten produc total separ recognit show typic lpc templat nine notic formant ridg due common characterist featur ridg upward fold left token character voic pitch lpc plot repres token plot weight valu connect output train show similar plot illustr weight learn train ten token plot like one weight associ spectral note formant recognit accuraci includ score class weight along contour mostli small respons voic sound common network learn discount discrimin also strong terrain near begin show network decid focu much note particular pair begin near formant could conceiv onset note complic detector pattern class easi discrimin produc rel flat sting weight highli convolut weight space must correl difficulti make littl sens network work hard late time perhap addit train might reduc sinc network would eventu find littl consist differ second experi conduct help network focu first frame input token averag produc averag spectra use simpl nearest recogn recognit accuraci measur function highest perform indic first word contain confus matrix focus first word resampl concentr time frame first lpc spectra recomput use order model network train new perform increas classif error confus matrix shown figur learn time experi consist ten pass train weight mere prime averag spectral valu rather random learn time decreas neural network capabl high perform pattern match exceed convent shown difficult speech problem time weak artifici neural network perform accuraci exceed perceptron learn difficult task effortlessli spite neural network digit proceed ie connectionist text ie confer neural san parallel distribut process report ucsd institut cognit la may connectionist model toward theori represent neural submit huang neural net ie intern confer neural june markel linear predict new minski mit intern error parallel distribut rumelhart mit rabin algorithm determin isol sako program optim spoken ie signal sejnowski parallel network read technic report john hopkin electr engin comput wieland analysi neural network ie intern confer neural san june,0
16,16,"154 
PRESYNAPTIC NEURAL INFORMATION PROCESSING 
L. R. Carley 
Department of Electrical and Computer Engineering 
Carnegie Mellon University, Pittsburgh PA 15213 
ABSTRACT 
The potential for presynaptic information processing within the arbor 
of a single axon will be discussed in this paper. Current knowledge about 
the activity dependence of the firing threshold, the conditions required for 
conduction failure, and the similarity of nodes along a single axon will be 
reviewed. An electronic circuit model for a site of low conduction safety in 
an axon will be presented. In response to single frequency stimulation the 
electronic circuit acts as a lowpass filter. 
I. INTRODUCTION 
The axon is often modeled as a wire which imposes a fixed delay on a 
propagating signal. Using this model, neural information processing is 
performed by synaptically summing weighted contributions of the outputs 
from other neurons. However, substantial information processing may be 
performed in by the axon itself. Numerous researchers have observed 
periodic conduction failures at norma.,[ physiological impulse activity rates 
(e.g., in cat 1, in frog 2, and in man'). The oscillatory nature of these 
conduction failures is a result of the dependence of the firing threshold on 
past impulse conduction activity. 
The simplest view of axonal (presynaptic) information processing is 
as a switch: the axon will either conduct an impulse or not. The state of 
the switch depends on how past impulse activity modulates the firing 
threshold, which will result in conduction failure if firing threshold is bigger 
than the incoming impulse strength. In this way, the connectivity of a 
synaptic neural network could be modulated by past impulse activity at 
sites of conduction failure within the network. More sophisticated 
presynaptic neural information processing is possible when the axon has 
more than one terminus, implying the existence of branch points within the 
axon. Section II will present a general description of potential for 
presynaptic information processing. 
The after-effects of previous activity are able to vary the connectivity 
of the axonal arbor at sites of low conduction safety according to the 
temporal pattern of the impulse train at each site (Raymond and Lettvin, 
1978; Raymond, 1979). In order to understand the information processing 
potential of presynaptic networks it is necessary to study the after-effects 
of activity on the firing threshold. Each impulse is normally followed by a 
brief refractory period (about 10 ms in frog sciatic nerve) of increased 
American Institute of Phmic 1 c,gg 
155 
threshold and a longer superexcitable period (about I s in frog sciatic 
nerve) during which the threshold is actually below its resting level. 
During prolonged periods of activity, there is a gradual increase in firing 
threshold which can persist long (> I hour in frog nerve) after cessation 
of impulse activity (Raymond and Lettvin, 1978). In section III, the 
methods used to measure the firing threshold and the after-effects of 
activity will be presented. 
In addition to understanding how impulse activity modulates sites of 
low conduction safety, it is important to explore possible constraints on 
the distribution of sites of low conduction safety within the axon's arbor. 
Section IV presents results from a study of the distribution of the after- 
effects of activity along an axon. 
Section V presents an electronic circuit model for a region of low 
conduction safety within an axonal arbor. It has been designed to have a 
firing threshold that depends on the past activity in a manner similar to the 
activity dependence measured for frog sciatic nerve. 
II. PRESYNAPTIC SIGNAL PROCESSING 
Conduction failure has been observed in many different organisms, 
including man, at normal physiological activity rates. TM The after- 
effects of activity can ""modulate"" conduction failures at a site of low 
conduction safety. One common place where the conduction safety is low 
is at branch points where an impedance mismatch occurs in the axon. 
In order to clarify the meaning of presynaptic information processing, 
a simple example is in order. Parnas reported that in crayfish a single 
axon separately activates the medial (DEA. and lateral (DEAL) branches 
of the deep abdominal extensor muscles. '"" At low stimulus frequencies 
(below 40-50 Hz) impulses travel down both branches; however, each 
impulse evokes much smaller contractions in DEAL than in DEAM resulting 
in contraction of DEAM without significant contraction of DEAL. At higher 
stimulus frequencies conduction in the branch leading to DEAM fails and 
DEAL contracts without DEAM contracting. Both DEAL and DEAM can be 
stimulated separately by stimulus patterns more complicated than a single 
frequency. 
The theory of ""fallible trees"", which has been discussed by Lettvin, 
McCulloch and Pitts, Raymond, and Waxman and Grossman among 
others, suggests that one axon which branches many times forms an 
information processing element with one input and many outputs. Thus, 
the after-effects of previous activity are able to vary the connectivity of 
the axonal arbor at regions of low conduction safety according to the 
temporal pattern of the impulse train in each branch. The transfer function 
of the fallible tree is determined by the distribution of sites of low 
conduction safety and the distribution of superexcitability and depressibility 
at those sites. Thus, a single axon with 1000 terminals can potentially be 
in 2 ��� different states as a function of the locations of sites of conduction 
failure within the axonal arbor. And, each site of low conduction safety is 
156 
modulated by the past impulse activity at that site. 
Fallible trees have a number of interesting properties. They can be 
used to cause different input frequencies to excite different axonal 
terminals. Also, fallible trees, starting at rest, will preserve timing 
information in the input signal; i.e., starting from rest, all branches will 
respond to the first impulse, 
III. AFTER-EFFECTS OF ACTIVITY 
In this section, the firing threshold will be defined and an experimental 
method for its measurement will be described. In addition, the after- 
effects of activity will be characterized and typical results of the 
characterization process will be given. 
The following method was used to measure the firing threshold. 
Whole nerves were placed in the experimental setup (shown in figure 1). 
The whole nerve fiber was stimulated with a gross electrode. The 
response from a single axon was recorded using a suction microelectrode. 
Firing threshold was measured by applying test stimuli through the gross 
stimulating electrode and looking for a response in the suction 
microelectrode. 
Motor- 
driven 
vernier 
micrometer 
J Fixed-clration 
variable-amplitude 
current stimulator Am lifter 
electrode JJJ A 
0-4 mm diameterJJJ Suction electrode j/I/ J t / Reference 
' ' le axon '  suction 
>11! Sing %/// electrode 
I nnnnnnnnnnnnnno0nn' '  i I 
Velcro  Ag-AgCl Plate  Sponge 
Figure 1. Drawing of the experimental recording chamber. 
Threshold Hunting, a process for choosing the test stimulus strength, 
was used to characterize the axons. 6 It uses the following paradigm. A 
test stimulus which fails to elicit a conducting impulse causes a small 
increase the strength of subsequent test stimuli. A test stimulus which 
157 
elicits an impulse causes a small decrease in the strength of subsequent 
test stimuli. Conditioning Stimuli, ones large enough to guarantee firing an 
impulse, can be interspersed between test stimuli in order to achieve a 
controlled overall activity rate. Rapid variations in threshold following one 
or more conditioning impulses can be measured by slowly increasing the 
time delay between the conditioning stimuli and the test stimulus. Several 
phases follow each impulse. First, there is a refractory period of short 
duration (about 10ms in frog nerve) during which another impulse cannot 
be initiated. Following the refractory period the axon actually becomes 
more excitable than at rest for a period (ranging from 200ms to ls in frog 
nerve, see figure 2). The superexcitable period is measured by applying a 
conditioning stimulus and then delaying by a gradually increasing time 
delay and applying a test stimulus (see figure 3). There is only a slight 
increase in the peak of the superexcitable period following multiple 
impulses. 7 The superexcitability of an axon was characterized by the % 
decrease of the threshold from its resting level at the peal< of the 
superexcitable period. 
0 250 500 750 
INTERVAl_ 
Figure 2. Typical superexcitable 
period in axon from frog sciatic 
rtsrvo. 
Figure 3. Stimulus pattern used 
for measuring superexcitability. 
During a period of repetitive impulse conduction, the firing threshold may 
gradually increase. After the period of increased impulse activity ends, the 
threshold gradually recovers from its maximum over the course of several 
minutes or more with complete return of the threshold to its resting level 
taking as long as an hour or two (in frog nerve) depending on the extent of 
the preceding impulse activity. The depressibility of an axon can be 
characterized by the initial upward slope of the depression and the time 
158 
constant of the recovery phase (see figure 4). The pattern of conditioning 
and test stimuli used to generate the curve in figure 4 is shown in figure 5. 
Depression may be correlated with microanatomical changes which 
occur ir the glial cells in the nodal region during periods of increased 
activity.- During periods of repetitive stimulation the size and number of 
extracellular paranodal intramyelinic vacuoles increases causing changes 
in the paranodal geometry. 
Success 
Threshold (percentage of resting level) 
2�� l Failure 
160 
120. 
80- 
4O 
5 t 15 0 25 3 
Time (ram} 
Success 
Failure 
Figure 4. Typical depression in an 
axon from frog sciatic nerve. The 
average activity rate was 4 
impulses/sec between the 5 rnin 
mark and the 10 rain mark. 
burst Test 
 stimulus 
On 
5 min  Time 
off 
Figure 5. Stimulus pattern used 
for measuring depression. 
IV. CONSTRAINTS ON FALLIBLE TREES 
The basic fallible tree theory places no constraints on the distribution 
of sites of conduction failure among the branches of a single axon. In this 
section one possible constraint on the distribution of sites of conduction 
failure will be presented. Experiments have been performed in an attempt 
to determine if the extremely wide variations in superexcitability an 
depressibility found between nodes from different axons in a single nerve 
(particularly for depressibility) also occur between nodes from the same 
axon. 
A study of the distribution of the after-effects of activity along an 
unbranching length of frog sciatic nerve OnUnd only small variations in the 
after-effects along a single axon."" Both superexcitability and 
depressibility were extremely consistent for nodes from along a single 
unbranching length of axon (see figures 6 and 7). This suggests that there 
may be a cell-wide regulatory system that maintains the depressibility and 
159 
superexcitability at comparable levels throughout the extent of the axon. 
Thus, portions of a fallible tree which have the same axon diameter would 
be expected to have the same superexcitability and depressibility. 
3.0 3 
9""5 
Superexcitability 
Upward slope 
Figure 6. PDF of Superexcitabili- 
ty, The upper trace represents 
the PDF of the entire population 
of nodes studied and the two 
lower traces represent the 
separate populations of nodes 
from two different axons. 
Figure 7, PDF of Depressibility, 
The upper trace represents the 
PDF of the entire population of 
nodes studied and the two lower 
traces represent the separate 
populations of nodes from two 
different axons, 
This study did not examine axons which branched, therefore it cannot be 
concluded that superexcitability and depressibility must remain constant 
throughout a fallible tree. For example, it is quite likely that the cell 
actually regulates quantities like pump-site density, not depressibility. In 
that case, daughter branches of smaller diameter might be expected to 
show consistently higher depressibility. Further research is needed to 
determine how the activity dependence of the threshold scales with axon 
diameter along a single axon before the consistency of the after-effects 
along an unbranching axon can be used as a constraint on presynaptic 
information processing networks. 
V. ELECTRICAL AXON CIRCUIT 
This section presents a simple electronic circuit which has been 
designed to have a firing threshold that depends on the past states of the 
output in a manner similar to the activity dependence measured for frog 
sciatic nerve. In response to constant frequency stimuli, the circuit acts as 
160 
a lowpass filter whose corner frequency depends on the coefficients which 
determine the after-effects of activity. 
Figure 8 shows the circuit diagram for a switched capacitor circuit 
which approximates the after-effects of activity found in the frog sciatic 
nerve. The circuit employs a two phase nonoverlapping clock, � for the 
even clock and o for the odd clock, typical of switched capacitor circuits. 
It incorporates a basic model for superexcitability and depressibility. Vnv 
represents the resting threshold of the axon. On each clock cycle the V#v 
is compared with VTH+Vo--Vs. 
The two capacitors and three switches at the bottom of figure 8 model 
the change in threshold caused by superexcitability. Note that each 
impulse resets the comparator's minus input to (1-==)Vnv, which decays 
back to VTH on subsequent clock cycles with a time constant inversely 
proportional to Is. This is a slight deviation from the actual physiological 
situation in which multiple conditioning7jmpulses will generate slightly more 
superexcitability than a single impulse. 
The two capacitors and two switches at the upper left of figure 8 
model the depressibility of the axon. The current source represents a 
fixed increment in the firing threshold with every past impulse. The 
depression voltage decays back to 0 on subsequent clock cycles with a 
time constant inversely proportional to 
o^vo 
C o 
oAvo = 
Figure 8. Circuit diagram for electrical circuit analog of nerve threshold. 
The electrical circuit exhibits response patterns similar to those of 
neurons that are conducting intermittently (see figure 9). During bursts of 
conduction, the depression voltage increases linearly until the comparator 
161 
fails to fire. The electrical axon then fails to fire until the depression 
voltage decays back to (I+(zov)VTH. The connectivity between the input 
and output of the axon is defined to be the average fraction of impulses 
which are conducted. In terms of connectivity, the electrical axon model 
acts as a lowpass filter (see figure 10). 
Figure 9. Typical waveforms for 
intermittent conduction. The 
upper trace indicates whether 
impulses are conducted or not. 
VD and Vs are the depression 
voltage and the superexcitable 
voltage respectively. 
Figure 10. Frequency response of 
electrical axon model. The 
connectivity is reflected by the 
fraction of impulses which are 
conducted out of a sequence of 
100,000 stimuli where the 
frequency is in stimuli/second. 
For a fixed stimulus frequency, the average fraction of impulses 
which are conducted by the electrical model can be predicted analytically. 
The expressions can be greatly simplified by making the assumption that 
VD increases and decreases in a linear fashion. Under that assumption, in 
terms of the variables indicated on the schematic diagram, 
P (firing) = 
oov(1 - (1 - [D ) M) 
aov(1 - (1 - Io)M) + O. D 
where M is the number of clock cycles between input stimuli, which is 
inversely proportional to the input frequency. The frequency at which only 
half of the impulses are conducted is defined as the corner frequency of 
the lowpass filter. The corner frequency is 
162 
I log (1 - D) 
f(P -- 0.5)= M =D 
log(1 -- 
oov 
Using the above equations, lowpass filters with any desired cutoff 
frequency can be designed. 
The analysis indicates that the corner frequency of the lowpass filter 
can be varied by changing the degree of conduction safety (eov) without 
changing either depressibility or superexcitability. This suggests that the 
existence of a cell-wide regulatory system maintaining the depressibility 
and superexcitability at comparable levels throughout the extent of the 
axon would not prevent the construction of a bank of lowpass filters since 
their corner frequencies could still be varied by varying the degree of 
conduction safety (oov). 
Vl. CONCLUSIONS 
Recent studies report that the primary effect of several common 
anesthetics is to abolish the activity dependene of the firing threshold 
without interfering with impulse conduction. 1 This suggests that 
presynaptic processing may play an important role in human 
consciousness. This paper has explored some of the basic ideas of 
presynaptic information processing, especially the after-effects of activity 
and their modulation of impulse conduction at sites of low conduction 
safety. A switched capacitor circuit which simulates the activity dependent 
conduction block that occurs in axons has been designed and simulated. 
Simulation results are very similar to the intermittent conduction patterns 
measured experimentally in frog axons. One potential information 
processing possibility for the arbor of a single axon, suggested by the 
analysis of the electronic circuit, is to act as a filterbank; every terminal 
could act as a lowpass filter with a different corner frequency. 
BIBLIOGRAPHY 
[1] Barron D. H. and B. H. C. Matthews, Intermittent conduction in the 
spinal chord. J. Phy$iol. 85, p. 73-103 (1935). 
163 
[2] 
Fuortes M. G. F., Action of strychnine on the ""intermittent 
conduction"" of impulses along dorsal columns of the spinal chord of 
frogs. J. Physiol. ].].2, p.42 (1950). 
[3] Culp W. and J. Ochoa, Nerves and Muscles as Abnormal Impulse 
Generators. (Oxford University Press, London, 1980). 
[4] Grossman Y., I. Parnas, and M. E. Spira, Ionic mechanisms involved 
in differential conduction of action potentials at high frequency in a 
branching axon. J. Physiol. 2,95, p.307-322 (1978). 
[5] Parnas I., Differential block at high frequency of branches of a 
single axon innervating two muscles. J. Physiol. 35, p. 903-914, 
1972. 
[6] Carley, L.R. and S.A. Raymond, Threshold Measurement: 
Applications to Excitable Membranes of Nerve and Muscle. J. 
NeuroscL Meth. 9, p. 309-333 (1983). 
[7] 
Raymond S. A. and J. Y. Lettvin, After-effects of activity in 
peripheral axons as a clue to nervous coding. In Physiology and 
Pathobiology of Axons, S. G. Waxman (ed.), (Raven Press, New York, 
1978), p. 203-225. 
[8] Wurtz C. C. and M. H. Ellisman, Alternations in the ultrastructure of 
peripheral nodes of Ranvier associated with repetitive action 
potential propagation. J. Neurosci. 6(].].), 3133-3143 (1986). 
[9] Raymond S. A., Effects of nerve impulses on threshold of frog 
sciatic nerve fibers. J. Physiol. 290, 273-303 (1979). 
[10] Carley, L.R. and S.A. Raymond, Comparison of the after-effects of 
impulse conduction on threshold at nodes of Ranvier along single 
frog Sciatic axons. J. Physiol. 386, p. 503-527 (1987). 
[11] Raymond S. A. and J. G. Thaihammer, Endogenous activity- 
dependent mechanisms for reducing hyperexcitability of axons: 
Effects of anesthetics and CO_. In Inactivation of Hypersensistive 
Neurons, N. Chalazonitis and M. Gola, (eds.), (Alan R. Liss Inc., New 
York, 1987), p. 331-343. 
", neural inform process carley electr comput engin mellon pittsburgh pa potenti presynapt inform process within arbor singl axon discuss current knowledg activ depend fire condit requir similar node along singl axon electron circuit model site low conduct safeti axon respons singl frequenc stimul circuit act lowpass introduct axon often model wire impos fix delay use neural inform process synapt sum weight contribut output substanti inform process may axon numer research observ conduct failur physiolog impuls activ rate cat frog oscillatori natur failur result depend fire threshold impuls conduct simplest view axon inform process axon either conduct impuls state switch depend past impuls activ modul fire result conduct failur fire threshold bigger incom impuls connect neural network could modul past impuls activ conduct failur within sophist neural inform process possibl axon one impli exist branch point within section ii present gener descript potenti inform previou activ abl vari connect axon arbor site low conduct safeti accord pattern impuls train site order understand inform process presynapt network necessari studi activ fire impuls normal follow refractori period ms frog sciatic increas institut longer superexcit period frog sciatic threshold actual rest prolong period gradual increas fire persist long hour frog cessat impuls activ section use measur fire threshold addit understand impuls activ modul site conduct import explor possibl constraint distribut site low conduct safeti within iv present result studi distribut activ along present electron circuit model region low safeti within axon design threshold depend past activ manner similar depend measur frog sciatic presynapt signal process failur observ mani differ normal physiolog activ tm activ conduct failur site low one common place conduct safeti low branch point imped mismatch occur order clarifi mean presynapt inform simpl exampl parna report crayfish singl separ activ medial later branch deep abdomin extensor low stimulu frequenc impuls travel evok much smaller contract deal deam result contract deam without signific contract higher frequenc conduct branch lead deam fail contract without deam deal deam separ stimulu pattern complic singl theori discuss culloch waxman grossman among suggest one axon branch mani time form process element one input mani previou activ abl vari connect axon arbor region low conduct safeti accord pattern impuls train transfer function fallibl tree determin distribut site low safeti distribut superexcit depress singl axon termin potenti differ state function locat site conduct within axon site low conduct safeti past impuls activ tree number interest caus differ input frequenc excit differ axon fallibl start preserv time input start branch first activ fire threshold defin experiment measur activ character typic result process follow method use measur fire nerv place experiment setup figur whole nerv fiber stimul gross singl axon record use suction threshold measur appli test stimuli gross electrod look respons suction stimul lifter mm suction electrod refer le axon suction sing electrod cl plate spong draw experiment record process choos test stimulu use character use follow stimulu fail elicit conduct impuls caus small strength subsequ test test stimulu impuls caus small decreas strength subsequ condit one larg enough guarante fire interspers test stimuli order achiev overal activ rapid variat threshold follow one condit impuls measur slowli increas delay condit stimuli test sever follow refractori period short frog anoth impuls can not follow refractori period axon actual becom excit rest period ls frog see figur superexcit period measur appli stimulu delay gradual increas time appli test stimulu figur slight peak superexcit period follow multipl superexcit axon character threshold rest level typic superexcit axon frog sciatic stimulu pattern use measur period repetit impuls fire threshold may period increas impuls activ gradual recov maximum cours sever complet return threshold rest level long hour two frog depend extent preced impuls depress axon initi upward slope depress time recoveri phase figur pattern condit test stimuli use gener curv figur shown figur may correl microanatom chang glial cell nodal region period increas period repetit stimul size number paranod intramyelin vacuol increas caus chang paranod rest failur typic depress frog sciatic activ rate rnin rain test stimulu min time stimulu pattern use measur constraint fallibl tree basic fallibl tree theori place constraint distribut site conduct failur among branch singl one possibl constraint distribut site conduct experi perform attempt determin extrem wide variat superexcit found node differ axon singl nerv also occur node studi distribut activ along length frog sciatic nerv und small variat along singl superexcit extrem consist node along singl length axon figur suggest regulatori system maintain depress compar level throughout extent portion fallibl tree axon diamet would expect superexcit slope pdf upper trace repres pdf entir popul node studi two trace repres popul node two differ pdf upper trace repres entir popul studi two lower repres separ node two studi examin axon therefor can not superexcit depress must remain constant fallibl quit like cell regul quantiti like daughter branch smaller diamet might expect consist higher research need activ depend threshold scale axon along singl axon consist unbranch axon use constraint presynapt process electr axon circuit section present simpl electron circuit fire threshold depend past state manner similar activ depend measur frog respons constant frequenc circuit act lowpass filter whose corner frequenc depend coeffici show circuit diagram switch capacitor circuit approxim activ found frog sciatic circuit employ two phase nonoverlap clock odd typic switch capacitor incorpor basic model superexcit vnv rest threshold clock cycl compar two capacitor three switch bottom figur model chang threshold caus note reset minu input decay vth subsequ clock cycl time constant invers slight deviat actual physiolog multipl gener slightli singl two capacitor two switch upper left figur depress current sourc repres increment fire threshold everi past voltag decay back subsequ clock cycl constant invers proport avo circuit diagram electr circuit analog nerv electr circuit exhibit respons pattern similar conduct intermitt figur burst depress voltag increas linearli compar electr axon fail fire depress decay back connect input output axon defin averag fraction impuls term electr axon model lowpass filter figur typic waveform trace indic whether conduct vs depress superexcit frequenc respons axon reflect impuls sequenc stimuli fix stimulu averag fraction impuls conduct electr model predict express greatli simplifi make assumpt increas decreas linear variabl indic schemat number clock cycl input proport input frequenc impuls conduct defin corner frequenc lowpass corner frequenc log lowpass filter desir cutoff analysi indic corner frequenc lowpass filter vari chang degre conduct safeti without either depress suggest regulatori system maintain depress superexcit compar level throughout extent would prevent construct bank lowpass filter sinc corner frequenc could still vari vari degre safeti conclus studi report primari effect sever common abolish activ fire threshold interf impuls suggest process may play import role human paper explor basic idea inform especi activ modul impuls conduct site low conduct switch capacitor circuit simul activ depend block occur axon design result similar intermitt conduct pattern experiment frog one potenti inform possibl arbor singl suggest electron act everi termin act lowpass filter differ corner barron intermitt conduct action strychnin impuls along dorsal column spinal chord culp nerv muscl abnorm impuls univers grossman ionic mechan involv differenti conduct action potenti high frequenc parna differenti block high frequenc branch axon innerv two threshold excit membran nerv activ axon clue nervou physiolog waxman new wurtz altern ultrastructur node ranvier associ repetit action raymond effect nerv impuls threshold frog nerv comparison conduct threshold node ranvier along singl sciatic raymond endogen mechan reduc hyperexcit anesthet inactiv hypersensist chalazon liss new,0
17,17,"164 
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR 
OF NEURONAL MODELS 
BY 
.JOHN Y. CHEUNG 
MASSOUD OMIDVAR 
SCHOOL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCE 
UNIVERSITY OF OKLAHOMA 
NORMAN, OK 73019 
Presented to the IEEE Conference on Neural Information Processing Systems- 
Natural and Syntheticf Denver, November 8-12, 1987, and to be published in 
the Collection of Papers from the IEEE Conference on NIPS. 
Please address all further correspondence to: 
John Y. Cheung 
School of EECS 
202 W. Boyd, CEC 219 
Norman, OK 73019 
(405)325-4721 
November, 1987 
� American Institute of Physics 1988 
165 
MATHEMATICAL ANALYSIS OF LEARNING BEHAVIOR 
OF NEURONAL MODELS 
John Y. Cheung and Massoud Omidvar 
School of Electrical Engineering 
and Computer Science 
ABSTRACT 
In this paper, we wish to analyze the convergence behavior of a number 
of neuronal plasticity models. Recent neurophysiological research suggests that 
the neuronal behavior is adaptive. In particular, memory stored within a neuron 
is associated with the synaptic weights which are varied or adjusted to achieve 
learning. A number of adaptive neuronal models have been proposed in the 
literature. Three specific models will be analyzed in this paper, specifically the 
Hebb model, the Sutton-Barto model, and the mot recent trace model. In this 
paper we will examine the conditions for convergence, the position of conver- 
gence and the rate at convergence, of these models as they applied to classical 
conditioning. Simulation results are also presented to verify the analysis. 
INTRODUCTION 
A number of static models to describe the behavior of a neuron have been 
in use in the past decades. More recently, research in neurophysiology suggests 
that a static view may be insufficient. Rather, the parameters within a neuron 
tend to vry with past history to achieve learning. It was suggested that by 
altering the internal parameters, neurons may adapt themselves to repetitive 
input stimuli and become conditioned. Learning thus occurs when the neurons 
are conditioned. To describe this behavior of neuronal plasticity, a number 
of models have been proposed. The earliest one may have been postulated 
by Hebb and more recently by Sutton and Barto . We will also introduce a 
new model, the most recent trce (or MRT) model in this paper. The primary 
objective of this paper, however, is to analyze the convergence behavior of these 
models during adaptation. 
The general neuronal model used in this paper is shown in Figure 1. There 
are a number of neuronal inputs xi(t),i = 1,... ,N. Ech input is scaled by 
the corresponding synaptic weights wi(t),i - 1,...,N. The weighted inputs 
are arithmetically summed. 
y(t) =  xi(t)wi(t) - e(t) (1) 
i----I 
where O(t) is taken to be zero. 
166 
Neuronal inputs are assumed to take on numerical values ranging from zero 
to one inclusively. Synaptic weights are allowed to take on any reasonable values 
for the purpose of this paper though in reality, the weights may very well be 
bounded. Since the relative magnitude of the weights and the neuronal inputs 
are not well defined at this point, we will not put a bound on the magnitude 
of the weights also. The neuronal output is normally the result of a sigmoidal 
transformation. For simplicity, we will approximate this operation by a linear 
transformation. 
x 1 
x 2 
$yuaptc 
vl ca Silodial 
Transformation 
v2   Y 
neurorl 
output 
Figure 1. A eneral euronal m!el. 
For convergence analysis, we will assume that there are only two neuronal 
inputs in the traditional classical conditioning environment for simplicity. Of 
course, the analysis techniques can be extended to any number of inputs. In 
classical conditioning, the two inputs are the conditioned stimulus x�(t) and 
the unconditioned stimulus x,(t). 
THE SUTTON-BARTO MODEL 
More recently, Sutton and Barto I have proposed an adaptive model based 
on both the signal trace i(t) and the output trace (t) as given below: 
wi(t + 1) =wi(t) + ci(t)(y(t)) - (t) 
(t + 1) =/3(t) + (1 - t3)y(t) 
� ,(t + 1)=.,(t)+ 
(2a) 
(2b) 
(2c) 
where both a and f/are positive constants. 
167 
Condition of Convergence 
In order to simplify the analysis, we will choose  = 0 and/3 = 0, i.e.: 
(t) - (t- ) 
nd 
y(t)=y(t-1) 
In other words, (2a) becomes: 
wi(t + 1) = wi(t) + �xi(t)(y(t) - y(t - 1)) 
(3) 
The above assumption only serves to simplify the analysis and will not affect the 
convergence conditions because the boundedhess of i(t) and (t) only depends 
on that for xi(t) and y(t- 1) respectively. 
As in the previous section, we recognize that (3) is a recurrence relation so 
convergence can be checked by the ratio test. It is also possible to rewrite (3) 
in matrix format. Due to the recursion of the neuronal output in the equation, 
we will include the neuronal output y(t) in the parameter vector also: 
(t + ) ) 
w(t 9- 1) 
y(t) 
= cx(t)x(t) l+cx](t) -cx(t) w(t) 
x(t) x(t) o y(t- 1) 
(4) 
or 
w(S-"")(t + ) = A(s-.) W�S-)(t ) 
To show convergence, we need to set the magnitude of the determinant of 
A (s-B) to be less than unity. 
It(s-"")l- c(;(t) + (t)) (s) 
Hence, the condition for convergence is: 
1 
c < (t) + (t) 
From (6), we can see that the adaptation constant must be chosen to be less 
than the reciprocal of the Euclidean sum of energies of all the inputs. The 
same techniques can be extended to any number of inputs. This can be proved 
merely by following the same procedures outlined above. 
Position At Convergence 
168 
Having proved convergence of the Sutton-Barto model equations of neu- 
tonal plasticity, we want to find out next at what location the system remains 
when converged. We have seen earlier that at convergence, the weights cease to 
change and so does the neuronal output. We will denote this converged position 
as (w(S-S)) * -= W(S-S)(oo). In other words: 
(w(S-S)) * = A(S-S)(w(S-S)) * 
(7) 
Since any arbitrary parameter vector can always be decomposed into a weighted 
svm of the eigenvectors, i.e. 
w(S-S)(O) = cq + c2V2 + a3V3 
The constants a, a2, and a3 can easily be found by inverting A (s-s). The 
eigenvalues of A ($-s) can be shown to be 1, 1, and c(x q- x22). When c is 
within the region of convergence, the magnitude of the third eigenvalue is less 
than unity. That means that at convergence, there will be no contribution from 
the third eigenvector. Hence, 
lim w(S_S)(t ) _ a -F a2V2 (O) 
(w(S-S))' = t --. oo 
From (9), we can predict precisely what the converged position would be given 
only with the initial conditions. 
Rate of Convergence 
We have seen that when � is carefully chosen, the Sutton-Barto model will 
converge and we have also derived an expression for the converged position. 
Next we want to find out how fast convergence can be attained. The rate 
of convergence is a measure of how fast the initial parameter approaches the 
optimal position. The asymptotic rate of convergence is2: 
Roo( A (s-a)): -logS( A (s-a)) (10) 
where S(A (s-s) is the spectral radius and is equalled to c(x + x) in this 
case. This completes the convergence analysis on the Sutton-Barto model of 
neuronal plasticity. 
THE MRT MODEL OF NEURONAL PLASTICITY 
The most recent trace (MRT) model of neuronal plasticity 3 developed by 
the authors can be considered as a cross between the Sutton-Barto model and 
the Klopf's model 4. The adaptation of the synaptic weights can be expressed 
as follows: 
wi(t -f- 1) --- wi(t) -f- cwi(t)xi(t)(y(t) - y(t - 1)) (11) 
169 
A comparison of (11) nd the Sutton-Barto model in (3) show that the econd 
term on the right hand side contnz n extra factor, w(t), which is used to 
speed up the convergence z shown later. The output trace hz been replaced 
by It(t- 1), the most recent output, hence the name, the most recent trace 
model. The input trace is also replaced by the most recent input. 
Condition of Convergence 
We can now proceed to analyse the condition of convergence for the MRT 
model. Due to the presence of the ,vi(t) factor in the second term in (31), the 
ratio test cannot be applied here. To nalyze the convergence behavior further, 
let us rewrite (11) in matrix format: 
x,(t)) (xz(t) 0 
+c(w,(,) w,(,) 1)) x,(,) o ,,(,) 
-1 0 0 
(12) 
or 
W(M!tT)(t -t- 1) = A(M!tT)w(M!tT)(t) 't- c (W(MRT)(t))T.Bcv(MRT)(t) 
The superscript T denotes the matrix transpose operation. The above equation 
is quadratic in W(tRr)(t). Complete convergence analysis of this equation is 
extremely difficult. 
In order to understand the convergence behavior of (12), we note that 
the dominant term that determines convergence mainly relates to the second 
quadratic term. Hence for convergence analysis only, we will ignore the first 
term: 
W(MItr)(t -t- 1)  �(W(MItr)(t))r BCW(MIrr)(t) (13) 
We can readily see from above that the primary convergence factor is BrC '. 
Since C is only dependent on xi(t), convergence can be obtained if the duration 
of the synaptic inputs being active is bounded. It can be shown that the 
condition of convergence is bounded by: 
1 
< + 
170 
We can readily see that the adaptation constant c can be chosen according 
to (14) to ensure convergence for t < T. 
SIMULATIONS 
To verify the theoretical analysis of these three adaptive neuronal models 
based on classical conditioning, these models have been simulated on the IBM 
3081 mainframe using the FORTRAN language in single precision. Several test 
scenarios have been designed to compare the analytical predictions with actual 
simulation results. 
To verify the conditions for convergence, we will vary the value of the 
adaptation constant c. The conditioned and unconditioned stimuli were set 
to unity and the value of c varies between 0.1 to 1.0. For the Sutton-Barto 
model the simulation given in Fig. 2 shows that convergence is obtained for 
c < 0.$ as expected from theoretical analysis. For the MRT model, simulation 
results given in Fig. 3 shows that convergence is obtained for c < 0.7, also as 
expected from theoretical analysis. The theoretical location at convergence for 
the Sutton and Barto model is also shown in Figure 2. It is readily seen that 
the simulation results confirm the theoretical expectations. 
2: c - 0.2 
3: c - 0.3 
&: c - O.& 
5: c - 0.5 
6: c - 0.6 
7: c - 0.7 
Bmber of Iterations 
Figure 2. Plots of euro''l outputs versus the mber of iterations for the 
$utton-arto model rtb different values of ndaptatou constant c. 
171 
urol 
Otput 
2: 
3: 
&: 
6: 
c-O.1 
c-0.2 
c-0.3 
c-O.& 
c - 0.. 
c-0.6 
Bumbet of Aterations 
Figure 3. Plots of neurons! outputs versus the utmber of iterations 
for the JfJ7 model with different values of mdatation 
col tnnt c. 
To illustrate the rate of convergence, we will plot the trajectory of the 
deviation in synaptic weights from the optimal values in the logarithmic scale 
since this error is logarithmic as found earlier. The slope of the line yields the 
rate of convergence. The trajectory for the Sutton-Barto Model is given in 
Figure 4 while that for the MRT model is given in Figure 5. It is clear from 
Figure 4 that the trajectory in the logarithmic form is a straight line. The 
slope ,(A (s-B)) can readily be calculated. The curve for the MRT model 
given in Figure 5 is also a straight line but with a much larger slope showing 
faster convergence. 
SUMMARY 
In this paper, we have sought to discover analytically the convergence 
behavior of three adaptive neuronal models. From the analysis, we see that 
the Hebb model does not converge at all. With constant active inputs, the 
output will grow exponentially. In spite of this lack of convergence the Hebb 
model is still a workable model realizing that the divergent behavior would 
be curtailed by the sigmoidal transformation to yield realistic outputs. The 
172 
Figure &. 
Trajectories of neuroual output deviations frou static values 
for the Suttore-Barto oael rlth ifferent values of misptation 
constant c. 
!/usber of iterations 
Figure 5. 
Trajectories of neurons] output deviations froe static 
values for the MT model vitb different values of 
adaptation constant c, 
173 
analysis on the Sutton and Barto model shows that this model will converge 
when the adaptation constant c is carefully chosen. The bounds for c is also 
found for this model. Due to the structure of this model, both the location at 
convergence and the rate of convergence are also found. We have also introduced 
a new model of neuronal plasticity called the most recent trace (MRT) model. 
Certain similarities exist between the MRT model and the Sutton-Barto model 
and also between the MRT model and the Klopf model. Analysis shows that the 
update equations for the synaptic weights are quadratic resulting in polynomial 
rate of convergence. Simulation results also show that much faster convergence 
rate can be obtained with the MRT model. 
REFERENCES 
1. Sutton, R.S. and A.G. Barto, Psychological Review, vol. 88, p. 135, (1981). 
2. Hageman, L. A. and D.M. Young. Applied Interactive Methods. (Aca- 
demic Press, Inc. 1981). 
3. Omidvar, Massoud. Analysis of Neuronal Plasticity. Doctoral disserta- 
tion, School of Electrical Engineering and Computer Science, University of 
Oklahoma, 1987. 
4. Klopf, A.H. Proceedings of the American Institute of Physics Conference 
#151 on Neural Networks for Computing, p. 265-270, (1986). 
", analysi learn behavior neuron model cheung omidvar electr engin comput scienc oklahoma ok ie confer inform process syntheticf novemb publish collect paper ie confer address correspond cheung eec cec ok american institut physic analysi learn behavior neuron model cheung massoud omidvar electr engin comput scienc wish analyz converg behavior number neuron plastic recent neurophysiolog research suggest neuron behavior memori store within neuron associ synapt weight vari adjust achiev number adapt neuron model propos three specif model analyz specif recent trace examin condit posit rate model appli classic simul result also present verifi number static model describ behavior neuron use past research neurophysiolog suggest static view may paramet within neuron past histori achiev suggest intern neuron may adapt repetit stimuli becom learn thu occur neuron describ behavior neuron number model earliest one may postul hebb recent sutton barto also introduc recent model primari analyz converg behavior gener neuron model use paper shown figur number neuron input input scale correspond synapt weight weight input arithmet taken input assum take numer valu rang zero one synapt weight allow take reason valu purpos paper though weight may well sinc rel magnitud weight neuron input well defin put bound magnitud weight neuron output normal result sigmoid approxim oper linear silodi converg assum two neuron tradit classic condit environ analysi techniqu extend number two input condit stimulu uncondit stimulu model sutton barto propos adapt model base signal trace output trace given posit converg order simplifi choos assumpt serv simplifi analysi affect condit boundedhess depend previou recogn recurr relat check ratio also possibl rewrit matrix due recurs neuron output includ neuron output paramet vector show need set magnitud determin less condit converg see adapt constant must chosen less reciproc euclidean sum energi techniqu extend number prove follow procedur outlin converg prove converg model equat want find next locat system remain seen earlier weight ceas neuron denot converg posit arbitrari paramet vector alway decompos weight cq constant easili found invert shown region magnitud third eigenvalu less mean contribut third oo predict precis converg posit would given initi converg seen care model also deriv express converg want find fast converg rate converg measur fast initi paramet approach asymptot rate converg spectral radiu equal complet converg analysi model mrt model neuron plastic recent trace model neuron plastic develop author consid cross model model adapt synapt weight express comparison model right hand side extra use converg shown output trace replac recent henc recent trace input trace also replac recent converg proceed analys condit converg mrt due presenc factor second term test can not appli converg behavior us rewrit matrix superscript denot matrix transpos equat quadrat complet converg analysi equat order understand converg behavior note domin term determin converg mainli relat second henc converg analysi ignor first readili see primari converg factor depend converg obtain durat synapt input activ shown converg bound readili see adapt constant chosen accord ensur converg verifi theoret analysi three adapt neuron model classic model simul ibm mainfram use fortran languag singl sever test design compar analyt predict actual verifi condit vari valu constant condit uncondit stimuli set uniti valu vari simul given show converg obtain expect theoret mrt simul given show converg obtain also theoret theoret locat converg sutton barto model also shown figur readili seen simul result confirm theoret iter plot output versu iter model differ valu constant ater plot output versu utmber iter model differ valu tnnt illustr rate plot trajectori synapt weight optim valu logarithm scale error logarithm found slope line yield trajectori model given mrt model given figur clear trajectori logarithm form straight readili curv mrt model figur also straight line much larger slope show sought discov analyt converg three adapt neuron see hebb model converg constant activ grow spite lack converg hebb still workabl model realiz diverg behavior would curtail sigmoid transform yield realist neuroual output deviat frou static valu valu misptat iter output deviat froe static model vitb differ valu constant sutton barto model show model converg adapt constant care bound also due structur locat rate converg also also introduc new model neuron plastic call recent trace similar exist mrt model model also mrt model klopf analysi show equat synapt weight quadrat result polynomi simul result also show much faster converg obtain mrt psycholog appli interact analysi neuron doctor school electr engin comput univers proceed american institut physic confer neural network,1
18,18,"174 
A Neural Network C1A-sifier Based on Coding Theory 
Tzi-Dar Chiueh and Rodney Goodman 
California Institute of Technology, Pasadena, California 91125 
ABSTRACT
The new neural network classifier we propose transforms the 
classification problem into the coding theory problem of decoding a noisy 
codeword. An input vector in the feature space is transformed into an internal 
representation which is a codeword in the code space, and then error correction 
decoded in this space to classify the input feature vector to its class. Two classes 
of codes which give high performance are the Hadamard matrix code and the 
maximal length sequence code. We show that the number of classes stored in an 
N-neuron system is linear in N and significantly more than that obtainable by 
using the Hopfield type memory as a classifier. 
I. INTRODUCTION 
Associative recall using neural networks has recently received a great deal 
of attention. Hopfield in his papers [1,2] describes a mechanism which iterates 
through a feedback loop and stabilizes at the memory element that is nearest the 
input, provided that not many memory vectors are stored in the machine. He has 
also shown that the number of memories that can be stored in an N-neuron 
system is about 0.15N for N between 30 and 100. McEliece et al. in their work [3] 
showed that for synchronous operation of the Hopfield memory about N/(21ogN) 
data vectors can be stored reliably when N is large. Abu-Mostafa [4] has predicted 
that the upper bound for the number of data vectors in an N-neuron Hopfield 
machine is N. We believe that one should be able to devise a machine with M, the 
number of data vectors, linear in N and larger than the 0.15N achieved by the 
Hopfield method. 
N 
Feature Space = B = {-1 ,1 } 
Ae 
eC 
B. 
N L 
L 
Code Space = B = 
Figure 1 (a) Classification problems versus (b) Error control decoding problems 
In this paper we are specifically concerned with the problem of 
classification as in pattern recognition. We propose a new method of building a 
neural network classifier, based on the well established techniques of error 
control coding. Consider a typical classification problem (Fig. l(a)), in which one 
is given apriori a set of classes, C(a), a =1 ..... M. Associated with each class is a 
feature vector which labels the class ( the exemplar of the class ), i.e. it is the 
@ American Institute of Physics 1988 
175 
most representative point in the class region. The input is classified into the 
class with the nearest exemplar to the input. Hence for each class there is a 
region in the N-dimensional binary feature space BN --- [1,-1)N, in which every 
vector will be classified to the corresponding class. 
A similar problem is that of decoding a codeword in an error correcting 
code as shown in Fig. l(b). In this case codewords are constructed by design and 
are usually at least dmin apart. The received corrupted codeword is the input to 
the decoder, which then finds the nearest codeword to the input. In principle 
then, ff the distance between codewords is greater than 2t + 1, it is possible to 
decode (or classify) a noisy codeword (feature vector) into the correct codeword 
(exemplar) provided that the Hamming distance between the noisy codeword and 
the correct codeword is no more than t. Note that there is no guarantee that the 
exemplars are uniformly distributed in BN, consequently the attraction radius 
(the maximum number of errors that can occur in any given feature vector such 
that the vector can still be correctly classified) will depend on the minimum 
distance between exemplars. 
Many solutions to the minimum Hamming distance classification have 
been proposed, the one commonly used is derived from the idea of matched filters 
in communication theory. Lippmann [5] proposed a two-stage neural network 
that solves this classification problem by first correlating the input with all 
exemplars and then picking the maximum by a ""winner-take-all"" circuit or a 
network composed of two-input comparators. In Figure 2, fl,f2 ..... fN are the N 
input bits, and Sl,S2 .... SM are the matching scores(similarity) of f with the M 
exemplars. The second block picks the maximum of Sl,S2 ..... SM and produces the 
index of the exemplar with the largest score. The main disadvantage of such a 
classifier is the complexity of the maximum-picking circuit, for example a 
""winner-take-all"" net needs connection weights of large dynamic range and 
graded-response neurons, whilst the comparator maximum net demands M-1 
comparators organized in log2M stages. 
fl 
S. c(CO+ 
g= e � 
fN 
M 
A 
X 
I 
M 
U 
M 
class(f ) 
f= d(a+ ) e 
Featu re Code 
Space Space 
ODER 
DEC 
Fig. 2 A matched filter type classifier Fig. 3 Structure of the proposed classifier 
Our main idea is thus to transform every vector in the feature space to a 
vector in some code space in such a way that every exemplar corresponds to a 
codeword in that code. The code should preferably (but not necessarily) have the 
property that codewords are uniformly distributed in the code space, that is, the 
Hamming distance between every pair of codewords is the same. With this 
transformation, we turn the problem of classification into the coding problem of 
decoding a noisy codeword. We then do error correction decoding on the vector in 
the code space to obtain the index of the noisy codeword and hence classify the 
original feature vector, as shown in Figure 3. 
This paper develops the construction of such a classification machine as 
follows. First we consider the problem of transforming the input vectors from the 
feature space to the code space. We describe two hetero-associative memories for 
doing this, the first method uses an outer product matrix technique similar to 
176 
that of Hopfield's, and the second method generates its matrix by the 
pseudoinverse technique[6,7]. Given that we have transformed the problem of 
associative recall, or classification, into the problem of decoding a noisy 
codeword, we next consider suitable codes for our machine. We require the 
codewords in this code to have the property of orthogonality or 
pseudo-orthogonality, that is, the ratio of the cross-correlation to the 
auto-correlation of the codewords is small. We show two classes of such good 
codes for this particular decoding problem i.e. the Hadamard matrix codes, and 
the maximal length sequence codes[8]. We next formulate the complete decoding 
algorithm, and describe the overall structure of the classifier in terms of a two 
layer neural network. The first layer performs the mapping operation on the 
input, and the second one decodes its output to produce the index of the class to 
which the input belongs. 
The second part of the paper is concerned with the performance of the 
classifier. We first analyze the performance of this new classifier by finding the 
relation between the maximum number of classes that can be stored and the 
classification error rate. We show (when using a transform based on the outer 
product method) that for negligible misclassification rate and large N, a not very 
tight lower bound on M, the number of stored classes, is 0.22N. We then present 
comprehensive simulation results that confirm and exceed our theoretical 
expectations. The simulation results compare our method with the Hopfield 
model for both the outer product and pseudo-inverse method, and for both the 
analog and hard limited connection matrices. In all cases our classifier exceeds 
the performance of the Hopfield memory in terms of the number of classes that 
can be reliably recovered. 
II. TRANSFORM TECHNIQUF_ 
Our objective is to build a machine that can discriminate among input 
vectors and classify each one of them into the appropriate class. Suppose 
d(a) e BN is the exemplar of the corresponding class C(C0, ct = 1,2 ..... M. Given the 
input f, we want the machine to be able to identify the class whose exemplar is 
closest to f, that is, we want to calculate the following function, 
class(f) = a 
iff If-d(COI <lf-d(l 
where   denotes Hamming distance in BN. 
We approach the problem by seeking a transform , that maps each 
exemplar d(a) in BN to the corresponding codeword w(a) in BL. And an input 
feature vector f = d(�) + e is thus mapped to a noisy codeword g = w(�) + e' where e 
is the error added to the exemplar, and e' is the corresponding error pattern in the 
code space. We then do error correction decoding on g to get the index of the 
corresponding codeword. Note that e' may not have the same Hamming weight as 
e, that is, the transformation , may either generate more errors or eliminate 
errors that are present in the original input feature vector. We require , to 
satisfy the following equation, 
a=o, 1 ..... M-1 
and , will be implemented using a single-layer feedfonvard network. 
177 
Thus we first construct a matrix according to the sets of d(a)'s and w(a)'s, call it T, 
and define  as 
where sgn is the threshold operator that maps a vector in RL to BL and R is the 
field of real numbers. 
Let D be an N x M matrix whose ath column is d(a) and W be an L x M 
matrix whose [th column is w([). The two possible methods of constructing the 
matrix for  are as follows: 
Scheme A [outer product mth0cl) [3,6]: In this scheme the matrix T is 
defined as the sum of outer products of all exemplar-codeword pairs, i.e. 
M-1 
T (A)ij = ,, wi(a)' dj(a) 
a=0 
or equivalently, 
T(A) = WDt 
Scheme B (pseudo-inverse method) [6,7] � We want to find a matrix T(B) 
satisfying the following equation, 
In general D is not a square matrix, moreover D may be singular, so D-1 
may not exist. To circumvent this difficulty, we calculate the pseudo-inverse 
(denoted DS) of the matrix D instead of its real inverse, let DS-- (DtD)-lDt. T(B) can 
be formulated as, 
T(B) = W D = W (Dr D)-IDt 
IlL CODES 
The codes we are looking for should preferably have the property that its 
codewords be distributed uniformly in BL, that is, the distance between each two 
codewords must be the same and as large as possible. We thus seek classes of 
equidistant codes. Two such classes are the Hadamard matrix codes, and the 
maximal length sequence codes. 
First der'me the word pseudo-orthogonal. 
Definition: Let w(a) = (w0(a),Wl(a) ....... wL_l(a)) E BL be the ath codeword of 
code C, where cc = 1,2 ..... M. Code C is said to be pseudo-orthogonal iff 
L-1 
(w(a),w()) =  
i=0 
w(a) w() 
where E << L 
where (,) denotes inner product of two vectors. 
Hadamard Matrices: An orthogonal code of length L whose L codewords are 
rows or columns of an L x L Hadamard matrix. In this case e = 0 and the 
distance between any two codewords is L/2. It is conjectured that there exist such 
codes for all L which are multiples of 4, thus providing a large class of codes[8). 
178 
Maximal Length Sequence Codes: There exists a famfiy of maximal length 
sequence (also called pseudo-random or PN sequence) codes[8], generated by shift 
registers, that satisfy pseudo-orthogonality with e = -1. Suppose g (x) is a 
primitive polynomial over GF (2) of degree D, and let L = 2D - 1, and if 
f(x) = 1/g (x) = Z Ck' xk 
k=0 
then co,c 1 ....... is a periodic sequence of period L ( since g (x) I x L _ 1). If code C is 
made up of the L cyclic shifts of 
c = (1-2c0,1-2Cl .... 1-2CL_l) 
then code C satisfies pseudo-orthogonality with e = - 1. One then easily sees that 
the minimum distance of this code is (L - 1)/2 which gives a correcting power of 
approximately L/4 errors for large L. 
IV. OVERAI.I. CLASSIFIER STRUCTURE 
We shall now describe the overall classifier structure, essentially it 
consists of the mapping  followed by the error correction decoder for the 
maximal length sequence code or Hadamard matrix code. The decoder operates 
by correlating the input vector with every codeword and then thresholding the 
result at (L + e)/2. The rationale of this algorithm is as follows, since the distance 
between every two codewords in this code is exactly (L - e)/2 bits, the decoder 
should be able to correct any error pattern with less than (L - e)/4 errors if the 
threshold is set halfway between L and e i.e. (L + e )/2. 
Suppose the input vector to the decoder is g = w(a) + e and e has Hamming 
weight s (i.e. s nonzero components) then we have 
(g,w(C0) = L- 2s 
(g,w{5) < 2s+ e 
where 
From the above equation, if g is less than (L- e)/4 errors away from w(a) 
{i.e. s < {L - e)/4 ) then ( g, w(a)) will be more than {L + e)/2 and (g, w([)) wfil be 
less than (L + e)/2, for all [ g= a. As a result, we arrive at the following decoding 
algorithm, 
decode{ = sgn{Wtg -{(L+ /2)J) 
where J = [ 1 1 ..... 1 ]t, which is an M x 1 vector. 
In the case when e = -1 and less than (L+l)/4 errors in the input, the output 
will be a vector in BM ----- {1,-1}M with only one component positive (+1), the index 
of which is the index of the class that the input vector belongs. However if there 
are more than (L+1)/4 errors, the output can be either the all negative(- 1) vector 
(decoder failure) or another vector with one positive component{decoder error). 
The function class can now be defined as the composition of g and decode, 
the overall structure of the new classifier is depicted in Figure 4. It can be viewed 
as a two-layer neural network with L hidden units and M output neurons. The 
first layer is for mapping the input feature vector to a noisy codeword in the code 
space ( the ""internal representation"" ) while the second one decodes the first's 
output and produces the index of the class to which the input belongs. 
179 
fl 
� 
� 
� 
fN-1 
fN 
Figure 4 
or (B) W t 
T (A) T 
g 
gL 
hi 
� 
� 
� 
Overall architecture of the new neural network classifier 
V. PERFORMANCE ANALYSIS 
From the previous section, we know that our classifier will make an error 
only if the transformed vector in the code space, which is the input to the decoder, 
has no less than (L - e)/4 errors. We now proceed to find the error rate for this 
classifier in the case when the input is one of the exemplars (i.e. no error), say 
f = d() and an outer product connection matrix for . Following the approach of 
McEliece et. al.[3], we have 
N-1 M-1 
(d()),= ( Z Z wi(a) dj(a)dj() ) 
j=o (I=o 
sgn( Nw( + 
N-1 M-1 
j=o a=o 
Assume without loss of generality that wi() = - 1, and ff 
wl(a) dj(a) dj() ) 
then 
N-1 M-1 
X ---- Z Z wi(a) dj(a)dj() -> N 
j=O a=0 
( d{))i � wi{) 
Notice that we assumed all d{a)'s are random, namely each component of 
any d(a) is the outcome of a Bernoulli trial, accordingly, X is the sum of N(M-1) 
independent identically distributed random variables with mean 0 and variance 
1. In the asymptotic case, when N and M are both very large, X can be 
approximated by a normal distribution with mean 0, variance NM. Thus 
P 
--- Pt{ ( d(j))i � wi(O) } 
1 t2/2 
where 9(x) = �- e 
dt 
180 
Next we calculate the mtsclassfftcatlon rate of the new classifier as follows 
(assuming e << L), 
L 
PE = =L/4 (L)pk(1-p)L-k 
k j k 
where L J is the integer floor. Since in general it is not possible to express the 
summation explicitly, we use the Chernoff method to bound Pe from above. 
Multiplying each term in the summation by a number larger than unity 
( et(k - L/4) with t > 0 ) and summing from k = 0 instead of k = LL/4J, 
L 
Pe < Z (L)pk(1.p)L-ket(k-L/4) = e-Lt/4(l_p+pet)L 
k=0 k 
Differentiating the RIdS of the above equation w.r.t. t and set it to 0, we find 
the optimal to as eto = (1-p)/3p. The condition that to > 0 implies that p < 1/4, 
and since we are dealing with the case where p is small, it is automatically 
satisfied. Substituting the optimal to, we obtain 
Pe < c L .pL/4. (1_p)3Iy4 where c = 4/(33/4 ) = 1.7547654 
From the expression for Pe, we can estimate M, the number of classes that 
can be classffied with negligible misclasstfication rate, in the following way, 
suppose Pe = / where / << land p << 1, then 
/4/L< C 4 'P .{1_p)3  p = Q( N > c -4 � (l-p)-3 . 4/L 
For small x we have Q-I(z) - /21og(l/z) and since 6 is a fixed value, as L 
approaches infinity, we have 
M > N = N 
81ogc 4.5 
From the above lower bound for M, one easily see that this new machine is able to 
classify a constant times N classes, which is better than the number of memory 
items a Hopfield model can store i.e. N/(21ogN). Although the analysis is done 
assuming N approaches infinity, the simulation results in the next section show 
that when N is moderately large (e.g. 63) the above lower bound applies. 
VI. SIMULATION RESULTS AND A CHARACTER RECOGNITION EXAMPI E 
We have simulated both the Hopfield model and our new machine(using 
maximal length sequence codes) for L = N = 31, 63 and for the following four cases 
respectively. 
(i) connection matrix generated by outer product method 
(ii) connection matrix generated by Dseudo-inverse mth0d 
(iii) connection matrix generated by outer t)roduct method, the components of the 
connection matrix are hard limited. 
(iv) connection matrix generated by pseudo-inverse method, the components of 
the connection matrix are hard limited. 
181 
For each case and each choice of N, the program fixes M and the number of 
errors in the input vector, then randomly generates 50 sets of M exemplars and 
computes the connection matrix for each machine. For each machine it 
randomly picks an exemplar and adds noise to it by randomly complementing 
the specified number of bits to generate 20 trial input vectors, it then simulates 
the machine and checks whether or not the input is classified to the nearest class 
and reports the percentage of success for each machine. 
The simulation results are shown in Figure 5, in each graph the horizontal 
axis is M and the vertical axis is the attraction radius. The data we show are 
obtained by collecting only those cases when the success rate is more than 98%, 
that is for fixed M what is the largest attraction radius (number of bits in error of 
the input vector) that has a success rate of more than 98%. Here we use the 
attraction radius of -1 to denote that for this particular M, with the input being 
an exemplar, the success rate is less than 98�/6 in that machine. 
-e- Hopfield Model o- New Classifier(OP) -- New Classffier(PI) [ 
.o  o,[. N=31  1 
  : .t Binary Connection Matrix   
,  , ,t'-. , ,.. 
'IV '"" 
M 
(a) 
N=31 
Analog Connection Matrix 
M 
 23 
="" � x Binary Connection Matrix 
.  � . 
 13' N=63 
i Analog Connection Matrix 
3 7 11 15 19 23 27 31 35 39 43 47 51 55 59 63 
(c) (d) 
Figure 5 Simulation results of the Hopfield memory and the new classifier 
182 
I-*- Hopfield Model - New Classifier(OP,L=63) - New Classifier(OP,L=31) I 
Figure 6 Performance of the new classifier using codes of different lengths 
In all cases our classifier exceeds the performance of the Hopfield model 
in terms of the number of classes that can be reliably recovered. For example, 
consider the case of N = 63 and a hard limited connection matrix for both the new 
classifier and the Hopfield model, we find that for an attraction radius of zero, 
that Is, no error in the input vector, the Hopfield model has a classification 
capacity of approximately 5, while our new model can store 47. Also, for an 
attraction radius of 8, that is, an average of N/8 errors in the Input vector, the 
Hopfield model can reliably store 4 classes while our new model stores 27 
classes. Another simulation (Ftg. 6) using a shorter code (L = 31 instead of L = 63) 
reveals that by shortening the code, the performance of the classifier degrades 
only slightly. We therefore conjecture that it is possible to use traditional error 
correcting codes (e.g. BCH code) as internal representations, however, by going to 
a higher rate code, one Is trading minimum distance of the code (error tolerance) 
for complexity (number of hidden units), which implies possibly poorer 
performance of the classifier. 
We also notice that the superiority of the pseudoinverse method over the 
outer product method appears only when the connection matrices are hard 
limited. The reason for this is that the pseudoinverse method is best for 
decorrelating the dependency among exemplars, yet the exemplars in this 
simulation are generated randomly and are presumably independent, 
consequently one can not see the advantage of pseudoInverse method. For 
correlated exemplars, we expect the pseudoinverse method to be clearly better 
(see next example). 
Next we present an example of applying this classifier to recognizing 
characters. Each character is represented by a 9 x 7 pixel array, the input Is 
generated by flipping every pixel with 0.1 and 0.2 probability. The input is then 
passed to five machines: Hopfield memory, the new classfflei  with either the 
pseudoinverse method or outer product method, and L = 7 or L = 31. Figure 7 and 8 
show the results of all 5 machines for 0.1 and 0.2 pixel flipping probability 
respectively, a blank output means that the classifier refuses to make a decision. 
First note that the L = 7 case is not necessarily worse than the L = 31 case, this 
confirms the earlier conjecture that fewer hidden units (shorter code) only 
degrades performance slightly. Also one easily sees that the pseudoinverse 
method is better than the outer product method because of the correlation 
between exemplars. Both methods outperform the Hopfield memory since the 
latter mixes exemplars that are to be remembered and produces a blend of 
exemplars rather than the exemplars themselves, accordingly it cannot classify 
the input without mistakes. 
183 
Figure 7 The character recognition 
example with 10% pixel reverse 
probabfiity (a) input (b) correct 
output {c) Hopfield Model (d)-(g) new 
classifier (d) OP, L = 7 (e)OP, L = 31 
(i) PI, L= 7 (g) PI, L= 31 
Figure 8 The character recognition 
example with 20% pixel reverse 
probability (a) input (b) correct 
output (c) Hopfield Model (d)-(g) new 
classifier (d) OP, L = 7 (e)OP, L = 31 
(0 PI, L= 7 {g} PI, L = 31 
VII. CONCLUSION 
In this paper we have presented a new neural network classifier design 
based on coding theory techniques. The classifier uses codewords from an error 
correcting code as its internal representations. Two classes of codes which give 
high performance are the Hadamard matrix codes and the maximal length 
sequence codes. In performance terms we have shown that the new machine is 
significantly better than using the Hopfield model as a classifier. We should also 
note that when comparing the new classifier with the Hopfield model, the 
increased performance of the new classifier does not entail extra complexity, 
since it needs only L + M hard limiter neurons and L(N + M) connection weights 
versus N neurons and N2 weights in a Hopfield memory. 
In conclusion we believe that our model forms the basis of a fast, practical 
method of classification with an efficiency greater than other previous neural 
network techniques. 
References
[1] J.J. Hopfield, Proc. Nat. Acacl. ScL USA, Vol. 79, pp. 2554-2558 (1982). 
[2] J.J. Hopfield, Proc. Nat. Acad. ScL USA, Vol. 81, pp. 3088-3092 (1984). 
[3] R.J. McEliece, et. al,/EEE Tran. on Information Theory, Vol. IT-33, 
pp. 461-482 (1987). 
[4] Y. S. Abu-Mostafa and J. St. Jacques, IEEE Tran. on Information Theory , 
Vol. IT-31, pp. 461-464 (1985). 
[5] R. Lippmann, IEEEASSPMagazine, Vol. 4, No. 2, pp. 4-22 (Aprfi 1987). 
[6] T. Kohonen, Associative Memory- A System-Theoretical Approach 
(Springer-Verlag, Berlin Heidelberg, 1977). 
[7] S.S. Venkatesh,Linear Map with Point Rules, Ph.D Thesis, Caltech, 1987. 
[8] E. R- Berlekamp, Algebraic Coding Theory , Aegean Park Press, 1984. 
", neural network base code theori chiueh rodney goodman institut california new neural network classifi propos transform problem code theori problem decod noisi input vector featur space transform intern codeword code error correct space classifi input featur vector two class code give high perform hadamard matrix code length sequenc show number class store system linear significantli obtain hopfield type memori introduct recal use neural network recent receiv great deal hopfield paper describ mechan iter feedback loop stabil memori element nearest provid mani memori vector store shown number memori store eliec et work synchron oper hopfield memori vector store reliabl predict upper bound number data vector hopfield believ one abl devis machin data linear larger achiev space space classif problem versu error control decod problem paper specif concern problem pattern propos new method build network base well establish techniqu error consid typic classif problem one given apriori set associ class vector label class exemplar class american institut physic repres point class input classifi nearest exemplar henc class binari featur space bn everi classifi correspond similar problem decod codeword error correct shown case codeword construct design usual least dmin receiv corrupt codeword input find nearest codeword principl ff distanc codeword greater possibl noisi codeword correct codeword provid ham distanc noisi codeword correct codeword note guarante uniformli distribut consequ attract radiu maximum number error occur given featur vector vector still correctli depend minimum solut minimum ham distanc classif one commonli use deriv idea match filter commun lippmann propos neural network solv classif problem first correl input pick maximum circuit compos figur sm match second block pick maximum sm produc exemplar largest main disadvantag complex exampl net need connect weight larg dynam rang whilst compar maximum net demand organ code space match filter type classifi structur propos classifi main idea thu transform everi vector featur space code space way everi exemplar correspond code prefer codeword uniformli distribut code distanc everi pair codeword turn problem classif code problem noisi error correct decod vector code space obtain index noisi codeword henc classifi featur shown figur paper develop construct classif machin first consid problem transform input vector space code describ two memori first method use outer product matrix techniqu similar second method gener matrix given transform problem problem decod noisi next consid suitabl code requir code properti orthogon ratio codeword show two class good particular decod problem hadamard matrix maxim length sequenc next formul complet decod describ overal structur classifi term two neural first layer perform map oper second one decod output produc index class input second part paper concern perform first analyz perform new classifi find maximum number class store error show use transform base outer neglig misclassif rate larg lower bound number store present simul result confirm exceed theoret simul result compar method hopfield outer product hard limit connect case classifi exce perform hopfield memori term number class reliabl transform object build machin discrimin among input classifi one appropri suppos bn exemplar correspond class ct given want machin abl identifi class whose exemplar want calcul follow denot ham distanc approach problem seek transform map bn correspond codeword input vector thu map noisi codeword error ad correspond error pattern error correct decod get index note may ham weight transform may either gener error elimin present origin input featur requir follow implement use feedfonvard first construct matrix accord set call defin sgn threshold oper map vector rl bl real matrix whose ath column whose column two possibl method construct product scheme matrix sum outer product wdt want find matrix follow gener squar moreov may circumv calcul matrix instead real let formul code code look prefer properti distribut uniformli distanc two must larg thu seek class two class hadamard matrix length sequenc word let bl ath codeword cc code said iff denot inner product two orthogon code length whose codeword column hadamard case two codeword conjectur exist multipl thu provid larg class length sequenc exist famfiy maxim length call pn gener shift satisfi suppos polynomi gf degre let xk period sequenc period sinc code cyclic shift code satisfi one easili see minimum distanc code give correct power error larg classifi structur shall describ overal classifi essenti map follow error correct decod length sequenc code hadamard matrix decod oper correl input vector everi codeword threshold rational algorithm sinc distanc everi two codeword code exactli decod abl correct error pattern less error set halfway input vector decod ham nonzero less error away wfil arriv follow decod case less error output vector bm one compon posit index index class input vector howev output either vector anoth vector one posit function class defin composit overal structur new classifi depict figur view neural network hidden unit output layer map input featur vector noisi codeword code second one decod produc index class input architectur new neural network classifi perform analysi previou know classifi make error transform vector code input less proceed find error rate case input one exemplar say outer product connect matrix follow approach eliec without loss gener ff assum name compon outcom bernoulli sum ident distribut random variabl mean varianc asymptot normal distribut mean varianc thu calcul mtsclassfftcatlon rate new classifi follow integ sinc gener possibl express use chernoff method bound pe term summat number larger uniti sum instead equat set find optim eto condit impli sinc deal case automat substitut optim obtain express estim number class classffi neglig misclasstf follow pe land small sinc fix lower bound one easili see new machin abl constant time better number memori hopfield model store although analysi done approach simul result next section show moder larg lower bound simul result charact recognit exampi simul hopfield model new length sequenc follow four case connect matrix gener outer product method connect matrix gener connect matrix gener outer compon matrix hard connect matrix gener compon connect matrix hard case choic program fix number input randomli gener set exemplar connect matrix machin pick exemplar add nois randomli complement specifi number bit gener trial input simul machin check whether input classifi nearest class report percentag success simul result shown figur graph horizont vertic axi attract data show collect case success rate fix largest attract radiu bit error input success rate use radiu denot particular input success rate less hopfield model new new binari connect matrix connect matrix binari connect matrix analog connect matrix simul result hopfield memori new classifi hopfield model new new perform new classifi use code differ length case classifi exce perform hopfield model term number class reliabl case hard limit connect matrix new hopfield find attract radiu error input hopfield model classif approxim new model store radiu averag error input model reliabl store class new model store anoth simul use shorter code instead shorten perform classifi degrad therefor conjectur possibl use tradit error code bch intern go higher rate one trade minimum distanc code complex hidden impli possibl poorer also notic superior pseudoinvers method product method appear connect matric hard reason pseudoinvers method best depend among yet exemplar gener randomli presum one see advantag invers expect pseudoinvers method clearli better next present exampl appli classifi recogn charact repres pixel input flip everi pixel input five hopfield new classfflei either method outer product figur result machin pixel flip probabl blank output mean classifi refus make note case necessarili wors earlier conjectur fewer hidden unit perform also one easili see pseudoinvers better outer product method correl method outperform hopfield memori sinc mix exemplar rememb produc blend rather exemplar accordingli can not classifi input without charact recognit pixel revers input correct hopfield model new charact recognit pixel revers input correct hopfield model new conclus paper present new neural network classifi design code theori classifi use codeword error code intern two class code give perform hadamard matrix code maxim length perform term shown new machin better use hopfield model also compar new classifi hopfield perform new classifi entail extra need hard limit neuron connect weight neuron weight hopfield conclus believ model form basi practic classif effici greater previou neural inform ie inform theori associ approach berlin map point algebra code theori aegean park,0
19,19,"184 
THE CAPACITY OF THE KANERVA ASSOCIATIVE MEMORY IS EXPONENTIAL 
P. A. Chou  
Stanford University, Stanford, CA 94305 
ABSTRACT 
The capacity of an associative memory is defined as the maximum 
ntuzber of words that can be stored and retrieved reliably by an address 
within a given sphere of attraction. It is shown by sphere packing 
ar%uents that as the address length increases, the capacity of any 
associative memory is limited to an exponential growth rate of 1 - 
where h2() is the binary entropy function in bits, and  is the radius 
of the sphere of attraction. This exponential growth in capacity can 
actually be achieved by the Kanerva associative memory, if its 
parameters are optimally set. Formulas for these optimal values are 
provided. The exponential growth in capacity for the Kanerva 
associative memory contrasts sharply with the sub-linear growth in 
capacity for the Hopfield associative memory. 
ASSOCIATIVE MEMORY AND ITS CAPACITY 
Our model of an associative memory is the following. Let (X,Y) be 
an (address, datum) pair, where X is a vector of n ls and Y is a 
vector of rn ls, and let (XO),YO)),...,(x(M),y(M)), be M (address, 
datum) pairs stored in an associative memory. If the associative memory 
is presented at the input with an address X that is close to some 
stored address X (j), then it should produce at the output a word Y that 
is close to the corresponding contents Y(J). To be specific, let us say 
that an associative memory can corctfraction  errors if an X within 
Hamming distance n6 of X (3) retrieves Y equal to yO). The Hmming 
sphere around each X (3) will be called the sphere of attraction, and  
will be called the radius of attraction. 
One notion of the capacity of this associative memory is the 
maximum number of words that it can store while correcting fraction  
errors. Unfortunately, this notion of capacity is ill-defined, because 
it depends on exactly which (address, datum) pairs have been stored. 
Clearly, no associative memory can correct fraction  errors for �ucry 
sequence of stored (address, datum) pairs. Consider, for example, a 
sequence in which several different words are written to the sme 
address. No memory can reliably retrieve the contents of the 
overwritten words. At the other extreme, any associative memory'can 
store an unlimited number of words and retrieve them all reliably, if 
their contents are identical. 
A useful definition of capacity must lie somewhere between these 
two extremes. In this paper, we are interested in the largest M such 
that for most sequences of addresses X(1),...,X (M) and most sequences of 
data y(X)...y(M), the memory can correct fraction  errors. We define 
This work was supported by the National Science Foundation under NSF 
grant IST-8S0980 and by an IBM Doctoral Fellowship. 
� American Institute of Physics 1988 
185 
'most sequences' in a probabilistic sense, as some set of sequences with 
total probability greater than say, .99. When all sequences are 
equiprobable, this reduces to the deterministic version: 99 of all 
sequences. 
In practice it is too difficult to compute the capacity of a given 
associative memory with inputs of length n and outputs of length n. 
Fortunately, though, it is easier to compute the asymptotic rate at 
which M increases, as n and rn increase, for a given family of 
associative memories. This is the approach taken by McEliece et al. 
towards the capacity of the Hopfield associative memory. We take the 
same approach towards the capacity of the Kanerva associative memory, 
and towards the capacities of associative memories in general. In the 
next section we provide an upper bound on the rate of growth of the 
capacity of any associative memory fitting our general model. It is 
shown by sphere packing arguments that capacity is limited to an 
exponential rate of growth of 1- h2(), where h2(5) is the binary entropy 
function in bits, and  is the radius of attraction. In a later section 
it will turn out that this exponential growth in capacity can actually 
be achieved by the Kanerva associative memory, if its parameters are 
optimally set. This exponential growth in capacity for the Kanerva 
associative memory contrasts sharply with the sub-linear growth in 
capacity for the Hopfield associative memory 
A UNIVERSAL UPPER BOUND ON CAPACITY 
Recall that our definition of the capacity of an associative memory 
is the largest M such that for most sequences of addresses 
.�(1),...,x(M) and most sequences of data Y(x),...,Y(M), The memory can 
correct fraction  errors. Clearly, an upper bound to this capacity is 
the largest M for which there exists some sequence of addresses 
X (1),... ,X � such that for most sequences of data Y(1),... ,Y(M), the 
memory can correct fraction  errors. We now derive an expression for 
this upper bound. 
Let  be the radius of attraction and let DH(X(J),d) be the sphere 
of attraction, i.�., the set of all Xs at most Hamming distance d = [nJ 
from .�(J). Since by assumption the memory corrects fraction  errors, 
every address =� 6 DH(X(3),d) retrieves the word y(3). The size of 
DH(X(),d) is easily shown to be independent of X(j) and equal to 
out of a total of 2  n-bit addresses, at least ,d addresses retrieve 
Y(), at least ,d addresses retrieve Y(2), at least w,d addresses 
retrieve y(3), and so forth. It follows that the total number of 
distinct Y(3)s can be at most 2""/,d. Now, from Stirling's formula it 
can be shown that if d _ n/2, then w. = 2 h2(d/)+O(1�$) , where 
h2(5) =-51og25-(1-)1og2(1-6) is the binary entropy function in bits, 
and 69(logn) is some function whose magnitude grows more slowly than a 
constant times log n. Thus the total number of distinct Y()s can be at 
most 2 n(-:(5))+O(1�g) . Since any set containing 'most sequences' of M 
m-bit words will contain a large number of distinct words (if rn is 
186 
1 2 --- n 
Figure 1: Neural net representation of the Kanerva associative memory. Signals propa- 
gate from the bottom (input) to the top (output). Each arc multiphes the signal by its 
weight; each node adds the incoming signals and then thresholds. 
sufficiently large --- see [2] for details), it follows that 
M _< 2 n(1-h(6))+O(l�gn). (1) 
In general a function f(n) is said to be O(g(n)) if f(n)/g(n) is 
bounded, i.e., if there exists a constant a such tha; If(n)[ < aig(n)[ for 
all n. Thus (1) says that there exists a constant a such that 
M < 2 n(1-h2(5))+al�g'. It should be emphasized that since ct is unknown, 
this bound has no meaning for fixed n. However, it indicates that 
asymptotically in n, the maximum exponential rate of growth of M is 
- 
Intuitively, only a sequence of addresses XO),...,X � that 
optimally pack the address space {-1,+1} ' can hope to achieve this 
upper bound. Remarkably, most such sequences are optimal in this sense, 
when n is large. The Kanerva associative memory can take advantage of 
this fact. 
THE KANERVA ASSOCIATIVE MEMORY 
The Kanerva associative memory [3,4] can be regarded as a two-layer 
neural network, as shown in Figure 1, where the first layer is a 
preprocessor and the second layer is the usual Hopfield style array. 
The preprocessor essentially encodes each n-bit input address into a 
very large k-bit internal representation, k>>n, whose size will be 
permitted to grow exponentially in n. It does not seem surprising, 
then, that the capacity of the Kanerva associative memory can grow 
exponentially in n, for it is known that the capacity of the Hopfield 
array grows almost linearly in k, assuming the coordinates of the 
k-vector are drawn at random by independent flips of a fair coin 
187 
1 k 
w 
� o 
z 
Figure 2: Matrix representation of the Kanerva associative memory. Signals propagate 
from the right (input) to the left (output). Dimensions are shown in the box corners. 
Circles stand for functional composition; dots stand for matrix multiplication. 
In this situation, however, such an assumption is ridiculous: Since the 
k-bit internal representation is a function of the m-bit input address, 
it can contain at most m bits of information, whereas independent flips 
of a fair coin contain k bits of information. Kanerva's primary 
contribution is therefore the specification of the preprocessor, that 
is, the specification of how to map each m-bit input address into a very 
large k-bit internal representation. 
The operation of the preprocessor is easily described. Consider 
the matrix representation shown in Figure 2. The matrix Z is randomly 
populated with ls. This randomness assumption is required to ease the 
analysis. The function fr is 1 in the ith coordinate if the ith row of 
Z is within Hamming distance r of X, and is 0 otherwise. This is 
accomplished by thresholding the ith input against m - 2r. The 
parameters r and k are two essential parameters in the Kanerva 
associative memory� If r and k are set correctly, then the number of is 
in the representation (ZX) will be very small in comparison to the 
number of Os. Hence (ZX) can be considered to be a sparse internal 
representation of X. 
The second stage of the memory operates in the usual way, except on 
the internal representation of X. That is, Y = g(Wfr(ZX)), where 
M 
W = Y(J)[fr(ZX(J))] t, (2) 
j=l 
and g �s the threshold function whose ith coordinate is +1 if the 
input is greater than 0 and -1 is the ith input is less than 0. The ith 
column of W can be regarded as a memory location whose address is the 
ith row of Z. Every X within Hamming distance r of the ith row of Z 
accesses this location� Hence r is known as the access radius, and k is 
the number of memory cations. 
The approach taken in this paper is to fix the linear rate p at 
which r grows with n, and to fix the exponential rate  at which k grows 
with m. It turns out that the capacity then grows at a fixed 
exponential rate Cp,(6), depending on p, , and 6. These exponential 
rates are sufficient to overcome the standard loose but simple 
polynomial bounds on the errors due to combinatorial approximations. 
188 
THE CAPACITY OF THE KANERVA ASSOCIATIVE MEMORY 
Fix OS 1, OpS 1/2, and 0S5 J mJn{2p, 1/2}. Let n be the 
input address length, and let m be the output word length. It is 
assumed that m is at most polynomial in n, i.e., m = exp{O(logn)}. Let 
r = [pn] be the access radius, let k = 2 [n] be the number of memory 
locations, and let d = [Sn] be the radius of attraction. Let Mn be the 
number of stored words. The components of the n-vectors J(1),...,x(M""), 
... y(%4,), and the k x n matrix Z are assumed to be 
the m-vectors y(1), , 
IID equiprobable 1 random variables. Finally, given an n-vector X, 
let Y = 9(Wf.(ZX)) where W M . 
Define the quantity 
c.,(5) = { 25 + 2(1- 5)n(.;_- ) + - 2n(p) if  <_ o(p) 
c,o()(5) if  > o(p) ' 
() 
where 
and 
o(p) = 2n(p) - 2 - 2(1 - )n([_-) + 1 - n() 
(4) 
-r = ]- - 2p(1 - p). 
Theorem: If 
M <_ 2 c"",()+�0�) 
then for all e > O, all sufficiently large n, all j 6 {1,...,Mn}, and all 
X � DH(X(J),d), 
P{Y  Y('/)} < e. 
Proof: See [2]. 
Interpretation: If the exponential growth rate of the number of 
stored words M is asymptotically less than Cp,(5), then for every 
sufficiently large address length n, there is some realization of the 
n X 2 "" preprocessor matrix Z such that the associative memory can 
correct fraction 5 errors for most sequences of Mn (address, datum) 
pairs. Thus C,,(5) is a lower bound on the exponential growth rate of 
the capacity of the Kanerva associative memory with access radius n and 
number of memory locations 2 "". 
Figure 3 shows C,(5) as a function of the radius of attraction 5, 
for  = 0() and  = 0.1, 0.2, 0.3, 0.4 and 0.45. For. any fixed access 
radius p, C,,0()(5 ) decreases as 5 increases. This reflects the fact 
that fewer (address, datum) pairs can be stored if a greater fraction of 
errors must be corrected. As p increases, C,,o(,)(5 ) begins at a lower 
point but falls off less steeply. In a moment we shall see that  can 
be adjusted to provide the optimal performance for a given 5. 
Not shown in Figure 3 is the behavior of C,,(5) as a function of . 
However, the behavior is simple. For  > 0(), C,,(5) remains 
unchanged. while for  < 0(P). C,.(5) is simply shifted down by the 
difference 0(P)- - This establishes the conditions under which the 
Kanerva associative memory is robust against random component failures. 
Although increasing the number of memory locations beyond 2 ""0("") does 
not increase the capacity, it does increase robustness. Random 
189 
t.1 
=0.2 
0.3 
Figure 3: Graphs of Cp,o(p)(5 ) as defined by (3). The upper envelope is 1 - ha(5). 
component failures will not affect the capacity until so many components 
have failed that the number of surviving memory locations is less than 
Perhaps the most important curve exhibited in Figure 3 is the 
sphere packing upper bound !- h(6), which is achieved for a particular 
3 - 2p(1- p). Equivalently, the upper bound is achieved 
pby=- 
for a particular 6 by p equal to 
(5) 
Thus (4) and ($) specify the optimal values of the parameters  and p, 
respectively. These functions are shown in Figure 4. With these 
optimal values, (3) simplifies to 
= - 
the sphere packing bound. 
It can also be seen that for  = 0 in (3), the exponential Towth 
rate of the capacity is asymptotically equal to , which is the 
exponential growth rate of the number of memory locations, k. That is, 
AJ = 2 n+O(g) = k.2 0(). Kanerva [3] and Keeler [5] have argued 
that the capacity at  = 0 is proportional to the number of memory 
locations, i.e., /=k. , for some constant . Thus our results are 
consistent with those of Kanerva and Keeler, provided the polynomial' 
O(n) can be proved to be a constant. However, the usual statement of 
their result, /= k. , that the capacity is simply proportional to the 
number of memory locations, is false, since in light of the universal 
190 
o 
0 0.1 0.2 0.3 0.9 0.5 
p 
Figure 4: Graphs of no(p) and So(p), the inverse of po(5), as defined by (4) and (5). 
upper bound, ir is impossible for the capacity to grow without bound, 
with no dependence on'the dimension n. In our formulation, this 
difficulty does nor arise because we have explicitly related the number 
of memory locations ro the input dimension: kn = 2 n. In fact, our 
formulation provides explicit, coherent relationships between all of the 
following variables: the capacity M, the number of memory locations k, 
the input and output dimensions n and m, the radius of attraction 6, 
and the access radius p. We are therefore able ro generalize the 
results of [3,S] ro the case  > 0, and provide explicit expressions for 
the asymptotically optimal values of p and n as well. 
CONCLUSION 
We described a fairly general model of associative memory and 
selected a useful definition of its capacity. A universal upper bound 
on the growth of the capacity of such an associative memory was shown by 
a sphere packing ar&xmenr ro be exponential with rate 1 - h2(), where 
h2(5) is the binary entropy function and  is the radius of attraction. 
We reviewed the operation of the Kanerva associative memory, and stared 
a lower bound on the exponential growth rare of its capacity. This 
lower bound meets the universal upper bound for optimal values of the 
memory parameters p and n. We provided explicit formulas for these 
optimal values. Previous results for  = 0 staring rhar the capacity of 
the Kanerva associative memory is proportional to the number of memory 
locations cannot be strictly true. Our formulation corrects the problem 
and generalizes those results ro the case  > 0. 
191 
References
1. R.J. McEliece, E.C. Posner, E.R. Rodemich, and S.S. Venkatesh, 
''The capacity of the Hopfield associative memory,'' IEEE 
Transactions on Information Theory, submitted. 
2. P.A. Chou, ''The capacity of the Kanerva associative memory,'' 
IEEE Transactions on Information Theory, submitted. 
3. P. Kanerva, ''Self-propagating search: a unified theory of 
memory,'' Tech. Rep. CSLI-84-7, Stanford Center for the Study of 
Language and Information, Stanford, CA, March 1984. 
4. P. Kanerva, ''Parallel structures in human and computer memory,'' 
in Neural NetworksforOomputing, (J.S. Denker, ed.), New York: 
American Institute of Physics, 1986. 
5. J.D. Keeler, ''Comparison between sparsely distributed memory and 
Hopfield-type neural network models,'' Tech. Rep. RIACS TR 86.31, 
NASA Research Institute for Advanced Computer Science, Mountain 
Vie, CA, Dec. 1986. 
", capac kanerva associ memori exponenti chou ca capac associ memori defin maximum word store retriev reliabl address given sphere shown sphere pack address length capac memori limit exponenti growth rate binari entropi function radiu sphere exponenti growth capac achiev kanerva associ optim formula optim valu exponenti growth capac kanerva memori contrast sharpli growth hopfield associ memori capac model associ memori let vector rn let pair store associ associ memori present input address close address produc output word close correspond content let us say associ memori error within distanc retriev equal around call sphere call radiu notion capac associ memori number word store correct fraction notion capac depend exactli pair associ memori correct fraction error store sever differ word written memori reliabl retriev content associ unlimit number word retriev content use definit capac must lie somewher interest largest sequenc address sequenc memori correct fraction defin work support nation scienc foundat nsf ibm doctor american institut physic probabilist set sequenc probabl greater sequenc reduc determinist practic difficult comput capac given memori input length output length easier comput asymptot rate rn given famili approach taken eliec et capac hopfield associ take approach toward capac kanerva associ toward capac associ memori section provid upper bound rate growth associ memori fit gener sphere pack argument capac limit rate growth binari entropi radiu later section turn exponenti growth capac actual achiev kanerva associ paramet exponenti growth capac kanerva memori contrast sharpli growth hopfield associ memori univers upper bound capac definit capac associ memori largest sequenc address sequenc data memori fraction upper bound capac largest exist sequenc address sequenc data correct fraction deriv express upper radiu attract let sphere set xs ham distanc sinc assumpt memori correct fraction address retriev word size easili shown independ equal total least address retriev least address retriev least address follow total number formula shown binari entropi function function whose magnitud grow slowli time log thu total number distinct sinc set contain word contain larg number distinct word rn neural net represent kanerva associ signal bottom top arc multiph signal node add incom signal larg see follow gener function said exist constant thu say exist constant emphas sinc ct bound mean fix indic maximum exponenti rate growth sequenc address pack address space hope achiev sequenc optim kanerva associ memori take advantag kanerva associ memori kanerva associ memori regard shown figur first layer second layer usual hopfield style preprocessor essenti encod input address larg intern whose size grow exponenti seem capac kanerva associ memori grow known capac hopfield grow almost linearli assum coordin drawn random independ flip fair coin matrix represent kanerva associ signal propag right left dimens shown box stand function dot stand matrix assumpt sinc intern represent function input contain bit wherea independ flip fair coin contain bit primari therefor specif specif map input address intern oper preprocessor easili consid matrix represent shown figur matrix randomli random assumpt requir eas function fr ith coordin ith row within ham distanc threshold ith input two essenti paramet kanerva set number represent small comparison henc consid spars intern second stage memori oper usual except intern represent threshold function whose ith coordin greater ith input less ith regard memori locat whose address row everi within ham distanc ith row henc known access number memori approach taken paper fix linear rate grow fix exponenti rate grow turn capac grow fix rate depend exponenti suffici overcom standard loos simpl bound error due combinatori capac kanerva associ memori let address let output word polynomi let access let number memori let radiu let mn store compon matrix assum equiprob random given quantiti suffici larg see exponenti growth rate number word asymptot less everi larg address length realiz preprocessor matrix associ memori fraction error sequenc mn thu lower bound exponenti growth rate capac kanerva associ memori access radiu memori locat show function radiu attract fix access decreas reflect fact fewer pair store greater fraction must begin lower fall less moment shall see adjust provid optim perform given shown figur behavior function behavior remain simpli shift establish condit associ memori robust random compon increas number memori locat beyond increas increas random graph defin upper envelop failur affect capac mani compon fail number surviv memori locat less import curv exhibit figur pack upper bound achiev particular upper bound achiev particular equal specifi optim valu paramet function shown figur simplifi sphere pack also seen exponenti capac asymptot equal growth rate number memori kanerva keeler argu capac proport number memori constant thu result kanerva provid prove usual statement capac simpli proport memori sinc light univers graph invers defin ir imposs capac grow without depend dimens aris explicitli relat number memori locat ro input kn provid coher relationship capac number memori locat input output dimens radiu attract access radiu therefor abl ro gener ro case provid explicit express asymptot optim valu describ fairli gener model associ memori use definit univers upper bound growth capac associ memori shown sphere pack ro exponenti rate binari entropi function radiu review oper kanerva associ stare lower bound exponenti growth rare bound meet univers upper bound optim valu paramet provid explicit formula previou result stare rhar capac kanerva associ memori proport number memori can not strictli formul correct problem gener result ro case capac hopfield associ ie inform capac kanerva associ transact inform unifi theori stanford center studi march structur human comput neural new institut spars distribut memori neural network riac tr research institut advanc comput mountain,0
20,20,"192 
PHASE TRANSITIONS IN NEURAL NETWORKS 
Joshua Chover 
University o� Wisconsin, Madison, WI 53706 
ABSTRACT
Various simulations o� cortical subnetworks have evidenced 
something like phase transitions with respect to key parameters. 
We demonstrate that. such transitions must. indeed exist_ in analogous 
in�inite array models. For related �inite array models classical 
phase transit.ions (which describe steady-state behavior) may not. 
exist., but. there can be distinct. qualitative changes in 
(""metastable"") transient. behavior as key system parameters pass 
through critical values. 
INTRODUCTION 
Suppose that. one st.imulates a neural network - actual or 
simulated - and in some manner records the subsequent �iring 
activity o� cells. Suppose �urther that. one repeats the experiment. 
�or di��erent values o� some parameter (p) o� the system: and that. 
one �inds a ""critical value"" (pc) o� the parameter, such that. 
(say) �or values P ) Pc the activity tends to be much higher than 
it. is �or values P < Pc' Then, by analogy with statistical 
mechanics (where, e.g., p may be temperature, with critical 
values �or boiling and �reezing) one can say that. the neural 
network undergoes a ""phase transition"" at. Pc' Intracellular phase 
transitions, parametrized by membrane potential, are well known. 
Here we consider intercellular phase transitions. These have been 
evidenced in several detailed cortical simulations: e.g., of the 
pitiform cortex 1 and of the hippocampus 2 In the pitiform case, 
the parameter p represented the frequency of high amplitude 
spontaneous EPSPs received by a typical pyramidal cell; in the 
hippocampal case, the parameter was the ratio of inhibitory to 
excitatory cells in the system. 
By what. mechanisms could approach to, and retreat. from, a 
critical value of some parameter be brought about? An intriguing 
conjecture is that. neuromodulators can play such a role in certain 
3 
networks; temporarily raising or depressing synaptic efficacies 
What. possible interesting consequences could approach to 
criticality have for system performance. Good effects could be 
these: for a network with plasticity, heightened firing response 
to a stimulus can mean faster changes in synaptic e�ficacies, which 
would bring about_ faster memory storage. More and longer activity 
could also mean faster access to memory. A bad effect. o� 
@ American Institute of Physics 1988 
193 
near-criticality - depending on other parameters - can be wild, 
epilepti�orm activity. 
Phase transitions as they might. relate to neural networks have 
4 
been studied by many authors Here, �or clarity, we look at. a 
particular category o� network models - abstracted �rom the 
piri�orm cortex setting re�erred to above - and show the �ollowing: 
a) For ""elementary"" reasons, phase transition would have to 
exist i� there were in�initely many cells; and the near-subcritical 
state involves prolonged cellular �iring activity in response to an 
initial stimulation. 
b) Such prolonged �iring activity takes place �or analogous 
large �inite cellular arrays - as evidenced also by computer 
simulations. 
What. we shall be examining is space-time patterns which 
describe the mid-term transient. activity o� (Markovian) systems 
that. tend to silence (with high probability) in the long run. 
(There is no re�erence to energy �unctions, nor to long-run stable 
�iring rates - as such rates would be zero in most. o� our cases.) 
In the �ollowing models time will proceed in discrete steps. 
(In the more complicated settings these will be short. in comparison 
to other time constants, so that_ the e��ect o� quantization becomes 
smaller.) The parameter p will be the probability that at. any 
given time a given cell will experience a certain amount. o� 
excitatory ""spontaneous �iring"" input.: by itsel� this amount. will 
be insu��icient. to cause the cell to �ire, but. in conjunction with 
su��iciently many excitatory inputs �rom other cells it. can assist. 
in reaching �iring threshold. (Other related parameters such as 
average �iring threshold value and average e�ficcy value give 
similar results.) In all the models there is a refractory period 
after a cell fires, during which it cannot fire again; and there 
may be local (shunt. type) inhibition by a firing cell on near 
neighbors as well as on itself - but. there is no long-distance 
inhibition. We look first. at. limiting cases where there are 
infinitely many cells and - classically - phase transition appears 
in a sharp �orm. 
A ""SIMPLE"" MODEL 
We consider an infinite linear array of similar cells which 
obey the following rules, pictured in Fig. 1A: 
(i) If cell k fires at. time n, then it. must. be silent. 
at. time n+l; 
(ii) if cell 
neighbors k-1 and 
at. time n+l; 
(iii) if cell k is silent at time n and Just one of its 
neighbors (k-1 or k+l) fires at. time n, then cell k will 
fire at time n+l with probability p and not. fire with 
probability l-p, independently of similar decisions at. other 
cells and at. other times. 
k is silent. at. time n but. both of its 
k+l do fire at. time n, then cell k fires 
194 
Fig. 1. ""Simple model"". A: firing rules; cells are represented 
horizontally, time proceeds downwards; filled squares 
denote firing. B: sample development. 
Thus, ef�ecttvely, signal propagation speed here is one cell 
per unit. time, and a cell's firing threshold value is 2 (EPSP 
units). I{ we stimulate one cell to {ire at time n--O, will its 
influence necessarily die out or can it. go on forever? (See 
Fig. lB.) For an answer we note that. in this simple case the 
firing pattern (if any) at. time n must. be an alternating stretch 
o{ firing/silent cells o{ some length, call it. L . Moreover, 
n 
2 
Ln+ 1 = L +2 with probability p (when there are sponteneous 
n 
firing assists on both ends o{ the stretch), or Ln+ 1 = Ln-2 with 
probability (l-p) 2 (when there is no assist at. either. end o{ the 
stretch), or Ln+ 1 = L n with probability 2p(1-p) (when there is 
an assist. at. just. one end o{ the stretch). 
Starting with any finite alternating stretch L O, the 
successive values L constitute a ""random walk"" among the 
n 
nonnegative integers. Intuition and simple analysis 5 lead to the 
same conclusion: i{ the probability {or L n to decrease ((l-p) 2) 
is greater than that_ {or it. to increase (p2) _ i.e. if the average 
step taken by the random walk is negative - then ultimately L 
n 
will reach 0 and the firing response dies out. Contrariwise, i{ 
195 
2 l_p)2 
p > ( then the L can drift_ to even higher values with 
n 
positive probability. In Fig. 2A we sketch the probability for 
ultimate die-out as a function of p; and in Fig. 2B, the average 
time until die out. Figs. 2A and B show a classic example of phase 
transition (Pc = 1/2) for this infinite array. 
Fig. 2. Critical behavior. A: probability of ultimate die out. (or 
of reaching other traps, in finite array case). 
B: average time until die-out (or for reaching other 
traps). Solid curves refer to an infinite array; dashed, 
to finite arrays. 
MORE COMPI.EX MODELS 
For an infinite linear array of cells, as sketched in Fig. 3 , 
we describe now a much more general (and hopefully more realistic) 
set. of rules: 
(i') A cell cannot. fire, nor receive excitatory inputs, at. 
time n if it has fired at any time during the preceding m R time 
units (refraction and feedback inhibition). 
(ii') Each cell x has a local ""inhibitory neighborhood"" 
consisting of a number (j) of cells to its immediate right. and 
left_, The given cell x cannot. fire or receive excitatory inputs 
at time n if any other cell y in its inhibitory neighborhood 
has fired at_any time between t and t+m I units preceding n, 
where t is the time it. would take for a message to travel from y 
to x at. a speed of v I cells per unit time. (This rule 
represents local shuntstype inhibition.) 
(iii') Each cell x has an ""excitatory neighborhood"" 
consisting of a number (e) of cells to the immediate right_and left 
of its inhibitory neighborhood. If a cell y in that. neighborhood 
fires at. a certain time, that firing causes a unit impulse to 
travel to cell x at a speed of v E cells per unit. time. The 
impulse is received at. x subject to rules (i') and (ii'). 
196 
(iv') All cells share a ""�iring threshold"" value 0 and an 
""integration time constant? s (s (0). In addition each cell, at. 
each time n and independently o� other times and other cells, can 
receive a random amount. X o� ""spontaneous excitatory input?. 
n 
The variable X can have a general distribution; however, �or 
n 
simplicity we suppose here that. it. assumes only one o� two values: 
b or O, with probabilities p and 1-p respectively. (We 
suppose that. b ('0, so that. the spontaneous ""assist? itsel� is 
insu��icient. �or �iring.) The above quantities enter into the 
�ollowing firin rule: a cell will fire at. time n if it_ is not. 
prevented by rules (i') and (ii') and i� the total number of inputs 
from other cells, received during the integration ""window"" lasting 
between times n-s+l and n inclusive, plus the assist. X n, 
equals or exceeds the threshold O. 
(The propagation speeds v I and V E and the neighborhoods 
are here given leftsright symmetry merely �or ease in exposition.) 
Fig. 3. Hessage travel in complex model: 
(i')-(iv'). 
see text. rules 
Will such a model display phase transition at. some critical 
value of the spontaneous firir frequency p ? The dependence of 
responses upon the initial conditions and upon the various 
parameters is intricate and will a�fect the answer. We briefly 
discuss here conditions under which the answer is again yes. 
(1) For a given configuration of parameters and a given 
initial stimulation (of a stretch of cont.iuous cells) we compare 
the development. of the model's firing response first. to that. of an 
auxiliary ""more active"" system: Suppose that. L now denotes the 
n 
distance at. time n between the left and right-most cells which 
are either firing or in refractory mode. Because no cell can fire 
without_ influence �rom others and because such influence travels at_ 
a given speed, there is a maximal amount_ (D) whereby L can 
n+l 
exceed L n. There is also a maximum probability Q(p) - which 
197 
depends on the spontaneous firing parameter p - that. Ln+ 1  L n 
(whatever n). 'We can compare L with a random walk ""A"" 
n n 
defined so that_ An+ 1 = An+D with prohability Q(p) and 
� is 
An+ 1 = An-1 with probability 1-Q(p) At each transition, A n 
more likely to increase than L n. Hence L n is more likely to die 
out. than A n . In the many cases where Q(p) tends to zero as p 
does, the average step size of A n (viz., DQ(p)+(-1)(1-Q(b))) 
will become negative for p below a ""critical"" value Pa' Thus, 
as in the ""simple"" model above, the probability of ultimate die-out 
for the A n , hence also for the L of the complex model will be 
n ' 
1 when 0  p < Pa' 
(2) There will be a phase transition for the complex model if 
its probability of die out.- given the same parameters and initial 
stimulation is in (1) - becomes less than 1 for some p values 
with Pa < p < 1. Comparison of the complex process with a simpler 
""less active"" process is difficult. in general. However, there are 
parameter configurations which ultimately can channel all or part. 
of the firing activity into a (space-time) sublattice analgous to 
that_ in Fig. 1. Fig. 4 illustrates such a case. For p 
sufficiently large there is positive probability that. the activity 
will not. die out, just as in the ""simple"" model. 
Fig. 4. Activity on a sublattice. (Parameter values: J=2, e=6, 
MR=2, Mi=I, VR=Vi=I, 0--3, s=2, and b=l.) Rectangular 
areas indicate refraction/inhibition; diagonal lines, 
excitatory influence. 
198 
LARGE FINITE ARRAYS 
Consider now a large finite array of N cells, again as 
sketched in Fig. 3 ; and operating according to rules similar to 
{i'}-{iv'} above, with suitable modifications near the edges. 
Appropriately encoded, its activity can be described by a (huge} 
Markov transition matrix, and - depending on the initial 
stimulation - must. tend 5 to one of a set. of steady-state 
distributions over firing patterns. For example, (a) if N is 
odd and the rules are those for Fig. 1, then extinction is the 
unique steady state, for any p < 1 (since the L form a random 
n 
walk with ""reflecting"" upper barrier}. But, (} if N is even 
and the cells are arranged in a ring, then, for any p with 
0 < p < 1, both extinction and an alternate flip-flop firing 
pattern of period 2 are ""traps"" for the system - with relative long 
run probabilities determined by the initial state. See the dashed 
line in Fig. 2A for the extinction probability in the () case, 
and in Fig. 2B for the expected time until hitting a trap in the 
(a) case (p<�) and the () case. 
What qualitative properties related to phase transition and 
critical p values carry over from the infinite to the finite 
array case? The (a) example above shows that lon term activity 
may now be the same for all 0 < p < I but_ that parameter 
intervals can exist. whose key feature is a particularly large 
expected time before the system hits a trap. (Again, the critical 
region can depend upon the initial stimulation.) Prior to being 
trapped the system spends its time among many states in a kind of 
""metastable"" equilibrium. (We have some preliminary theoretical 
results on this conditional equilibrium and on its relation to the 
infinite array case. See also Ref. 6 concerning time scales for 
which certain corresponding infinite and finite stochastic automata 
systems display similar behavior.) 
Simulation of models satisfying rules (i')-(iv') does indeed 
display large changes in length of firing activity corresponding to 
parameter changes near a critical value. See Fig. 5 for a typical 
example: As a function of p, the expected time until the system 
is trapped (for the given parameters) rises approximately linearly 
in the interval .05<p<.12, with most. runs resulting in extinction 
- as is the case in Fig. 5A at. time n=115 (for p=.10). But. for 
p>.15 a relatively rigid patterning sets in which leads with high 
probability to very long runs or to traps other than extinction - 
as is the case in Fig. 5B (p=.20) where the run is arbitrarity 
truncated at. n--525. (The patterning is highly influenced by the 
large size of the excitatory neighborhoods.) 
199 
A 
Fig. 5. Space time firing patterns for one configuration of basic 
parameters. (There are 200 cells; j=2, e=178, MR=10, 
Mi=9, VR=Vi=7, =25, s=2, and b=12; 50 are stimulated 
initially.) A: p=.10. B: p=.20. 
CONCLUSION 
Mechanisms such as neuromodulators, which can (temporarily) 
bring spontaneous �iring levels - or synapt.ic e��icacies, or 
average �iring thresholds, or other similar parameters - to 
near-critical values, can thereby induce large ampli�ication o� 
response activity to selected stimuli. The repertoire o� such 
responses is an important. aspect_ o� the system's �unction. 
200 
Acknowledgement: Thanks to C. Bezuidenhout and J. Kane for help 
with simulations.
References
M. Wilson, J. Bower, J. Chover, L. Haberly, 16th Neurosci. 
Soc. Mtg. Abstr. 370.11 (1986). 
R. D. Traub, R. Hiles, R.K.S. Wong, 16th Neurosci. Soc. Htg. 
Abstr. 196.12 (1986). 
A. Selverston, this conference, also, Hodel Neural Networks 
and Behavior, Plenum (1985); E. Harder, S. Hooper, J. Eisen, 
Synaptic Function, Wiley (1987) p.305. 
E.g.: W. Kinzel, Z. Phys. B55, p. 231 (1985); A. Noest. 
Phys� Rev. Let_. 57(1), p. 90 (1986); R. Durrett (to appear); 
C. Carpenter, J. Di��. Eqns. 23, p.335 (1977); C. Ermentraut, 
S. Cohen, Biol. Cyb. 34, p.137 (1979); H. Wilson, S. Cowan, 
Biophys. J. 12 (1972). 
W. Feller, An Introd. to Prob. Th'y. and Appl'ns. I. Wiley 
(1S) Ch. 14, 15. 
T. Cox and A. Craven (to appear). 
", transit neural network chover wi simul cortic subnetwork evidenc like phase transit respect key demonstr transit inde analog array relat array model classic describ may qualit chang behavior key system paramet pass critic one neural network actual manner record subsequ suppos one repeat valu paramet valu pc activ tend much higher valu analog statist may critic boil one say neural undergo intracellular phase parametr membran well consid intercellular phase sever detail cortic cortex hippocampu pitiform paramet repres frequenc high amplitud epsp receiv typic pyramid paramet ratio inhibitori cell mechan could approach valu paramet brought intrigu neuromodul play role certain temporarili rais depress synapt efficaci possibl interest consequ could approach system good effect could network heighten fire respons stimulu mean faster chang synapt bring faster memori longer activ also mean faster access bad american institut physic depend paramet transit relat neural network studi mani author look categori network model abstract cortex set show phase transit would mani involv prolong cellular activ respons prolong activ take place analog cellular array evidenc also comput shall examin pattern activ system tend silenc high long energi stabl rate rate would zero model time proceed discret complic set comparison time quantiz becom paramet probabl time given cell experi certain caus cell conjunct mani excitatori input cell reach relat paramet threshold valu averag valu give model refractori period cell can not fire local inhibit fire cell near well look limit case mani cell classic phase transit appear sharp model consid infinit linear array similar cell follow pictur cell fire time time cell time cell silent time one fire time cell time probabl fire independ similar decis time fire time cell fire fire cell repres time proce fill squar sampl signal propag speed one cell fire threshold valu stimul one cell time necessarili die go answer note simpl case pattern time altern stretch cell call probabl sponten assist end assist end probabl one end finit altern stretch valu constitut among intuit simpl analysi lead probabl decreas greater increas averag taken random walk neg ultim reach fire respons die even higher valu sketch probabl function averag die show classic exampl phase infinit critic probabl ultim die reach finit array averag time reach solid curv refer infinit finit model infinit linear array sketch describ much gener hope cell receiv excitatori fire time preced time feedback cell local number cell immedi given cell fire receiv excitatori input time cell inhibitori neighborhood fire time unit preced time would take messag travel speed cell per unit rule local shuntstyp cell number cell immedi left inhibitori cell neighborhood certain fire caus unit impuls cell speed cell per receiv subject rule cell share valu time addit time independ time random excitatori variabl gener suppos assum one two probabl spontan quantiti enter cell fire time rule total number input receiv integr last time plu exce threshold propag speed neighborhood given leftsright symmetri mere eas hessag travel complex rule model display phase transit critic spontan frequenc depend upon initi condit upon variou intric briefli condit answer given configur paramet given stimul stretch compar fire respons suppos denot time cell either fire refractori cell fire influenc other influenc travel given maxim wherebi also maximum probabl spontan fire paramet compar random walk prohabl probabl like increas henc like die mani case tend zero averag step size becom neg valu model probabl ultim henc also complex model phase transit complex model probabl die given paramet initi becom less valu pa comparison complex process simpler process configur ultim channel fire activ sublattic analg illustr larg posit probabl activ die activ rectangular indic diagon finit array larg finit array oper accord rule similar suitabl modif near activ describ transit depend initi tend one fire rule extinct steadi form random upper even cell arrang extinct altern fire period system rel long probabl determin initi see dash extinct probabl expect time hit trap case qualit properti relat phase transit valu carri infinit finit exampl show term activ paramet whose key featur particularli larg time system hit critic depend upon initi prior system spend time among mani state kind preliminari theoret condit equilibrium relat array see also concern time scale certain correspond infinit finit stochast automata display similar model satisfi rule inde larg chang length fire activ correspond chang near critic see typic function expect time system trap given rise approxim linearli interv run result extinct case time rel rigid pattern set lead high long run trap extinct case run arbitrar pattern highli influenc size excitatori space time fire pattern one configur basic stimul spontan level similar paramet therebi induc larg activ select repertoir thank bezuidenhout kane help hodel neural network plenum wiley durrett wiley cox craven,1
21,21,"201 
NEW HARDWARE FOR MASSIVE NEURAL NETWORKS 
D. D. Coon and A. G. U. Perera 
Applied Technology Laboratory 
University of Pittsburgh 
Pittsburgh, PA 15260. 
ABSTRACT 
Transient phenomena associated with forward biased silicon p+ - n - n + struc- 
tures at 4.2K show remarkable similarities with biological neurons. The devices play 
a role similar to the two-terminal switching elements in Hodgkin-Huxley equivalent 
circuit diagrams. The devices provide simpler and more realistic neuron emulation 
than transistors or op-amps. They have such low power and current requirements 
that they could be used in massive neural networks. Some observed properties of 
simple circuits containing the devices include action potentials, refractory periods, 
threshold behavior, excitation, inhibition, summation over synaptic inputs, synaptic 
weights, temporal integration, memory, network connectivity modification based on 
experience, pacemaker activity, firing thresholds, coupling to sensors with graded sig- 
nal outputs and the dependence of firing rate on input current. Transfer functions 
for simple artificial neurons with spiketrain inputs and spiketrain outputs have been 
measured and correlated with input coupling. 
INTRODUCTION 
Here we discuss the simulation of neuron phenomena by electronic processes in 
silicon from the point of view of hardware for new approaches to electronic processing 
of information which parallel the means by which information is processed in intelli- 
gent organisms. Development of this hardware basis is pursued through exploratory 
work on circuits which exhibit some basic features of biological neural networks. Fig. 1 
shows the basic circuit used to obtain spiketrain outputs. A distinguishing feature 
of this hardware basis is the spontaneous generation of action potentials as a device 
physics feature. 
Figure 1: Spontaneous, 
neuronlike spiketrain 
generating circuit. The 
spikes are nearly equal in 
amplitude so that 
information is contained in 
the frequency and 
temporal pattern of the 
spiketrain generation. 
@ American Institute of Physics 1988 
202 
TWO-TERMINAL SWITCHING ELEMENTS 
The use of transistor based circuitry 1 is avoided because transistor electrical 
characteristics are not similar to neuron characteristics. The use of devices with 
fundamentally non-neuronlike character increases the complexity of artificial neural 
networks. Complexity would be an important drawback for massive neural networks 
and most neural networks in nature achieve their remarkable performance through 
their massive size. In addition, transistors have three terminals whereas the switching 
elements of Hodgkin-Huxley equivalent circuits have two terminals. Motivated in 
part by Hodgkin-Huxley equivalent circuit diagrams, we employ two-terminal p+ - 
n - n + devices which execute transient switching between low conductance and high 
conductance states. (See Fig. 2) We call these devices injection mode devices (IMDs). 
In the ""OFF-STATE"", a typical current through the devices is ~ 100fA/mm 2, and 
in the ""ON-STATE"" a typical current is ~ 10mA/mm 2. Hence this device is an 
extremely good switch with a ON/OFF ratio of 10 ll. As in real neurons , the current 
in the device is a function of voltage and time, not only voltage. The devices require 
cryogenic cooling but this results in an advantageously low quiescent power drain of 
< I nanowatt/cm  of chip area and the very low leakage currents mentioned above. 
In addition, the highly unique ability of the neural networks described here to operate 
in a cryogenic environment is an important advantage for infrared image processing 
at the focal plane (see Fig. 3 and further discussion below). Vision systems begin 
processing at the focal plane and there are many benefits to be gained from the 
vision system approach to IR image processing. 
= 
Figure 2: Switching element 
in Hodgkin-Huxley equivalent cir- 
cuits. 
I R 
Vco > 
c 
 +  I/Pulse 
VD Output 
Figure 3: Single stage conversion of 
infrared intensity to spiketrain fre- 
quency with a neuron-like semicon- 
ductor device. No pre-amplifiers 
are necessary. 
Coding of graded input signals (see Fig. 4) such as photocurrents into ac- 
tion potential spike trains with millimeter scale devices has been experimentally 
demonstrated s with currents from I A down to about I picoampere with coding 
noise referred to input of < 10 femtoamperes. Coding of much smaller current levels 
should be possible with smaller devices. Figure 5 clearly shows the threshold behavior 
of the ]]ID. For devices studied to date, a transition from action potential output to 
graded signal output is observed for input currents of the order of 0.5 picoamperes 1.s 
2O3 
VDC 
OUTPUT 
' 4 
z lO 
o 
LLI 
2 
rY 10 
Ld 
v 
Ld 
 lO 0 
rY 
Ld 
 lO -2 
CURRENT (AMPERES) 
Figure 4: Coding of NIR-VISIBLE-UV intensity into firing frequency of a spiketrain 
and the experimentally determined firing rate rs. the input current for one device. 
Note that the dynamic range is about 10 7 . 
I I I I I I I I I I 
500/z$/div 
Figure 5: Illustration of the threshold firing of the 
device in response to input step functions. 
This transition is remarkably well described in yon Neumann's discussion 5,6 of 
the mixed character of neural elements which he relates to the concept of sublimi- 
nal stimulation levels which are too low to produce the stereotypical all-or-nothing 
response. Neural network modelers frequently adopt viewpoints which ignore this 
interesting mixed character. The yon Neumann viewpoint links the mixed character 
to concepts of nonlinear dynamics in a way which is not apparent in recent neural 
network modeling literature. The scaling down of IMD size should result in even 
lower current requirements for all-or-nothing response. 
DEVICE PHYSICS 
Recently, neuronlike action potential transients in ]]VIDs have been the subject 
of considerable research s,4,7,s,9,t�,lt,t2,1s. In the simple circuits of Fig. 1, the IMD 
gives rise to a spontaneous neuronlike spiketrain output. Between pulses, the IMD is 
polarized in the sense that it is in a low conductance state with a substantial voltage 
occurring across it, even though it is forward biased. The low conductance has been 
attributed to small interfacial work functions due to band offsets at the n+-n and 
p+-n interfaces s. 
Low temperatures inhibit thermionic injection of electrons and holes into the 
n-region from the n+-layer and p+-layer impurity bands TM. Pulses are caused by 
204 
switching to depolarized states with low diode potential drops and large injection 
currents which are believed to be triggered by the slow buildup of a small thermionic 
injection current from the n+-layer into the n-region. The injection current can cause 
impact ionization of n-region donor impurities resulting in an increasingly positive 
space charge which further enhances the injection current to the point where the IMD 
abruptly switches to the low conductance state with large injection current. Switching 
times are typically under lOOns. Charging of the load capacitance C� cuts off the 
large injection current and resets the diode to its low conductance state. The load 
capacitor C� then discharges through R�. During the C� discharging time constant 
R�C� the voltage across the ]MD itself is low and therefore the bias voltage would 
have to be raised substantially to cause further firing. Thus, R�C� is analogous to 
the refractory period of a neuron. The output pulses of an ]MD generally have about 
the same amplitude while the rate of pulsing varies over a wide range depending on 
the bias voltage and the presence of electromagnetic radiation. 7,s,1� 
DETECTOR ARRAY 
TRANSIENT SENSING 
Figure 6: Illustrative 
laminar architecture 
showing stacked wafers in 
3-dimensions. 
REAL TIME PARALLEL ASYNCHRONOUS PROCESSING 
The devices described here could form the hardware basis for a parallel asyn- 
chronous processor in much the same way that transistors form the basis for digital 
computers. The devices could be used to construct networks which could perform real 
time signal processing. Pulse propagation through silicon chips (parallel firethrough, 
see Fig. 7) as opposed to the lateral planar propagation in conventional integrated 
circuits has been proposed? This would permit the use of laminar, stacked wafer 
architectures. See Fig. 6. 
Such architectures would eliminate the serial processing limitations of stan- 
dard processors which utilize multiplexing and charge transfer. There are additional 
advantages in terms of elimination of pre-amplifiers and reduction in power consump- 
tion. The approach would utilize the low power, low noise devices 1� described here 
to perform input signal-to-frequency conversion in every processing channel. 
POWER CONSUMPTION FOR A BRAIN SCALE SYSTEM 
The low power and low current requirements together with the electronic sim- 
plicity (lower parts-count as compared with transistor and op-amp approaches) and 
205 
INPUTS 
p Si wafer 
P $i wafer 
p Si wafer 
p Si wafer 
p Si wafer 
p Si wafer 
Figure 7: Schematic illus- 
tration of the signal flow 
pattern through a real time 
parallel asynchronous pro- 
cessor consisting of stacked 
silicon wafers. 
OUTPUTS 
the natural emulation of neuron features means that the approach described here 
would be especially advantageous for very large neural networks, e.g. systems com- 
parable to supercomputers in which power dissipation and system complexity are im- 
portant considerations. The power consumption of large scale analog t6 and digital t7 
systems is always a major concern. For example, the power consumption of the 
CRAY XMP-48 is of the order of 300 kilowatts. For the devices described here, the 
power consumption is very low. For these devices, we have observed quiescent power 
drains of about I nW/cm 2 and pulse power consumption of about 500 nJ/pulse[cm:. 
We estimate that a system with 10  active 10/m x 10/m elements (comparable 
to the number of neurons in the brain s) all firing with an average pulse rate of 1 
KHz (corresponding to a high neuronal firing rate 5) would consume about 50 watts. 
The quiescent power drain for this system would be 0.1 milliwatts. Thus, power 
(P) requirements for such an artificial neural network with the size scale (10 l pulse 
generating elements) of the human brain and a range of activity between zero and 
the maximum conceivable sustained activity for neurons in the brain would be 0.1 
milliwatts < P < 50 watts for 10 micron technology. For comparison, we note that 
yon Neumann's estimate for the power dissipation of the brain is of order 10 to 25 
watts. 5,6 Fabrication of a 10 t element 10/m artificial neural network would require 
processing of about 1500 four inch wafers. 
NETWORK CONNECTIVITY 
For a network with coupling between many ]VID's s we have shown 4 that 
dVi N 
CiRi-- - Vi-  wijrj (Vj) - Rili (1) 
j=l 
where Vi is the voltage across the diode and the input capacitance Ci of the i-th 
network node, Ri represents a leakage resistance in parallel with Ci, and Ii represents 
an external current input to the i-th diode. ii-1,2,3, ..... label different network nodes 
and Tij incoporates coupling between network elements. Equation I has the same 
form as equations which occur in the Hopfield model 2�,''23 for neural networks. 
Sejnowski has also discussed similar equations in connection with skeleton filters in 
2O6 
INPUTS 
� t R l V 
TRANSMISSION LINE 
OUTPUTS 
Io 
o 
o 
o 
RL 
_ 
Figure 8: a) Main features of a typical neuron from Kandel and Schwartz? b) Our 
artificial neuron, which shows the summation over synaptic inputs and fan-out. 
the brain.24,25 Nonlinear threshold behavior of IMD's enters through F(V) as it does 
in the neural network models. 
In Fig. 8-b a range of input capacitances is possible. This range of capacitances 
is related to the range of possible synaptic weights. The circuit in Fig. 8 accomplishes 
pulse height discrimination and each pulse can contribute to the charge stored on 
the central node capacitance C. The charge added to C during each input pulse is 
linearly related to the input capacitance except at extreme limits. The range of input 
capacitances for a particular experiment was .002/zF to .2/zF which differ by a factor 
of about 100. The effect of various input capacitance values (synaptic weights) on 
input-output firing rates is shown in Fig. 9. Also the Fig. 8-b shows many capacitive 
inputs/outputs to/from a single IMD. i.e. fan-in and fan-out. For pulses which arrive 
at different inputs at about the same time, the effect of the pulses is additive. The 
time within which inputs are summed is just the stored charge lifetime. Summation 
over many inputs is an important feature of neural information processing. 
EXCITATION, INHIBITION, MEMORY 
Both excitatory and inhibitory input circuits are shown in Fig. 10. Input pulses 
cause the accumulation of charge on C in excitatory circuits and the depletion of 
charge on C in inhibitory circuits. Charge associated with input spiketrains is inte- 
grated/stored on C. The temporally integrated charge is depleted by the firing of the 
IMD. Thus, the storage time is related to the firing rate. After an input spiketrain 
raises the potential across C to a value above the firing threshold, the resulting IMD 
207 
Figure 9: Output pulse 
rate vs. the input 
pulse rate for different 
input capacitance 
values Ci values 
(o) 
INPUT 
o 
Va pC 
INPUT 
Voc 
OUTPUT 
 OU?UT 
CL RL 
Figure 10: Circuits which incorporate rec- 
tifying synaptic inputs. a) an excitatory 
input. b) an inhibitory input. 
output spiketrain codes the input information. The output firing rate is linearly re- 
lated to the input firing rate times the synaptic coupling strength (linearly related to 
Ci). See Fig. 9. If the input ceases, then the potential across C relaxes back to a value 
just below the firing threshold. When not firing, the IMD has a high impedance. If 
there is negligible leakage of charge from C, then V can remain near VT (threshold 
voltage) for a long time and a new input signal will quickly take the IMD over the 
firing threshold. See Fig. 11. We have observed stored charge lifetimes of 56 days and 
longer times may be acheivable. The lifetime of charge stored on C can be reduced 
by adding a resistance in parallel with C. 
From the discussion of integration, we see that long term storage of charge on C 
is equivalent to long term memory. The memory can be read by seeing if a new input 
pulse or spiketrain produces a prompt output pulse or spiketrain. The read signal 
input channel in Fig. 8-b can be the same as or different from the channel which 
resulted in the charge storage. In either case memory would produce a change in the 
pattern of connectivity if the circuit was imbedded in a neural network. Changes in 
patterns of connectivity are similar to Hebb's ruie considerations 26 in which memory 
is associated with increases in the strength (weight) of synaptic couplings. Frequently, 
208 
Input Potential 
Figure 11: Firing rate vs. the bias voltage. 
The region where the firing is negligible is 
associated with memory. The state of the 
memory is associated with the proximity 
to the firing threshold. 
the increase in synaptic weights is modeled by increased conductance whereas in the 
circuits in Figs. 10(a) and 8-b memory is achieved by integration and charge storage. 
Note that for these particular circuits, the memory is not eraseable although volatile 
(short term) memory can easily be constructed by adding a resistor in parallel with 
C. Thus, a continuous range of memory lifetimes can be achieved. 
2-D PARALLEL ASYNCHRONOUS CHIP-TO-CHIP TRANSMISSION 
For many ]]VID's the output pulse heights for a circuit like that in Fig. 1 are 
>3 volts. Thus, output from the first stage or any later stage of the network could 
easily be transmitted to other parts of an overall system. Two-dimensional arrays 
of devices on different chips could be coupled by indium bump bonding to form 
the laminar architecture described above. Planar technology could be used for local 
lateral interconnections in the processor. (See Fig. 7) In addition to transmission of 
electrical pulses, optical transmission is possible because the pulses can directly drive 
LED's. 
Emerging GaAs-on-Si technology is interesting as a means of fabricating two 
dimensional emitter arrays. Optical transmission is not necessary but it might be 
useful (A) for processed image data transfer, (B) for coupling to an optical proces- 
sor, or (C) to provide 2-D optical interconnects between chips bearing 2-D arrays of 
p+ - n - n + diodes. Note that with optical interconnects between chips, the circuits 
employed here would be internal receivers. The p-i-n diodes employed in the present 
work would be well suited to the receiver role. An interesting possibility would en- 
tail the use optical interconnects between chips to achieve local, lateral interaction. 
This would be accomplished by having each optical emitter in a 2-D array broadcast 
locally to multiple receivers rather than to a single receiver. Similarly, each receiver 
would have a reeeptive field extending over multiple transmitters. It is also possible 
that an optical element could be placed in the gap between parallel transmitter and 
receiver planes to structure, control or alter 2-D patterns of interconnection. This 
would be an alternative to a planar technology approach to lateral interconnection. 
If the optical elements were active then the system would constitute a hybrid opti- 
cal/electronic processor, whereas if passive optical elements were employed, we would 
regard the system as an optoelectronic processor. In either case, we picture the pro- 
cessing functions of temporal integration, spatial summation over inputs, coding and 
pulse generation as residing on-chip. 
209 
ACKNOWLEDGEMENTS 
The work was supported in part by U.S. DOE under contract #DF_,-ACO2- 
80ER10667 and NSF under grant # ECS-8603075. 
References 
[1] L. D. Harmon, Kybernetik 1, 89 (1961). 
[2] A. L. Hodgkin and A. F. Huxley, J. Physiol 117, 500 (1952). 
[3] D. D. Coon and A. G. U. Perera, Int. J. Electronics 63, 61 (1987). 
[4] K. M. S. V. Banclara, D. D. Coon and R. P. G. Karunasiri, In&ared Transient 
Sensing, to be published. 
[5] J. yon Neumann, The Computer and the Brain, Yle University Press, New 
Haven and London, 1958. 
[6] J. yon Neumann, Collected Works, Pergamon Press, New York, 1961. 
[7] D. D. Coon and A. G. U. Perera, Int. J. Infrared and Millimeter Waves 7, 1571 
(1986). 
[8] D. D. 
[9] D. D. 
[10] D. D. 
[11] D. D. Coon 
[12] D. D. Coon 
[13] K. M. S. V. 
961 (1987). 
Coon and S. D. Gunspals, 
Coon, S. N. Ma and A. G. 
Coon and A. G. U. Peters, 
and A. G. U. Peters, 
and A. G. U. Peters, 
Bandata, D.D. Coon 
J. Appl. Phys 57, 5525 (1985). 
U. Peters, Phys. Rev. Let. 58, 1139 (1987). 
Applied Physics Letters 51, 1711 (1987). 
Solid-State Electronics 29, 929 (1986). 
Applied Physics Letters 51, 1086 (1987). 
and R. P. G. Karunasiri, Appl. Phys. Lett 51, 
[14] Y. N. Yang, D. D. Coon and P. F. Shepard, Applied Physics Letters 45, 752 
(1984). 
[15] 
[17] 
D. D. Coon and A. G. U. Perera, Int. J. IR and Millimeter Waves 8, 1037 (1987). 
M. A. Sivilotti, M. R. Emerling and C. A. Mead, VLSI Architectures/'or Im- 
plementation of NeurM Networks, Neural Networks for Computing, A.I.P., 
1986, pp. 408-413. 
R. W. Keyes, Proc. IEEE 63, 740 (1975). 
E. R. Kandel and J. H. Schwartz, Principles of NeurM Science, Elsevier, New 
York, 1985. 
210 
[19] E. R. Kandel and J. H. Schwartz, Principles of Neural Science, Elsevier, New 
York, 1985, page 15, Reproduced by permission of Elsevier Science Publishing 
Co., N.Y.. 
[20] J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A 81, 3088 (1984). 
[21] J. J. Hopfield and D. W. Tank, Biol. Cybern 52, 141 (1985). 
[22] J. J. Hopfield and D. W. Tank, Science 233,625 (1986). 
[23] D. W. Tank and J. J. Hopfield, IEEE. Circuits Syst. CAS-33, 533 (1986). 
[24] T. J. Sejnowski, J. Math. Biology 4, 303 (1977). 
[25] T. J. Sejnowski, Skeleton Filters in the Brain, Lawrence Erlbaum, New Jersey, 
1981, pp. 189-212, edited by G. E. Hinton and J. A. Anderson. 
[26] J. L. McClelland, D. E. Rumelhart and the PDP research group, Parallel Dis- 
tributed Processing, The MIT Press, Cambridge, Massachusetts, 1986, two vol- 
umes. 
", hardwar massiv neural network coon perera technolog laboratori pittsburgh pa phenomena associ forward bias silicon show remark similar biolog devic play role similar switch element equival devic provid simpler realist neuron emul transistor low power current requir could use massiv neural observ properti circuit contain devic includ action refractori summat synapt synapt tempor network connect modif base pacemak fire coupl sensor grade output depend fire rate input transfer function simpl artifici neuron spiketrain input spiketrain output correl input discuss simul neuron phenomena electron process point view hardwar new approach electron process inform parallel mean inform process develop hardwar basi pursu exploratori circuit exhibit basic featur biolog neural basic circuit use obtain spiketrain distinguish featur hardwar basi spontan gener action potenti devic spiketrain nearli equal contain frequenc pattern american institut physic switch element use transistor base circuitri avoid transistor electr similar neuron use devic charact increas complex artifici neural complex would import drawback massiv neural network neural network natur achiev remark perform massiv transistor three termin wherea switch equival circuit two motiv equival circuit employ devic execut transient switch low conduct high call devic inject mode devic typic current devic typic current henc devic good switch ratio real neuron current devic function voltag devic requir cool result advantag low quiescent power drain chip area low leakag current mention highli uniqu abil neural network describ oper cryogen environ import advantag infrar imag process focal plane discuss vision system begin focal plane mani benefit gain system approach ir imag switch element equival output singl stage convers intens spiketrain grade input signal photocurr potenti spike train millimet scale devic experiment current picoamper code refer input code much smaller current level possibl smaller figur clearli show threshold behavior devic studi transit action potenti output signal output observ input current order picoamper code intens fire frequenc spiketrain experiment determin fire rate input current one dynam rang illustr threshold fire respons input step transit remark well describ yon discuss mix charact neural element relat concept stimul level low produc stereotyp neural network model frequent adopt viewpoint ignor mix yon neumann viewpoint link mix charact concept nonlinear dynam way appar recent neural model scale imd size result even current requir physic neuronlik action potenti transient subject consider research simpl circuit imd rise spontan neuronlik spiketrain imd sens low conduct state substanti voltag across even though forward low conduct small interfaci work function due band offset interfac temperatur inhibit thermion inject electron hole impur band puls caus depolar state low diod potenti drop larg inject believ trigger slow buildup small thermion current inject current caus ioniz donor impur result increasingli posit charg enhanc inject current point imd switch low conduct state larg inject switch typic charg load capacit cut inject current reset diod low conduct load discharg discharg time constant voltag across low therefor bia voltag would rais substanti caus analog refractori period output puls gener amplitud rate puls vari wide rang depend bia voltag presenc electromagnet array sens illustr architectur stack wafer time parallel asynchron process devic describ could form hardwar basi parallel processor much way transistor form basi digit devic could use construct network could perform real signal puls propag silicon chip oppos later planar propag convent integr would permit use stack wafer see architectur would elimin serial process limit processor util multiplex charg addit term elimin reduct power approach would util low low nois devic describ perform input convers everi process consumpt brain scale system low power low current requir togeth electron compar transistor si wafer wafer si wafer si wafer si wafer si wafer schemat signal flow real time asynchron consist stack natur emul neuron featur mean approach describ especi advantag larg neural system supercomput power dissip system complex power consumpt larg scale analog digit alway major power consumpt order devic describ consumpt observ quiescent power puls power consumpt estim system activ element number neuron brain fire averag puls rate high neuron fire rate would consum quiescent power drain system would power requir artifici neural network size scale puls human brain rang activ zero maximum conceiv sustain activ neuron brain would watt micron note estim power dissip brain order fabric element artifici neural network would requir four inch connect network coupl mani shown vi wijrj rili vi voltag across diod input capacit ci ri repres leakag resist parallel ii repres extern current input label differ network node tij incopor coupl network equat equat occur hopfield model neural also discuss similar equat connect skeleton filter line main featur typic neuron kandel show summat synapt input nonlinear threshold behavior enter neural network rang input capacit rang capacit relat rang possibl synapt circuit accomplish height discrimin puls contribut charg store central node capacit charg ad input puls relat input capacit except extrem rang input particular experi differ factor effect variou input capacit valu fire rate shown also show mani capacit singl puls arriv differ input effect puls within input sum store charg summat mani input import featur neural inform memori excitatori inhibitori input circuit shown input puls accumul charg excitatori circuit deplet inhibitori charg associ input spiketrain tempor integr charg deplet fire storag time relat fire input spiketrain potenti across valu fire result imd output puls input rate differ capacit ci valu rl circuit incorpor synapt excitatori inhibitori spiketrain code input output fire rate linearli input fire rate time synapt coupl strength relat see input potenti across relax back valu fire imd high neglig leakag charg remain near vt long time new input signal quickli take imd see observ store charg lifetim day time may lifetim charg store reduc ad resist parallel discuss see long term storag charg equival long term memori read see new input spiketrain produc prompt output puls read signal channel differ channel charg either case memori would produc chang connect circuit imbed neural chang connect similar ruie consider memori associ increas strength synapt potenti fire rate bia region fire neglig state associ proxim fire increas synapt weight model increas conduct wherea memori achiev integr charg particular memori eras although volatil memori easili construct ad resistor parallel continu rang memori lifetim parallel asynchron transmiss mani output puls height circuit like output first stage later stage network could transmit part overal array devic differ chip could coupl indium bump bond form laminar architectur describ planar technolog could use local interconnect addit transmiss optic transmiss possibl puls directli drive technolog interest mean fabric two emitt optic transmiss necessari might process imag data coupl optic provid optic interconnect chip bear array note optic interconnect circuit would intern diod employ present would well suit receiv interest possibl would use optic interconnect chip achiev later would accomplish optic emitt array broadcast multipl receiv rather singl receiv reptiv field extend multipl also possibl optic element could place gap parallel transmitt plane control alter pattern altern planar technolog approach later optic element activ system would constitut hybrid wherea passiv optic element would system optoelectron either pictur function tempor spatial summat code gener resid work support part doe contract nsf grant kybernetik hodgkin physiol coon electron coon transient yon comput univers new yon collect pergamon new coon infrar millimet wave coon coon coon phi physic letter electron physic letter lett coon appli physic letter coon ir millimet wave emerl vlsi neural network ie kandel principl new kandel principl neural new page reproduc permiss elsevi scienc publish hopfield cybern hopfield scienc tank circuit biolog skeleton filter lawrenc new edit hinton rumelhart pdp research parallel mit two,0
22,22,"211 
ltI6H DENSITY ASSOCIATIVE ORIES 1 
Air Dembo 
Information Systems Laboratory, Stanford University 
Stanford, CA 94305 
Ofer Ze itouni 
Laboratory for Informat ion and Dec is ion Systems 
MIT, Cambridge, MA 02139 
ABSTRACT
A class of high density associative memories is constrcted, 
starting from a description of des ired properties those should 
exhibit. These properties include high capacity, oontrollable basins 
of attraction and fast speed of convergence. lortunately enough, the 
resulting memory is implementable by an artificial Neural Net. 
I I/fl!01) UCTION 
Most of the work on associative memories has been structure 
oriented! i.e., given a Neural architecture, efforts were directed 
towards the analysis of the resulting network. Issues like capacity, 
basins of attractions, etc. were the main objects to be analyzed of., 
e.g. [11, [21, [31, [41 and references there, among others. 
In this paper, we take a different approach! we start by 
explicitly stating the desired properties of the network, in terms of 
capacity, etc. Those requirements are given in terms of axioms (c.f. 
below). Then, we bring a synthesis method which enables one to design 
an architecture which will yield the des ired performance. 
Surprisingly enough, it turns out that one gets rather easily the 
following propert ies: 
(a) High capacity (unlimited in the continuous state-space case, 
bounded only by sphere-packing bounds in the discrete state 
case) . 
(b) Guaranteed basins of attractions in terms of the natural 
metric of the state space. 
(c) High speed of oonvergence in the guaranteed basins of 
attract ion. 
Moreover, it turns out that the architecture suggested below is the 
only one which satisfies all our axioms ('desired properties')! 
Our approach is based on defining a potential and following a 
descent algergrim (e.g., a gradient alger grim). The main design task 
is to construct such a potential (and, to a lesser extent, an 
implementation of the descent algorithm via a Neural network). In 
doing so, it turns out that, for reasons described below, it is useful 
to regard each desired memory location as a ""particle' in the state 
space. It is natural to require now the following requirement from a 
1An expanded version of this work has been submitted to Phys. Rev. A. 
This work was carried out at the Center for Neural Science, Brown 
Univers Sty. 
American Institute of Physics 1988 
212 
memory: 
(P1) The potential should be linear w.r.t. adding partic les in 
the sense that the potential of two particles should be the sum of the 
potentials induced by the individual particles (i.e., we do not allow 
interpart ioles interact ion). 
(P2) Particle locations are the only possible sites of stable 
memory 1coat ions. 
(P3) The system should be invariant to translations and 
rotations of the coordinates. 
We note that the last requirement is made only for the sake of 
simplicity. It is not essential and may be dropped without affecting 
the results. 
In the sequel, we construct a potential which satisfies the above 
requirements. We refer the reader to [5] for details of the proofs, 
OtC. 
Acknowledgements. We would like to thank Prof. L.N. Cooper and C.M. 
Baolmann for many fruitful discussions. In particular, section 2 is 
part of a joint work with them ([6]). 
2. HIGH DENSITY STORAGE MODEL 
In what follows we present a particular case of a method for the 
construction of a high storage density neural memory. We define a 
function with an arbitrary number of minima that lie at preassigned 
points and define an appropriate relaxation procedure. The general 
case in presented in [5]. 
Let l,...,m be a set of m arbitrary distinct memories in R N. 
The 'energy' function we viii use is: 
m 
1 
:i 
i=1 
(1) 
where we assume tloughout that N _} 3, L _} (N - 2), and Qi ) 0 and use 
1... [ to denote the Euclidean distance. Note that for L = 1, N=3, [ 
is the electrostatic potential induced by negative fixed particles 
with charges -Qi' This 'energy' function possesses global minima at 
l,...,m (where (i) ----) and has no local minima except at these 
points. A rigorous proof is presented in [5] together with the 
complete characterization of functions having this property. 
As a relaxation procedure, we can choose any dynamical system for 
which [ is strictly decreasing, uniformly in compacts. In this 
instance, the theory of dynamical systems guarantees that for almost 
any initial data, the trajectory of the system converges to one of the 
desired points l,...,m. However, to give concrete results and to 
further exploit the resemblanoe to electrostatic, consider the 
relaxat ion: 
213 
 = - = - i (ti[ - i I-(L+2) ( - Xi) 
i=1 
where for N=3, L=I, equation (2) describes the motion of a positive 
test pazticle in the electrostatic field  Eenerated by the neEative 
fixed chazEes -QI' ' ' ' '- -O at El' ' ' ' 'Era' 
Since the field  is just minus the Eradient of 5, it is clear 
that alon E trajectories  of (2), d/dt _{ 0, with equality only at the 
fixed points of (2), which are exactly the stationary points of 
Therefore, usinE (2) as the relaxation procedure, we can conclude 
that enterinE at any (0), the system converEes to a stationary point 
of . The space of inputs is part itioned into m domains of 
attraction, each one correspondin E to a different memory, and the 
boundaries (a set of measure zero), on which (0) will converEe to a 
saddle point of 5. 
We can now explain why  has no spurious local minima, at least 
� . Suppose  a 
for L=I, N=3 usinE elementary physical arEuments has 
spurious local minima at   l,...,m, then in a small neiEhborhood 
of  which does not include any of the i' the field  points towards 
. Thus� on any closed surface in that neiEhborhood, the inteEral of 
the normal inward component of .. is positive. However, this inteEral 
is just the total charEe included inside the surface, which is zero. 
Thus we arrive at a contradiction, so  can not be a local minimum. 
We now have a relaxation procedure, such that almost any (0) is 
attracted by one of the i' but we have not yet specified the shapes 
of the basins of attraction. By varyin E the charEes Qi' we can 
enlarEe one basin of attraction at the expense of the others (and vice 
versa) , 
]ven when all of the /t i are equal, the position of the 
cause (0) not to converEe to the closest memory, as emphasized in the 
example in fiE. 1. However, let r = minl_iij_%[ i - be the 
minimal distance between any two memories! then if It(0) - 
it can be shown that (0) will converEe to i' (provided that k = 
- 1). Thus, if the memories are densely packed in a hypersphere, by 
choosin E k larEe enouEh (i.e. enlarEin E the parameter L), converEence 
to the closest memory for any 'interest in E' input, that is an input 
(0) with a distinct closest memory, is Euaranteed. The detailed 
proof of the above property is Eiven in [5]. It is based on boundinE 
the number of _., ji, in a hypersphere of radius R(lr) around i' by 
[2R/r + 1] N, then boundinE the maEnitude of the field induced b,y any 
j, ji, on the bounda,] of such a hypersphere by (R-[(O)-i[)-IL+l), 
and finally inteEratinE to show that for i(0)_i[i C 
the converEence of (0) to i i is within finite time T, which behaves 
like 0 L+2 for L )) I and 0 { I and fixed. Intuitively the reason for 
214 
this behaviour is the short-range nature of the fields used in 
equation (2). Because of this. we also expect extremely low 
convergence rate for inputs (0) far away from all of the i' 
The radial nature of these fields suggests a 
way to overcome this difficulty. that is to 
increase the convergence rate from points very far 
away. without disturbing all of the aforementioned 
desirable properties of the model. Assume that we 
"" know in advance that all of the i lie inside some 
large hypersphere S around the o_rigin. Then. at 
any point  outside S. the field  has a positive 
projection radially into S. By'adding a long- 
2 range force to p. effective only outside of S. we 
can hasten the movement towards S. from points far 
away. without creating additional minima inside of 
', S. As an example the force (- for   S! 0 for 
, 7 � 4  � S) will pull any test input (0) to 
,, the boundary of S within the small finite time T  
� , 1/iS[. and from then on the system will behave 
inside S according to the original field h; 
Up to this point. our derivations e been 
for a continuous system. but from it we can deduce 
Figure 1 
a discrete system. We shall do this mainly for a 
R)) 1 and 5  1 clearer comparison between our high density memory 
model and the discrete version of Hopfield's 
model. Before continuing in that direction, note 
that our continuous system has unlimited storage 
o apac ity unlike flop field ' s cent inuous system, 
which Iike his disc fete model, has Iimit ed 
o ap ac ity. 
Nor the discrete system, assume that the i are composed of 
elements +1 and replace the Euclidean distance in (1) with the 
normalized Hamming distance Il - -I --0 [j=ll - jl. This places 
the vectors i on the unit hypersphere. 
The relaxation process for the discrete system will be of the 
type defined in Hopfield's model in [i] . Choose at random a 
component to be updated (that is, a neighbor ' of  such that 
[' -[ = 2/N), calculate the 'enersy' difference,  -- (-(), 
and only if [ ( 0, change this component, that is: 
i '9i sign([() - [()), () 
where () is the potential energy. in (1). Since there is a finite 
number of possible  vectors (2""), convergence in finite tie is 
guaranteed. 
This relaxation procedure is rigid since the movement is limited 
to points with components +1. Therefore, although the local minima of 
() defined in (2) are only at the desired points ii' the relaxation 
may et stuck at some  which is not a stationary point of (). 
However, the short range behaviour of the potential (), unlike the 
long-range behavior of the quadratic potential used by flopfield, gives 
215 
rise to results similar to those we have quoted for the continuous 
model (equation (1)). 
Speoifioally, let the stored memories l,...,m be separated from 
one another by hay ins at least pN different oomponents (0 ( p _( 1/2 
and p fixed), and let (0) asree up to at least one i with at most 
0pN errors between them (0 _( 0 ( 1/2, with 0 fixed), then (0) 
oonverses monotonioally to i by the relaxation prooedure siren in 
equation (3). 
This result holds independently of m, provided that N is larse 
enoush (typically, Np ln() -)1)and L is chosen so that _(ln({-) 
The proof is oonstuoted by bound in s the cummulative effeot of terms 
[ - it[ -L, ji, to the enersy differenoe $5 and showinS that it is 
dominaffed by [- ii[ -L. For details, we refer the reader asain to 
[51. 
Note the importance of this property: unlike the Hopfield model 
whioh is limited to m _( N, the sussested system is optimal in the 
sense of Information Theory, sinoe for every set of memories 
separated from eaoh other by a ltammin s distanoe pN, up to 1/2 pN 
errors in the input can be oorreoted, provided that N is larse and L 
properly ohosen. 
As for the oomplexity of the system, we note that the nonlinear 
operation a -L for a}0 and L inteser (whioh is at the heart of our 
system computat ionally)' is equivalent to e -Lln(a) and oan be 
implemented, therefore, by a simple electrical circuit composed of 
diodes, which have exponent ial input-output characteristics, and 
resisters, which can carry out the necessary multiplications (cf. the 
implementation of section 3). 
Further, since both [ii[ and [[ are held fixed in the discrete 
system, where all states are on the unit hypersphere, [ - i[ 2 is 
equivalent to the inner product of  and i' up to a constant. 
To conclude, the sussested model involves about m'N 
multiplications, followed by m nonlinear operation_s, and then 
additions. The orisinal model of flopfield involves N z multiplications 
and add it ions, and then N nonlinear operations, but is limited to 
m _( N. Therefore, whenever the flopfield model is applicable the 
complexity of both models is comparable. 
3. DPLF2NTATION 
We propose below one possible network which implements the 
discrete time and space version of the model described above. An 
implementation for the ocntinuous time case, which is even simpler, is 
also hinted. We point out that the implementation described below is 
by no means unique, (and maybe even not the simplest one). foreover, 
the 'neurons' used are artificial neurons which perform various tasks, 
as follows: There are (N+I) neurons which are delay elements, and 
pointwise non-linear functions (which may be interpreted as delay 
less, intermediate neurons). There are mB[ synaptic connections 
between those two layers of neurons. In addition, as in the Hopfield 
216 
model, we have at each iteration to specify (either deterministically 
or stochastically) which coordinate are we updating. To do that, we 
use an N dimensional 'control register' whose content is always a unit 
vectoz of [0, 1] N (and the location of the 'X' will denote the next 
coordiante to be changed). This vector may be varied from instant n 
to n + ! either by shift ('sequential coordinate update') or at 
random. 
Let Ai, i_(i(N be the i-th output of the '0ontrol' register, x i, 
_i(N and V be the (N+I) neurons taputs and x i = xi(1-2Ai) the 
corresponding outputs (where x, xs[+l,-1], as(0,1], but V is a real 
number), p,, l_j_m be the input of the j-th intermediate neuron 
(-1-(p,-l), Jq: :-(i-p,) -L be its output, and . .W_. i --u!J)/N be the 
i-th element of the j-th memory. 
The system's equations are: 
i ""' xi(! - 2Ai) 
! _ i - N (4a) 
N 
= wj 
i=! 
! _( j _< m (4b) 
qj - -(x - j)-L 
I _ j _ m (4c) 
V = qj (4d) 
j=! 
! 
s = t-sign(V - v)) 
(4e) 
x i <--x i + 83. ! < i -< N (4f) 
V <--V + $ (4g) 
The system is initialized by x i = xi(O) (the probe vector), and 
V -- + m. A block diagram of this sytem appears in Fig. 2. Note that 
we made use of N + m + I neurons and O(Nm) oonnections. 
As for the continuous time case (with memories on the unit 
sphere) we wiII get the equations: 
217 
x. + 2m Vx = LN W iq , 
 i j j 
N N 
j = N  jixl, 5 =  X, 
i=l i=1 
-(- + 1) 
qj -- (1 + 5 - 2fj) , 
! - i _4 N (3a) 
 _< j _< m (st,) 
  j J m (Sc) 
j=l 
with similar interpretation (here there is no 'control' register as 
all components are updated continuously). 
Control Register 
\ / / Intermediate 
' , \l/ ~ / Neurons 
I _  I-q , l/,_' w,, / It,l IT, Auxiliary Neurons 
.-dij"" 
' 7 2 
'--I_LJ - w.,.. I I lr,l 
s 
L._.egend 
l -,o 
Delay Unit (Neuron) 
 c=O 
Synoptic Switch (0 = i 2 c=l ) 
i--.. � Synoptic Swilch (O:{_ii c:O 
tc c:l ) 
li' ? ComputotionUn,t(O-1,2__(I-sign(i2-il ))) 
F_[igure 2. Neural Network Implementorion 
218 
REFERENCES 
Y.Y. Hopfleld, 'Neural Networks and Physical Systems with 
Emergent Collective Computational Abilities', Proc. Nat. Acad. 
Sci. U.S.A., Vol. 79 (1982), pp. 2554-2558. 
R.Y. McEliece, et al., 'The Capacity of the Hop field Associative 
Memory', IEEE' Trans. on Inf. Theory, Vol. IT-33 (1987), pp. 461- 
482. 
A. Dembo, 'On the Capacity of the Hop field Memory', submitted, 
IEEB Trans. on Inf. Theory. 
Kohonen, T., Self Organization and Associative Memory, Springer, 
Berlin, 1984. 
Dembo, A. and Zeitouni, 0., General Potential Surfaces and Neural 
Networks, submitted, Phys. Rev. A. 
Bachmann, C.M., Cooper, L.N., Dembo, A. and Zeitouni, 0., A 
relazation Model for Memory with high storage density, to appear, 
Proc. Natl. Ac. Science. 
", densiti associ dembo system stanford univers ca ze itouni informat ion dec ion system class high densiti associ memori descript de ire properti properti includ high oontrol basin attract fast speed memori implement artifici neural uction work associ memori structur given neural effort direct analysi result issu like main object analyz refer among take differ start state desir properti term requir given term axiom bring synthesi method enabl one design architectur yield de ire turn one get rather easili propert high capac continu bound discret state guarante basin attract term natur state high speed oonverg guarante basin turn architectur suggest one satisfi axiom approach base defin potenti follow algergrim gradient alger main design task construct potenti lesser descent algorithm via neural turn reason describ use regard desir memori locat state natur requir follow requir expand version work submit work carri center neural brown institut physic potenti linear ad partic le sens potenti two particl sum induc individu particl allow iol interact particl locat possibl site stabl system invari translat note last requir made sake essenti may drop without affect construct potenti satisfi refer reader detail would like thank cooper mani fruit section joint work high densiti storag model follow present particular case method high storag densiti neural defin arbitrari number minima lie preassign defin appropri relax gener present set arbitrari distinct memori function vi use assum qi use denot euclidean note electrostat potenti induc neg fix particl charg function possess global minima local minima except rigor proof present togeth character function relax choos dynam system strictli uniformli theori dynam system guarante almost initi trajectori system converg one point give concret result exploit resemblano consid equat describ motion posit pazticl electrostat field eener eativ ee field minu eradi clear alon trajectori equal point exactli stationari point relax conclud system ee stationari point space input part ition domain one correspondin differ set measur ee point explain spuriou local least suppos elementari physic eument local minima small ehborhood includ field point toward close surfac eral normal inward compon eral total ee includ insid arriv local relax almost one yet specifi shape basin varyin ee ee one basin attract expens other vice posit ee closest emphas let distanc two shown ee memori dens pack ee eh ein paramet eenc closest memori input distinct closest detail properti eiven base number hyperspher radiu around enitud field induc hyperspher final show eenc within finit time behav intuit reason behaviour natur field use also expect extrem low rate input far away radial natur field suggest overcom converg rate point far without disturb aforement properti assum know advanc lie insid hyperspher around point outsid field posit radial rang forc effect outsid hasten movement toward point far without creat addit minima insid exampl forc pull test input boundari within small finit time system behav accord origin field deriv continu deduc discret shall mainli clearer comparison high densiti memori discret version continu note continu system unlimit storag apac iti unlik flop field cent inuou iik disc fete iimit ed ap ac discret assum compos replac distanc ham distanc place vector unit relax process discret system defin model choos random updat neighbor calcul chang potenti sinc finit possibl vector converg finit relax procedur rigid sinc movement limit point compon although local minima defin desir point relax stuck stationari point short rang behaviour potenti unlik behavior quadrat potenti use give result similar quot continu let store memori separ anoth hay in least differ oompon let asre least one error monotonio relax prooedur siren result hold independ provid lars np chosen proof bound cummul effeot term enersi differeno refer reader asain import unlik hopfield model limit sussest system optim inform sino everi set memori eaoh ltammin distano input provid lars oomplex note nonlinear intes heart computat equival oan simpl electr circuit compos expon ial carri necessari multipl section sinc held fix discret state unit inner product sussest model involv follow nonlinear orisin model flopfield involv multipl add nonlinear limit whenev flopfield model applic model propos one possibl network implement time space version model describ ocntinu time even point implement describ mean mayb even simplest use artifici neuron perform variou neuron delay function may interpret intermedi synapt connect two layer hopfield iter specifi determinist coordin dimension whose content alway unit locat denot next vector may vari instant either shift coordin output taput output real input intermedi neuron element equat wj qj system initi probe block diagram sytem appear note made use neuron continu time case memori unit ii get vx ln iq similar interpret regist compon updat regist intermedi neuron auxiliari neuron unit switch synopt swilch neural network implementorion network physic system collect comput et capac hop field associ capac hop field self organ associ gener potenti surfac neural model memori high storag,2
23,23,"219 
Network Generality, Training Required, 
and Precision Required 
John S. Denker and Ben S. Wittner 
AT&T Bell Laboratories 
Holmdel, New Jersey 07733 
Keep your hand on your wa]let. 
-- Leon Cooper, 1987 
Abstract 
We show how to estimate (1) the number of functions that can be implemented by a 
particular network architecture, (2) how much ana]og precision is needed in the con- 
nections in the network, and (3) the number of training examples the network must see 
before it can be expected to form reliable genera]izations. 
Generality versus Training Data Required 
Consider the following objectives: First, the network should be very powerful and ver- 
satile, i.e., it should implement any function (truth table) you like, and secondly, it 
should learn easily, forming meaningful generalizations from a small number of training 
examples. Well, it is information-theoretica]ly impossible to create such a network. We 
will present here a simplified argument; a more complete and sophisticated version can 
be found in Denker eta]. (1987). 
It is customary to regard learning as a dynamica] process: adjusting the weights (etc.) 
in a single network. In order to derive the results of this paper, however, we take 
a different viewpoint, which we call the ensemble viewpoint. Imagine making a very 
large number of replicas of the network. Each replica has the same architecture as the 
original, but the weights are set differently in each case. No further adjustment takes 
place; the ""learning process"" consists of winnowing the ensemble of replicas, searching 
for the one(s) that satisfy our requirements. 
Training proceeds as follows: We present each item in the training set to every network 
in the ensemble. That is, we use the abscissa of the training pattern as input to the 
network, and compare the ordinate of the training pattern to see if it agrees with the 
actual output of the network. For each network, we keep a score reflecting how many 
times (and how badly) it disagreed with a training item. Networks with the lowest score 
are the ones that agree best with the training data. If we had complete confidence in 
 Currently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604 
American Institute of Physics 1988 
220 
the reliability of the training set, we could at each step simply throw away all networks 
that disagree. 
For definiteness, let us consider a typical network architecture, with No input wires and 
N! units in each processing layer l, for I E {1..-L}. For simplicity we assume NL = 1. 
We recognize the importance of networks with continuous-valued inputs and outputs, 
but we will concentrate for now on training (and testing) patterns that are discrete, 
with N = No bits of abscissa and NL = I bit of ordinate. This allows us to classify the 
networks into bins according to what Boolean input-output relation they implement, 
and simply consider the ensemble of bins. 
There are 22 possble bns. If the network architecture is completely general and 
powerful, all 22 functions will exist in the ensemble of bins. On average, one expects 
that each training item will throw away at most half of the bins. Assuming maximal 
efficiency, if m training items are used, then when m > 2 N there will be only one bin 
remaining, and that must be the unique function that consistently describes all the 
data. But there are only 2 N possible abscissas using N bits. Therefore a truly general 
network cannot possibly exhibit meaningful generalization -- 100% of the possible data 
is needed for training. 
Now suppose that the network is not completely general, so that even with all possible 
settings of the weights we can only create functions in 2 30 bins, where So << 2 N. We call 
So the initial entropy of the network. A more formal and general definition is given in 
Denker et al. (1987). Once again, we can use the training data to winnow the ensemble, 
and when m > So, there will be only one remaining bin. That function will presumably 
generalize correctly to the remaining 2 N - m possible patterns. Certainly that function 
is the best we can do with the network architecture and the training data we were given. 
The usual problem with automatic learning is this: If the network is too general, So 
will be large, and an inordinate amount of training data will be required. The required 
amount of data may be simply unavailable, or it may be so large that training would be 
prohibitively time-consuming. The shows the critical importance of building a network 
that is not more general than necessary. 
Estimating the Entropy 
In real engineering situations, it is important to be able to estimate the initial entropy 
of various proposed designs, since that determines the amount of training data that will 
be required. Calculating So directly from the definition is prohibitively difficult, but we 
can use the definition to derive useful approximate expressions. (You wouldn't want to 
calculate the thermodynamic entropy of a bucket of water directly from the definition, 
either.) 
221 
Suppose that the weights in the network at each connection i were not continuously 
adjustable real numbers, but rather were specified by a discrete code with bi bits. Then 
the totaJ number of bits required to specify the configuration of the network is 
B =  bi (1) 
Now the total number of functions that could possibly be implemented by such a network 
architecture would be at most 2 $. The actual number will always be smaller than this, 
since there are various ways in which different settings of the weights can lead to identical 
functions (bins). For one thing, for each hidden layer l E {1... L-l), the numbering of 
the hidden units can be permuted, and the polarity of the hidden units can be flipped, 
which means that 2 s� is less than 2 $ by a factor (among others) of I-It Nt! 2 N' � In 
addition, if there is an inordinately large number of bits bl at each connection, there 
will be many settings where small changes in the connection will be immaterial. This 
will make 2 s� smaller by an additional factor. We expect OSo/Obi  1 when bl is small, 
and OSo/Obi  0 when bi is large; we must now figure out where the crossover occurs. 
The number of ""useful and significant"" bits of precision, which we designate b*, typically 
scaJes like the logarithm of number of connections to the unit in question. This can be 
understood as follows: suppose there are N connections into a given unit, and an input 
signal to that unit of some size A is observed to be significant (the exact value of A 
drops out of the present caJculation). Then there is no point in having a weight with 
magnitude much larger than A, nor much smaller than A/N. That is, the dynamic 
range should be comparable to the number of connections. (This argument is not exact, 
and it is easy to devise exceptions, but the conclusion remains useful.) If only a fraction 
1/S of the units in the previous layer are active (nonzero) at a time, the needed dynamic 
range is reduced. This implies b*  log(N/S). 
Note: our calculation does not involve the dynamics of the learning process. Some 
numerical methods (including versions of back propagation) commonly require a number 
of temporary ""guard bits"" on each weight, as pointed out by Richard Durbin (private 
communication). Another log N bits ought to suffice. These bits are not needed after 
learning is complete, and do not contribute to So. 
If xve combine these ideas and apply them to a network with N units in each layer, fully 
connected, we arrive at the following expression for the number of different Boolean 
functions that can be implemented by such a network: 
2 B 
(2) 
N! 2 N 
where 
B  LN 2 log N (3) 
These results depend on the fact that we are considering only a very restricted type of 
processing unit: the output is a monotone function of a weighted sum of inputs. Cover 
222 
(1965) discussed in considerable depth the capabilities of such units. Valiant (1986) has 
explored the learning capabilities of various models of computation. 
Abu-Mustafa has emphasized the principles of information and entropy and applied 
them to measuring the properties of the training set. At this conference, formulas 
similar to equation 3 arose in the work of Baum, Psaltis, and Venkatesh, in the context 
of calculating the number of different training patterns a network should be able to 
memorize. We originally proposed equation 2 as an estimate of the number of patterns 
the network would have to memorize before it could form a reliable generalization. The 
basic idea, which has numerous consequences, is to estimate the number of (bins of) 
networks that can be realized. 
References 
1. Yasser Abu-Mustafa, these proceedings. 
2. Eric Baum, these proceedings. 
3. T. M. Cover, ""Geometrical and statistical properties of systems of linear inequal- 
ities with applications in pattern recognition,"" IEEE Trans. Elec. Comp., EC-14, 
326-334, (June 1965) 
4. John Denker, Daniel Schwartz, Ben Wittner, Sara Solla, John Hopfield, Richard 
Howard, and Lawrence Jackel, Complex Systems, in press (1987). 
5. Demetri Psaltis, these proceedings. 
6. L. G. Valiant, SIAM J. Comput. 15(2), 531 (1986), and references therein. 
7. Santosh Venkatesh, these proceedings. 
", train precis requir denker ben wittner bell laboratori new jersey hand leon show estim number function implement network much precis need number train exampl network must see expect form reliabl versu train data requir follow network power implement function learn form meaning gener small number train imposs creat present simplifi complet sophist version found denker customari regard learn adjust weight singl order deriv result take differ call ensembl imagin make number replica replica architectur weight set differ adjust take consist winnow ensembl search satisfi proce present item train set everi network use abscissa train pattern input compar ordin train pattern see agre output keep score reflect mani disagre train network lowest score one agre best train complet confid current nynex scienc westchest white ny institut physic reliabl train could step simpli throw away network let us consid typic network input wire unit process layer simplic assum nl recogn import network input concentr train pattern bit abscissa nl bit allow us classifi bin accord boolean relat simpli consid ensembl network architectur complet gener function exist ensembl one expect train item throw away half assum maxim train item one bin must uniqu function consist describ possibl abscissa use therefor truli gener can not possibl exhibit meaning gener possibl data need suppos network complet even possibl weight creat function call initi entropi formal gener definit given et use train data winnow one remain function presum correctli remain possibl certainli function best network architectur train data usual problem automat learn network inordin amount train data requir data may simpli may larg train would show critic import build network gener entropi real engin import abl estim initi entropi variou propos sinc determin amount train data calcul directli definit prohibit use definit deriv use approxim want thermodynam entropi bucket water directli weight network connect continu real rather specifi discret code bi number bit requir specifi configur network bi total number function could possibl implement network would actual number alway smaller variou way differ set weight lead ident one hidden layer number hidden unit polar hidden unit mean less factor inordin larg number bit bl mani set small chang connect make smaller addit expect bl bi must figur crossov number bit design typic je like logarithm number connect unit suppos connect given input unit size observ signific exact valu present point weight much larger much smaller dynam compar number argument easi devis conclus remain fraction unit previou layer activ need dynam impli calcul involv dynam learn method version back commonli requir number temporari point richard durbin anoth log bit ought bit need contribut xve combin idea appli network unit fulli arriv follow express number differ boolean implement ln log result depend fact consid restrict type output monoton function weight sum cover discuss consider depth capabl valiant learn capabl variou model emphas principl inform entropi appli measur properti train formula equat aros work context calcul number differ train pattern network abl origin propos equat estim number pattern network would memor could form reliabl numer estim number yasser eric statist properti system linear applic pattern ie john daniel ben sara john richard lawrenc complex press demetri siam refer santosh,0
24,24,"223 
'Ensemble' Boltzmann Units 
have Collective Computational Properties 
like those of Hopfield and Tank Neurons 
Mark Derthick and Joe Tebelskis 
Department of Computer Science 
Carnegie-Mellon University 
ABSTRACT
1 Introduction 
There are three existing connection:,t models in which network states are assigned 
a computational energy. These models Hopfield nets, Hopfield and Tank nets, and 
Boltzmann Machines--search for states with minimal energy. Every link in the net- 
work can be thought of as imposing a constraint on acceptable states, and each vio- 
lation adds to the total energy. This is convenient for the designer because constraint 
satisfaction problems can be mapped easily onto a network. Multiple constraints can 
be superposed, and those states satisfying the most constraints will have the lowest 
energy. 
Of course there is no free lunch. Constraint satisfaction problems are generally 
combinatorial and remain so even with a parallel implementation. Indeed, Merrick 
Furst (personal communication) has shown that an NP-complete problem, graph col- 
oring, can be reduced to deciding whether a connectionist network has a state with 
an energy of zero (or below). Therefore designing a practical network for solving a 
problem requires more than simply putting the energy minima in the right places. The 
topography of the energy space affects the ease with which a network can find good 
solutions. If the problem has highly interacting constraints, there will be many local 
minima separated by energy barriers. There are two principal approaches to search- 
ing these spaces: monotonic gradient descent, introduced by Hopfield [1] and refined 
by Hopfield and Tank [2]; and stochastic gradient descent, used by the Boltzmann 
Machine [3]. While the monotonic methods are not guaranteed to find the optimal 
solution, they generally find good solutions much faster than the Boltzmann Machine. 
This paper adds a refinement to the Boltzmann Machine search algorithm analogous 
to the Hopfield and Tank technique, allowing the user to trade off the speed of search 
for the quality of the solution. 
American Institute of Physics 1988 
224 
2 Hopfield nets 
A Hopfield net [1] consists of binary-valued units connected by symmetric weighted 
links. The global energy of the network is defined to be 
1 
E = -   Wij$i$ j -- E IiSi 
i piti i 
where si is the state of unit i, and wij is the weight on the link between units i and j. 
The search algorithm is: randomly select a unit and probe it until quiescence. 
During a probe, a unit decides whether to be on or off, determined by the states of 
its neighbors. When a unit is probed, there are two possible resulting global states. 
The difference in energy between these states is called the unit's energy gap: 
Ak  gsk=O -- gsk =1 '- E WikSi q' Ik 
The decision rule is 
{ 0ifAi< 0 
si = 1 otherwise 
This rule chooses the state with lower energy. With time, the global energy of the 
network monotonically decreases. Since there are only a finite number of states, the 
network must eventually reach quiescence. 
3 Boltzmann Machines 
A Boltzmann Machine [3] also has binary units and weighted links, and the same 
energy function is used. Boltzmann Machines also have a learning rule for updating 
weights, but it is not used in this paper. Here the important difference is in the 
decision rule, which is stochastic. As in probing a Hopfield unit, the energy gap is 
determined. It is used to determine a probability of adopting the on state: 
1 
P(si = 1)= 
1 + e-ai/r 
where T is the computational temperature. With this rule, energy does not decrease 
monotonically. The network is more likely to adopt low energy states, but it some- 
times goes uphill. The idea is that it can search a number of minima, but spends 
more time in deeper ones. At low temperatures, the ratio of time spent in the deepest 
minima is so large that the chances of not being in the global minimum are negligible. 
It has been proven [4] that after searching long enough, the probabilities of the states 
are given by the Boltzmann distribution, which is strictly a function of energy and 
temperature, and is independent of topography: 
P = e -(�-)/r (1) 
P 
225 
The approach to equilibrium, where equation 1 holds, is speeded by initially 
searching at a high temperature and gradually decreasing it. Unfortunately, reaching 
equilibrium stills takes exponential time. While the Hopfield net settles quickly and 
is not guaranteed to find the best solution, a Boltzmann Machine can theoretically be 
run long enough to guarantee that the global optimum is found. Most of the time the 
uphill moves which allow the network to escape local minima are a waste of time, 
however. It is a direct consequence of the guaranteed ability to find the best solution 
that makes finding even approximate solutions slow. 
4 Hopfield and Tank networks 
In Hop field and Tank nets [2], the units take on continuous values between zero and 
one, so the search takes place in the interior of a hypercube rather than only on its 
vertices. The search algorithm is deterministic gradient descent. By beginning near 
the center of the space and searching in the direction of steepest descent, it seems 
likely that the deepest minimum will be found. There is still no guarantee, but good 
results have been reported for many problems. 
The modified energy equation is 
g -- - y  wij$isj q- i 1($)d$ - y Ii$i 
i � i 
(2) 
Ri is'the input resistance to unit i, and g(u) is the sigrnoidal unit transfer function 
1 1 
+--7r;,. The second term is zero for extreme values of $i, and is minimized at si = 3' 
The Hop field and Tank model is continuous in time as well as value. Instead of 
proceeding by discrete probes, the system is described by simultaneous differential 
equations, one for each unit. Hopfield and Tank show that the following equation of 
motion results in a monotonic decrease in the value of the energy function: 
= -ul/r + wijsj + 
where r = RC, C is a constant determining the speed of convergence, u = g-(si), 
and the gain, A, is analgous to (the inverse of) temperature in a Boltzmann Machine. 
A determines how important it is to satisfy the constraints imposed by the links to 
other units. When A is low, these consuaints are largely ignored and the second term 
dominates, tending to keep the system near the center of the search space, where 
there is a single global minimum. At high gains, the minima lie at the comers of 
the search space, in the same locations as for the Hopfield model and the Boltzmann 
model. If the system is run at high gain, but the initial state is near the center of the 
space, the search gradually moves out towards the comers, on the way encountering 
""continental divides"" between watersheds leading to all the various local minima. The 
initial steepness of the watersheds serves as a heuristic for choosing which minima is 
226 
likely to be lower. This search heuristic emerges automatically from the architecture, 
making network design simple. For many problems this single automatic heuristic 
results in a system comparable to the best knowledge intensive algorithms in which 
many domain specific heuristics are laboriously hand programmed. 
For many problems, Hop field and Tank nets seem quite sufficient [5, 6]. However 
for one network we have been using [7] the Hopfield and Tank model invariably settles 
into poor local minima. The solution has been to use a new model combining the 
advantages of Boltzmann Machines and Hop field and Tank networks. 
5 'Ensemble' Boltzmann Machines 
It seems the Hop field and Tank model gets its advantage by measuring the actual 
gradient, giving the steepest direction to move. This is much more informative than 
picking a random direction and deciding which of the two corners of the space to try, 
as models using binary units must do. Peter Brown (personal communication) has 
investigated continuous Bokzmann Machines, in which units stochastically adopt a 
state between zero and one. The scheme presented here has a similar effect, but the 
units actually take on discrete states between zero and one. Each ensemble unit can 
be thought of as an ensemble of identically connected conventional Boltzmann units. 
To probe the ensemble unit, each of its constituents is probed, and the state of the 
ensemble unit is the average of its constituents' states. Because this average is over 
a number of identical independent binary random variables, the ensemble unit's state 
is binomially distributed. 
Figure 1 shows an ensemble unit with three constituents. At infinite temperature, 
all unit states tend toward .�, and at zero temperature the states go to zero or one 
unless the energy gap is exactly zero. This is similar to the behavior of a Hop field and 
Tank network at low and high gain, respectively. In Ensemble Boltzmann Machines 
(EBMs) the tendency towards � in the absence of constraints from other units results 
from the shape of the binomial distribution. In contrast, the second term in the energy 
equation is responsible for this effect in the Hopfield and Tank model. 
Although an EBM proceeds in discrete time using probes, over a large number of 
probes the search tends to proceed in the direction of the gradient. Every time a unit 
is probed, a move is made along one axis whose length depends on the magnitude of 
the gradient in that direction. Because probing still contains a degree of stochasticity, 
EBMs can escape from local minima, and if run long enough are guaranteed to find 
the global minimum. By varying n, the number of components of each ensemble 
unit, the system can exhibit any intermediate behavior in the tradeoff between the 
speed of convergence of Hopfield and Tank networks, and the ability to escape local 
minima of Boltzmann Machines. 
Clearly when n = 1 the performance is identical to a conventional Boltzmann 
Machine, because each unit consists of a single Boltzmann unit. As n  c the 
227 
s=1/3 s=2/3 
Figure 1: The heavy lines depict an 'Ensemble' Boltzmann Machine with two units. With 
an ensemble size of three, this network behaves like a conventional Boltzmann Machine 
consisting of six units (light lines). The state of the ensemble units is the average of the states 
of its components. 
value a unit takes on after probing becomes deterministic. The stable points of the 
system are then identical to the ones of the Hop field and Tank model. 
To prove this, it suffices to show that at each probe the ensemble Boltzmann 
unit takes on the state which gives rise to the lowest (Hopfield and Tank) energy. 
Therefore the energy must monotonically decrease. Further, if the system is not at a 
global (Hopfield and Tank) energy minimum, there is some unit which can be probed 
so as to lower the energy. 
To show that the state resulting from a probe is the minimum possible, we show 
first that the derivative of the energy with resepect to the unit's state is zero at the 
resulting state, and second that the second derivative is positive over the entire range 
of possible states, zero to one. 
Taking the derivative of equation 2 gives 
dE_ 1  
dsk Y WikSi + --g- (Sk) -- Ik 
i Ri 
Now 
so 
LetT=  
2AR' 
1 
g(u) = 
I + e -2xu 
I $ 
g- (u) = - In l-s 
The EBM update rule is 
1 
1 + e -Adt 
228 
Therefore 
-- i+,_Ak/T 
= -A+Tln l+e-a/r 
e--Ak/T 
l+e-Zak/r 
= -A +Tln e a/r 
= --At + T(At/T) 
= 0 
and 
d2E 
= 1 1 - s,. [(1 - sk) - (-sk)' 
2R s (1 - s0 2 
1 
2Rs(1 - s) 
> 0 on0<st,< 1 
In writing a program to simulate an EBM, it would be wasteful to explicitly 
represent the components of each ensemble unit. Since each component has an 
identical energy gap, the average of their values is given by the binomial distribution 
b(n,p) where n is the ensemble size, and p is  
+e_-zz-ff. There are numerical methods 
for sampling from this distribution in time independent of n [8]. When n is infinite, 
there is no need to bother with the distribution because the result is just p. 
Hop field and Tank suggest [2] that the Hopfield and Tank model is a mean field 
approximation to the original Hop field model. In a mean field approximation, the 
average value of a variable is used to calculate its effect on other variables, rather 
than calculating all the individual interactions. Consider a large ensemble of Hopfield 
nets with two units, A and B. To find the distribution of final states exactly, each B 
unit must be updated based on the A unit in the same network. The calculation must 
be repeated for every network in the ensemble. Using a mean field approximation, 
the average value of all the B units is calculated based on the average value of all 
the A units. This calculation is no harder than that of the state of a single Hopfield 
network, yet is potentially more informative since it approximates an average property 
of a whole ensemble of Hopfield networks. The states of Hopfield and Tank units 
can be viewed as representing the ensemble average of the states of Hopfield units 
in this way. Peterson and Anderson [9] demonstrate rigorously that the behavior is a 
mean field approximation. 
In the EBM, it is intuitively clear that a mean field approximation is being made. 
The network can be thought of as a real ensemble of Boltzmann networks, except with 
additional connections between the networks so that each Boltzmann unit sees not 
only its neighbors in the same net, but also sees the average state of the neighboring 
units in all the nets (see figure 1). 
229 
6 Traveling Salesman Problem 
The traveling salesman problem illustrates the use of energy-based connectionist net- 
works, and the ease with which they may be designed. Given a list of city locations, 
the task is to find a tour of minimum length through all the cities and returning to 
the starting city. To represent a solution to an n city problem in a network, it is 
convenient to use n columns of n rows of units [2]. If a unit at coordinates (i, j) is 
on, it indicates that the ith city is the jth to be visited. A valid solution will have n 
units on, one in every column and one in every row. The requirements can be divided 
into four constraints: there can be no more than one unit on in a row, no more that 
one unit on in a column, there must be n units on, and the distances between cities 
must be minimized. Hop field and Tank use the following energy function to effect 
these constraints: 
E  
A/2 E E E SxiSxj + 
x i ji 
E E E sx, + 
i x Yx 
0/2 E E E dxYSxi(Sy, i+I + Sy, i-1) (3) 
X YttX i 
Here units are given two subscripts to indicate their row and column, and the sub- 
scripts ""wrap around"" when outside the range 1 _( i _( n. The first term is imple- 
mented with inhibitory links between every pair of units in a row, and is zero only 
if no two are on. The second term is inhibition within columns. In the third term, n 
is the number of cities in the tour. When the system reaches a vertex of the search 
space, this term is zero only if exactly n units are on. This constraint is implemented 
with inhibitory links between all n 4 pairs of units plus an excitatory input current to 
all units. In the last term dx is the distance between cities X and Y. At points in 
the search space representing valid tours, the summation is numerically equal to the 
length of the tour. 
As long as the constraints ensuring that the solution is a valid tour are stronger 
than those minimizing distance, the global energy minimum will represent the shortest 
tour. However every valid tour will be a local energy minimum. Which tour is chosen 
will depend on the random initial starting state, and on the random probing order. 
7 Empirical Results 
The evidence that convinced me EBMs offer improved performance over Hopfield 
and Tank networks was the ease of tuning them for the Ted Turner problem reported 
230 
in [7]. However this evidence is entirely subjective; it is impossible to show that 
no set of parameters exist which would make the Hopfield and Tank model perform 
well. Instead we have chosen to repeat the traveling salesman problem experiments 
reported by Hop field and Tank [2], using the same cities and the same values for the 
constants in equation 3. The tour involves 10 cities, and the shortest tour is of length 
2.72. An average tour has length 4.55. Hopfield and Tank report finding a valid tour 
in 16 of 20 settlings,/tnd that half of these are one of the two shortest tours. 
One advantage of Hopfield and Tank nets over Boltzmann Machines is that they 
move continuously in the direction of the gradient. EBMs move in discrete jumps 
whose size is the value of the gradient along a given axis. When the system is 
far from equilibrium these jumps can be quite large, and the search is inefficient. 
Although Hopfield and Tank nets can do a whole search at high gain, Boltzmann 
Machines usually vary the temperature so the system can remain close to equilibrium 
as the low temperature equilibrium is approached. For this reason our model was 
more sensitive to the gain parameter than the Hop field and Tank model, and we used 
temperatures much higher than  
2),R' 
As expected, when n is infinite, an EBM produces results similar to those reported 
by Hopfield and Tank. 85 out of 100 settlings resulted in valid tours, and the average 
length was 2.73. Table 1 shows how n affects the number of valid tours and the 
average tour length. As n decreases from infinity, both the average tour length and 
the number of valid tours increases. (We have no explanation for the anomalously 
low number of valid tours for n = 40.) Both of these effects result from the increased 
sampling noise in determining the ensemble unit states for lower n. With more 
noise, the system has an easier time escaping local minima which do not represent 
valid tours. Yet at the same time the discriminability between the very best tours 
and moderately good tours decreases, because these smaller energy differences are 
swamped by the noise. 
Rather than stop trials when the network was observed to converge, a constant 
number of probes, 200 per unit, was made. However we noted that convergence was 
generally faster for larger values of n. Thus for the traveling salesman problem, large 
n give faster and better solutions, but a smaller values gives the highest reliability. 
Depending on the application, a value of either infinity or 50 seems best. 
8 Conclusion 
'Ensemble' Boltzmann Machines are completely upward compatible with conveno 
tional Boltzmann Machines. The above experiment can be taken to show that they 
perform better at the traveling salesman problem. In addition, at the limit of infinite 
ensemble size they perform similarly to Hopfield and Tank nets. For TSP and perhaps 
many other problems, the latter model seems an equally good choice. Perhaps due to 
the extreme regularity of the architecture, the energy space must be nicely behaved 
231 
Ensemble Size 
Percent Valid 
Average Tour Length 
1 93 3.32 
40 84 2.92 
50 95 2.79 
100 89 2.79 
1000 90 2.80 
infinity 85 2.73 
Table 1: Number of valid tours out of 100 trials and average tour length, as a function 
of ensemble size. An ensemble size of one corresponds to a Boltzmann Machine. Infinity 
loosely corresponds to a Hopfield and Tank network. 
in that the ravine steepness near the center of the space is a good indication of its 
eventual depth. In this case the ability to escape local minima is not required for 
good performance. 
For the Ted Turner problem, which has a very irregular architecture and many 
more constraint types, the ability to escape local minima seems essential. Conven- 
tional Boltzmann Machines are too noisy, both for efficient search and for debugging. 
EBMs allow the designer the flexibility to add only as much noise as is necessary. In 
addition, lower noise can be used for debugging. Even though this may give poorer 
performance, a more deterministic search is easier for the debugger to understand, 
allowing the proper fix to be made. 
Acknowledgements 
We appreciate receiving data and explanations from David Tank, Paul Smolensky, 
and Erik Sobel. This research has been supported by an ONR Graduate Fellowship, 
by NSF grant EET-8716324, and by the Defense Advanced Research Projects Agency 
(DOD), ARPA Order No. 4976 under contract F33615-87-C-1499 and monitored by 
the: 
Avionics Laboratory 
Air Force Wright Aeronautical Laboratories 
Aeronautical Systems Division (AFSC) 
Wright-Patterson AFB, OH 45433-6543 
This research was also sponsored by the same agency under contract N00039-87- 
C-0251 and monitored by the Space and Naval Warfare Systems Command. 
232 
References 
[1] J. J. Hopfield, ""Neural networks and physical systems with emergent collective 
computational abilities,"" Proceedings of the National Academy of Sciences U.S,4., 
vol. 79, pp. 2554-2558, April 1982. 
[2] J. Hopfield and D. Tank, ""'Neural' computation of decisions in optimization 
problems,"" Biological Cybernetics, vol. 52, pp. 141-152, 1985. 
[3] G. E. Hinton and T. J. Sejnowski, ""Learning and relearning in Boltzmann Ma- 
chines,"" in Parallel distributed processing: Explorations in the microstructure of 
cognition, Cambridge, MA: Bradford Books, 1986. 
[4] S. Geman and D. Geman, ""Stochastic relaxation, Gibbs distributions, and the 
Bayesian restoration of images,"" IEEE Transactions on Pattern Analysis and 
Machine Intelligence, vol. PAMI-6, pp. 721-741, 1984. 
[5] J. L. Marroquin, Probabilistic Solution of Inverse Problems. PhD thesis, MIT, 
September 1985. 
[6] J. Hopfield and D. Tank, ""Simple 'Neural' optimization networks: an a/d con- 
verter, signal decision circuit and a linear programming circuit,"" IEEE Transac- 
tions on Circuits and Systems, vol. 33, pp. 533-541, 1986. 
[7] M. Derthick, ""Counterfactual reasoning with direct models,"" in AAAI-87, Morgan 
Kaufmann, July 1987. 
[8] D. E. Knuth, The Art of Computer Programming. Second Edition. Vol. 2, 
Addison-Wesley, 1981. 
[9] C. Peterson and J. R. Anderson, ""A mean field theory learning algorithm for 
neural networks,"" Tech. Rep. EI-259-87, MCC, August 1987. 
", boltzmann unit collect comput properti hopfield tank neuron derthick joe tebelski comput scienc univers introduct three exist model network state assign comput model hopfield hopfield tank state minim everi link thought impos constraint accept add total conveni design constraint problem map easili onto multipl constraint state satisfi constraint lowest cours free constraint satisfact problem gener remain even parallel merrick shown graph reduc decid whether connectionist network state energi zero therefor design practic network solv requir simpli put energi minima right energi space affect eas network find good problem highli interact mani local separ energi two princip approach monoton gradient introduc hopfield refin hopfield tank stochast gradient use boltzmann monoton method guarante find optim gener find good solut much faster boltzmann paper add refin boltzmann machin search algorithm analog hopfield tank allow user trade speed search qualiti institut physic hopfield net hopfield net consist unit connect symmetr weight global energi network defin si piti si state unit wij weight link unit search algorithm randomli select unit probe unit decid whether determin state unit two possibl result global differ energi state call energi gsk si ik decis rule otherwis rule choos state lower global energi monoton sinc finit number must eventu reach boltzmann machin boltzmann machin also binari unit weight function boltzmann machin also learn rule updat use import differ probe hopfield energi gap use determin probabl adopt comput energi decreas network like adopt low energi goe idea search number spend time deeper low ratio time spent deepest larg chanc global minimum proven search long probabl state given boltzmann strictli function energi independ approach equat speed initi high temperatur gradual decreas reach still take exponenti hopfield net settl quickli guarante find best boltzmann machin theoret long enough guarante global optimum time move allow network escap local minima wast direct consequ guarante abil find best solut make find even approxim solut hopfield tank network hop field tank net unit take continu valu zero search take place interior hypercub rather search algorithm determinist gradient begin near center space search direct steepest seem deepest minimum still good report mani modifi energi equat input resist unit sigrnoid unit transfer function second term zero extrem valu minim si hop field tank model continu time well instead discret system describ simultan differenti one hopfield tank show follow equat result monoton decreas valu energi wijsj constant determin speed analg invers temperatur boltzmann determin import satisfi constraint impos link consuaint larg ignor second term tend keep system near center search singl global high minima lie comer search locat hopfield model boltzmann system run high initi state near center search gradual move toward way encount watersh lead variou local steep watersh serv heurist choos minima search heurist emerg automat network design mani problem singl automat heurist system compar best knowledg intens algorithm domain specif heurist labori hand mani hop field tank net seem quit suffici howev one network use hopfield tank model invari settl poor local solut use new model combin boltzmann machin hop field tank boltzmann machin seem hop field tank model get advantag measur actual give steepest direct much inform random direct decid two corner space model use binari unit must peter brown continu bokzmann unit stochast adopt zero scheme present similar actual take discret state zero ensembl unit thought ensembl ident connect convent boltzmann probe ensembl constitu state unit averag averag number ident independ binari random ensembl state binomi show ensembl unit three infinit unit state tend toward zero temperatur state go zero one energi gap exactli similar behavior hop field network low high ensembl boltzmann machin tendenc toward absenc constraint unit result shape binomi second term energi respons effect hopfield tank ebm proce discret time use larg number search tend proceed direct everi time unit move made along one axi whose length depend magnitud gradient probe still contain degre escap local run long enough guarante find global vari number compon ensembl system exhibit intermedi behavior tradeoff converg hopfield tank abil escap local boltzmann perform ident convent boltzmann unit consist singl boltzmann heavi line depict boltzmann machin two ensembl size network behav like convent boltzmann machin six unit state ensembl unit averag state unit take probe becom stabl point ident one hop field tank prove suffic show probe ensembl boltzmann take state give rise lowest energi must monoton system energi unit probe lower show state result probe minimum show deriv energi resepect state zero second second deriv posit entir rang possibl zero deriv equat give si ik ri ebm updat rule write program simul would wast explicitli compon ensembl sinc compon energi averag valu given binomi distribut ensembl numer method sampl distribut time independ need bother distribut result field tank suggest hopfield tank model mean field origin hop field mean field valu variabl use calcul effect rather calcul individu consid larg ensembl hopfield two find distribut final state must updat base unit calcul must repeat everi network use mean field averag valu unit calcul base averag valu calcul harder state singl hopfield yet potenti inform sinc approxim averag properti whole ensembl hopfield state hopfield tank unit view repres ensembl averag state hopfield unit peterson anderson demonstr rigor behavior field intuit clear mean field approxim network thought real ensembl boltzmann except connect network boltzmann unit see neighbor also see averag state neighbor net figur travel salesman problem travel salesman problem illustr use connectionist eas may given list citi task find tour minimum length citi return start repres solut citi problem use column row unit unit coordin indic ith citi jth valid solut one everi column one everi requir divid four one unit unit must unit distanc citi hop field tank use follow energi function effect sxj unit given two subscript indic row outsid rang first term inhibitori link everi pair unit zero two second term inhibit within third number citi system reach vertex search term zero exactli unit constraint implement inhibitori link pair unit plu excitatori input current last term distanc citi point search space repres valid summat numer equal long constraint ensur solut valid tour stronger minim global energi minimum repres shortest howev everi valid tour local energi tour chosen depend random initi start random probe empir result evid convinc ebm offer improv perform hopfield tank network eas tune ted turner problem report howev evid entir imposs show set paramet exist would make hopfield tank model perform instead chosen repeat travel salesman problem experi hop field tank use citi valu equat tour involv shortest tour length averag tour length hopfield tank report find valid tour half one two shortest advantag hopfield tank net boltzmann machin continu direct ebm move discret jump size valu gradient along given system equilibrium jump quit search hopfield tank net whole search high boltzmann usual vari temperatur system remain close equilibrium low temperatur equilibrium reason model sensit gain paramet hop field tank use much higher ebm produc result similar report hopfield settl result valid averag tabl show affect number valid tour tour decreas averag tour length number valid tour explan anomal number valid tour effect result increas nois determin ensembl unit state lower system easier time escap local minima repres yet time discrimin best tour moder good tour smaller energi differ stop trial network observ constant per howev note converg faster larger valu thu travel salesman larg give faster better smaller valu give highest valu either infin seem conclus boltzmann machin complet upward compat conveno boltzmann experi taken show better travel salesman limit infinit size perform similarli hopfield tank tsp perhap latter model seem equal good perhap due extrem regular energi space must nice behav size valid tour length number valid tour trial averag tour function ensembl ensembl size one correspond boltzmann infin correspond hopfield tank ravin steep near center space good indic case abil escap local minima requir ted turner irregular architectur mani constraint abil escap local minima seem boltzmann machin effici search allow design flexibl add much nois lower nois use even though may give poorer determinist search easier debugg proper fix appreci receiv data explan david paul erik research support onr graduat nsf grant defens advanc research project agenc arpa order contract monitor laboratori forc wright aeronaut laboratori system divis oh research also sponsor agenc contract monitor space naval warfar system network physic system emerg collect proceed nation academi scienc april hopfield comput decis optim biolog hinton relearn boltzmann parallel distribut explor microstructur bradford geman gibb restor ie transact pattern analysi probabilist solut invers hopfield optim signal decis circuit linear program ie circuit reason direct morgan juli art comput second peterson mean field theori learn algorithm august,0
25,25,"233 
HIGH ORDER NEURAL NETWORKS FOR EFFICIENT 
ASSOCIATIVE MEMORY DESIGN 
I. GUYON*, L. PERSONNAZ*, J.P. NADAL** and G. DREYFUS* 
* Ecole SupOrieure de Physique et de Chimie Industrielles de la Ville de Pads 
Laboratoire d'Electronique 
10, rue Vauquelin 
75005 Paris (France) 
** Ecole Normale Sup0rieure 
Groupe de Physique des Solides 
24, rue Lhomond 
75005 Paris (France) 
ABSTRACT 
We propose learning rules for recurrent neural networks with high-order 
interactions between some or all neurons. The designed networks exhibit the 
desired associative memory function: perfect storage and retrieval of pieces 
of information and/or sequences of information of any complexity. 
INTRODUCTION 
In the field of information processing, an important class of potential 
applications of neural networks arises from their ability to perform as 
associative memories. Since the publication of J. Hopfield's seminal paper 1, 
investigations of the storage and retrieval properties of recurrent networks 
have led to a deep understanding of their properties. The basic limitations of 
these networks are the following: 
- their storage capacity is of the order of the number of neurons; 
- they are unable to handle structured problems; 
- they are unable to classify non-linearly separable data. 
@ American Institute of Physics 1988 
234 
In order to circumvent these limitations, one has to introduce additional 
non-linearities. This can be done either by using ""hidden"", non-linear units, or 
by considering multi-neuron interactions 2. This paper presents learning rules 
for networks with multiple interactions, allowing the storage and retrieval, 
either of static pieces of information (autoassociative memory), or of temporal 
sequences (associative memory), while preventing an explosive growth of the 
number of synaptic coefficients. 
AUTOASSOCIATIVE MEMORY 
The problem that will be addressed in this paragraph is how to design an 
autoassociative memory with a recurrent (or feedback) neural network when 
the number p of prototypes is large as compared to the number n of neurons. 
We consider a network of n binary neurons, operating in a synchronous 
mode, with period . The state of neuron i at time t is denoted by (i(t), and the 
state of the network at time t is represented by a vector (t)whose 
components are the (i(t). The dynamics of each neuron is governed by the 
following relation: 
(i(t+) = sgn vi(t ). (1) 
In networks with two-neuron interactions only, the potential vi(t ) is a linear 
function of the state of the network: 
n 
For autoassociative memory design, it has been shown 3 that any set of 
correlated patterns, up to a number of patterns p equal to 2 n, can be made the 
stable states of the system, provided the synaptic matrix is computed as the 
orthogonal projection matrix onto the subspace spanned by the stored 
vectors. However, as p increases, the rank of the family of prototype vectors 
will increase, and finally reach the value of n. In such a case, the synaptic 
matrix reduces to the identity matrix, so that all 2 n states are stable and the 
energy landscape becomes flat. Even if such an extreme case is avoided, the 
attractivity of the stored states decreases with increasing p, or, in other terms, 
235 
the number of fixed points which are not the stored patterns increases; this 
problem can be alleviated to a large extent by making a useful use of these 
""spurious"" fixed points 4. Another possible solution consists in ""gardening"" the 
state space in order to enlarge the basins of attraction of the fixed points 5. 
Anyway, no dramatic improvements are provided by all these solutions since 
the storage capacity is always O(n). 
We now show that the introduction of high-order interactions between 
neurons, increases the storage capacity proportionally to the number of 
connections per neuron. The dynamical behaviour of neuron i is still governed 
by (1). We consider two and three-neuron interactions, extension to higher 
order are straightforward. 
The potential vi(t ) is now defined as 
vi(t ) = ,.,j Ci, j oj(t) + ,T_.,j, I Ci,jl oj(t) ol(t). 
It is more convenient, for the derivation of learning rules, to write the potential 
in the matrix form ' 
v(t) = C /(t), 
where 3(t) is an m dimensional vector whose components are taken among 
the set of the (n2+n)/2 values � (1 , ..-, On , (1(2 , '"", (j (1 , -.-, (n-1 On' 
As in the case of the two-neuron interactions model, we want to compute the 
interaction coefficients so that the prototypes are stable and attractor states. 
A condition to store a set of states (k (k=l to p) is that v_k= (k for all k. Among 
the solutions, the most convenient solution is given by the (n,m) matrix 
C = y.,[ ""1 (2) 
where 7_., is the (n,p) matrix whose columns are the _q.k and .1 is the (p,m) 
pseudoinverse of the (m,p) matrix ' whose columns are the 3 k . This solution 
satisfies the above requirements, up to a storage capacity which is related to 
the dimension m of vectors 35 Thus, in a network with three-neuron 
236 
interactions, the number of patterns that can be stored is O(n2). Details on 
these derivations are published in Ref.6. 
By using only a subset of the products {(j (1}, the increase in the number of 
synaptic coefficients can remain within acceptable limits, while the attractivity 
of the stored patterns is enhanced, even though their number exceeds the 
number of neurons ; this will be examplified in the simulations presented 
below. 
Finally, it can be noticed that, if vector :ycontains all the {(i (j}, i=1 ,...n, j=l ,...n, 
only, the computation of the vector potential v=C:ycan be performed after the 
following expression: 
V : [ {(I]T[))} I ([T_)) 
where  stands for the operation which consists in squaring all the matrix 
coefficients. Hence, the computation of the synaptic coefficients is avoided, 
memory and computing time are saved if the simulations are performed on a 
conventional computer. This formulation is also meaningful for optical 
implementations, the function  being easily performed in optics 7. 
In order to illustrate the capabilities of the learning rule, we have performed 
numerical simulations which show the increase of the size of the basins of 
attraction when second-order interactions, in addition to the first-order ones, 
are used. The simulations were carried out as follows. The number of neurons 
n being fixed, the amount of second-order interactions was chosen ; p 
prototype patterns were picked randomly, their components being _+1 with 
probability 0.5; the second-order interactions were chosen randomly. The 
synaptic matrix was computed from relation (2). The neural network was 
forced into an initial state lying at an initial Hamming distance H i from one of 
the prototypes _k; it was subsequently left to evolve until it reached a stable 
state at a distance Hf from _k. This procedure was repeated many times for 
each prototype and the Hf were averaged over all the tests and all the 
prototypes. 
Figures la. and lb. are charts of the mean values of Hf as a function of the 
number of prototypes, for n = 30 and for various values of m (the dimension of 
237 
vector :y). These curves allowed us to determine the maximum number of 
prototype states which can be stored for a given quality of recall. Perfect recall 
implies Hf =0; when the number of prototypes increases, the error in recall 
may reach Hf--Hi: the associative memory is degenerate. The results 
obtained for H i/n =10% are plotted on Figure l a. When no high-order 
interactions were used, Hf reached H i for p/n = 1, as expected; conversely, 
virtually no error in recall occured up to p/n = 2 when all second-order 
interactions were taken into account (m=465). Figure lb shows the same 
quantities for Hi=20%; since the initial states were more distant from the 
prototypes, the errors in recall were more severe. 
1,2 
1.0 
0.8 
^ 0.6 
� 
0.4 
0.2 
0.0 
0 1 2 3 
pin 
(a) 
1.2 
1.0 
0,8 
0.6 
0.4 
0.2 
0.0 
0 
i I 
pin 
(b) 
Fig. 1. Improvement of the attractivity by addition of three-neuron interactions 
to the two-neuron interactions. All prototypes are always stored exactly (all 
curves go through the origin). Each point corresponds to an average over 
min(p,10) prototypes and 30 tests for each prototype. 
r'l Projection' m = n = 30; � m = 120; � m = 180; {) m = 465 (all interactions) 
la: H i/n=10% ; lb:H i/n=20%. 
TEMPORAL SEQUENCES (ASSOCIATIVE MEMORY) 
The previous section was devoted to the storage and retrieval of items of 
information considered as fixed points of the dynamics of the network 
(autoassociative memory design). However, since fully connected neural 
networks are basically dynamical systems, they are natural candidates for 
238 
storing and retrieving information which is dynamical in nature, i.e., temporal 
sequences of patterns8: In this section, we propose a general solution to the 
problem of storing and retrieving sequences of arbitrary complexity, in 
recurrent networks with parallel dynamics. 
Sequences consist in sets of transitions between states _k_> (k+l, k=l ,..., p. 
A sufficient condition to store these sets of transitions is that vk= (k+l for all k. 
In the case of a linear potential v=C _, the storage prescription proposed in 
ref.3 can be used: C=7_.,+ I , 
where 7., is a matrix whose columns are the (k and 7., + is the matrix whose 
columns are the successors (k+l of (k. If p is larger than n, one can use 
high-order interactions, which leads to introduce a non-linear potential v=C , 
with as previously defined. We proposed in ref.10 the following storage 
prescription: 
C=Z+F I (3) 
The two above prescriptions are only valid for storing simple sequences, 
where no patterns occur twice (or more). Suppose that one pattern occurs 
twice; when the network reaches this b/furcat/on po/nt, it is unable to make a 
decision according the deterministic dynamics described in (1), since the 
knowledge of the present state is not sufficient. Thus, complex sequences 
require to keep, at each time step of the dynamics, a non-zero memory span. 
The vector potential y.=C:y must involve the states at time t and t-,c, which 
leads to define the vector  as a concatenation of vectors (7(0, _(t-), (7(t)�(7(t), 
(7(t)�(7(t-), or a suitable subset thereof. The subsequent vector (7(t+'c) is still 
determined by relation (1). In this form, the problem is a generalization of the 
storage of patterns with high order interactions, as described above. The 
storage of sequences can be still processed by relation (3). 
The solution presented above has the following features: 
i) Sequences with bifurcation points can be stored and retrieved. 
ii) The dimension of the synaptic matrix is at most (n,2(n2+n)), and at least 
(n,2n) in the linear case, so that at most 2n(n2+n) and at least 2n 2 synapses 
are required. 
239 
iii) The storage capacity is 0(m), where m is the dimension of the vector 
iv) Retrieval of a sequence requires initializing the network with two states in 
succession. 
The example of Figure 2 illustrates the retrieval performances of the latter 
learning rule. We have limited vector :yto (7(t)�_(z(t-). In a network of n=48 
neurons, a large number of poems have been stored, with a total of p=424 
elementary transitions. Each state is consists in the 6 bit codes of 8 letters. 
ALOUETTE 
JE TE 
PLUMERAI 
ALOUETTE 
GENTILLE 
ALOUETTE 
ALOUETTE 
JE TE 
PLUMERAI 
JE NE 
OLVMERAI 
AQFUETTE 
JEHKILLE 
SLOUETTE 
ALOUE-FFE 
JE TE 
PLUMERAI 
Fig. 2. One of the stored poems is shown in the first column. The network is 
initialized with two states (the first two lines of the second column). After a few 
steps, the network reaches the nearest stored sequence. 
LOCAL LEARNING 
Finally, it should be mentioned that all the synaptic matrices introduced in this 
paper can be computed by iterative, local learning rules. 
For autoassociative memory, it has been shown analytically 9 that the 
procedure � 
Cij(k ) = Cij(k-1 ) + (1/n) ( (i k- vi k ) (jk with Cij(0 ) = 0, 
which is a Widrow-Hoff type learning rule, yields the projection matrix, when 
240 
the number of presentations of the prototypes {k} goes to infinity, if the latter 
are linearly independent. 
A derivation along the same lines shows that, by repeated presentations of 
the prototype transitions, the learning rules: 
Cij(k ) = Cij(k-1 ) + (1/n) ( oi k- vik ) ?]k with Cij(O ) = 0 
Cij(k ) = Cij(k-1 ) + (1/n) ( oi k+l - vi k ) 7j k with Cij(O ) = 0 
lead to the exact solutions (relations (2) and (3) respectively), if the vectors 
are linearly independent. 
GENERALIZATION TASKS 
Apart from storing and retrieving static pieces of information or sequences, 
neural networks can be used to solve problems in which there exists a 
structure or regularity in the sample patterns (for example presence of clumps, 
parity, symmetry...) that the network must discover. Feed-forward networks 
with multiple layers of first-order neurons can be trained with 
back-propagation algorithms for these purposes; however, one-layer 
feed-forward networks with multi-neuron interactions provide an interesting 
alternative. For instance, a proper choice of vector :y (second-order terms only) 
with the above learning rule yields a perfectly straightforward solution to the 
exclusive-OR problem. Maxwell et al. have shown that a suitable high-order 
neuron is able to exhibit the ""ad hoc network solution"" for the contiguity 
problem 11 
CONCLUSION 
The use of neural networks with high-order interactions has long been 
advocated as a natural way to overcome the various limitations of the Hopfield 
model. However, no procedure guaranteed to store any set of information as 
fixed points or as temporal sequences had been proposed. The purpose of 
the present paper is to present briefly such storage prescriptions and show 
241 
some illustrations of the use of these methods. Full derivations and extensions 
will be published in more detailed papers. 
REFERENCES 
1. J.J. Hopfield, Proc. Natl. Acad. Sci. (USA) 79, 2554 (1982). 
2. P. Peretto and J. J. Niez, Biol. Cybern. ;4, 53 (1986). 
P. Baldi and S.S. Venkatesh, Phys. Rev. Lett. 58,913 (1987). 
For more references see ref.6. 
3. L. Personnaz, I. Guyon, G. Dreyfus, J. Phys. Lett. 4�, 359 (1985). 
L. Personnaz, I. Guyon, G. Dreyfus, Phys. Rev. A 34,4217 (1986). 
4. I. Guyon, L. Personnaz, G. Dreyfus, in ""Neural Computers"", R. Eckmiller 
and C. von der Malsburg eds (Springer, 1988). 
5. E. Gardner, Europhys. Lett. 4, 481 (1987). 
G. Pppel and U.Krey, Europhys. Lett., 4, 979 (1987). 
6. L. Personnaz, I. Guyon, G. Dreyfus, Europhys. Lett. 4, 863 (1987). 
7. D. Psaltis and C. H. Park, in ""Neural Networks for Computing"", J. S. Denker 
ed., (A.I.P. Conference Proceedings 151,1986). 
8. P. Peretto, J. J. Niez, in ""Disordered Systems and Biological Organization"", 
E. Bienenstock, F. Fogelman, G. Weisbush eds (Springer, Berlin 1986). 
S. Dehaene, J.P. Changeux, J.P. Nadal, PNAS (USA) 84, 2727 (1987). 
D. Kleinfeld, H. Sompolinsky, preprint 1987. 
J. Keeler, to appear in J. Cog. Sci. 
For more references see ref. 9. 
9. I. Guyon, L. Personnaz, J.P. Nadal and G. Dreyfus, submitted for 
publication. 
10. S. Diederich, M. Opper, Phys. Rev. Lett. 58, 949 (1987). 
11. T. Maxwell, C. Lee Giles, Y. C. Lee, Proceedings of ICNN-87, San Diego, 
1987. 
", order neural network effici memori design ecol orieur de physiqu et de chimi industriel de la vill de pad rue vauquelin pari ecol normal de physiqu de solid rue lhomond pari propos learn rule recurr neural network design network exhibit associ memori perfect storag retriev piec inform sequenc inform field inform import class potenti neural network aris abil perform sinc public semin paper storag retriev properti recurr network led deep understand basic limit network storag capac order number unabl handl structur unabl classifi separ american institut physic order circumv one introduc addit done either use consid interact paper present learn rule network multipl allow storag static piec inform tempor prevent explos growth synapt memori problem address paragraph design memori recurr neural network number prototyp larg compar number consid network binari oper synchron period state neuron time denot network time repres vector dynam neuron govern sgn network interact potenti linear state autoassoci memori shown set number pattern equal made state provid synapt matrix comput project matrix onto subspac span store rank famili prototyp vector final reach valu synapt reduc ident state stabl landscap becom even extrem case store state decreas increas number fix point store pattern allevi larg extent make use use fix point anoth possibl solut consist space order enlarg basin attract fix point dramat improv provid solut sinc storag capac alway show introduct interact increas storag capac proport number per dynam behaviour neuron still govern consid two extens higher potenti defin deriv learn write potenti matrix form dimension vector whose compon taken among set valu case interact want comput coeffici prototyp stabl attractor condit store set state among conveni solut given matrix matrix whose column matrix whose column solut storag capac relat dimens vector network number pattern store detail deriv publish use subset product increas number coeffici remain within accept attract store pattern even though number exce neuron examplifi simul present notic vector comput vector potenti perform stand oper consist squar matrix comput synapt coeffici comput time save simul perform formul also meaning optic function easili perform optic order illustr capabl learn perform simul show increas size basin addit simul carri number neuron amount interact chosen pattern pick compon interact chosen matrix comput relat neural network initi state lie initi ham distanc one prototyp subsequ left evolv reach stabl distanc hf procedur repeat mani time prototyp hf averag test chart mean valu hf function variou valu dimens curv allow us determin maximum number state store given qualiti perfect recal hf number prototyp error recal reach associ memori result plot figur hf reach error recal occur taken account figur lb show sinc initi state distant error recal improv attract addit interact prototyp alway store exactli go point correspond averag prototyp test sequenc previou section devot storag retriev item consid fix point dynam network memori sinc fulli connect neural basic dynam natur candid retriev inform dynam tempor propos gener solut store retriev sequenc arbitrari network parallel consist set transit state suffici condit store set transit case linear potenti storag prescript propos matrix whose column matrix whose successor larger one use lead introduc potenti previous propos follow storag two prescript valid store simpl pattern occur twice suppos one pattern occur network reach unabl make accord determinist dynam describ sinc present state complex sequenc time step memori vector potenti must involv state time defin vector concaten vector suitabl subset subsequ vector still relat problem gener pattern high order describ sequenc still process relat solut present follow sequenc bifurc point store dimens synapt matrix least linear least synaps storag capac dimens vector retriev sequenc requir initi network two state exampl figur illustr retriev perform latter limit vector network larg number poem total state consist bit code te te ne te one store poem shown first network two state first two line second network reach nearest store learn mention synapt matric introduc comput local learn autoassoci shown analyt vi type learn yield project number present prototyp goe latter linearli deriv along line show repeat present prototyp learn oi vik oi vi exact solut vector linearli task store retriev static piec inform network use solv problem exist regular sampl pattern exampl presenc network must network multipl layer neuron train algorithm network interact provid interest proper choic vector term learn rule yield perfectli straightforward solut maxwel et shown suitabl abl exhibit hoc network contigu use neural network interact long natur way overcom variou limit hopfield procedur guarante store set inform point tempor sequenc purpos present paper present briefli storag prescript show illustr use full deriv extens publish detail peretto baldi refer see eckmil von der malsburg ed psalti network denker confer proceed system biolog weisbush ed berlin pna preprint appear refer see nadal submit lee proceed san,0
26,26,"242 
THE SIGMOID NONLINEARITY IN PREPYRIFORM CORTEX 
Frank H. Eeckman 
University of California, Berkeley, CA 94720 
ABSTRACT 
We report a study bn the relationship between EEG amplitude values and unit 
spike output in the prepyriform cortex of awake and motivated rats. This relationship 
takes the form of a sigmoid curve, that describes normalized pulse-output for 
normalized wave input. The curve is fitted using nonlinear regression and is 
described by its slope and maximum value. 
Measurements were made for both excitatory and inhibitory neurons in the cortex. 
These neurons are known to form a monosynaptic negative feedback loop. Both 
classes of cells can be described by the same parameters. 
The sigmoid curve is asymmetric in that the region of maximal slope is displaced 
toward the excitatory side. The data are compatible with Freeman's model of 
prepyriform burst generation. Other analogies with existing neural nets are being 
discussed, and the implications for signal processing are reviewed. In particular the 
relationship of sigmoid slope to efficiency of neural computation is examined. 
INTRODUCTION 
The olfactory cortex of mammals generates repeated nearly sinusoidal bursts of 
electrical activity (EEG) in the 30 to 60 Hz. range 1. These bursts ride on top of a 
slower ( 1 to 2 Hz.), high amplitude wave related to respiration. Each burst begins 
shortly after inspiration and terminates during expiration. They are generated locally 
in the cortex. Similar bursts occur in the olfactory bulb (OB) and there is a high 
degree of correlation between the activity in the two structures 1. 
The two main cell types in the olfactory cortex are the superficial pyramidal cell 
(type A), an excitatory neuron receiving direct input from the OB, and the cortical 
granule cell (type B), an inhibitory interneuron. These cell groups are 
monosynaptically connected in a negative feedback loop2. 
Superficial pyramidal cells are mutually excitatory3, 4, 5 as well as being 
excitatory to the granule cells. The granule cells are inhibitory to the pyramidal cells 
as well as to each other3, 4, 6. 
In this paper we focus on the analysis of amplitude dependent properties: How is 
the output of a cellmass (pulses) related to the synaptic potentials (ie. waves)? The 
concurrent recording of multi-unit spikes and EEG allows us to study these 
phenomena in the olfactory cortex. 
The anatomy of the olfactor system has been extensively studied beginning with 
the work of S. Ramon y Caj al 7. The regular geometry and the simple three-layered 
architecture makes these structures ideally suitable for EEG recording 4, 8. The EEG 
generators in the various olfactory regions have been identified and their synaptic 
connectivities have been extensively studied9, 10, 5, 4, 11, 6. 
The EEG is the scalar sum of synaptic currents in the underlying cortex. It can 
be recorded using low impedance (< .5 Mohm) cortical or depth electrodes. Multi- 
unit signals are recorded in the appropriate cell layers using high impedance (> .5 
Mohm) electrodes and appropriate high pass filtering. 
Here we derive a function that relates waves (EEG) to pulses in the olfactory 
cortex of the rat. This function has a sigmoidal shape. The derivative of this curve 
American Institute of Physics 1988 
243 
gives us the gain curve for wave-to-pulse conversion. This is the forward gain for 
neurons embedded in the cortical cellmass. The product of the forward gain values of 
both sets of neurons (excitatory and inhibitory) gives us the feedback gain values. 
These ultimately determine the dynamics of the system under study. 
MATERIALS AND METHODS 
A total of twenty-nine rats were entered in this study. In each rat a linear array of 
6 100 micron stainless steel electrodes was chronically implanted in the prepyriform 
(olfactory) cortex. The tips of the electrodes were electrolytically sharpened to 
produce a tip impedance on the order of .5 to 1 megaohm. The electrodes were 
implanted laterally in the midcortex, using stereotaxic coordinates. Their position was 
verified electrophysiologically using a stimulating electrode in the olfactory tract. 
This procedure has been described earlier by Freeman 12. At the end of the recording 
session a small iron deposit was made to help in histological verification. Every 
electrode position was verified in this manner. 
Each rat was recorded from over a two week period following implantation. All 
animals were awake and attentive. No stimulation (electrical or olfactory) was used. 
The background environment for recording was the animal's home cage placed in the 
same room during all sessions. 
For the present study two channels of data were recorded concurrently. Channel 
1 carried the EEG signal, filtered between 10 and 300 Hz. and digitized at 1 ms 
intervals. Channel 2 carried standard pulses 5 V, 1.2 ms wide, that were obtained by 
passing the multi-unit signal (filtered between 300 Hz. and 3kHz.) through a 
window discriminator. 
These two time-series were stored on disk for off-line processing using a Perkin- 
Elmer 3220 computer. All routines were written in FORTRAN. They were tested on 
data files containing standard sine-wave and pulse signals. 
DATA PROCESSING 
The procedures for obtaining a two-dimensional conditional pulse probability 
table have been described earlier 4. This table gives us the probability of occurrence 
of a spike conditional on both time and normalized EEG amplitude value. 
By counting the number of pulses at a fixed time-delay, where the EEG is 
maximal in amplitude, and plotting them versus the normalized EEG amplitudes, one 
obtains a sigmoidal function: The Pulse probability Sigmoid Curve (PSC) 13, 14. 
This function is normalized by dividing it by the average pulse level in the record. It 
is smoothed by passing it through a digital 1:1:1 filter and fitted by nonlinear 
regression. 
The equations are: 
Q = Qmax ( 1- exp [ - ( ev - 1) / Qmax ] ) for v > - u0 
Q = -1 for v < - u0 
(1) 
where u0 is the steady state voltage, and Q = (p-p0)/p0. 
and Qmax =(pmax-p0)/p0. 
p0 is the background pulse count, Pmax is the maximal pulse count. 
These equations rely on one parameter only. The derivation and justification for 
these equations were discussed in an earlier paper by Freeman 13. 
244 
RESULTS 
Data were obtained from all animals. They express normalized pulse counts, a 
dimensionless value as a function of normalized EEG values, expressed as a Z-score 
(ie. ranging from - 3 sd. to + 3 sd., with mean of 0.0). The true mean for the EEG 
after filtering is very close to 0.0 mV and the distribution of amplitude values is very 
nearly Gaussian. 
The recording convention was such that high EEG-values ( ie. > 0.0 to + 3.0 sd.) 
corresponded to surface-negative waves. These in turn occur with activity at the 
apical dendrites of the cells of interest. Low EEG values (ie. from - 3.0 sd. to < 0.0) 
corresponded to surface-positive voltage values, representing inhibition of the cells. 
The data were smoothed and fitted with equation (1). This yielded a Qmax value 
for every data file. There were on average 5 data files per animal. Of these 5, an 
average of 3.7 per animal could be fitted succesfully with our technique. In 25 % of 
the traces, each representing a different electrode pair, no 6orrelations between spikes 
and the EEG were found. 
Besides Qmax we also calculated Q' the maximum derivative of the PSC, 
representing the maximal gain. 
There were 108 traces in all. In the first 61 cases the Qmax value described the 
wave-to-pulse conversion for a class of cells whose maximum firing probability is in 
phase with the EEG. These cells were labelled type A cells 2. These traces 
correspond to the excitatory pyramidal cells. The mean for Qmax in that group was 
14.6, with a standard deviation of 1.84. The range was 10.5 to 17.8. 
In the remaining 47 traces the Qmax described the wave-to-pulse conversion for 
class B cells. Class B is a label for those cells whose maximal firing probability lags 
the EEG maximum by approximately 1/4 cycle. The mean for Qmax in that group 
was 14.3, with a standard deviation of 2.05. The range in this group was 11.0 to 
18.8. 
The overall mean for Qmax was 14.4 with a standard deviation of 1.94. There is 
no difference in Qmax between both groups as measured by the Student t-test. The 
nonparametric Wilcoxon rank-sum test also found no difference between the groups 
( p = 0.558 for the t-test; p = 0.729 for the Wilcoxon). 
Assuming that the two groups have Qmax values that are normally distributed ( in 
group A, mean = 14.6, median = 14.6; in group B, mean = 14.3, median = 14.1), 
and that they have equal variances ( st. deviation group A is 1.84; st. deviation group 
B is 2.05) but different means, we estimated the power of the t-test to detect that 
difference in means. 
A difference of 3 points between the Qmax'S of the respective groups was 
considered to be physiologically significant. Given these assumptions the power of 
the t-test to detect a 3 point difference was greater than .999 at the alpha .05 level for 
a two sided test. We thus feel reasonably confident that there is no difference 
between the Qmax values of both groups. 
The first derivative of the PSC gives us the gain for w,e-to-pulse conversion4. 
The maximum value for this first derivative was labelled Q. The location at which 
the maximum Q' occurs was labelled Vmax. Vmax is expressed in units of standard 
deviation of EEG amplitudes. 
The mean for Q' in group A was 5.7, with a standard deviation of .67, in group B 
it was 5.6 with standard deviation of .73. Since Q' depends on Qmax, the same 
statistics apply to both: there was no significant difference between the two groups 
for slope maxima. 
245 
Figure 1. Distribution of Qmax values 
group A group B 
14 
' lO 
8 
6 
4 
2 
0 
1011121314151617181920 
qmax values 
14 
12 
6 
4 
2 
1011121314151617181920 
Qmx values 
The mean for Vmax was at 2.15 sd. +/- .307. In every case Vmax was on the 
excitatory side from 0.00, ie. at a positive value of EEG Z-scores. All values were 
greater than 1.00. A similar phenomenon has been reported in the olfactory bulb 4, 
14, 15. 
Figure 2. Examples of sigmoid fits. 
A cell B cell 
14 14 
12 12 
10 10 
4 4 
2 2 
o m o 
-4 -4  
-3 -2 -1 0 1 2 3 -3 -2 -1 0 1 2 3 
ormalized EES amplitmte 
Qm = 14.0 Qm = 13.4 
246 
COMPARISON WITH DATA FROM THE OB 
Previously we derived Qmax values for the mitml cell population in the olfactory 
bulb14. The mitral cells are the output neurons of the bulb and their axons form the 
lateral olfactory tract (LOT). The LOT is the main input to the pyramidal cells (type 
A) in the cortex. 
For awake and motivated rats (N = 10) the mean Qmax value was 6.34 and the 
standard deviation was 1.46. The range was 4.41- 9.53. For anesthetized animals 
(N= 8) the mean was 2.36 and the standard deviation was 0.89. The range was 1.15- 
3.62. There was a significant difference between anesthetized and awake animals. 
Furthermore there is a significant difference between the Qmax value for cortical cells 
and the Qmaxvalue for bulbar cells ( non - overlapping distributions). 
DISCUSSION 
An important characteristic of a feedback loop is its feedback gain. There is ample 
evidence for the existence of feedback at all levels in the nervous system. Moreover 
specific feedback loops between populations of neurons have been described and 
analyzed in the olfactory bulb and the prepyriform cortex 3, 9, 4. 
A monosynaptic negative feedback loop has been shown to exist in the PPC, 
between the pyramidal cells and inhibitory cells, called granule cells 3, 2, 6, 16. 
Time series analysis of concurrent pulse and EEG recordings agrees with this idea. 
The pyramidal cells are in the forward limb of the loop: they excite the granule 
cells. They are also mutually excitatory 2,4,16. The granule cells are in the feedback 
limb: they inhibit the pyramidal cells. Evidence for mutual inhibition (granule to 
granule) in the PPC also exists 17, 6. 
The analysis of cell firings versus EEG amplitude at selected time-lags allows one 
to derive a function (the PSC) that relates synaptic potentials to output in a neural 
feedback system. The first derivative of this curve gives an estimate of the forward 
gain at that stage of the loop. The procedure has been applied to various structures in 
the olfactory system 4, 13, 15, 14. The olfactory system lends itself well to this type 
of analysis due to its geometry, topology and well known anatomy. 
Examination of the experimental gain curves shows that the maximal gain is 
displaced to the excitatory side. This means that not only will the cells become 
activated by excitatory input, but their mutual interaction strength will increase. The 
result is an oscillatory burst of high frequency ( 30- 60 Hz.) activity. This is the 
mechanism behind bursting in the olfactory EEG 4, 13. 
In comparison with the data from the olfactory bulb one notices that there is a 
significant difference in the slope and the maximum of the PSC. In cortex the values 
are substantially higher, however the Vmax is similar. C. Gray 15 found a mean 
value of 2.14 +/- 0.41 for Vmax in the olfactory bulb of the rabbit (N= 6). Our value 
in the present study is 2.15 +/- .31. The difference is not statistically significant. 
There are important aspects of nonlinear coupling of the sigmoid type that are of 
interest in cortical functioning. A sigmoid interaction between groups of elements 
(""neurons"") is a prominent feature in many artificial neural nets. S. Grossberg has 
extensively studied the many desirable properties of sigmoids in these networks. 
Sigmoids can be used to contrast-enhance certain features in the stimulus. Together 
with a thresholding operation a sigmoid rule can effectively quench noise. Sigmoids 
can also provide for a built in gain control mechanism 18, 19. 
247 
Changing sigmoid slopes have been investigated by J. Hopfield. In his network 
changing the slope of the sigmoid interaction between the elements affects the 
number of attractors that the system can go to 20. We have previously remarked 
upon the similarities between this and the change in sigmoid slope between waking 
and anesthetized animals 14. Here we present a system with a steep slope (the PPC) 
in series with a system with a shallow slope (the OB). 
Present investigations into similarities between the olfactory bulb and Hopfield 
networks have been reported 21, 22. Similarities between the cortex and Hopfield- 
like networks have also been proposed 23. 
Spatial amplitude panems of EEG that correlate with significant odors exist in the 
bulb 24. A transmission of ""wave-packets"" from the bulb to the cortex is known to 
occur 25. It has been shown through cofrequency and phase analysis that the bulb 
can drive the cortex 25, 26. It thus seeems likely that spatial patterns may also exist 
in the cortex. A steeper sigmoid, if the analogy with neural networks is correct, 
would allow the cortex to further classify input patterns coming from the olfactory 
bulb. 
In this view the bulb could form an initial classifier as well as a scratch-pad 
memory for olfactory events. The cortex could then be the second classifier, as well 
as the more permanent memory. 
These are at present speculations that may turn out to be premature. They 
nevertheless are important in guiding experiments as well as in modelling. 
Theoretical studies will have to inform us of the likelihood of this kind of processing. 
REFERENCES 
1 S.L. Bressler and W.J. Freeman, Electroencephalogr. Clin. Neurophysiol. 50: 19 
(1980). 
2 W.J. Freeman, J. Neurophysiol. 31:1 (1968). 
3 W.J. Freeman, Exptl. Neurol. 10:525 (1964). 
4 W.J. Freeman, Mass Action in the Nervous System. (Academic Press, N.Y., 
1975), Chapter 3. 
5 L.B. Haberly and G.M. Shepherd, Neurophys. 36:789 (1973). 
6 L.B. Haberly and J.M. Bower, J. Neurophysiol. 51:90 (1984). 
7 S. Ramon y Cajal, Histologie du Systeme Nerveux de rHomme et des Vertebres. 
( Ed. Maloine, Paris, 1911). 
8 W.J. Freeman, Biol. Cybernetics. 35:21 (1979). 
9 W. Rall and G.M. Shepherd, J. Neurophysiol. 31:884 (1968). 
10 G.M. Shepherd, Physiol. Rev. 52:864 (1972). 
11 L.B. Haberly and J.L. Price, J. Comp. Neurol. !79; 711 (1978). 
12 W.J. Freeman, Exptl. Neurol. 6:70 (1962). 
13 W.J. Freeman, Biol. Cybernetics. 33:237 (1979). 
14 F.H. Eeckman and W.J. Freeman, AIP Proc. 151:135 (1986). 
15 C.M. Gray, Ph.D. thesis, Baylor College of Medicine (Houston, 1986) 
16 L.B. Haberly, Chemical Senses, 10:219 (1985). 
17 M. Satou et al., J. Neurophysiol. 49:1157 (1982). 
18 S. Grossberg, Studies in Applied Mathematics, Vol LII, 3 (MIT Press, 1973) 
p 213. 
19 S. Grossberg, SIAM-AMS Proc. 15:107 (1981). 
20 J.J Hopfield, Proc. Natl. Acad. Sci. USA 81:3088 (1984). 
21 W.A. Baird, Physica 22D: 150 (1986). 
22 W.A. Baird, AIP Proceedings 151:29 (1986). 
23 M. Wilson and J. Bower, Neurosci. Abstr. 387.10 (1987). 
248 
24 K.A. Grajski and W.J. Freeman, AIP Proc. 151:188 (1986). 
25 S.L. Bressler, Brain Res. 409:285 (1986). 
26 S.L. Bressler, Brain Res. 409:294 (1986). 
", sigmoid nonlinear prepyriform cortex eeckman ca report studi bn relationship eeg amplitud valu unit output prepyriform cortex awak motiv relationship form sigmoid describ normal wave curv fit use nonlinear regress slope maximum made excitatori inhibitori neuron neuron known form monosynapt neg feedback cell describ sigmoid curv asymmetr region maxim slope displac excitatori data compat model burst analog exist neural net implic signal process particular sigmoid slope effici neural comput olfactori cortex mammal gener repeat nearli sinusoid burst activ rang burst ride top high amplitud wave relat burst begin inspir termin gener local similar burst occur olfactori bulb high correl activ two structur two main cell type olfactori cortex superfici pyramid cell excitatori neuron receiv direct input cortic cell inhibitori cell group connect neg feedback pyramid cell mutual well granul granul cell inhibitori pyramid cell well paper focu analysi amplitud depend output cellmass relat synapt potenti record spike eeg allow us studi olfactori anatomi system extens studi begin work ramon caj al regular geometri simpl make structur ideal suitabl eeg record eeg variou olfactori region identifi synapt extens eeg scalar sum synapt current underli record use low imped cortic depth signal record appropri cell layer use high imped electrod appropri high pass deriv function relat wave puls olfactori function sigmoid deriv curv institut physic us gain curv forward gain embed cortic product forward gain valu set neuron give us feedback gain ultim determin dynam system method total rat enter rat linear array micron stainless steel electrod chronic implant prepyriform tip electrod electrolyt sharpen tip imped order electrod later use stereotax posit electrophysiolog use stimul electrod olfactori procedur describ earlier freeman end record small iron deposit made help histolog everi posit verifi rat record two week period follow awak stimul background environ record home cage place room present studi two channel data record channel carri eeg filter digit ms channel carri standard puls ms obtain signal two store disk process use routin written test file contain standard puls process procedur obtain condit puls probabl describ earlier tabl give us probabl occurr spike condit time normal eeg amplitud count number puls fix eeg plot versu normal eeg one sigmoid puls probabl sigmoid curv function normal divid averag puls level smooth pass digit filter fit nonlinear equat qmax exp ev qmax steadi state qmax background puls pmax maxim puls equat reli one paramet deriv justif equat discuss earlier paper freeman obtain express normal puls valu function normal eeg express rang mean true mean eeg filter close distribut amplitud valu record convent high turn occur activ dendrit cell low eeg valu voltag repres inhibit data smooth fit equat yield qmax valu everi data averag data file per per anim could fit succes repres differ electrod spike eeg qmax also calcul maximum deriv maxim trace first case qmax valu describ convers class cell whose maximum fire probabl cell label type cell trace excitatori pyramid mean qmax group standard deviat rang remain trace qmax describ convers class label cell whose maxim fire probabl lag eeg maximum approxim mean qmax group standard deviat rang group overal mean qmax standard deviat differ qmax group measur student wilcoxon test also found differ group two group qmax valu normal distribut mean median group mean median equal varianc deviat group deviat group differ estim power detect differ point respect group physiolog given assumpt power detect point differ greater alpha level two side thu feel reason confid differ qmax valu first deriv psc give us gain maximum valu first deriv label locat maximum occur label vmax express unit standard eeg mean group standard deviat group standard deviat sinc depend appli signific differ two group slope distribut qmax valu group valu valu mean vmax everi case vmax side posit valu eeg valu similar phenomenon report olfactori bulb exampl sigmoid cell cell ee amplitmt qm data ob deriv qmax valu mitml cell popul olfactori mitral cell output neuron bulb axon form olfactori tract lot main input pyramid cell awak motiv rat mean qmax valu deviat rang anesthet anim mean standard deviat rang signific differ anesthet awak signific differ qmax valu cortic cell qmaxvalu bulbar cell non overlap import characterist feedback loop feedback ampl exist feedback level nervou moreov feedback loop popul neuron describ olfactori bulb prepyriform cortex monosynapt neg feedback loop shown exist pyramid cell inhibitori call granul cell seri analysi concurr puls eeg record agre pyramid cell forward limb excit granul also mutual excitatori granul cell feedback inhibit pyramid evid mutual inhibit ppc also exist analysi cell fire versu eeg amplitud select allow one deriv function relat synapt potenti output neural first deriv curv give estim forward stage procedur appli variou structur olfactori system olfactori system lend well type analysi due topolog well known experiment gain curv show maxim gain excitatori mean cell becom excitatori mutual interact strength oscillatori burst high frequenc behind burst olfactori eeg comparison data olfactori bulb one notic differ slope maximum cortex valu substanti howev vmax gray found mean vmax olfactori bulb rabbit valu present studi differ statist import aspect nonlinear coupl sigmoid type cortic sigmoid interact group element promin featur mani artifici neural grossberg studi mani desir properti sigmoid use certain featur togeth threshold oper sigmoid rule effect quench sigmoid also provid built gain control mechan sigmoid slope investig network slope sigmoid interact element affect attractor system go previous remark similar chang sigmoid slope wake anesthet anim present system steep slope seri system shallow slope investig similar olfactori bulb hopfield report similar cortex network also propos amplitud panem eeg correl signific odor exist transmiss bulb cortex known shown cofrequ phase analysi bulb drive cortex thu sem like spatial pattern may also exist steeper analog neural network allow cortex classifi input pattern come olfactori view bulb could form initi classifi well olfactori cortex could second well perman present specul may turn import guid experi well studi inform us likelihood kind bressler mass action nervou chapter haberli haberli ramon histologi du system nerveux de homm et de rall haberli eeckman aip baylor colleg medicin chemic satou et studi appli vol usa physica aip proceed wilson grajski aip brain brain,1
27,27,"249 
HIERARCHICAL LEARNING CONTROL - 
AN APPROACH WITH NEURON-LIKE ASSOCIATIVE MEMORIES 
E. Ers 
ISRA Systemtechnik GmbH, Sch6fferstr. 15, D-6100 Darmstadt, FRG 
H. Tolle 
TH Darmstadt, Institut fgr Regelungstechnik, 
Schlograben 1, D-6100 Darmstadt, FRG 
ABSTRACT 
Advances in brain theory need two complementary approaches: 
Analytical investigations by in situ measurements and as well syn- 
thetic modelling supported by computer simulations to generate 
suggestive hypothesis on purposeful structures in the neural 
tissue. In this paper research of the second line is described: 
Starting from a neurophysiologically inspired model of stimulus- 
response (S-R) and/or associative memorization and a psychological- 
ly motivated ministructure for basic control tasks, pre-conditions 
and conditions are studied for cooperation of such units in a 
hierarchical organisation, as can be assumed to be the general 
layout of macrostructures in the brain. 
I. INTRODUCTION 
Theoretic modelling in brain theory is a highly speculative 
subject. However, it is necessary since it seems very unlikely to 
get a clear picture of this very complicated device by just analy- 
zing the available measurements on sound and/or damaged brain parts 
only. As in general physics, one has to realize, that there are 
different levels of modelling: in physics stretching from the ato- 
mary level over atom assemblies till up to general behavioural 
models like kinematics and mechanics, in brain theory stretching 
from chemical reactions over electrical spikes and neuronal cell 
assembly cooperation till general human behaviour. 
The research discussed in this paper is located just above the 
direct study of synaptic cooperation of neuronal cell assemblies as 
studied e.g. in /Amari 1988/. It takes into account the changes of 
synaptic weighting, without simulating the physical details of such 
changes, and makes use of a general imitation of learning situation 
(stimuli) - response connections for building up trainable basic 
control loops, which allow dynamic S-R memorization and which are 
themselves elements of some more complex behavioural loops. The 
general aim of this work is to make first steps in studying struc- 
tures, preconditions and conditions for building up purposeful 
hierarchies and by this to generate hypothesis on reasons and 
American Institute of Physics 1988 
250 
meaning behind substructures in the brain like the columnar organi- 
zation of the cerebral cortex (compare e.g. /Mountcastle 1978/). 
The paper is organized as follows: In Chapter II a short descrip- 
tion is given of the basic elements for building up hierarchies, 
the learning control loop LERNAS and on the role of its subelement 
AMS, some ssociative memory system inspired by neuronal network 
considerations. Chapter III starts from certain remarks on sub- 
structures in the brain and discusses the cooperation of LERNAS- 
elements in hierarchies as possible imitations of substructures. 
Chapter IV specifies the steps taken in this paper in the direction 
of Chapter III and Chapter V presents the results achieved by com- 
puter simulations. Finally an outlook will be given on further 
investigations. 
II. LERNAS AND AMS 
Since the formal neuron was introduced by /McCulloch and Pitts 
1943/, various kinds of neural network models have been proposed, 
such as the perceptron by /Rosenblatt 1957/ the neuron equation of 
/Calanclio 1961/, the cerebellar model articulation controller CMAC 
by /Albus 1972, 1975/ or the associative memory models by 
/Fukushima 1973/, /Kohonen 1977/ and /Amari 1977/. However, the 
ability of such systems to store information efficiently and to 
perform certain pattern recognition jobs is not adequate for sur- 
vival of living creatures. So they can be only substructures in the 
overall brain organization; one may call them a microstructure. 
Purposeful acting means a goal driven coordination of sensory in- 
formation and motor actions. Although the human brain is a very 
complex far end solution of evolution, the authors speculated in 
1978 that it might be a hierarchical combination of basic elements, 
which would perform in an elementary way like the human brain in 
total, especially since there is a high similarity in the basic 
needs as well as in the neuronal tissue of human beings and rela- 
tively simple creatures. This led to the design of the learning 
control loop LERNAS in 1981 by one of the authors - /Ersfi 1984/ - 
on the basis of psychological findings. He transformed the state- 
ment of /Piaget 1970/, that the complete intelligent action needs 
three elements: ""1) the question, which directs possible search 
actions, 2) the hypothesis, which anticipates eventual solutions, 
3) the control, which selects the solution to be chosen"" into the 
structure shown in Fig. 1, by identifying the ""question"" with an 
performance criterion for assessment of possible advantages/disad- 
vantages of certain actions, the ""hypothesis"" with a predictive 
model of environment answers and the ""control"" with a control stra- 
tegy which selects for known situations the best action, for un- 
known situations some explorative action (active learning). 
In detail, Fig. 1 has to be understood in the following way: The 
predictive model is built up in a step by step procedure from a 
characterization of the actual situation at the time instant k-T 
s 
251 
T sampling time) and the measured response of the unknown en- 
s 
vironment at time instant (k+l)T s. The actual situation consists of 
measurements regarding the stimuli and responses of the environment 
at time instant k.T plus - as far as necessary for a unique char- 
s 
acterization - of the situation-stimuli and responses at time in- 
stants (k-1)T s, (k-2)Ts..., provided by the short term memory. To 
reduce learning effort, the associative memory system used to store 
the predictive model has the ability of local generalization, that 
means making use of the trained response value not only for the 
corresponding actual situation, but also in similar situations. The 
assessment module generates on the basis of a given goal - a wanted 
environment response - with an adequate performance criterion an 
evaluation of possible actions through testing them with the pre- 
dictive model, as far as this is already built up and gives mean- 
ingful answers. The result is stored in the control strategyAMS 
together with its quality: real optimal action for the actual situ- 
ation or only relatively optimal action, if the testing reached the 
border of the known area in the predictive model of the environ- 
ment. In the second case, the real action is changed in a sense of 
curiosity, so that by the action the known area of the predictive 
model is extended. By this, one reaches more and more the first 
case, in which the real optimal actions are known. Since the first 
guess for a good action in the optimization phase is given to the 
assessment module from the control strategy AMS - not indicated in 
Fig. 1 to avoid unnecessary complication - finally the planning 
level gets superfluous and one gets very quick optimal reactions, 
the checking with the planning level being necessary and helpful 
only to find out, whether the environment has not changed, possi- 
bly. Again the associative memory system used for the control stra- 
tegy is locally generalizing to reduce the necessary training 
effort. 
The AMS storage elements for the predictive model, and for opti- 
mized actions are a refinement and implementation for on-line 
application of the neuronal network model CMAC from J. Albus - see 
e.g. /Ers6, Militzer 1982/ -, but it could be any other locally 
generalizing neural network model and even a storage element based 
on pure mathematical considerations, as has been shown in 
/Militzer, Tolle 1986/. 
The important property to build up an excellent capability to 
handle different tasks in an environment known only by some sensory 
information - the property which qualifies LERNAS as a possible 
basic structure (a ""ministructure"") in the nervous system of living 
creatures - has been proven by its application to the control of a 
number of technical processes, starting with empty memories for the 
predictive model and the control strategy storage. Details on this 
as well as on the mathematical equations describing LERNAS can be 
found in /Ers6, Mao 1983/, /Ers6, Tolle 1984/ and /Ers6, Militzer 
1984/. 
252 
It should be mentioned that the concept of an explicit predictive 
environmental model - as used in bERNAS - is neither the only mean- 
ingful description of human job handling nor a necessary part of 
our basic learning element. It suffices to use a prediction whether 
a certain action is advantegeous to reach the actual goal or 
whether this is not the case. More information on such a basic 
element MINLERNAS, which may be used instead of LERNAS in general 
(however, with the penalty of some performance degradation) are 
given in /Erst, Tolle 1988/. 
III. HIERARCHIES 
There are a number of reasons to believe, that the brain is 
built up as a hierarchy of control loops, the higher levels having 
more and more coordinative functions. A very simple example shows 
the necessity in certain cases. The legs of a jumping jack can move 
together, only. If one wants to move them separately, one has to 
cut the connection, has to build up a separate controller for each 
leg and a coordinating controller in a hierarchically higher level 
to restore the possibility of coordinated movements. Actually, one 
can find such an evolution in the historical development of certain 
animals. In a more complex sense a multilevel hierarchy exists in 
the extrapyramidal motor system. Fig. 2 from /Albus 1979/ specifies 
five levels of hierarchy for motor control. It can be speculated, 
that hierarchical organizations are not existing in the senso-moto- 
ric level only, but also in the levels of general abstractions and 
thinking. E.g. /D6rner 1974/ supports this idea. 
If one assumes out of these indications, that hierarchies are a 
fundamental element of brain structuring - the details and numbers 
of hierarchy-levels not being known - one has to look for certain 
substructures and groupings of substructures in the brain. In this 
connection one finds as a first subdivision the cortical layers, 
but then as another more detailed subdivision the columns, cell 
assemblies heavily connected in the axis vertical to cortical 
layers and sparsely connected horizontally. /Mountcastle 1978/ 
defines minicolumns, which comprise in some neural tissue roughly 
100 in other neural tissue roughly 250 individual cells. In addi- 
tion to these minicolumns certain packages of minicolumns, consist- 
ing out of several hundreds of the minicolumns, can be located. 
They are called macrocolumns by /Mountcastle 1978/. Fig. 3 gives 
some abstraction, how such structures could be interpreted: each 
minicolumn is considered to be a ministructure of the type LERNAS, 
a number of LERNAS units - here shown in a ring structure instead 
of a filled up cylindrical structure - building up a macrocolumn. 
The signals between the LERNAS elements could be overlapping and 
cooperating. Minicolumns being elements of macrocolumns of a higher 
cortical layer - here layer j projecting to layer k - could initi- 
ate and/or coordinate this cooperation in a hierarchical sense. 
Such a complex system is difficult to simulate. One has to go into 
this direction in a step by step procedure. In a first step the 
253 
overlapping or crosstalk between the minicolumns may be suppressed 
and the number of ministructures bERNAS representing the mini- 
columns should be reduced heavily. This motivates Fig. 4 as a fun- 
damental blockdiagram for research on cooperation of bERNAS ele- 
ments. 
IV. TOPICS ADDRESSED 
From Fig. 4 only the lowest level of coordination (layer 1), 
that means the coordination of two subprocesses was implemented up 
to now - right half of Fig. 5. This has two reasons: Firstl�, a 
number of fundamental questions can be posed and discussed with 
such a formulation already. Secondly, it is difficult to set up 
meaningful subprocesses and coordination goals for a higher order 
system. 
The problem discussed in the following can be understood as the 
coordination of two minicolumns as described in Chapter III, but 
also as the coordination of higher level subtasks, which may be 
detailed themselves by ministructures and/or systems like Fig. 4. 
This is indicated in the left half of Fig. 5. 
Important questions regarding hierarchies of learning control loops 
are: 
What seem to be meaningful interventions from the coordinator 
onto the lower level systems? 
II. 
Is parallel learning in both levels possible or requires a 
meaningful learning strategy that the control of subtasks has 
to be learned at first before the coordination can be learned? 
III. Normally one expects, that the lower level takes care of short 
term requirements and the upper level of long term strategies. 
Is that necessary or what happens if the upper level works on 
nearly the same time horizon as the lower levels? 
IV. 
Furtheron one expects, that the upper level may look after 
other goals than the lower level, e.g. the lower level tries 
to suppress disturbances effects since the upper level tries 
to minimize overall energy consumption. But can such different 
strategies work without oscillations or destabilization of the 
system? 
Question I can be discussed by some general arguments, for ques- 
tions II-IV only indications of possible answers can be given from 
simulation results. This will be postponed to Chapter V. 
Fig. 6 shows three possible intervention schemes from the coordina- 
tor. 
By case a) an intervention into the structure or the parameters of 
254 
the sublevel (=local) controllers is meant. Since associative 
mappings like AMS have no parameters being directly responsible for 
the behaviour of the controller - as would be the case with a para- 
metrized linear or non-linear differential equation being the de- 
scription of a conventional controller - this does not make sense 
for the controller built up in LERNAS. However, one could consider 
the possibility to change parameters or even elements, that means 
structural terms of the performance criterion, which is responsible 
for the shaping of the controller. But this would require to learn 
anew, which takes a too long time span in general. 
By case b) a distribution of work load regarding control commands 
is meant. The possible idea could be, that the coordinator gives 
control inputs to hold the long range mean value required, since 
the local controllers take into account fast dynamic fluctuations 
only. However, this has the disadvantage that the control actions 
of the upper level have to be included into the inputs to the local 
controllers, extending the dimension of in-put space of these 
storage devices, since otherwise the process appears to be highly 
time variant for the local controllers, which is difficult to 
handle for LERNAS. 
So case c) seems to be the best solution. In this case the coordi- 
nator commands the set points of the local controllers, generating 
by this local subgoals for the lower level controllers. Since this 
requires no input space extension for the local controllers and is 
in full agreement with the working conditions of single LERNAS 
loops, it is a meaningful and effective approach. 
Fig. 7 shows the accordingly built up structure in detail. The 
control strategy of Fig. 1 is divided here in two parts the storage 
element (the controller C) and the active learning AL. The elements 
are explicitly characterized for the upper level only. The whole 
lower level is considered by the coordinator as a single pseudo- 
process to be controlled (see Fig. 4). 
V. SIMULATION RESULTS 
For answering questions II and III the very simple non-linear 
process shown in Fig. 8 - detailing the subprocesses SP1, SP2 and 
their coupling in Fig. 7 - was used. For the comparison of bottom 
up and parallel learning suitably fixed PI-controllers were used 
for bottom up learning instead of LERNAS 1 and LERNAS 2, simulating 
optimally trained local controllers. Fig. 9a shows the result due 
to which in the first run a certain time is required for achieving 
a good set point following through coordinator assistance. However, 
with the third repetition (4th run) a good performance is reached 
from the first set point change on already. For parallel learning 
all (and not only the coordinator AMS-memories) were empty in the 
beginning. Practically the same performance was achieved as in 
bottom up training - Fig. 9b -, indicating, that at least in simple 
problems, as considered here, parallel learning is a real possibi- 
255 
lity. However - what is not illustrated here - the coordinator 
sampling time must be sufficiently long, so that the local control- 
lers can reach the defined subgoals at least qualitatively in this 
time span. 
For answering question III, in which respect a higher difference in 
the time horizon between local controller and coordinator changes 
the picture, a doubling of the sampling rate for the coordinator 
was implemented. Fig. 10 give the results. They can be interpreted 
as follows: Smaller sampling rates allow the coordinator to get 
more information about the pseudo-sub-processes, the global goal is 
reached faster. Larger sampling rates lead to a better overall 
performance when the goal is reached: there is a higher amount of 
averaging regarding informations about the pseudo-sub-processes. 
up to now in both levels the goal or performance criterion was the 
minimization of differences between the actual plant output and the 
requested plant output. The influence of different coordinator 
goals - question IV - was investigated by simulating a two stage 
waste water neutralization process. A detailed description of this 
process set up and the simulation results shall not be given here 
out of space reasons. It was found that: 
� in hierarchical systems satisfactory overall behaviour may be 
reached by well defined subgoals with clearly different coordi- 
nator goals. 
� since learning is goal driven, one has to accept that implicit 
wishes on closed loop behaviour are fulfilled by chance only. 
Therefore important requirements have to be included in the 
performance criteria explicitly. 
It should be remarked finally, that one has to keep in mind, that 
simulation results with one single process are indications of 
possible behaviour only, not excluding that in other cases a funda- 
mentally different behaviour can be met. 
VI. OUTLOOK 
As has been mentioned already in Chapter III and IV, this work 
is one of many first steps of investigations regarding hierarchical 
organization in the brain, its preconditions and possible behav- 
iour. 
Subjects of further research should be the self-organizing task 
distribution between the processing units of each layer, and the 
formation of interlayer projections in order to build up meta-tasks 
composed of a sequence of frequently occuring elementary tasks. 
These investigations will on the other hand show to what extent 
this kind of higher-learning functions can be achieved by a hier- 
archy of LERNAS-type structures which model more or less low-level 
basic learning behaviour. 
256 
VII. ACKNOWLEDGEMENTS 
The work presented has been supported partly by the Stiftung 
Volkswagenwerk. The detailed evaluations of Chapter IV and V have 
been performed by Dipl.-Ing. M. Zoll and Dipt.-Ing. S. Gehlen. We 
are very thankful for this assistance. 
REFERENCES 
Albus, J. S. 
Albus, J. S. 
Albus, J. S. 
Amari, S. I. 
Amari, S. I. 
Caianello, E. R. 
D6rner, D. 
Erst, E. 
Ers6, E. 
Mao, X. 
Theoretical and Experimental Aspects of a 
Cerebellar Model, Ph.D. Thesis, Univ. of 
Maryland, 1972 
A New Approach to Manipulator Control: 
The Cerebellar Model Articulation Controller 
(CMAC), Trans. ASmE series, G, 1975 
A Model of the Brain for Robot Control - 
Part 3: A Comparison of the Brain and Our 
Model, Byte, 1979 
Neural Theory of Association and Concept 
Formation, Biol. Cybernetics, Vol. 26, 1977 
Mathematical Theory of Self-Organization in 
Neural Nets, in: Organization of Neural 
Networks, Structures and Models, ed. by 
yon Seelen, Shaw, Leinhos, VHC-Verlagsges. 
Weinheim, W.-Germany, 1988 
Outline of a Theory of Thought Process and 
Thinking Machines, Journal of Theoretical 
Biology, Vol. 1, 1961 
Problem16sen als Informationsverarbeitung 
Verlag H. Huber, 1974 
On the Application of Associative Neural 
Network Models to Technical Control Problems, 
in: Localization and Orientation in Biology and 
Engineering, ed. by Varju, Schnitzler, 
Springer Verlag Berlin, W.-Germany, 1984 
Control of pH by Use of a Self-Organizing 
Concept with Associative Memories, ACI'83, 
Kopenhagen (Denmark), 1983 
257 
ErsS, E. 
Militzer, J. 
Software Implementation of a Neuron-Like 
Associative Memory System for Control 
Application, Proceedings of the 2nd IASTED 
Conference on Mini- and Microcomputer Appli- 
cations, MIMI'82, Dayos (Switzerland), 1982 
ErsL, E. 
Militzer, J. 
Real-Time Implementation of an Associative 
Memory-Based Learning Control Scheme for Non- 
Linear Multivariable Processes, Symposium 
""Applications of Multivariable System 
Techniques"", Plymouth (UK), 1984 
Ers6, E. 
Tolle, H. 
A New Concept for Learning Control Inspired by 
Brain Theory, Proceed. 9th IFAC World Congress, 
Budapest (Hungary), 1984 
Ersd, E. 
Tolle, H. 
Learning Control Structures with Neuron-Like 
Associative Memory Systems, in: Organization of 
Neural Networks, Structures and Models, ed. by 
yon Seelen, Shaw, Leinhos, VCH Verlagsgesell- 
schaft Weinheim, W.-Germany, 1988 
Fukushima, K. 
A Model of Associative Memory in the Brain 
Biol. Cybernetics, Vol. 12, 1973 
Kohonen, T. 
Associative Memory, Springer Verlag Berlin, 
W.-Germany, 1977 
McCulloch, W. S. 
Pitts, W. H. 
A Logical Calculus of the Ideas, Immanent in 
Nervous Activity, Bull. Math. Biophys. 9, 1943 
Militzer, J. 
Tolle, H. 
Vertiefungen zu einem Teilbereiche der mensch- 
lichen Intelligenz imitierenden Regelungsansatz 
Tagungsband-DGLR-Jahrestagung, MLnchen, 
W.-Germany, 1986 
Mountcastle, V. B. An Organizing Principle for Cerebral Function: 
The Unit Module and the Distributed System, in: 
The Mindful Brain by G. M. Edelman, 
V. B. Mountcastle, The MIT-Press, Cambridge, 
USA, 1978 
Piaget, J. 
Psychologie der Intelligenz, Rascher Verlag, 
4th printing, 1970 
Rosenblatt, F. 
The Perceptron: A Perceiving and Recognizing 
Automation, Cornell Aeronautical Laboratory, 
Report No. 85-460-1, 1957 
258 
FIGURES 
 Asociative Situation-Response Uapping (Long Term Ifemory) 
Fig. 1. lrehitectural element LKRIgAS 
iiYPO$ 
NUCLEUS 
ETI CULA,E 
FO!ATIO 
SUB C NUCLEUS 
NUCLEUS 
PiE OOliI S SURALI S 
Fig. 2. The hierarchy of motor control that exists in the extra- 
pyramidal motor system. Basic reflexes remain even if the brain 
stem is cut at A-A. Coordination of these reflexes for standing is 
possible if the cut is at B-B. The sequential coordination required 
for walking requires the area below C-C to be operable. Simple 
tasks can be executed if the region below D-D is intact. Lengthy 
tasks and complex goals require the cerebral cortex. (/Albus 1979/) 
259 
la, k 
Fig. 3. Generic scetch of macrocolumns - drawn as ring 
structures - from different cortical layers with 
hERNAS-subunits representing minicolumns 
]jer n 
Fig. 4. hERNAS-hierarchy as a simplified research model 
for cooperation of columnar structures 
260 
Process 
ILERNAS (oo,,.t,)] 
SUBPROCESS 
Fig. 5. Hierarchical work/ 
control distribution 
Fig. 6. Methods of 
intervention from the 
coordinator 
fiOOEL 
! 
Fig. 7. Implementation of the hierarchical structure 
261 
non-linear proce I 
Fig. 8. Hierarchical structure with non-linear 
multivariable test-process 
reference value 
? 
1st run) 
4th run) 
reference value 
Fig. 9. Learning on coordinator level using already 
trained (a) and untrained (b) lower levels 
(Tcoor d = 2 sec, Tlo c = 0.5 sec) 
Tcoord=4 sec ,, Tcoord=2sec 
Fio. 10. Coordinator learning behaviour using different 
coordinator horizons (Tlo c = 0.5 sec) 
", learn control approach associ memori systemtechnik frg toll institut fgr frg brain theori need two complementari investig situ measur well model support comput simul gener hypothesi purpos structur neural paper research second line neurophysiolog inspir model associ memor motiv ministructur basic control condit studi cooper unit assum gener macrostructur introduct model brain theori highli specul necessari sinc seem unlik clear pictur complic devic avail measur sound damag brain part gener one level physic stretch level atom assembl till gener behaviour like kinemat brain theori stretch chemic reaction electr spike neuron cell cooper till gener human research discuss paper locat studi synapt cooper neuron cell assembl take account chang without simul physic detail make use gener imit learn situat respons connect build trainabl basic allow dynam memor element complex behaviour aim work make first step studi precondit condit build purpos gener hypothesi reason institut physic behind substructur brain like columnar cerebr cortex paper organ chapter ii short given basic element build learn control loop lerna role subel memori system inspir neuron network chapter start certain remark brain discuss cooper hierarchi possibl imit iv specifi step taken paper direct chapter chapter present result achiev final outlook given lerna am formal neuron introduc culloch pitt variou kind neural network model perceptron neuron equat cerebellar model articul control cmac associ memori model system store inform effici certain pattern recognit job adequ live substructur brain one may call act mean goal driven coordin sensori motor although human brain far end solut author specul might hierarch combin basic would perform elementari way like human brain especi sinc high similar basic well neuron tissu human be simpl led design learn loop lerna one author basi psycholog transform complet intellig action need direct possibl search anticip eventu select solut shown identifi criterion assess possibl certain predict environ answer control select known situat best situat explor action understood follow model built step step procedur actual situat time instant sampl measur respons unknown time instant actual situat consist regard stimuli respons environ time instant plu far necessari uniqu respons time provid short term learn associ memori system use store predict model abil local make use train respons valu actual also similar modul gener basi given goal want respons adequ perform criterion possibl action test far alreadi built give result store control am real optim action actual rel optim test reach known area predict model second real action chang sens action known area predict one reach first real optim action sinc first good action optim phase given modul control strategi am indic avoid unnecessari complic final plan get superflu one get quick optim check plan level necessari help find whether environ associ memori system use control local gener reduc necessari train am storag element predict action refin implement neuron network model cmac albu see militz could local neural network model even storag element base pure mathemat shown toll import properti build excel capabl differ task environ known sensori properti qualifi lerna possibl structur nervou system live proven applic control technic start empti memori model control strategi detail well mathemat equat describ lerna mao toll militz mention concept explicit predict model use erna neither descript human job handl necessari part basic learn suffic use predict whether certain action advanteg reach actual goal inform basic may use instead lerna gener penalti perform toll hierarchi number reason brain hierarchi control higher level coordin simpl exampl show necess certain leg jump jack move one want move one build separ control coordin control hierarch higher level restor possibl coordin one find evolut histor develop certain complex sens multilevel hierarchi exist extrapyramid motor specifi level hierarchi motor hierarch organ exist level also level gener abstract support one assum hierarchi element brain structur detail number known one look certain group substructur one find first subdivis cortic anoth detail subdivis cell heavili connect axi vertic cortic spars connect compris neural tissu roughli neural tissu roughli individu minicolumn certain packag sever hundr call macrocolumn give structur could consid ministructur type number lerna unit shown ring structur instead fill cylindr structur build signal lerna element could overlap minicolumn element macrocolumn higher layer layer project layer could coordin cooper hierarch complex system difficult one go direct step step first step crosstalk minicolumn may suppress number ministructur erna repres reduc motiv blockdiagram research cooper erna topic address lowest level coordin mean coordin two subprocess implement right half two fundament question pose discuss formul difficult set subprocess coordin goal higher order problem discuss follow understood two minicolumn describ chapter coordin higher level may ministructur system like indic left half question regard hierarchi learn control loop seem meaning intervent coordin lower level parallel learn level possibl requir learn strategi control subtask learn first coordin normal one lower level take care short requir upper level long term necessari happen upper level work time horizon lower one upper level may look goal lower lower level tri suppress disturb effect sinc upper level tri minim overal energi differ work without oscil destabil discuss gener indic possibl answer given postpon chapter show three possibl intervent scheme case intervent structur paramet sublevel control sinc associ like am paramet directli respons behaviour control would case linear differenti equat convent control make sens control built one could consid possibl chang paramet even mean term perform respons shape would requir learn take long time span case distribut work load regard control command possibl idea could coordin give input hold long rang mean valu sinc local control take account fast dynam fluctuat disadvantag control action upper level includ input local extend dimens space sinc otherwis process appear highli variant local difficult case seem best case command set point local gener local subgoal lower level sinc input space extens local control full agreement work condit singl lerna meaning effect show accordingli built structur strategi divid two part storag control activ learn element explicitli character upper level whole level consid coordin singl control simul result answer question ii simpl shown detail subprocess coupl comparison bottom parallel learn suitabl fix use bottom learn instead lerna lerna simul train local show result due first run certain time requir achiev good set point follow coordin third repetit good perform reach first set point chang parallel learn coordin empti practic perform achiev train least simpl consid parallel learn real howev illustr coordin time must suffici local reach defin subgoal least qualit answer question respect higher differ time horizon local control coordin chang doubl sampl rate coordin give interpret smaller sampl rate allow coordin get inform global goal larger sampl rate lead better overal goal higher amount regard inform level goal perform criterion differ actual plant output plant influenc differ coordin question iv investig simul two stage water neutral detail descript set simul result shall given space found hierarch system satisfactori overal behaviour may well defin subgoal clearli differ sinc learn goal one accept implicit close loop behaviour fulfil chanc import requir includ criteria remark one keep result one singl process indic behaviour exclud case differ behaviour outlook mention alreadi chapter work one mani first step investig regard hierarch precondit possibl research task process unit interlay project order build sequenc frequent occur elementari investig hand show extent kind function achiev structur model less learn acknowledg work present support partli stiftung detail evalu chapter iv perform zoll thank experiment aspect new approach manipul cerebellar model articul control model brain robot control comparison brain theori associ concept theori organ neural structur theori thought process journal theoret al informationsverarbeitung applic associ neural model technic control local orient biolog verlag use associ implement memori system control proceed iast microcomput dayo implement associ learn control scheme multivari symposium multivari system plymouth new concept learn control inspir ifac world control structur memori organ structur vch model associ memori brain springer verlag logic calculu imman zu einem teilbereich der intelligenz imitierenden regelungsansatz organ principl cerebr unit modul distribut mind brain der rascher perceiv recogn cornel aeronaut uap term lrehitectur element nucleu surali hierarchi motor control exist motor basic reflex remain even brain cut coordin reflex stand cut sequenti coordin requir walk requir area simpl execut region lengthi complex goal requir cerebr gener scetch macrocolumn drawn ring differ cortic layer repres minicolumn simplifi research model cooper columnar structur hierarch distribut method ooel implement hierarch structur hierarch structur valu valu learn coordin level use alreadi untrain lower level tlo sec coordin learn behaviour use differ horizon,0
28,28,"262 
ON TROPISTIC PROCESSING AND ITS APPLICATIONS 
Manuel F. FernRndez 
General Electric Advanced Technology Laboratories 
Syracuse, New York 13221 
ABSTRACT 
The interaction of a set of tropisms is sufficient in many 
cases to explain the seemingly complex behavioral responses 
exhibited by varied classes of biological systems to combinations of 
stimuli. It can be shown that a straightforward generalization of 
the tropism phenomenon allows the efficient implementation of 
effective algorithms which appear to respond ""intelligently"" to 
changing environmental conditions. Examples of the utilization of 
troplstic processing techniques will be presented in this paper in 
applications entailing simulated behavior synthesis, path-planning, 
pattern analysis (clustering), and engineering design optimization. 
INTRODUCTION 
The goal of this paper is to present an intuitive overview of 
a general unsupervised procedure for addressing a variety of system 
control and cost minimization problems. This procedure is based on 
the idea of utilizing ""stimuli"" produced by the environment in which 
the systems are designed to operate as basis for dynamically 
providing the necessary system parameter updates. 
This is by no means a new idea: countless examples of this 
approach abound in nature, where innate reactions to specific 
stimuli (""tropisms"" or ""taxis"" --not to be confused with 
""instincts"") provide organisms with built-in first-order control 
laws for triggering varied responses [8]. (It is hypothesized that 
""knowledge"" obtained through evolution/adaptation or through 
learning then refines or suppresses most of these primal reactions). 
Several examples of the implicit utilization of this approach 
can also be found in the literature, in applications ranging from 
behavior modeling to pattern analysis. We very briefly depict some 
these applications, underlining a common pattern in their 
formulation and generalizing it through the use of basic field 
theory concepts and representations. A more rigorous and detailed 
exposition --regarding both mathematic and 
application/implementation aspects-- is presently under preparation 
and should be ready for publication sometime next year ([6]). 
TROPI SMS 
Tropisms can be defined in general as class-invariant systemic 
responses to specific sets of stimuli [6]. All time-invariant 
systems can thus be viewed as tropistic provided that we allow all 
possible stimuli to form part of our set of inputs. In most 
tropistic systems, however, response- (or time-) invariance applies 
only to specific inputs: green plants, for example, twist and grow 
in the direction of light (phototropism), some birds  flight 
patterns follow changes in the Earth's magnetic field 
(magnetotropism), various organisms react to gravitational field 
@ American Institute of Physics 1988 
263 
variations (geotropism), etc. 
Tropism/stimuli interactions can be portrayed in term of the 
superposition of scalar (e.g., potential) or vector (e.g., force) 
fields exhibiting properties paralleling those of the suitably 
constrained ""reactions"" we wish to model [1],[6]. The resulting 
field can then be used as a basis for assessing the intrinsic cost 
of pursuing any given path of action, and standard techniques (e.g., 
gradient-following in the case of scalar fields or divergence 
computation in the case of vector fields) utilized in determining a 
response*. In addition, the global view of the situation provided by 
field representations suggest that a basic theory of tropistic 
behavior can also be formulated in terms of energy expenditure 
minimization (Euler-Lagrange equations). This formulation would 
yield integral-based representations (Feynman path integrals 
[4],[11]) satisfying the observation that tropistic processes 
typically obey the principle of least action. 
Alternatively, fields may also be collapsed into ""attractors"" 
(points of a given ""mass"" or ""charge"" in cost space) through laws 
defining the relationships that are to exist among these 
""attractors"" and the other particles traveling through the space. 
This provides the simplification that when updating dynamically 
changing situations only the effects caused by the interaction of 
the attractors with the particles of interest --rather than the 
whole cost field-- may have to be recalculated. 
For example, appropriately positioned point charges exerting 
on each other an electrostatic force inversely proportional to the 
square of their distance can be used to represent the effects of a 
coulombic-type cost potential field. A particle traveling through 
this field would now be affected by the combination of forces 
ensuing from the interaction of the attractors  charges with its 
own. If this particle were then to passively follow the composite of 
the effects of these forces it would be following the gradient of 
the cost field (i.e., the vector resulting from the superposition of 
the forces acting on the particle would point in the direction of 
steepest change in potential). 
Finally, other representations of tropism/stimuli interactions 
(e.g., Value-Driven Decision Theory approaches) entail associating 
""profit"" functions (usually sigmoidal) with each tropism, modeling 
the relative desirability of triggering a reaction as a function of 
the time since it was last activated [9]. These representations are 
* In order to bring extra insight into tropism/stimuli 
interactions and simplify their formulation, one may exchange vector 
and scalar field representations through the utilization of 
appropriately selected mappings. Some of the most important of such 
mappings are the gradient operator (particularly so because the 
gradient of a scalar --potential-- field is proportional to a 
""force"" --vector-- field), the divergence (which may be thought of 
as performing in vector fields a function analogous to that 
performed in scalar fields by the gradient), and their combinations 
(e.g., the Laplacian, a scalar-to-scalar mapping which can be 
visualized as performing on potential fields the equivalent of a 
second derivative operation. 
264 
� Model fly as a positive geotropistic point of mass M. 
� Model fence stakes as negative geotropistic points 
with masses m t, m  ..... m . 
� At each update time compute sum of forces acting on 
frog: 
F-k 
d I N 
i-I d m 
m I 
Compute frog's heading and acceleration based on 
the ensuing force: then update frog's position, 
Figure 1: Attractor-based representation of a frog-fence-fly 
scenario (see [1] for a vector-field representation). The objective 
is to model a frog's path-planning decision-making process when 
approaching a fly in the presence of obstacles. (The picket fence is 
represented by the elliptical outline with an opening in the back, 
the fly --inside the fenced space-- is represented by a ""+"" sign, 
and arrows are used to indicate the direction of a frog's trajectory 
into and out of fenced area). 
265 
particularly amenable to neural-net implementations [6]. 
TROPISTIC PROCESSING 
Tropistic processing entails building into systems tropisms 
appropriate for the environment in which these systems are expected 
to operate. This allows taking advantage of environment-produced 
""stimuli"" for providing the required control for the systems' 
behavior. 
The idea of tropistic processing has been utilized with good 
results in a variety of applications. Arbib et.al., for example, 
have implicitly utilized tropistic processing to describe a 
batrachian's reaction to its environment in terms of what may be 
visualized as magnetic (vector) fields' interactions [1]. 
Watanabe [12] devised for pattern analysis purposes an 
interaction of tropisms (""geotropisms"") in which pattern ""atoms"" are 
attracted to each other, and hence ""clustered"", subject to a 
squared-inverse-distance (""feature distance"") law similiar to that 
from gravitational mechanics. It can be seen that if each pattern 
atom were considered an ""organism"", its behavior would not be 
conceptually different from that exhibited by Arbibian frogs: in 
both cases organisms passively follow the force vectors resulting 
from the interaction of the environmental stimuli with the 
organisms' tropisms. It is interesting, though, to note that the 
""organisms'"" behavior will nonetheless appear ""intelligent"" to the 
casual observer. 
The ability of tropistic processes to emulate seemingly 
rational behavior is now begining to be explored and utilized in the 
development of synthetic-psychological models and experiments. 
Braitenberg, for example, has placed tropisms as the primal building 
block from which his models for cognition, reason, and emotions 
evolve [3]**; Barto [2] has suggested the possibility of combining 
tropisms and associative (reinforced) learning, with aims at 
enabling the automatic triggering of behavioral responses by 
previously experienced situations; and Fernandez [6] has used 
CROBOTS [10], a virtual multiprocessor emulator, as laboratory for 
evaluating the effects of modifying tropistic responses on the basis 
of their projected future consequences. 
Other applications of tropistic processing presently being 
investigated include path-planning and engineering design 
optimization [6]. For example, consider an air-reconnaissance 
mission deep behind enemy lines; as the mission progresses and 
unexpected SAM sites are discovered, contingency flight paths may be 
developed in real time simply by modeling each SAM or interdiction 
site as a mass point towards which the aircraft exhibits negative 
geotropistic tendencies (i.e., gravitational forces repel it), and 
modeling the objective as a positive geotropistic point. A path to 
** Of particular interest within the sole context of Tropistic 
Processing is Dewdney's [5] commented version of the first chapters 
of Braitenbergts book [3], in which the ""behavior"" of mechanically 
very simple cars, provided with ""eyes"" and phototropism-supporting 
connections (including Ledley-type ""neurons"" [4]), is ""analyzed"". 
266 
� 
� 
� 
Figure 2 (Geotropistic clustering [12]): The problem being 
 ............ portrayed 
here is t at of clustering dots distributed in [x,y]-space as shown 
and uniformly in color ([red,blue,green]). The approach followed is 
that outlined in Figure 1, with the differences that normalized 
(Mahalanobis) distances are used and when merges occur, conservation 
of momentum is observed. Tags are also kept --specifying with which 
dots and in what order merges occur-- to a].low drawing cluster 
boundaries in the original data set. (Efficient implementation of 
this clustering technique entails using a ring of processors, each 
of which is assigned the ""features"" of one or more ""dots"" and the 
task of carrying out computations with respect to these features. If 
the features of each dot are then transmitted through the ring, all 
the forces imposed on it by the rest will have been determined upon 
completion of the circuit). 
267 
the target will then be automatically drawn by the interaction of 
the tropisms with the gravitational [orces. (Once the mission has 
been completed, the'target and its effects can be eliminated, 
leaving active only the repulsive forces, which will then ""guide"" 
the airplane out of the danger zone). 
In engineering design applications such as lens modeling and 
design, lenses (gradient-index type, for example) can be modeled in 
terms of photons attempting to reach an objective plane through a 
three-dimensional scalar field of refraction indices; modeling the 
process tropistically (in a manner analogous to that of the 
air-reconnaissance example above) would yield the least-action paths 
that the individual photons would follow. Similarly, in 
""surface-of-revolution"" fuselage design (""Newton's Problem""), the 
characteristics of the interaction of forces acting within a sheet 
of metal foil when external forces (collisions with a fluid's 
molecules) are applied can be modeled in terms of tropistic 
reactions which will tend to reconfigure the sheet so as to make it 
present the least resistance to friction when traversing a fluid. 
Additional applications of tropistic processing include target 
tracking and multisensor fusion (both can be considered instances of 
""clustering"") 6], resource allocation and game theory (both closely 
related to path-planning) [9], and an assortment of other 
cost-minimization functions. Overall, however, one of the most 
important applications of tropistic processing may be in the 
modeling and understanding of analog processes 6], the imitation of 
which may in turn lead to the development of effective strategies 
PAST EXPERIENCE 
(e.g. MEMORY MAPS) 
RESPONSE 
FUNCTION 
PREDICTED (i.e. MODELLED) 
OUTCOME 
 RESPONSE 
TROPISM-BASED SYSTEM 
Figure 3: The combination of tropisms and associative (reinforced) 
learning-can be used to enable the automatic triggering of 
behavioral responses by previously experienced situations [2]. Also, 
the modeled projection of the future consequences of a tropistic 
decision can be utilized in the modification of such decision |6]. 
(Note analogy to filtering problem in which past history and 
predicted behavior are used to smooth present observations). 
268 
/"" 
Figure 4: Simplified representation of air-reconnaissance mission 
example (see text): objective is at center of coordinate axis, thick 
dots represent SAM sites, and arrows denote airp]anes direction of 
flight (airplane's maximum attainable speed and acceleration are 
constrained). All portrayed scenarios are identical except for 
tropistic control-law parameters (mainly objective to SAM-sites mass 
ratios in the first three scenarios). Varying the masses of the 
objective and SAM sites can be interpreted as trading off the 
relative importance of the mission vs. the aircrafts safety, and 
can produce dramatically differing flight paths, induce chaotic 
behavior (bottom-left scenario), or render the system unstable. The 
bottom-right scenario portrays the situation in which a tropistic 
decision is projected into the future and, if not meeting some 
criterion, modified (altering the direction of flight --e.g., 
following an isokline--, re-evaluating the mission's relative 
importance --revising masses--, changing the update rate, etc.). 
269 
for taking full advantage of parallel architectures [11]***. It is 
thus expected that the flexibility of tropistic processes to adapt 
to changing environmental conditions will prove highly valuable to 
the advancement of areas such as robotics, parallel processing and 
artificial intelligence, where at the very least they will provide 
some decision-making capabilities whenever unforeseen circumstances 
are encountered. 
ACKNOWLEDGEMENTS 
Special thanks to D. P. Bray for the ideas provided in our 
many discussions and for the development of the finely detailed 
simulations that have enabled the visualization of unexpected 
aspects of our work. 
REFERENCES 
[1] Arbib, M.A. and House, D.H.: ""Depth and Detours: Decision Making 
in Parallel Systems"". IEEE Workshop on Languages for Automation: 
Cognitive Aspects in Information Processing; pp. 172-180 (1985). 
[2] Barto, A.G. (Editor): ""Simulation Experiments with Goal-Seeking 
Adaptive Elements"". Avionics Laboratory, Wright-Patterson Air 
Force Base, OH. Report # AFWAL-TR-84-1022. (1984). 
[3] Braitenberg, V.: Vehicles: Experiments in Synthetic Psychology. 
The MIT Press. (1984). 
[4] Cheng, G.C.; Ledley, R.S.; and Ouyang, B.: ""Pattern Recognition 
with Time Interval Modulation Information Coding"". IEEE 
Transactions on Aerospace and Electronic Systems. AES-6, No.2; 
pp. 221-227 (1970). 
[5] Dewdney, A.K.: ""Computer Recreations"". Scientific American. 
Vol.256, No.3; pp. 16-26 (1987). 
[6] Fernandez, M.F.: ""Tropistic Processing"". To be published (1988). 
[7] Feynman, R.P.: Statistical Mechanics: A Set of Lectures. 
Frontiers in Physics Lecture Note Series (1982). 
[8] Hirsch, J.: ""Nonadaptive Tropisms and the Evolution of 
Behavior"". Annals of the New York Academy of Sciences. Vol.223; 
pp. 84-88 (1973). 
[9] Lucas, G. and Pugh, G.: ""Applications of Value-Driven 
Automation Methodology for the Control and Coordination of 
Netted Sensors in Advanced C*'3"". Report # RADC-TR-80-223. 
Rome Air Development Center, NY. (1980). 
[10] Poindexter, T.: ""CROBOTS"". Manual, programs, and files (1985). 
2903 Winchester Dr., Bloomington, IL., 61701. 
[11] Wallqvist, A.; Berne, B.J.; and Pangali, C.: ""Exploiting 
Physical Parallelism Using Supercomputers: Two Examples from 
Chemical Physics"". Computer. Vol.20, No.5; pp. 9-21 (1987). 
[12] Watanabe, S.: Pattern Recognition: Human and Mechanical. 
John Wiley & Sons; pp. 160-168 (1985). 
*** Optical Fourier transform operations, for instance, can be 
modeled in high-granularity machines through a procedure analogous 
to the gradient-index lens simulation example, with processors 
representing diffraction-grating ""atoms"" [6]. 
", tropist process applic rndez electr advanc technolog laboratori new york interact set tropism suffici mani explain seemingli complex behavior respons vari class biolog system combin shown straightforward gener tropism phenomenon allow effici implement algorithm appear respond environment exampl util process techniqu present paper entail simul behavior analysi engin design goal paper present intuit overview gener unsupervis procedur address varieti system cost minim procedur base idea util produc environ system design oper basi dynam necessari system paramet mean new countless exampl abound innat reaction specif confus provid organ control trigger vari respons hypothes obtain refin suppress primal exampl implicit util approach also found applic rang model pattern briefli depict underlin common pattern gener use basic field concept rigor detail mathemat present prepar readi public sometim next year sm defin gener system specif set stimuli thu view tropist provid allow stimuli form part set invari appli specif green twist grow direct light bird flight follow chang magnet field variou organ react gravit field american institut physic interact portray scalar vector exhibit properti parallel suitabl wish model result use basi assess intrins cost pursu given path standard techniqu case scalar field diverg case vector util determin global view situat provid represent suggest basic theori tropist also formul term energi expenditur formul would represent path integr satisfi observ tropist process obey principl least field may also collaps given cost law relationship exist among particl travel provid simplif updat dynam situat effect caus interact attractor particl interest cost may appropri posit point charg exert electrostat forc invers proport distanc use repres effect cost potenti particl travel field would affect combin forc interact attractor charg particl passiv follow composit effect forc would follow gradient cost field vector result superposit forc act particl would point direct chang represent interact decis theori entail associ function model rel desir trigger reaction function time sinc last activ represent order bring extra insight simplifi one may exchang vector scalar field represent util select import gradient oper scalar field proport diverg may thought perform vector field function analog scalar field combin map perform potenti field equival deriv model fli posit geotropist point mass model fenc stake neg geotropist point mass updat time comput sum forc act head acceler base ensu updat represent object model process fli presenc picket fenc ellipt outlin open fli fenc repres arrow use indic direct trajectori fenc amen implement process process entail build system tropism environ system expect allow take advantag provid requir control idea tropist process util good varieti arbib implicitli util tropist process describ reaction environ term may magnet interact devis pattern analysi purpos tropism pattern henc subject law similiar gravit seen pattern consid behavior would differ exhibit arbibian case organ passiv follow forc vector result interact environment stimuli note behavior nonetheless appear abil tropist process emul seemingli behavior begin explor util model place tropism primal build model emot barto suggest possibl combin associ aim automat trigger behavior respons experienc fernandez use virtual multiprocessor laboratori effect modifi tropist respons basi project futur applic tropist process present includ engin design consid deep behind enemi mission progress sam site conting flight path may real time simpli model sam interdict mass point toward aircraft exhibit neg tendenc gravit forc repel object posit geotropist path particular interest within sole context tropist comment version first chapter braitenbergt book mechan simpl provid cluster problem portray cluster dot distribut shown uniformli color approach follow outlin figur differ normal distanc use merg conserv momentum tag also kept order merg draw cluster origin data implement cluster techniqu entail use ring assign one carri comput respect featur dot transmit forc impos rest determin upon target automat drawn interact tropism gravit mission effect activ repuls airplan danger engin design applic len model lens model photon attempt reach object plane scalar field refract model tropist manner analog exampl would yield path individu photon would fuselag design interact forc act within sheet metal foil extern forc appli model term tropist tend reconfigur sheet make least resist friction travers applic tropist process includ target multisensor fusion consid instanc resourc alloc game theori close assort one applic tropist process may understand analog process imit may turn lead develop effect strategi experi memori respons system combin tropism associ use enabl automat trigger respons previous experienc situat model project futur consequ tropist util modif decis analog filter problem past histori behavior use smooth present simplifi represent mission object center coordin thick repres sam arrow denot direct maximum attain speed acceler portray scenario ident except paramet object mass first three vari mass sam site interpret trade import mission produc dramat differ flight induc chaotic render system scenario portray situat tropist project futur meet modifi direct flight rel chang updat take full advantag parallel architectur expect flexibl tropist process adapt chang environment condit prove highli valuabl advanc area parallel process least provid capabl whenev unforeseen circumst thank bray idea provid discuss develop fine detail enabl visual unexpect decis make parallel ie workshop languag aspect inform experi avion air report experi synthet mit recognit time interv modul inform ie aerospac electron scientif publish statist set physic lectur note seri tropism evolut annal new york academi methodolog control coordin sensor advanc report air develop file winchest parallel use two exampl pattern human wiley optic fourier transform machin procedur analog len simul processor,1
29,29,"27O 
Correlational Strength and Computational Algebra 
of Synaptic Connections Between Neurons 
Eberhard E. Fetz 
Department of Physiology & Biophysics, 
University of Washington, Seattle, WA 98195 
ABSTRACT 
Intracellular recordings in spinal cord motoneurons and cerebral 
cortex neurons have provided new evidence on the correlational strength of 
monosynaptic connections, and the relation between the shapes of 
postsynaptic potentials and the associated increased firing probability. In 
these cells, excitatory postsynaptic potentials (EPSPs) produce cross- 
correlogram peaks which resemble in large part the derivative of the EPSP. 
Additional synaptic noise broadens the peak, but the peak area -- i.e., the 
number of above-chance firings triggered per EPSP -- remains proportional to 
the EPSP amplitude. A typical EPSP of 100 gv triggers about .01 firings per 
EPSP. The consequences of these data for information processing by 
polysynaptic connections is discussed. The effects of sequential polysynaptic 
links can be calculated by convolving the effects of the underlying 
monosynaptic connections. The net effect of parallel pathways is the sum of 
the individual contributions. 
INTRODUCTION 
Interactions between neurons are determined by the strength and 
distribution of their synaptic connections. The strength of synaptic 
interactions has been measured directly in the central nervous system by two 
techniques. Intracellular recording reveals the magnitude and time course of 
postsynaptic potentials (PSPs) produced by synaptic connections, and cross- 
correlation of extracellular spike trains measures the effect of the PSP's on the 
firing probability of the connected cells. The relation between the shape of 
excitatory postsynaptic potentials (EPSPs) and the shape of the cross- 
correlogram peak they produce has been empirically investigated in cat 
motoneurons 2,4,5 and in neocortical cells 10. 
RELATION BETWEEN EPSP'S AND CORRELOGRAM PEAKS 
Synaptic interactions have been studied most thoroughly in spinal 
cord motoneurons. Figure I illustrates the membrane potential of a 
rhythmically firing motoneuron, and the effect of EPSPs on its firing. An 
EPSP occurring sufficiently close to threshold (�) will cause the motoneuron 
to fire and will advance an action potential to its rising edge (top). 
Mathematical analysis of this threshold-crossing process predicts that an 
EPSP with shape e(t) will produce a firing probability f(t), which resembles 
� American Institute of Phys. ics 1988 
271 
EPSP 
CROSS- 
CORRELOGRAM 
f(t) 
TIME '1- 
Fig. 1. The relation between EPSP's and motoneuron firing. Top: membrane trajectory of 
rhythmically firing motoneuron, showing EPSP crossing threshold (O) and shortening the 
normal interspike interval by advancing a spike. V(t) is difference between membrane 
potential and threshold. Middle: same threshold-crossing process aligned with EPSP, with 
v(t) plotted as falling trajectory. Intercept (at upward arrow) indicates time of the advanced 
action potential. Bottom: Cross-correlation histogram predicted by threshold crossings. The 
peak in the firing rate fit) above baseline (fo) is produced by spikes advanced from baseline, 
as indicated by the changed counts for the illustrated trajectory. Consequently, the area in 
the peak equals the area of the subsequent trough. 
272 
the derivative of the EPSP 4,8. Specifically, for smooth membrane potential 
trajectories approaching threshold (the case of no additional synaptic noise): 
f(t) = fo + fro/:g) de/dt 
(1) 
where fo is the baseline firing rate of the motoneuron and ' is the rate of 
closure between motoneuron membrane potential and threshold. This 
relation can be derived analytically by tranforming the process to a 
coordinate system aligned with the EPSP (Fig. 1, middle) and calculating the 
relative timing of spikes advanced by intercepts of the threshold trajectories 
with the EPSP 4. The above relation (1) is also valid for the correlogram 
trough during the falling ph. ase of the EPSP, as long as de/dt > -{'; if the EPSP 
falls more rapidly than -v, the trough is limited at zero firing rate (as 
illustrated for the correlogram at bottom). The fact that the shape of the 
correlogram peak above baseline matches the EPSP derivative has been 
empirically confirmed for large E?S?s in cat motoneurons 4. This relation 
implies that the height of the correlogram peak above baseline is proportional 
to the EPS? rate of rise. The integral of this relationship predicts that the area 
between the correlogram peak and baseline is proportional to the EPSP 
amplitude. This linear relation further implies that the effects of 
simultaneously arriving EPSPs will add linearly. 
The presence of additional background synaptic ""noise"", which is 
normally produced by randomly occurring synaptic inputs, tends to make the 
correlogram peak broader than the duration of the EPSP risetime. This 
broadening is produced by membrane potential fluctuations which cause 
additional threshold crossings during the decay of the EPSP by trajectories 
that would have missed the EPSP (e.g., the dashed trajectory in Fig. 1, 
middle). On the basis of indirect empirical comparisons it has been proposed 
6,7 that the broader correlogram peaks can be described by the sum of two 
linear functions of e(t): 
f(t) = fo + a e(t) + b de/dt 
(2) 
This relation provides a reasonable match when the coefficients (a and b) can 
be optimized for each case 5,7, but direct empirical comparisons 2,4 indicate 
that the difference between the correlogram peak and the derivative is 
typically briefer than the EPSP. 
The effect of synaptic noise on the transform 'between EPSP and 
correlogram peak has not yet been analytically derived (except for the case of 
Gaussian noisel). However the threshold-crossing process has been 
simulated by a computer model which adds synaptic noise to the trajectories 
intercepting the EPSP 1. The correlograms generated by the simulation match 
the correlograms measured empirically for small EPS?'s in motoneurons 2, 
confirming the validity of the model. 
Although synaptic noise distributes the triggered firings over a wider 
peak, the area of the correlogram peak, i.e., the number of motoneuron firings 
produced by an EPSP, is essentially preserved and remains proportional to 
EPSP amplitude for moderate noise levels. For unitary EPSP's (produced by 
273 
a single afferent fiber) in cat motoneurons, the number of firings triggered per 
EPSP (Np) was linearly related to the amplitude (h) of the EPSP 2: 
Np = (0.1/mv)o h (mv) + .003 
(3) 
The fact that the number of triggered spikes increases in proportion to E?S? 
amplitude has also been confirmed for neocortical neurons 10; for cells 
recorded in sensorimotor cortex slices (probably pyramidal cells) the 
coefficient of h was very similar: 0.07/rev. This means that a typical unitary 
EPSP with amplitude of 100 gv, raises the probability that the postsynaptic 
cell fires by less than .01. Moreover, this increase occurs during a specific 
time interval corresponding to the rise time of the EPS? - on the order of 1 - 2 
msec. The net increase in firing rate of the postsynaptic cell is calculated by 
the proportional decrease in interspike intervals produced by the triggered 
spikes 4. (While the above values are typical, unitary EPSP's range in size 
from several hundred gv down to undetectable levels of several gv., and 
have risetimes of .2 - 4 msec.) 
Inhibitory connections between cells, mediated by inhibitory 
postsynaptic potentials (IPSPs), produce a trough in the cross-correlogram. 
This reduction of firing probability below baseline is followed by a 
subsequent broad, shallow peak, representing the spikes that have been 
delayed during the IPSP. Although the effects of inhibitory connections 
remain to be analyzed more quantitatively, preliminary results indicate that 
small IPSP's in synaptic noise produce decreases in firing probability that are 
similar to the increases produced by EPS?'s 4,5. 
DISYNAPTIC LINKS 
The effects of polysynaptic links between neurons can be understood 
as combinations of the underlying monosynaptic connections. A 
monosynaptic connection from cell A to cell B would produce a first-order 
cross-correlation peak Pi(B[A,t), representing the conditional probability that 
neuron B fires above chance at time t, given a spike in cell A at time t = 0. As 
noted above, the shape of this first-order correlogram peak is largely 
proportional to the E?S? derivative (for cells whose interspike interval 
exceeds the duration of the EPSP). The latency of the peak is the conduction 
time from A to B (Fig. 2 top left). 
In contrast, several types of disynaptic linkages between A and B, 
mediated by a third neuron C, will produce a second-order correlation peak 
between A and B. A disynaptic link may be produced by two serial 
monosynaptic connections, from A to C and from C to B (Fig. 2, bottom left), 
or by a common synaptic input from C ending on both A and B (Fig. 2, 
bottom right). In both cases, the second-order correlation between A and B 
produced by the disynaptic link would be the convolution of the two first- 
order correlations between the monosynaptically connected cells: 
P2(BIA) = P(BIC) OP(CIA) (4) 
274 
As indicated by the diagram, the cross-correlogram peak P2(BIA,t) would be 
smaller and more dispersed than the peaks of the underlying first-order 
correlation peaks. For serial connections the peak would appear to the right 
of the origin, at a latency that is the sum of the two monosynaptic latencies. 
The peak produced by a common input typically straddles the origin, since its 
timing reflects the difference between the underlying latencies. 
Monosynaptic connection --> First-order correlation 
. : (AIB,t) = P(BIA,-t) 
: (B ,A, t) 
� , 
Disynaptic connection 
Serial connection 
Second-order correlation 
Common input 
. (C IA) 
: 
% 
(AIC) 
I% 
I \ 
' \./1 c) 
: � 
I 
_/N. P2 (BIA) 
Fig. 2. Correlational effects of monosynaptic and disynaptic links between two neurons. 
Top: monosynaptic excitatory link from A to B produces an increase in firing probability of B 
after A (left). As with all correlograms this is the time-inverted probability of increased firing 
in A relative to B (right). Bottom: Two common disynaptic links between A and B are a 
serial connection via C (left) and a common input from C. In both cases the effect of the 
disynaptic link is the convolution of the underlying monosynaptic links. 
275 
This relation means that the probability that a spike in cell A will 
produce a correlated spike in cell B would be the product of the two 
probabilities for the intervening monosynaptic connections. Given a typical 
N of 01/EPSP, this would reduce the effectiveness of a given disynaptic 
p � 
linkage by two orders of magnitude relative to a monosynaptic connection. 
However, the net strength of all the disynaptic linkages between two given 
cells is proportional to the number of mediating interneurons {C}, since the 
effects of parallel pathways add. Thus, the net potency of all the disynaptic 
linkages between two cells could approach that of a monosynaptic linkage if 
the number of mediating interneurons were sufficiently large. It should also 
be noted that some interneurons may fire more than once per E?S? and have 
a higher probability of being triggered to fire than motoneurons 11. 
For completeness, two other possible disynaptic links between A and B 
involving a third cell C may be considered. One is a serial connection from B 
to C to A, which is the reverse of the serial connection from A to B. This 
would produce a P2(B[A) with peak to the left of the origin. The fourth 
circuit involves convergent connections from both A and B to C; this is the 
only combination that would not produce any causal link between A and B. 
The effects of still higher-order polysynaptic linkages can be computed 
similarly, by convolving the effects produced by the sequential connections. 
For example, trisynaptic linkages between four neurons are equivalent to 
combinations of disynaptic and monosynaptic connections. 
The cross-correlograms between two cells have a certain symmetry, 
depending on which is the reference cell. The cross-correlation histogram of 
cell B referenced to A is identical to the time-inverted correlogram of A 
referenced to B. This is illustrated for the monosynaptic connection in Fig.2, 
top right, but is true for all correlograms. This symmetry represents the fact 
that the above-chance probability of B firing after A is the same as the 
probability of A firing before B: 
P(BIA, t) = P(AIB,-t) 
(5) 
As a consequence, polysynaptic correlational links can be computed as the 
same convolution integral (Eq. 4), independent of the direction of impulse 
propagation. 
PARALLEL PATHS AND FEEDBACK LOOPS 
In addition to the simple combinations of pair-wise connections 
between neurons illustrated above, additional connections between the same 
cells may form circuits with various kinds of loops. Recurrent connections 
can produce feedback loops, whose correlational effects are also calculated by 
convolving effects of the underlying synaptic links. Parallel feed-forward 
paths can form multiple pathways between the same cells. These produce 
correlational effects that are the sum of the effects of the individual 
underlying connections. 
The simplest feedback loop is formed by reciprocal connections 
between a pair of cells. The effects of excitatory feedback can be computed by 
276 
successive convolutions of the underlying monosynaptic connections (Fig. 3 
top). Note that such a positive feedback loop would be capable of sustaining 
activity only if the connections were sufficiently potent to ensure 
postsynaptic firing. Since the probabilities of triggered firings at a single 
synapse are considerably less than one, reverberating activity can be 
sustained only if the number of interacting cells is correspondingly increased. 
Thus, if the probability for a single link is on the order of .01, reverberating 
activity can be sustained if A and B are similarly interconnected with at least 
a hundred cells in parallel. 
Connections between three neurons may produce various kinds of 
loops. Feedforward parallel pathways are formed when cell A is 
monosynaptically connected to B and in addition has a serial disynaptic 
connection through C, as illustrated in Fig. 3 (bottom left); the correlational 
effects of the two linkages from A to B would sum linearly, as shown for 
excitatory connections. Again, the effect of a larger set of cells {C} would be 
additive. Feedback loops could be formed with three cells by recurrent 
connections between any pair; the correlational consequences of the loop 
again are the convolution of the underlying links. Three cells can form 
another type loop if both A and B are monosynaptically connected, and 
simultaneously influenced by a common interneuron C (Fig. 3 bottom right). 
In this case the expected correlogram between A and B would be the sum of 
the individual components -- a common input peak around the origin plus a 
delayed peak produced by the serial connection. 
Feedback loop 
] .1 (aim) P2(ata ) 
'..,.i ""-.....' 
, ?'., 
I / "" ."" ' 
Li ""'"" 
I 
Parallel feedforward path 
P1 (BIA)+P2(BIA) 
Common input loop 
I 
P1 (BIA) +P2 (BIA) 
Fig. 3. Correlational effects of parallel connections between two neurons. Top: feedback 
loop between two neurons A and B produces higher-order effects equivalent to convolution 
of monosynaptic effects. Bottom: Loops formed by parallel feedforward paths (left) and by a 
common input concurrent with a monosynaptic link (right) produce additive effects. 
277 
CONCLUSIONS 
Thus, a simple computational algebra can be used to derive the 
correlational effects of a given network structure. Effects of sequential 
connections can be computed by convolution and effects of parallel paths by 
summation. The inverse problem, of deducing the circuitry from the 
correlational data is more difficult, since similar correlogram features may be 
produced by different circuits 9. 
The fact that monosynaptic links produce small correlational effects on 
the order of .01 represents a significant constraint in the mechanisms of 
information processing in real neural nets. For example, secure propagation 
of activity through serial polysynaptic linkages requires that the small 
probability of triggered firing via a given link is compensated by a 
proportional increase in the number of parallel links. Thus, reliable serial 
conduction would require hundreds of neurons at each level, with 
appropriate divergent and convergent connections. It should also be noted 
that the effect of interneurons can be modulated by changing their activity. 
The intervening cells need to be active to mediate the correlational effects. As 
indicated by eq. 1, the size of the correlogram peak is proportional to the 
firing rate (fo) of the postsynaptic cell. This allows dynamic modulation of 
polysynaptic linkages. The greater the number of links, the more susceptible 
they are to modulation. 
Acknowledgements: The author thanks Mr. Garrett Kenyon for stimulating 
discussions and the cited colleagues for collaborative efforts. This work was 
supported in part by NIH grants NS 12542 and RR00166. 
REFERENCES 
1. Bishop, B., Reyes, A.D., and Fetz E.E., Soc. for Neurosci Abst. 11:157 (1985). 
2. Cope, T.C., Fetz, E.E., and Matsumura, M., J. Physiol. 390:161-18 (1987). 
3. Fetz, E.E. and Cheney, P.D., J. Neurophysiol. 44:751-772 (1980). 
4. Fetz, E.E. and Gustafsson, B., J. Physiol. 341:387-410 (1983). 
5. Gustafsson, B., and McCrea, D., J. Physiol. 347:431-451 (1984). 
6. Kirkwood, P.A., J. Neurosci. Meth. 1:107-132 (1979). 
7. Kirkwood, P.A., and Sears, T._ J. Physiol. 275:103-134 (1978). 
8. Knox, C.K., Biophys. J. 14:567-582 (1974). 
9. Moore, G.P., Segundo, J.P., Perkel, D.H. and Levitan, H., Biophys. !. 10:876- 
900 (1970). 
10. Reyes, A.D., Fetz E.E. and Schwindt, P.C., Soc. for Neurosci Abst. 13:157 
(1987). 
11. Surmeier, D.J. and Weinberg, R.J., Brain Res. 331:180-184 (1985). 
", strength comput algebra synapt connect neuron fetz physiolog wa record spinal cord motoneuron cerebr neuron provid new evid correl strength relat shape potenti associ increas fire excitatori postsynapt potenti produc peak resembl larg part deriv synapt nois broaden peak area fire trigger per epsp remain proport epsp typic epsp gv trigger fire per consequ data inform process connect effect sequenti polysynapt calcul convolv effect underli net effect parallel pathway sum individu neuron determin strength synapt strength synapt measur directli central nervou system two intracellular record reveal magnitud time cours potenti produc synapt extracellular spike train measur effect probabl connect relat shape postsynapt potenti shape peak produc empir investig cat neocort cell correlogram peak interact studi thoroughli spinal figur illustr membran potenti fire effect epsp occur suffici close threshold caus motoneuron fire advanc action potenti rise edg analysi process predict shape produc fire probabl resembl american institut ic relat motoneuron membran trajectori fire show epsp cross threshold shorten interspik interv advanc differ membran process align plot fall intercept upward indic time advanc histogram predict threshold fire rate baselin produc spike advanc indic chang count illustr area peak equal area subsequ deriv epsp smooth membran potenti approach threshold case addit synapt fo fo baselin fire rate motoneuron rate motoneuron membran potenti deriv analyt tranform process system align epsp calcul time spike advanc intercept threshold trajectori epsp relat also valid correlogram fall ase long epsp rapidli trough limit zero fire rate correlogram fact shape peak baselin match epsp deriv confirm larg cat motoneuron relat height correlogram peak baselin proport rate integr relationship predict area correlogram peak baselin proport epsp linear relat impli effect arriv epsp add presenc addit background synapt produc randomli occur synapt tend make peak broader durat epsp produc membran potenti fluctuat caus threshold cross decay epsp trajectori would miss epsp dash trajectori basi indirect empir comparison propos broader correlogram peak describ sum two function fo relat provid reason match coeffici optim case direct empir comparison indic differ correlogram peak deriv briefer effect synapt nois transform epsp peak yet analyt deriv case howev process comput model add synapt nois trajectori epsp correlogram gener simul match correlogram measur empir small motoneuron valid synapt nois distribut trigger fire wider area correlogram number motoneuron fire essenti preserv remain proport amplitud moder nois unitari singl affer cat number fire trigger per linearli relat amplitud epsp fact number trigger spike increas proport also confirm neocort neuron cell sensorimotor cortex slice pyramid mean typic unitari amplitud rais probabl postsynapt fire less increas occur specif interv correspond rise time order net increas fire rate postsynapt cell calcul proport decreas interspik interv produc trigger valu unitari rang size sever hundr gv undetect level sever risetim connect mediat inhibitori potenti produc trough reduct fire probabl baselin follow shallow repres spike although effect inhibitori connect analyz preliminari result indic synapt nois produc decreas fire probabl increas produc link effect polysynapt link neuron understood combin underli monosynapt connect cell cell would produc peak repres condit probabl fire chanc time given spike cell time shape correlogram peak larg deriv cell whose interspik interv durat latenc peak conduct top sever type disynapt linkag third neuron produc correl peak disynapt link may produc two serial bottom common synapt input end correl disynapt link would convolut two correl monosynapt connect indic peak would dispers peak underli serial connect peak would appear right latenc sum two monosynapt peak produc common input typic straddl sinc reflect differ underli connect correl connect connect correl input correl effect monosynapt disynapt link two monosynapt excitatori link produc increas fire probabl correlogram probabl increas fire rel two common disynapt link connect via common input case effect link convolut underli monosynapt relat mean probabl spike cell correl spike cell would product two interven monosynapt given typic would reduc effect given disynapt two order magnitud rel monosynapt net strength disynapt linkag two given proport number mediat interneuron sinc parallel pathway net potenc disynapt two cell could approach monosynapt linkag number mediat interneuron suffici also note interneuron may fire per higher probabl trigger fire motoneuron two possibl disynapt link third cell may one serial connect revers serial connect produc peak left fourth involv converg connect combin would produc causal link effect still polysynapt linkag comput convolv effect produc sequenti trisynapt linkag four neuron equival disynapt monosynapt two cell certain refer histogram referenc ident correlogram illustr monosynapt connect true symmetri repres fact probabl fire fire polysynapt correl link comput convolut integr independ direct impuls path feedback loop addit simpl combin connect neuron illustr addit connect may form circuit variou kind recurr connect produc feedback whose correl effect also calcul effect underli synapt parallel form multipl pathway produc effect sum effect individu simplest feedback loop form reciproc connect pair effect excitatori feedback comput convolut underli monosynapt connect note posit feedback loop would capabl sustain connect suffici potent ensur sinc probabl trigger fire singl consider less reverber activ number interact cell correspondingli probabl singl link order reverber sustain similarli interconnect least hundr cell three neuron may produc variou kind feedforward parallel pathway form cell connect addit serial disynapt illustr correl two linkag would sum shown effect larger set cell would feedback loop could form three cell recurr correl consequ loop convolut underli three cell form type loop monosynapt influenc common interneuron bottom case expect correlogram would sum individu compon common input peak around origin plu peak produc serial loop feedforward path input loop correl effect parallel connect two feedback two neuron produc effect equival convolut monosynapt loop form parallel feedforward path input concurr monosynapt link produc addit simpl comput algebra use deriv effect given network effect sequenti comput convolut effect parallel path invers deduc circuitri data sinc similar correlogram featur may differ circuit fact monosynapt link produc small correl effect order repres signific constraint mechan process real neural secur propag activ serial polysynapt linkag requir small trigger fire via given link compens increas number parallel reliabl serial would requir hundr neuron diverg converg also note effect interneuron modul chang interven cell need activ mediat correl size correlogram peak proport rate postsynapt allow dynam modul greater number suscept author thank garrett kenyon stimul cite colleagu collabor work part nih grant ns fetz neurosci fetz neurosci brain,0
30,30,"278 
THE HOPFIELD MODEL WITH MULTI-LEVEL NEURONS 
Michael Fleisher 
Depatmaent of Electrical Engineering 
Technion - Israel Institute of Technology 
Haifa 32000, Israel 
ABSTRACT 
The Hopfield neural network model for associative memory is generaEzed. The generalization 
replaces two state neurons by neurons taking a richer set of values. Two classes of neuron input output 
relations we developed guaranteeing convergence to stable states. The fu-st is a class of ""continuous"" rela- 
tions and the second is a class of allowed quantization rules for the neurons. The information capacity for 
networks from the second class is found to be of order S 3 bits for a network with S neurons. 
A generalization of the sum of outer products learning rule is developed and investigated as well. 
American Institute of Physics 1988 
279 
I. INTRODUCTION 
The ability to perform collective computation in a distributed system of flexible structure without 
global synchronization is an important engineering objective. Hopfield's neural network [1] is such a 
model of associative content addressable memory. 
An important property of the Hopfield neural network is its guaranteed convergence to stable states 
(interpreted as the stored memories). In this work we introduce a generalization of the Hopfield model by 
allowing the outputs of the neurons to take a richer set of values than Hopfield's original binary neurons. 
Sufficient conditions for preserving the convergence property are developed for the neuron input output 
relations. Two classes of relations are obtained. The first introduces neurons which simulate multi thres- 
hold functions, networks with such neurons will be called quantized neural networks (Q.N.N.). The secotad 
class introduces continuous neuron input output relations and networks with such neurons will be called 
continuous neural networks (C.N.N.). 
In Section II, we introduce Hopfield's neural network and show its convergence property. C.N.N. 
are introduced in Section HI and a sufficient condition for the neuron input output continuous relations is 
developed for preserving convergence. In Section IV, Q.N.N. are introduced and their input output rela- 
tions are analyzed in the same manner as in HI. In Section IV we look further at Q.N.N. by using the 
definition of information capacity for neural networks of [2] to obtain a tight asymptotic estimate of the 
capacity for a Qffq. N. with N neurons. Section VI is a generalized sum of outer products learning for the 
Q.N.N. and section VII is the discussion. 
II. THE HOPFIELD NEURAL NETWORK 
A neural network consists of N pairwise connected neurons. The i 'th neuron can be in one of two 
states: X i = -1 or X i = +1. The connections are fLxed real numbers denoted by Wij (the connection 
from neuron i to neuron j ). Define the state vector X to be a binary vector whose i 'th component 
corresponds to the state of the i 'th neuron. Randomly and asynchronously, each neuron examines its input 
and decides its next output in the following manner. Let t i be the threshold voltage of the i 'th neuron. If 
the weighted sum of the present other N-1 neuron outputs (which compose the i 'th neuron input) is 
280 
greater or equal to t i , the next X i (Xi +) is + 1, if not, Xi + is - 1. This action is given in (1). 
We give the following theorem 
N 
Xi+: sgn [ 2 WijXj-ti ] 
O) 
Theorem ,1, (of [1]) 
The network described with symmetric (llVij=W fi ) zero diagonal (Vii--0) connection matrix W 
has the convergence property. 
Pmo, ,,f. 
Define the quantity 
INN N 
E(x) =- � I; I; %xixj + I; tixi 
i j=l i=1 
(2) 
We show that E (X) can only de,,crea as a result of the action of the network. Suppose that X k changed 
to Xff = Xk +l, k , the resulting change in E is given by 
N 
=-axk ( E wkjxj-t) (3) 
j=l 
(Eq. (3) is correct because of the restrictions on W). The tetra in brackets is exactly the argument of the 
sgn function in (1) and therefore the signs of AX k and the tetra in brackets is the same (or Z k =0) and 
we get AE _< 0. Combining this with the fact that E (J.) is bounded shows that eventually the network 
will remain in a local minimum {fie (.). This completes the proof. 
The technique used in the proof of Theorem 1 is an important tool in analyzing neural networks. A 
network with a particular underlying E (X) function can be used to solve optimization problems with 
E (.) as the object of optimization. Thus we see another use of neural networks. 
281 
m. THE C.N.N. 
We ask ourselves the following question: How can we change the sgn function in (1) without affect- 
ing the convergence property? The new action rule for the i 'th neuron is 
N 
Xi+-- f i [ Z WijXj ] (4) 
j=l 
Our attention is focused on possible choices forfi ('). The following theorem gives a part of the answer. 
Theorem 2 
The network described by (4) (with symmetric zero diagonal W) has the convergence property if 
fi (') are strictly increasing and bounded. 
Proof 
Define 
1 N N N Xi 
E(.) =- -- Z WijXiXj 4-  I fi-l(tl)atl 
t j i=10 
(5) 
We show as before that E () can only decrease and since E is bounded (because of the boundedhess of 
fi 's) the theorem is proved. 
Xi 
Usingi(Xi)= I 
f i-l(u )du we have 
N 
i=l AXk 
] (6) 
Using the intermediale value theorem we get 
AE = - AXi [  WkjXj-gk(C )I = -AXi [ f ff X(Xk +AXi )-f ff l(C )] 
j=l 
(7) 
282 
where C is a point between X k and Xk+ k. Now, ff /�k >0 we have 
C - X k +l( k = > f-l(c ) - f-l(x k +AX k ) and the term in brackets is greater or equal to zero 
""-> AE _<0. A similar argument holds for AX k < 0 (of course AX k :=0 => AE =0). This completes 
the proof. 
Some remarks: 
(a) Strictly increasing hounded neuron relalions are not the whole class of relations conserving the conver- 
gence property. This is seen immediately from the fact that Hopfield's original model (1) is not in' this 
class. 
Co) The E (X_) in the C.N.N. coincides with Hopfield's continuous neural network [3]. The difference 
between the two networks lies in the updating scheme. In our C.N.N. the neurons update their outputs at 
the moments they examine their inputs while in [3] the updating is in the form of a set of differential equa- 
tions featuring the time evolution of the network outputs. 
(c) The boundedness requirement of the neuron relations results from the boundedness of E (.). It is 
possible to impose further restrictions on W resulting in unbounded neuron relations but keeping E (X) 
hounded (from below). This was done in [4] where the neurons exhibit linear relations. 
IV. THE Q.N.N. 
We develop the class of quantization rules for the neurons, keeping the convergence property. 
Denote the set of possible neuron outputs by Yo < Y 1 < '.. < Yn and the set of threshold values by 
t 1 < t 2 < ' ' ' < tn the action of the neurons is given by 
N 
Xi +-�1 if t I < Z Wijj -< tl+l /=O,...,n (8) 
j=! 
and t o = -o% t n + l = +oo. 
The following theorem gives a class of quantization rules with the convergence property. 
283 
Any quantization rule for the neurons which is an increasing step functioa that is 
Yo<Yi< '""Yn;tl< ... <t n 
Yields a network with the convergence property (with a g synunetric and zero diagonal). 
(9) 
Proof 
We proceed to prove. 
Define 
1N N N N 
E(X)=- I5 Z WijXiXj + tG(Xi)+ ZdXi 
i j=l i=1 i=1 
(lO) 
where G (X) is a piecewise linear convex U function defined by the relation 
G (YI)-G (YI-1) 
t +d=t I l=l,...,n (10 
Yi-YI_i 
As before we show AF _< 0. Suppose a change occurred in X k such thatX k =Yi_i,X;=Yi . We then 
have 
AE = -ZSX k 
[ - t 
j=l 
o(xD-c(xk) 
(12) 
A similar argument follows whenXk=Yi,X=Yi_ 1 < X k . Any bigger change inX k (from Yi to Yj 
with I i -j I > 1) yields the same result since it can be viewed as a sequence of I i -j I changes from Yi 
to Yj each resulting in AE -<0. The proof is completed by noting that ZSX k----O=-->AE =0 and E (X) is 
284 
Corollary 
Hopfield's original model is a special case of (9). 
V. INFORMATION CAPACITY OF THE Q.N.N. 
We use the dfinition of [2] for the information capacity of the Q.N.N. 
Definition 1 
The information capacity of the Q.N.N. (bits) is the log (Base 2) of the number of distinguishable 
networks of N neurons. Two networks are distinguishable if observing the state transitions of the neurons 
yields different observations. For Hopfield's original model it was shown in [2] that the capacity C of a 
network of N neurons is bounded by C < log (2(N-1)') 'v = 0(N3)b. It was also shown that 
C -> (N3)b and thus is exactly of the order N3b. It is obvious that in our case (which contains the 
original model) we must have C -> (N3)b as well (since the lower bound cannot decrease in this 
richer case). It is shown in the Appendix that the number of multi threshold functions of N-1 variables 
with n+l output levels is at most (n+l) N2+N+I since we have N neurons there will be 
( (n + ly v'+N +yv ti.ghe network thus 
C _(log ( (n+l)'V'-+v+f = 0(N3)b (14) 
o as before, C is exactly of 0(N 3)b. In fact, the rise in C is probably a factor of 0(log2n ) as can be 
seen from the upper bound. 
VI. ""OUTER PRODUCT"" LEARNING RULE 
For Hopfield's original network with two state neurons (taking the values �1) a natural and exten- 
sively investigated [ ],[ 1,[ ] learning mle is the so called sum of outer products construction. 
1 tc 
1--1 
where X 1 , X K re the desired stable states of the network. A well-known result for (15) is that the 
asymptotic capacity K of the network is 
285 
N-1 
K =  + 1 (16) 
41ogN 
In this section we introduce a natural generalization of (15) and prove a similar result for the asymp- 
totic capacity. We first limit the possible quantization rules to: 
X i = F (tl i ) =' 
Yo t l > Ui ->to 
Yn tn+l > ui -> tn 
(17) 
withYo < ''' < Yn 
to =-oo ; tn+l =oo 
with 
(a) n+l is even 
CO) V i Yi  O 
(C) Yi = - Yn-i 
Neat we state that the desired stable vectors X 1, � � - X_ K are such that each component is picked 
independently at random from { Yo,"" ' YM } with equal probability. Thus, the K � N components of 
theX's are zero mean i.i.D random variables. Our modified learning rule is 
Wij = S Z Xl' (18) 
/=1 
Note that �orXi  {+1, -1 } (18) is identical to (16). 
Define 
286 
A =max  
i,j IYj l 
We state that 
PROPOSITION: 
The asymptotic capacity of the above network is given by 
N 
16A 2 
 log N 
PROOF: 
(19) 
Define 
K vectors chosen randomly as 
P (K, N)= Pr[ are stable states with the W of 
described } 
() 
P(K,N)= 1 -Pr(L)A/j) > 1 -Pr(Aij) 
i =1,..., N (20) 
j=l ..... K 
where Aij is the event that the i th component of j th vector is in error. We concentrate on the event A 11 
W.L.G. 
The input U 1 when X ' is presented is given by 
N K-1 1 KN ,,. 
u= Z w,.xf =x +x +- Z Z x xf (2,) 
j=l N N /=2 j=2 XJ 
The first term is mapped by (17) into itseft and corresponds to the desired signal. 
The last term is a sum of (K-1)(N-1) i.i.D zero mean random variables and corresponds to 
noise. 
287 
K-1 X  is disposed of by assuming 
The middle term N 
O. (With a zero diagonal 
choice of W (using (18) with i ;j) this term does not appear). 
Pr(All)=Pr { noise gets us out of range } 
Denoting the noise by I we have 
Pt(All) <Pr(ll I > -) < 2exp - 
(K-1)(N-1)4A 2 
where the first inequality is from the der'tuition of AYand the second uses the lemma of [6] p. 58. We thus 
get 
P (K, N) > 1 - K � N � 2exp{ - 
8(K-1)(N-1)A2 
substituting (19) and taking N --> oo we get P (K, N) --> 1 and this completes the proof. 
(23) 
VII. DISCUSSION 
Two classes of generalization of the Hopfield neural network model were presented. We give some 
remarks: 
(a) Any combination of neurons from the two classes will have the convergence property as well. 
(b) Our definition of the information capacity for the C.N.N. is useless since a full observation of the pos- 
sible state transitions of the network is impossible. 
288 
APPENDIX 
We prove the foUowing theorem. 
Theorem 
An upper bound on the number of malt/ threshold functions with N inputs and ff 
domain (out of (n +l)tV possible poinls) CN M is the solution of lhe recurrence relat/on 
Proof 
c#-' +. 
points in the 
Let us look on the N dimensional weight space W. Each input point X divides the weight space 
N 
and the theorem is proved. 
The solution of the recurrence in the case M=(n+l) N (all possible points) we have a bound on 
the number of mult/threshold functions of S variables equal to 
N-l 
i=l 
(n+l)N-1] ni < 
i - 
and the result used is established. 
C= C -I + n .C_ l 
v- M-I 
isC=(n+l) i{I i 
into n+l regions by n parallel hyporplanes  WiXi=t k k-1,...,n. We keep adding points in such 
i=l 
a way that the new tt hyperplanes corresponding to each added point partition the W space into as many 
regions as possible. Assume M-1 points have made CN M-I regions and we add the M 'th point. Each 
hyperplane (out of n) is divided into at most CNM_ 1 regiont (being itself an N-] dimensional space 
divided by (M-1)n hyperlines). We thus have after passing the n hyperplanes: 
289 
REFERENCES 
[I] Hopfield J. J., ""Neural networks and physical systems with emergent collective computational abili- 
ties"", Proc. Nat. Acad. Sci. USA, Vol. 79 (1982), pp. 2554-2558. 
[2] Abu-Mostafa Y.S. and Jacques J. St., ""Inforotation capacity of the Hopfield model"", IEEE Trans. on 
Info. Theory, Vol. IT-31 (1985, pp. 461-464. 
[3] Hopfield J. J., ""Neurons with graded response have collective computational properties like those of 
two state neurons"", Proc. Nat. Acad. Sci. USA, Vol. 81 (1984). 
[4] Fleisher M., ""Fast processing of autoregressive signals by a neural network"", to be presented at IEEE 
Conference, Israel 1987. 
[5] Levin, E., Private communication. 
[6] Petroy, ""Sums of independent random variables"". 
", hopfield model neuron fleisher electr engin israel institut technolog israel hopfield neural network model associ memori gener two state neuron neuron take richer set two class neuron input output develop guarante converg stabl class second class allow quantiz rule inform capac second class found order bit network gener sum outer product learn rule develop investig institut physic introduct abil perform collect comput distribut system flexibl structur without synchron import engin neural network associ content address import properti hopfield neural network guarante converg stabl state store work introduc gener hopfield model output neuron take richer set valu origin binari condit preserv converg properti develop neuron input output two class relat first introduc neuron simul multi network neuron call quantiz neural network secotad introduc continu neuron input output relat network neuron call neural network section introduc neural network show converg introduc section hi suffici condit neuron input output continu relat preserv section introduc input output analyz manner section iv look use inform capac neural network obtain tight asymptot estim section vi gener sum outer product learn section vii hopfield neural network neural network consist pairwis connect neuron one two connect lxed real number denot wij connect neuron neuron defin state vector binari vector whose compon state randomli neuron examin input decid next output follow let threshold voltag weight sum present neuron output compos neuron equal next xi action given give follow theorem sgn network describ symmetr fi zero diagon connect matrix converg quantiti tixi show result action suppos chang xff xk result chang given correct restrict tetra bracket exactli argument function therefor sign ax tetra bracket get ae combin fact bound show eventu network remain local minimum complet techniqu use proof theorem import tool analyz neural particular underli function use solv optim problem object thu see anoth use neural ask follow chang sgn function without converg new action rule neuron xj attent focus possibl choic forfi follow theorem give part network describ symmetr zero diagon converg properti strictli increas xi xj show decreas sinc bound boundedhess theorem axk intermedial valu theorem get ff ff point ff term bracket greater equal zero ae similar argument hold ax cours ax ae complet strictli increas hound neuron relalion whole class relat conserv seen immedi fact origin model coincid continu neural network differ two network lie updat neuron updat output moment examin input updat form set differenti featur time evolut network bounded requir neuron relat result bounded impos restrict result unbound neuron relat keep done neuron exhibit linear develop class quantiz rule keep converg set possibl neuron output yo yn set threshold valu tn action neuron given follow theorem give class quantiz rule converg quantiz rule neuron increas step functioa network converg properti synunetr zero proceed xj xi piecewis linear convex function defin relat show suppos chang occur similar argument follow bigger chang yi yj yield result sinc view sequenc chang yi yj result ae proof complet note zsx origin model special case inform capac use inform capac inform capac log number distinguish two network distinguish observ state transit neuron differ origin model shown capac neuron bound log also shown thu exactli order obviou case contain must well lower bound can not decreas shown appendix number multi threshold function variabl output level sinc neuron ly network thu exactli rise probabl factor upper learn rule origin network two state neuron valu natur investig learn mle call sum outer product tc desir stabl state result capac network section introduc natur gener prove similar result first limit possibl quantiz rule ui ui tn yo yn even yi yi state desir stabl vector compon pick random ym equal compon zero mean random modifi learn rule xi ident iyj state asymptot capac network given log vector chosen randomli stabl state aij event th compon th vector concentr event input present given kn xf xj first term map itseft correspond desir last term sum zero mean random variabl correspond dispos assum middl term zero diagon term nois get us rang nois first inequ ayand second use lemma thu take oo get complet discuss class gener hopfield neural network model give combin neuron two class converg properti definit inform capac useless sinc full observ state transit network prove uow upper bound number threshold function input possibl cn solut lhe recurr us look dimension weight space input point divid weight space theorem solut recurr case possibl bound number function variabl equal ni result use region parallel hyporplan keep ad point way new tt hyperplan correspond ad point partit space mani assum point made cn region add divid regiont dimension space thu pass hopfield network physic system emerg collect comput jacqu capac hopfield ie hopfield grade respons collect comput properti like state fleisher process autoregress signal neural present ie israel privat independ random,1
31,31,"290 
CYCLES: A Simulation Tool for Studying 
Cyclic Neural Networks 
Michael T. Gately 
Texas Instruments Incorporated, Dallas, TX 75265 
ABSTRACT 
A computer program has been designed and implemented to allow a researcher 
to analyze the oscillatory behavior of simulated neural networks with cyclic con- 
nectivity. The computer program, implemented on the Texas Instruments Ex- 
plorer/Odyssey system, and the results of numerous experiments are discussed. 
The program, CYCLES, allows a user to construct, operate, and inspect neural 
networks containing cyclic connection paths with the aid of a powerful graphics- 
based interface. Numerous cycles have been studied, including cycles with one or 
more activation points, non-interruptible cycles, cycles with variable path lengths, 
and interacting cycles. The final class, interacting cycles, is important due to its 
ability to implement time-dependent goal processing in neural networks. 
INTRODUCTION 
Neural networks are capable of many types of computation. However, the 
majority of researchers are currently limiting their studies to various forms of 
mapping systems; such as content addressable memories, expert system engines, 
and artificial retinas. Typically, these systems have one layer of fully connected 
neurons or several layers of neurons with limited (forward direction only) connec- 
tivity. I have defined a new neural network topology; a two-dimensional lattice of 
neurons connected in such a way that circular paths are possible. 
The neural networks defined can be viewed as a grid of neurons with one 
edge containing input neurons and the opposite edge containing output neurons 
[Figure 1]. Within the grid, any neuron can be connected to any other. Thus 
from one point of view, this is a multi-layered system with full connectivity. I 
view the weights of the connections as being the long term memory (LTM) of the 
system and the propagation of information through the grid as being it's short 
term memory (STM). 
The topology of connectivity between neurons can take on any number of 
patterns. Using the mammalian brain as a guide, I have limited the amount of 
connectivity to something much less then total. In addition to' making analysis 
of such systems less complex, limiting the connectivity to some small percentage 
of the total number of neurons reduces the amount of memory used in computer 
simulations. In general, the connectivity can be purely random, or can form any 
of a number of patterns that are repeated across the grid of neurons. 
The program CYCLES allows the user to quickly describe the shape of the 
neural network grid, the source of input data, the destination of the output data, 
the pattern of connectivity. Once constructed, the network can be ""run."" during 
which time the STM may be viewed graphically. 
@ American Institute of Physics 1988 
291 
 0 O00000 O00000  
o 00 O0000 O00000 o 
00 O0000000 O00 
00 O00000 
O0 O0 O000 
00000000 
0 O000000 
00 O00000 
00000 O00 
8'-' 0 0 0 0 0 0 0 0 0 0 0 0 0 
292 
IMPLEMENTATION 
CYCLES was implemented on a TI Explorer/Odyssey computer system with 
8MB of RAM and 128MB of Virtual Memory. The program was written in Com- 
mon LISP. The program was started in July of 1986, put aside for a while, and 
finished in March of 1987. Since that time, numerous small enhancements have 
been made - and the system has been used to test various theories of cyclic neural 
networks. 
The code was integrated into the Neural Network Workstation (NNW), an 
interface to various neural network algorithms. The NNW utilizes the window 
interface of the Explorer LISP machine to present a consistent command input 
and graphical output to a variety of neural network algorithms [Figure 2]. 
The backpropagation-like neurons are collected together into a large three- 
dimensional array. The implementation actually allows the use of multiple two- 
dimensional grids; to date, however, I have studied only single-grid systems. 
Each neuron in a CYCLES simulation consists of a list of information; the 
value of the neuron, the time that the neuron last fired, a temporary value used 
during the computation of the new value, and a list of the neurons connectivity. 
The connectivity list stores the location of a related neuron and the strength of 
the connection between the two neurons. Because the system is implemented in 
arrays and lists, large systems tend to be very slow. However, most of my analysis 
has taken place on very small systems (< 80 neurons) and for this size the speed 
is acceptable. 
To help gauge the speed of CYCLES, a single grid system containing 100 
neurons takes 0.8 seconds and 1235 cons cells (memory cells) to complete one 
update within the LISP machine. If the graphics interface is disabled, a test 
requiring 100 updates takes a total of 10.56 seconds. 
TYPES OF CYCLES 
can 
1. 
o 
As mentioned above, several types of cycles have been observed. Each of these 
be used for different applications. Figure 3 shows some of these cycles. 
SIMPLE cycles are those that have one or more points of activation traveling 
across a set number of neurons in a particular order. The path length can be 
any size. 
NON-INTERRUPTABLE cycles are those that have sufficiently strong con- 
nectivity strengths that random flows of activation which interact with the 
cycle will not upset or vary the original cycle. 
VARIABLE PATH LENGTH cycles can, based upon external information, 
change their path length. There must be one or more neurons that are always 
a part of the path. 
INTERACTING cycles typically have one neuron in common. Each cycle 
must have at least one other neuron involved at the junction point in order to 
keep the cycles separate. This type of cycle has been shown to implement a 
complex form of a clock where the product of the two (or more) path lengths 
are the fundamental frequency. 
293 
Figure 3. Types of Cycles [Simple and Interacting] 
� � � � � 
� � � 
� � � 
Figure 4. Types of Connectivity [Nearest Neighbor and Gaussian] 
INPUT OUTPUT 
Intent 
Joint 3 Extended 
Joint 2 Centered 
Joint I Extended 
Chuck Opened 
Chuck Closed 
) ) Completed 
0 0 Move Joint3 
0  Move Joint2 
0 Move Joint 1 
0 0 0 Open Chuck 
0 Close Chuck 
Figure 5. Robot Arm used in Example 
294 
CONNECTIVITY 
Several types of connectivity have been investigated. These are shown in 
Figure 4. 
1. In TOTAL connectivity, every neuron is connected to every other neuron. 
This particular pattern produces very complex interactions with no apparent 
stability. 
2. With RANDOM connectivity, each neuron is connected to a random number 
of other neurons. These other neurons can be anywhere in the grid. 
3. A very useful type of connectivity is to have a PATTERN. The patterns can 
be of any shape, typically having one neuron feed its nearest neighbors. 
4. Finally, the GAUSSIAN pattern has been used with the most success. In this 
pattern, each neuron is connected to a set number of nodes - but the selection 
is random. Further, the distribution of nodes is in a Gaussian shape, centered 
around a point ""forward"" of itself. Thus the flow of information, in general, 
moves forward, but the connectivity allows cycles to be formed. 
ALGORITHM 
The algorithm currently being used in the system is a standard inner product 
equation with a sigmoidal threshold function. Each time a neuron's weight is to 
be calculated, the value of each contributing neuron on the connectivity list is 
multiplied by the strength of the connection and summed. This sum is passed 
through a sigmoidal thresholding function. The value of the neuron is changed 
to be the result of this threshold function. As you can see, the system updates 
neurons in an ordered fashion, thus certain interactions will not be observed. Since 
timing information is saved in the neurons, asynchrony could be simulated. 
Initially, the weights of the connections are set randomly. A number of inter- 
esting cycles have been observed as a result of this randomness. However, several 
experiments have required specific weights. To accommodate this, an interface to 
the weight matrix is used. The user can create any set of connection strengths 
desired. 
I have experimented with several learning algorithms-that is, algorithms that 
change the connection weights. The first mechanism was a simple Hebbian rule 
that states that if two neurons both fire, and there is a connection between them, 
then strengthen the strength of that connection. A second algorithm I experi- 
mented with used a pain/pleasure indicator to strengthen or weaken weights. 
An algorithm that is currently under development actually presets the weights 
from a grammar of activity required of the network. Thus, the user can describe 
a process that must be controlled by a network using a simple grammar. This 
description is then ""compiled"" into a set of weights that contain cycles to indicate 
time-independent components of the activity. 
295 
USAGE 
Even without a biological background, it is easy to see that the processing 
power of the human brain is far more than present associative memories. Our 
repertoire of capabilities includes, among other things: memory of a time line, 
creativity, numerous types of biological clocks, and the ability to create and ex- 
ecute complex plans. The CYCLES algorithm has been shown to be capable of 
executing complex, time-variable plans. 
A plan can be defined as a sequence of actions that must be performed in 
some preset order. Under this definition, the execution of a plan would be very 
straightforward. However, when individual actions within the plan take an inde- 
terminate length of time, it is necessary to construct an execution engine capable 
of dealing with unexpected time delays. Such a system must also be able to abort 
the processing of a plan based on new data. 
With careful programming of connection weights, I have been able to use 
CYCLES to execute time-variable plans. The particular example I have chosen 
is for a robot arm to change its tool. In this activity, once the controller receives 
the signal that the motion required, a series of actions take place that result in 
the tool being changed. 
As input to this system I have used a number of sensors that may be found 
in a robot; extension sensors in 2-D joints and pressure sensors in articulators. 
The outputs of this network are pulses that I have defined to activate motors on 
the robot arm. Figure 5 shows how this system could be implemented. Figure 
6 indicates the steps required to perform the task. Simple time delays, such as 
found with binding motors and misplaced objects are accommodated with the 
built in time-independence. 
The small cycles that occur within the neural network can be thought of as 
short term memory. The cycle acts as a place holder - keeping track of the system's 
current place in a series of tasks. This type of pausing is necessary in many ""real"" 
activities such as simple process control or the analysis of time varying data. 
IMPLICATIONS 
The success of CYCLES to simple process control activities such as robot arm 
control implies that there is a whole new area of applications for neural networks 
beyond present associative memories. The exploitation of the flow of activation as 
a form of short term memory provides us with a technique for dealing with many 
of the ""other"" type of computations which humans perform. 
The future of the CYCLES algorithm will take two directions. First, the 
completion of a grammar and compiler for encoding process control tasks into a 
network. Second, other learning algorithms will be investigated which are capable 
of adding and removing connections and altering the strengths of connections 
based upon an abstract pain/pleasure indicator. 
296 
The robot gets a signal 
to begin the tool change 
process. A cycle is started 
that outputs a signal to 
the chuck motor. 
� � � � � � 
When sensor indicates 
that the chuck is open, 
the first cycle is stopped 
and a second begins 
activating the motor 
in tile first joint. 
� � � � � � 
� � � � � 
� � � � � � 
When the first joint is 
fully extended, the joint 
sensor sends a signal 
that stops that cycle, and 
begins one that outputs 
a signal to the second 
joint. 
When the joint indicator 
indicates that the joint is 
centered, it changes the 
flow of activation to cause 
a cycle that activates the 
third joint. 
Next, the chuck is closed 
around the new tool bit. 
The last signal ends the 
sequence of cycles and 
sends the completed 
signal. 
Figure 6. Example use of CYCLES to control a Robot Arm 
References
", simul tool studi neural network gate instrument tx comput program design implement allow research analyz oscillatori behavior simul neural network cyclic comput implement texa instrument result numer experi allow user inspect neural contain cyclic connect path aid power numer cycl includ cycl one activ cycl variabl path interact final interact import due implement goal process neural network capabl mani type research current limit studi variou form content address expert system artifici system one layer fulli connect sever layer neuron limit direct defin new neural network lattic connect way circular path neural network defin view grid neuron one contain input neuron opposit edg contain output neuron within neuron connect thu one point system full weight connect long term memori propag inform grid short memori topolog connect neuron take number use mammalian brain limit amount someth much less addit make analysi system less limit connect small percentag total number neuron reduc amount memori use comput connect pure form number pattern repeat across grid program cycl allow user quickli describ shape network sourc input destin output pattern network time stm may view american institut physic implement ti comput system ram virtual program written program start juli put asid march sinc numer small enhanc made system use test variou theori cyclic neural code integr neural network workstat variou neural network nnw util window explor lisp machin present consist command input graphic output varieti neural network algorithm neuron collect togeth larg implement actual allow use multipl studi neuron cycl simul consist list time neuron last temporari valu use comput new list neuron connect list store locat relat neuron strength connect two system implement larg system tend analysi taken place small system size speed help gaug speed singl grid system contain take second con cell complet one within lisp graphic interfac test updat take total cycl mention sever type cycl use differ figur show cycl one point activ travel set number neuron particular path length cycl suffici strong strength random flow activ interact upset vari origin path length cycl base upon extern path must one neuron alway part cycl typic one neuron cycl least one neuron involv junction point order cycl type cycl shown implement form clock product two path length fundament type cycl type connect neighbor output extend center extend open close complet move move move joint open chuck close chuck robot arm use exampl type connect shown total everi neuron connect everi particular pattern produc complex interact appar random neuron connect random number neuron anywher use type connect pattern typic one neuron feed nearest gaussian pattern use neuron connect set number node select distribut node gaussian center point thu flow connect allow cycl algorithm current use system standard inner product sigmoid threshold time weight valu contribut neuron connect list strength connect sum pass sigmoid threshold valu neuron chang result threshold system updat order thu certain interact sinc inform save asynchroni could weight connect set number cycl observ result sever requir specif accommod interfac weight matrix user creat set connect strength experi sever learn algorithm connect first mechan simpl hebbian rule state two neuron connect strengthen strength second algorithm use indic strengthen weaken algorithm current develop actual preset weight grammar activ requir user describ process must control network use simpl set weight contain cycl indic compon without biolog easi see process human brain far present associ capabl among memori time numer type biolog abil creat complex cycl algorithm shown capabl plan defin sequenc action must perform preset execut plan would individu action within plan take length necessari construct execut engin capabl deal unexpect time system must also abl abort process plan base new care program connect abl use execut particular exampl chosen robot arm chang control receiv signal motion seri action take place result tool input system use number sensor may found extens sensor joint pressur sensor output network puls defin activ motor robot figur show system could figur indic step requir perform simpl time bind motor misplac object accommod small cycl occur within neural network thought term cycl act place holder keep track place seri type paus necessari mani simpl process control analysi time vari success cycl simpl process control activ robot arm impli whole new area applic neural network present associ exploit flow activ form short term memori provid us techniqu deal mani type comput human futur cycl algorithm take two grammar compil encod process control task learn algorithm investig capabl ad remov connect alter strength connect upon abstract robot get signal begin tool chang cycl start output signal chuck sensor indic chuck first cycl stop second begin motor tile first first joint joint send signal stop one output signal second joint indic joint chang activ caus cycl activ chuck close new tool last signal end cycl complet exampl use cycl control robot arm,1
32,32,"297 
TEMPORAL PATTERNS OF ACTIVITY IN 
NEURAL NETWORKS 
Paolo Gaudiano 
Dept. of Aerospace Engineering Sciences, 
University of Colorado, Boulder CO 80309, USA 
January 5, 1988 
Abstract 
Patterns of activity over real neural structures are known to exhibit time- 
dependent behavior. It would seem that the brain may be capable of utilizing 
temporal behavior of activity in neural networks as a way of performing functions 
which cannot otherwise be easily implemented. These might include the origination 
of sequential behavior and the recognition of time-dependent stimuli. A model is 
presented here which uses neuronal populations with recurrent feedback connec- 
tions in an attempt to observe and describe the resulting time-dependent behavior. 
Shortcomings and problems inherent to this model are discussed. Current models 
by other researchers are reviewed and their similarities and differences discussed. 
METHODS / PRELIMINARY RESULTS 
In previous papers,J2,3] computer models were presented that simulate a net con- 
sisting of two spatially organized populations of realistic neurons. The populations are 
richly interconnected and are shown to exhibit internally sustained activity. It was 
shown that if the neurons have response times significantly shorter than the typical unit 
time characteristic of the input patterns (usually 1 msec), the populations will exhibit 
time-dependent behavior. This will typically result in the net falling into a limit cycle. 
By a limit cycle, it is meant that the population falls into activity patterns during which 
all of the active cells fire in a cyclic, periodic fashion. Although the period of firing of 
the individual cells may be different, after a fixed time the overall population activity 
will repeat in a cyclic, periodic fashion. For populations organized in 7x7 grids, the 
limit cycle will usually start 20-200 msec after the input is turned off, and its period 
will be in the order of 20-100 msec. 
The point of interest is that if the net is allowed to undergo synaptic modifications by 
means of a modified hebbian learning rule while being presented with a specific spatial 
pattern (i.e., cells at specific spatial locations within the net are externally stimulated), 
subsequent presentations of the same pattern with different temporal characteristics 
will cause the population to recall patterns which are spatially identical (the same cells 
will be active) but which have different temporal qualities. In other words, the net can 
fall into a different limit cycle. These limit cycles seem to behave as attractors in that 
similar input patterns will result in the same limit cycle, and hence each distinct limit 
cycle appears to have a basin of attraction. Hence a net which can only learn a small 
� American Institute of Physics 1988 
298 
number of spatially distinct patterns can recall the patterns in a number of temporal 
modes. If it were possible to quantitatively discriminate between such temporal modes, 
it would seem reasonable to speculate that different limit cycles could correspond to 
different memory traces. This would significantly increase estimates on the capacity of 
memory storage in the net. 
It has also been shown that a net being presented with a given pattern will fall and 
stay into a limit cycle until another pattern is presented which will cause the system 
to fall into a different basin of attraction. If no other patterns are presented, the net 
will remain in the same limit cycle indefinitely. Furthermore, the net will fall into the 
same limit cycle independently of the duration of the input stimulus, so long as the 
input stimulus is presented for a long enough time to raise the population activity level 
beyond a minimum necessary to achieve self-sustained activity. Hence, if we suppose 
that the net ""recognizes"" the input when it falls into the corresponding limit cycle, it 
follows that the net will recognize a string of input patterns regardless of the duration of 
each input pattern, so long as each input is presented long enough for the net to fall into 
the appropriate limit cycle. In particular, our system is capable of. falling into a limit 
cycle within some tens of milliseconds. This can be fast enough to encode, for example, a 
string ofphonemes as would typically be found in continuous speech. It may be possible, 
for instance, to create a model similar to Rumelhart and McClelland's 1981 model on 
word recognition by appropriately connecting multiple layers of these networks. If the 
response time of the cells were increased in higher layers, it may be possible to have 
the lowest level respond to stimuli quickly enough to distinguish phonemes (or some 
sub-phonemic basic linguistic unit), then have populations from this first level feed into 
a slower, word-recognizing population layer, and so on. Such a model may be able to 
perform word recognition from an input consisting of continuous phoneme strings even 
when the phonemes may vary in duration of presentation. 
SHORTCOMINGS 
Unfortunately, it was noticed a short time ago that a consistent mistake had been 
made in the process of obtaining the above-mentioned results. Namely, in the process 
of decreasing the response time of the cells I accidentally reached a response time below 
the time step used in the numerical approximation that updates the state of each cell 
during a simulation. The equations that describe the state of each cell depend on the 
state of the cell at the previous time step as well as on the input at the present time. 
These equations are of first order in time, and an explicit discrete approximation is 
used in the model. Unfortunately it is a known fact that care must be taken in selecting 
the size of the time step in order to obtain reliable results. It is infact the case that 
by reducing the time step to a level below the response time of the cells the dynamics 
of the system varied significantly. It is questionable whether it would be possible to 
adjust some of the population parameters within reson to obtain the same results with 
a smaller step size, but the following points should be taken into account: 1) other 
researchers have created similar models that show such cyclic behavior (see for example 
Silverman, Shaw and PearsonI7]). 2) biological data exists which would indicate the 
existance of cyclic or periodic bahvior in real neural systems (see for instance BairdIll). 
As I just recently completed a series of studies at this university, I will not be able 
to perform a detailed examination of the system described here, but instead I will more 
299 
than likely create new models on different research equipment which will be geared more 
specifically towards the study of temporal behavior in neural networks. 
OTHER MODELS 
It should be noted that in the past few years some researchers have begun inves- 
tigating the possibility of neural networks that can exhibit time-dependent behavior, 
and I would like to report on some of the available results as they relate to the topic of 
temporal patterns. Baird[l] reports findings from the rabbit's olfctory bulb which indi- 
cate the existance of phase-locked oscillatory states corresponding to olfactory stimuli 
presented to the subjects. He outhnes an elegant model which attributes pattern recog- 
nition abihties to competing instabihties in the dynamic activity of neural structures. 
He further speculates that inhomogeneous connectivity in the bulb can be selectively 
modified to achieve input-sensitive oscillatory states. 
Silverman, Shaw and Pearson[7] have developed a model based on a biologically-inspired 
ideahzed neural structure, which they call the trion. This unit represents a localized 
group of neurons with a discrete firing period. It was found that small ensembles of tri- 
ons with symmetric connections can exhibit quasi-stable periodic firing patterns which 
do not require pacemakers or external driving. Their results are inspired by existing 
physiological data and are consistent with other works. 
Kleinfeld[6], and Sompolinsky and Kanter[8] independently developed neural network 
models that can generate and recognize sequential or cyclic patterns. Both models rely 
6n what could be summarized as the recirculation of information through time-delayed 
channels. 
Very similar results are presented by Jordan[4] who extends a typical connectionist or 
PDP model to include state and plan units with recurrent connections and feedback 
from output units through hidden units. He employs supervised learning with fuzzy 
constraints to induce learning of sequences in the system. 
From a shghtly different approach, Tank and Hopfield[9] make use of patterned sets 
of delays which effectively compress information in time. They develop a model which 
recognizes patterns by falling into local minima of a state-space energy function. They 
suggest that a systematic selection of delay functions can be done which will allow for 
time distortions that would be hkely to occur in the input. 
Finally, a somewhat different approach is taken by Homma, Atlas and Marks[5], who 
generalize a network for spatial pattern recognition to one that performs spario-temporal 
patterns by extending classical principles from spatial networks to dynamic networks. 
In particular, they replace multiplication with convolution, weights with transfer func- 
tions, and thresholding with non linear transforms. Hebbian and Delta learning rules 
are similarly generalized. The resulting models are able to perform temporal pattern 
recognition. 
The above is only a partial hst of some of the relevant work in this field, and there 
are probably various other results I am not aware of. 
DISCUSSION 
All of the above results indicate the importance of temporal patterns in neural net- 
works. The need is apparent for further formal models which can successfully quantify 
temporal behavior in neural networks. Several questions must be answered to further 
3OO 
clarify the role and meaning of temporal patterns in neural nets. For instance, there 
is an apparent difference between a model that performs sequential tasks and one that 
performs recognition of dynamic patterns. It seems that appropriate selection of delay 
mechanisms will be necessary to account for many types of temporal pattern recogni- 
tion. The question of scaling must also be explored: mechanism are known to exist in 
the brain which can cause delays ranging from the millisecond-range (e.g. variations 
in synaptic cleft size) to the tenth of a second range (e.g. axonal transmission times). 
On the other hand, the brain is capable of recognizing sequences of stimuli that can be 
much longer than the typical neural event, such as for instance being able to remember 
a song in its entirety. These and other questions could lead to interesting new aspects 
of brain function which are presently unclear. 
References 
[1] Baird, B., ""Nonlinear Dynamics of Pattern Formation and Pattern Recognition in 
the Rabbit Olfactory Bulb"". Physica 22D, 150-175. 1986. 
[2] Gaudiano, P., ""Computer Models of Neural Networks"". Unpublished Master's The- 
sis. University of Colorado. 1987. 
[3] 
Gaudiano, P., MacGregor, R.J., ""Dynamic Activity and Memory races in 
Computer-Simulated Recurrently-Connected Neural Networks"". Proceedings of the 
First International Conference on Neural Networks. 2:177-185. 1987. 
[4] 
Jordan, M.I., ""Attractor Dynamics and Parallelism in a Connectionist Sequential 
Machine"". Proceedings of the Eighth Annual Conference of the Cognitive Sciences 
Society. 1986. 
[5] 
Homma, T., Atlas, L.E., Marks, R.J.II, ""An Artificial Neural Network for Spatio- 
Temporal Bipolar Patterns: Application to Phoneme Classification"". To appear in 
proceedings of Neural Information Processing Systems Conference (AIP). 1987. 
[6] Kleinreid, D., ""Sequential State Generation by Model Neural Networks"". Proc. 
Natl. Acad. Sci. USA. 83: 9469-9473. 1986. 
[7] Silverman, D.J., Shaw, G.L., Pearson, J.C. ""Associative Recall Properties of the 
Trion Model of Cortical Organization"". Biol. Cybern. 53:259-271. 1986. 
[8] Sompolinsky, H., Kanter, I. ""Temporal Association in Asymmetric Neural Net- 
works"". Phys. Rev. Let. 57:2861-2864. 1986. 
[9] Tank, D.W., Hopfield, J.J. ""Neural Computation by Concentrating Information in 
Time"". Proc. Natl. Acad. Sci. USA. 84:1896-1900. 1987. 
", pattern activ network gaudiano aerospac engin boulder co usa activ real neural structur known exhibit would seem brain may capabl util behavior activ neural network way perform function can not otherwis easili might includ origin sequenti behavior recognit model use neuron popul recurr feedback attempt observ describ result problem inher model current model research review similar differ preliminari result previou comput model present simul net two spatial organ popul realist popul interconnect shown exhibit intern sustain neuron respons time significantli shorter typic unit characterist input pattern popul exhibit typic result net fall limit limit meant popul fall activ pattern activ cell fire period although period fire individu cell may fix time overal popul activ repeat period popul organ cycl usual start msec input turn period order point interest net allow undergo synapt modif modifi hebbian learn rule present specif spatial cell specif spatial locat within net extern present pattern differ tempor characterist caus popul recal pattern spatial ident cell differ tempor net differ limit limit cycl seem behav attractor input pattern result limit henc distinct limit appear basin henc net learn small american institut physic spatial distinct pattern recal pattern number tempor possibl quantit discrimin tempor would seem reason specul differ limit cycl could correspond memori would significantli increas estim capac storag also shown net present given pattern fall limit cycl anoth pattern present caus system fall differ basin pattern net remain limit cycl net fall limit cycl independ durat input long stimulu present long enough time rais popul activ level minimum necessari achiev suppos net input fall correspond limit net recogn string input pattern regardless durat input long input present long enough net fall appropri limit system capabl fall limit within ten fast enough ofphonem would typic found continu may creat model similar rumelhart model recognit appropri connect multipl layer time cell increas higher may possibl lowest level respond stimuli quickli enough distinguish phonem basic linguist popul first level feed popul model may abl word recognit input consist continu phonem string even phonem may vari durat notic short time ago consist mistak process obtain process decreas respons time cell accident reach respons time time step use numer approxim updat state cell equat describ state cell depend cell previou time step well input present equat first order explicit discret approxim unfortun known fact care must taken select size time step order obtain reliabl infact case reduc time step level respons time cell dynam system vari question whether would possibl popul paramet within reson obtain result smaller step follow point taken creat similar model show cyclic behavior exampl shaw biolog data exist would indic cyclic period bahvior real neural system instanc recent complet seri studi abl perform detail examin system describ instead like creat new model differ research equip gear toward studi tempor behavior neural model note past year research begun possibl neural network exhibit would like report avail result relat topic report find olfctori bulb exist oscillatori state correspond olfactori stimuli outhn eleg model attribut pattern abihti compet instabihti dynam activ neural specul inhomogen connect bulb select achiev oscillatori shaw develop model base neural call unit repres local neuron discret fire found small ensembl symmetr connect exhibit period fire pattern requir pacemak extern result inspir exist data consist sompolinski independ develop neural network gener recogn sequenti cyclic model reli could summar recircul inform similar result present extend typic connectionist model includ state plan unit recurr connect feedback output unit hidden employ supervis learn fuzzi induc learn sequenc shghtli differ tank make use pattern set delay effect compress inform develop model pattern fall local minima energi systemat select delay function done allow distort would hkeli occur somewhat differ approach taken atla network spatial pattern recognit one perform extend classic principl spatial network dynam replac multipl weight transfer threshold non linear hebbian delta learn rule similarli result model abl perform tempor pattern partial hst relev work probabl variou result awar result indic import tempor pattern neural need appar formal model success quantifi behavior neural sever question must answer role mean tempor pattern neural appar differ model perform sequenti task one recognit dynam seem appropri select delay necessari account mani type tempor pattern question scale must also mechan known exist brain caus delay rang variat synapt cleft tenth second rang axon transmiss brain capabl recogn sequenc stimuli longer typic neural instanc abl rememb song question could lead interest new aspect brain function present dynam pattern format pattern recognit rabbit olfactori physica model neural unpublish univers activ memori neural proceed intern confer neural dynam parallel connectionist sequenti proceed eighth annual confer cognit scienc artifici neural network bipolar applic phonem appear neural inform process system confer state gener model neural recal properti model cortic associ asymmetr neural comput concentr inform,1
33,33,"301 
ENCODING GEOMETRIC INVARIANCES IN 
HIGHER-ORDER NEURAL NETWORKS 
C.L. Giles 
Air Force Office of Scientific Research, Bolling AFB, DC 20332 
R.D. Griffin 
Naval Research Laboratory, Washington, DC 20375-5000 
T. Maxwell 
Sachs-Freeman Associates, Landover, MD 20785 
ABSTRACT 
We describe a method of constructing higher-order neural 
networks that respond invariantly under geometric transformations on 
the input space. By requiring each unit to satisfy a set of 
constraints on the interconnection weights, a particular structure is 
imposed on the network. A network built using such an architecture 
maintains its invariant performance independent of the values the 
weights assume, of the learning rules used, and of the form of the 
nonlinearities in the network. The invariance exhibited by a first- 
order network is usually of a trivial sort, e.g., responding only to 
the average input in the case of translation invariance, whereas 
higher-order networks can perform useful functions and still exhibit 
the invariance. We derive the weight constraints for translation, 
rotation, scale, and several combinations of these transformations, 
and report results of simulation studies. 
INTRODUCTION 
A persistent difficulty for pattern recognition systems is the 
requirement that patterns or objects be recognized independent of 
irrelevant parameters or distortions such as orientation (position, 
rotation, aspect), scale or size, background or context, doppler 
shift, time of occurrence, or signal duration. The remarkable 
performance of humans and other animals on this problem in the visual 
and auditory realms is often taken for granted, until one tries to 
build a machine with similar performance. Though many methods have 
been developed for dealing with these problems, we have classified 
them into two categories: 1) preprocessing or transformation 
(inherent) approaches, and 2) case-specific or ""brute force"" 
(learned) approaches. Common transformation techniques include: 
Fourier, Hough, and related transforms; moments; and Fourier 
descriptors of the input signal. In these approaches the signal is 
usually transformed so that the subsequent processing ignores 
arbitrary parameters such as scale, translation, etc. In addition, 
these techniques are usually computationally expensive and are 
sensitive to noise in the input signal. The ""brute force"" approach 
is exemplified by training a device, such as a perceptron, to 
classify a pattern independent of it's position by presenting the 
American Institute of Physics 1988 
302 
training pattern at all possible positions. MADALINE machines 2 have 
been shown to perform well using such techniques. Often, this type 
of invariance is pattern specific, does not easily generalize to 
other patterns, and depends on the type of learning algorithm 
employed. Furthermore, a great deal of time and energy is spent on 
learning the invariance, rather than on learning the signal. We 
describe a method that has the advantage of inherent invariance but 
uses a higher-order neural network approach that must learn only the 
desired signal. Higher-order units have been shown to have unique 
computational strengths and are quite amenable to the encoding of a 
priori knowledge. 3'7 
MATHEMATICAL DEVELOPMENT 
Our approach is similar to the group invariance approach, 8,10 
although we make no appeal to group theory to obtain our results. We 
begin by selecting a transformation on the input space, then require 
the output of the unit to be invariant to the transformation. The 
resulting equations yield constraints on the interconnection weights, 
and thus imply a particular form or structure 'for the network 
architecture. 
For the i-th unit Yi of order M defined on a discrete input 
space, let the output be given by 
Yi[WiM(x),p(x)] = f( wi � +  wil(xl) p(x 1) 
+ wi2(Xl,X2) p(xl) P(X2) + ... 
+ ... wiM(xl,..XM) p(xl)..p(x M) ), 
(1) 
where p(x) is the input pattern or signal function (sometimes called 
a pixel) evaluated at position vector x, wim(xl,...Xm) is the weight 
of order m connecting the outputs of units at Xl, x2,..x m to the i- 
th unit, i.e., it correlates m values, f(u) is some threshold or 
sigmoid output function, and the summations extend over the input 
space. wiM(x) represents the entire set of weights associated with 
the i-th unit. These units are equivalent to the sigma-pi units a 
defined by Rumelhart, Hinton, and Williams. 7 Systems built from 
these units suffer from a combinatorial explosion of terms, hence are 
more complicated to build and train. To reduce the severity of this 
problem, one can limit the range of the interconnection weights or 
the number of orders, or impose various other constraints. We find 
that, in addition to the advantages of inherent invariance, imposing 
an invariance constraint on Eq. (1) reduces the number of allowed 
aThe sigma-pi neural networks are multi-layer networks with 
higher-order terms in any layer. As such, most of the neural 
networks described here can be considered as a special case of the 
sigma-pi units. However, the sigma-pi units as originally formulated 
did not have invariant weight terms, though it is quite simple to 
incorporate such invariances in these units. 
303 
weights, thus simplifying the architecture and shortening the 
training time. 
We now define what we mean by invariance. The output of a unit 
is invariant with respect to the transformation T on the input 
pattern if 9 
T[Yi(WiM,p(x))] = Y(WiM,T[p(x)]) = y(wiM,p(x)) 
(2) 
An example of the class of invariant response defined by Eq. (2) 
would be invariant detection of an object in the receptive field of a 
panning or zooming camera. An example of a different class would be 
invariant detection of an object that is moving within the field of a 
fixed camera. One can think of this latter case as consisting of a 
fixed field of ""noise"" plus a moving field that contains only the 
object of interest. If the detection system does not respond to the 
fixed field, then this latter case is included in Eq. (2). 
To illustrate our method we derive the weight constraints for 
one-dimensional translation invariance. We will first switch to a 
continuous formulation, however, for reasons of simplicity and 
generality, and because it is easier to grasp the physical 
significance of the results, although any numerical simulation 
requires a discrete formulation and has significant implications for 
the implementation of our results. Instead of an index i, we now 
keep track of our units with the continuous variable u. With these 
changes Eq. (2) now becomes 
y[u;WM(x),p(x)] = f( w � + Idxl wl(u;xl) p(x 1) + ... 
+ f..fdxl..dxM(-;Xl,..xM> P(Xl)..p(xM) ), 
The limits on the integrals are defined by the problem and are 
crucial in what follows. Let T be a translation of the input pattern 
by -x0, so that 
T[p(x)] = p(x+x0) 
(4) 
where x 0 is the translation of the input pattern. Then, from eq (2), 
Ty[u;wM(x) ,p(x)] = y[u;ll(x),p(x+x0)] = y[u;WM(x) ,p(x)] (5) 
Since p(x) is arbitrary we must impose term-by-term equality in the 
argument of the threshold function; i.e., 
fdx 1 wl(u;xl) p(xl) = f dx 1 wl(u;Xl) p(xl+xO) , (5a) 
f f dxl dx2 w2(-;x1,x2) p(xl+O) p(x2+o), 
etc. 
304 
Making the substitutions x 1. x 1-xO, x 2 .x 2-xO, etc, we find that 
fdx I wl(u;Xl) P(Xl) - fdx 1 wl(u;Xl-X0) p(xl) , (6a) 
etc. 
Note that the limits of the integrals on the right hand side must be 
adjusted to satisfy the change-of-variables. If the limits on the 
integrals are infinite or if one imposes some sort of periodic 
boundary condition, the limits of the integrals on both sides of the 
equation can be set equal. We will assume in the remainder of this 
paper that these conditions can be met; normally this means the 
limits of the integrals extend to infinity. (In an implementation, 
it is usually impractical or even impossible to satisfy these 
requirements, but our simulation results indicate that these networks 
perform satisfactorily even though the regions of integration are not 
identical. This question must be addressed for each class of 
transformation; it is an integral part of the implementation design.) 
Since the functions p(x) are arbitrary and the regions of integration 
are the same, the weight functions must be equal. This imposes a 
constraint on the functional form of the weight functions or, in the 
discrete implementation, limits the allowed connections and thus the 
number of weights. In the case of translation invariance, the 
constraint on the functional form of the weight functions requires 
that 
w 1 (U;Xl) -- wl(u;xl-x0), 
w2(U;Xl,X2) - w2(U;Xl-X0,x2-x0), 
etc. 
(7a) 
(7b) 
These equations imply that the first order weight is independent of 
input position, and depends only on the output position u. The 
second order weight is a function only of vector differences, 10 i.e., 
wl(xi) m w!(, (Sa) 
w2(U;Xl,X 2) - w2(u;x].-x2). (85) 
For a discrete implementation with N input units (pixels) fully 
connected to an output unit, this requirement reduces the number of 
second-order weights from order N 2 to order N, i.e., only weights for 
differences of indexes are needed rather than all unique pair 
combinations. Of course, this advantage is multiplied as the number 
of fully-connected output units increases. 
FURTHER EXAMPLES 
We have applied these techniques to several other 
transformations of interest. For the case of transformation of scale 
305 
define the scale operator S such that 
Sp(x) = anp(ax) 
(9) 
where a is the scale factor, and x is a vector of dimension n. The 
factor a n is used for normalization purposes, so that a given figure 
always contains the same ""energy"" regardless of its scale. 
Application of the same procedure to this transformation leads to the 
following constraints on the weights: 
(tgx/a) = (tgxi) , 
w2(u;xL/a,x2/a) = w2(u;xi,x2), 
w 3(u;xl/a,x2/a,x3/a ) = w3(u;Xl,X2,X3), etc. 
(10a) 
(10b) 
(10c) 
Consider a two-dimensional problem viewed in polar coordinates (r,t). 
A set of solutions to these constraints is 
w(u;rl,tl) = 
w 2 (u; r 1 , r 2; t 1 , t 2) = w 2 (u; rl/r 2; t 1, t2), 
w3(u;rl,r2,r3;tl,t2,t3) = w3(u;(rl-r2)/r3;tl,t2,t3). 
(11a) 
(11b) 
(11e) 
Note that with increasing order comes increasing freedom in the 
selection of the functional form of the weights. Any solution that 
satisfies the constraint may be used. This gives the designer 
additional freedom to limit the connection complexity, or to encode 
special behavior into the net architecture. An example of this is 
given later when we discuss combining translation and scale 
invariance in the same network. 
Now consider a change of scale for a two-dimensional system in 
rectangular coordinates, and consider only the second-order weights. 
A set of solutions to the weight constraint is: 
w2(u;xl,Yl;X2,Y2) = w2(u;xl/Yl;X2/Y2), 
w2(u;xl,Yl;X2,Y2) = w2(u;Xl/X2;Yl/Y2), 
w2(u;xl,Yl;X2,Y2) = w2(u;(xl-x2)/(yl-Y2)), etc. 
(12a) 
(12b) 
(12c) 
We have done a simulation using the form of Eq. (12b). The 
simulation was done using a small input space (8x8) and one output 
unit. A simple least-mean-square (back-propagation) algorithm was 
used for training the network. When taught to distinguish the 
letters T and C at one scale, it distinguished them at changes of 
scale of up to 4X with about 15 percent maximum degradation in the 
output strength. These results are quite encouraging because no 
special effort was required to make the system work, and no 
corrections or modifications were made to account for the boundary 
condition requirements as discussed near Eq. (6). This and other 
simulations are discussed further later. 
As a third example of a geometric transformation, consider the 
case of rotation about the origin for a two-dimensional space in 
polar coordinates. One can readily show that the weight constraints 
306 
are satisfied if 
wl(u;rl,tl) = wl(u;rl), (13a) 
w 2 (u; rl, r 2; tl, t 2) = w 2 (u; r 1 , r 2; t 1- t2), etc. ( 13b ) 
These results are reminiscent of the results for translation 
invariance. This is not uncommon: seemingly different problems 
often have similar constraint requirements if the proper change of 
variable is made. This can be used to advantage when implementing 
such networks but we will not discuss it further here. 
An interesting case arises when one considers combinations of 
invariances, e.g., scale and translation. This raises the question 
of the effect of the order of the transformations, i.e., is scale 
followed by translation equivalent to translation followed by scale? 
The obvious answer is no, yet for certain cases the order is 
unimportant. Consider first the case of change-of-scale by a, 
followed by a translation x0; the constraints on the weights up to 
second order are: 
wl(u;Xl) = wl(u;(xl-x0)/a), (14a) 
w 2 (u; x 1 ,x2) = w2(u; (Xl-X0)/a , (x2-x0)/a), (14b) 
and for translation followed by scale the constraints are' 
wl(u;xl)  wl(u; (xl/a)-x0) , and (15a) 
w 2 (u; Xl, x 2) -- w 2 (u; (xl/a) - x0, (x2/a) -x0). ( 15b ) 
Consider only the second-order weights for the two-dimensional case. 
Choose rectangular coordinate variables (x,y) so that the translation 
is given by (x0,Y0). Then 
w2(u;xl,Yl;X2,Y2) = 
w2(u;(xl/a)-x0,(yl/a)-y0;(x2/a)-x0,(y2/a)-y0), (16a) 
or 
w2(u;xl,Yl;X2,Y2)  
w2(u;(xl-x0)/a,(yl-Y0)/a;(x2-x0)/a,(y2-Y0)/a). 
(16b) 
If we take as our solution 
w2(U;Xl,Yl;X2,Y2) = w2(u;(xl-x2)/(yl-Y2)), 
(17) 
then w 2 is invariant to scale and translation, and the order is 
unimportant. With higher-order weights one can be even more 
adventurous. 
As a final example consider the case of a change of scale by a 
factor a and rotation about the origin by an amount t O for a two- 
dimensional system in polar coordinates. (Note that the order of 
transformation makes no difference.) The weight constraints up to 
second order are: 
wl(u;rl,tl)  wl(u;rl/a,tl-tO), and (18a) 
307 
w2(rl,tl;r2,t2)  w2(u;rl/a,tl-to;r2/a,t2-t0). (18b) 
The first-order constraint requires that w 1 be independent of the 
input variables, but for the second-order term one can obtain a more 
useful solution: 
w2(u;rl,tl;r2,t2) = w2(u;rl/r2;tl-t2). (19) 
This implies that with second-order weights, one can construct a unit 
that is insensitive to changes in scale and rotation of the input 
space. How useful it is depends upon the application. 
SIMULATION RESULTS 
We have constructed several higher-order neural networks that 
demonstrated invariant response to transformations of scale and of 
translation of the input patterns. The systems were small, 
consisting of less than 100 input units, were constructed from 
second-and first-order units, and contained only one, two, or three 
layers. We used a back-propagation algorithm modified for the 
higher-order (sigma-pi) units. The simulation studies are still in 
the early stages, so the performance of the networks has not been 
thoroughly investigated. It seems safe to say, however, that there 
is much to be gained by a thorough study of these systems. For 
example, we have demonstrated that a small system of second-order 
units trained to distinguish the letters T and C at one scale can 
continue to distinguish them over changes in scale of factors of at 
least four without retraining and with satisfactory performance. 
Similar performance has been obtained for the case of translation 
invariance. 
Even at this stage, some interesting facets of this approach are 
becoming clear: 1) Even with the constraints imposed by the 
invariance, it is usually necessary to limit the range of connections 
in order to restrict the complexity of the network. This is often 
cited as a problem with higher-order networks, but we take the view 
that one can learn a great deal more about the nature of a problem by 
examining it at this level rather than by simply training a network 
that has a general-purpose architecture. 2) The higher-order 
networks seem to solve problems in an elegant and simple manner. 
However, unless one is careful in the design of the network, it 
performs worse than a simpler conventional network when there is 
noise in the input field. 3) Learning is often ""quicker"" than in a 
conventional approach, although this is highly dependent on the 
specific problem and implementation design. It seems that a tradeoff 
can be made: either faster learning but less noise robustness, or 
slower learning with more robust performance. 
DISCUSSION 
We have shown a simple way to encode geometric invariances into 
neural networks (instead of training them), though to be useful the 
networks must be constructed of higher-order units. The invariant 
encoding is achieved by restricting the allowable network 
308 
architectures and is independent of learning rules and the form of 
the sigmoid or threshold functions. The invariance encoding is 
normally for an entire layer, although it can be on an individual 
unit basis. It is easy to build one or more invariant layers into a 
multi-layer net, and different layers can satisfy different 
invariance requirements. This is useful for operating on internal 
features or representations in an invariant manner. For learning in 
such a net, a multi-layered learning rule such as generalized back- 
propagation 7 must be used. In our simulations we have used a 
generalized back-propagation learning rule to train a two-layer 
system consisting of a second-order, translation-invariant input 
layer and a first-order output layer. Note that we have not shown 
that one can not encode invariances into layered first-order 
networks, but the analysis in this paper implies that such invariance 
would be dependent on the form of the sigmoid function. 
When invariances are encoded into higher-order neural networks, 
the number of interconnections required is usually reduced by orders 
of powers of N where N is the size of the input. For example, a 
fully connected, first-order, single-layer net with a single output 
unit would have order N interconnections; a similar second-order net, 
order N 2. If this second-order net (or layer) is made shift 
invariant, the order is reduced to N. The number of multiplies and 
adds is still of order N 2. 
We have limited our discussion in this paper to geometric 
invariances, but there seems to be no reason why temporal or other 
invariances could not be encoded in a similar manner. 
REFERENCES 
o 
o 
o 
D.H. Ballard and C.M. Brown, Computer Vision (Prentice-Hall, 
Englewood Cliffs, N3, 1982). 
B. Widrow, IEEE First Intl. Conf. on Neural Networks, 87TH0191- 
7, Vol. 1, p. 143, San Diego, CA, June 1987. 
J.A. Feldman, Biological Cybernetics 46, 27 (1982). 
C.L. Giles and T. Maxwell, Appl. Optics 26, 4972 (1987). 
G.E. Hinton, Proc. 7th Intl. Joint Conf. on Artificial 
Intelligence, ed. A. Drina, 683 (1981). 
Y.C. Lee, G. Doolen, H.H. Chen, G.Z. Sun, T. Maxwell, H.Y. Lee, 
C.L. Giles, Physica 22D, 276 (1986). 
D.E. Rumelhart, G.E. Hinton, and R.J. Williams, Parallel 
Distributed Processing, Vol. 1, Ch. 8, D.E. Rumelhart and J.L. 
McClelland, eds., (MIT Press, Cambridge, 1986). 
309 
T. Maxwell, C.L. Giles, Y.C. Lee, and H.H. Chen, Proc. IEEE 
Intl. Conf. on Systems, Man, and Cybernetics, 86CH2364-8, p. 
627, Atlanta, GA, October 1986. 
W. Pitts and W.S. McCulloch, Bull. Math. Biophys. 9, 127 
(1947). 
10. 
M. Minsky and S. Papert, Perceptrons (MIT Press, Cambridge, 
Mass., 1969). 
", geometr invari neural network gile forc offic scientif boll dc griffin research dc maxwel md describ method construct neural respond invariantli geometr transform input requir unit satisfi set interconnect particular structur network built use architectur invari perform independ valu learn rule form invari exhibit network usual trivial respond averag input case translat wherea network perform use function still exhibit deriv weight constraint sever combin report result simul persist difficulti pattern recognit system pattern object recogn independ paramet distort orient scale background doppler time signal remark human anim problem visual auditori realm often taken one tri machin similar though mani method develop deal classifi two preprocess transform common transform techniqu relat fourier input approach signal transform subsequ process ignor paramet techniqu usual comput expens nois input approach exemplifi train pattern independ posit present institut physic pattern possibl madalin machin shown perform well use type invari pattern easili gener depend type learn algorithm great deal time energi spent rather learn method advantag inher invari neural network approach must learn unit shown uniqu strength quit amen encod develop approach similar group invari make appeal group theori obtain select transform input requir output unit invari equat yield constraint interconnect thu impli particular form structur network unit yi order defin discret input let output given wi input pattern signal function call evalu posit vector weight order connect output unit correl threshold output summat extend input repres entir set weight associ unit equival unit system built unit suffer combinatori explos henc complic build reduc sever one limit rang interconnect weight number impos variou find addit advantag inher impos invari constraint reduc number allow neural network network term neural describ consid special case unit origin formul invari weight though quit simpl invari thu simplifi architectur shorten defin mean output unit invari respect transform input exampl class invari respons defin invari detect object recept field zoom exampl differ class would detect object move within field one think latter case consist field plu move field contain detect system respond latter case includ illustr method deriv weight constraint translat first switch reason simplic easier grasp physic although numer simul discret formul signific implic implement instead index track unit continu variabl becom idxl limit integr defin problem let translat input pattern translat input eq arbitrari must impos equal threshold dx dxl substitut find fdx limit integr right hand side must satisfi limit infinit one impos sort period limit integr side set assum remaind condit normal mean integr extend usual impract even imposs satisfi simul result indic network satisfactorili even though region integr question must address class integr part implement function arbitrari region integr weight function must impos function form weight function limit allow connect thu case translat function form weight function requir equat impli first order weight independ depend output posit order weight function vector discret implement input unit fulli output requir reduc number weight order order weight index need rather uniqu pair advantag multipli number output unit exampl appli techniqu sever case transform scale scale oper scale vector dimens use normal given figur contain regardless procedur transform lead constraint problem view polar coordin set solut constraint increas order come increas freedom function form solut constraint may give design freedom limit connect encod behavior net exampl later discuss combin translat scale consid chang scale system consid set solut weight constraint done simul use form done use small input space one output simpl algorithm train taught distinguish one distinguish chang percent maximum degrad result quit encourag effort requir make system modif made account boundari requir discuss near discuss third exampl geometr consid rotat origin space one readili show weight constraint satisfi result reminisc result translat seemingli differ problem similar constraint requir proper chang use advantag implement network discuss interest case aris one consid combin scale rais question effect order scale translat equival translat follow obviou answer yet certain case order consid first case translat constraint weight order translat follow scale constraint weight rectangular coordin variabl translat given take solut invari scale order weight one even final exampl consid case chang scale rotat origin amount system polar order make weight constraint order constraint requir independ term one obtain impli one construct unit insensit chang scale rotat input use depend upon result construct sever neural network invari respons transform scale input system less input construct contain three use algorithm modifi simul studi still earli perform network seem safe much gain thorough studi demonstr small system train distinguish letter one scale distinguish chang scale factor four without retrain satisfactori perform obtain case translat interest facet approach even constraint impos usual necessari limit rang connect order restrict complex often problem take view one learn great deal natur problem level rather simpli train network seem solv problem eleg simpl unless one care design wors simpler convent network input learn often although highli depend problem implement seem tradeoff either faster learn less nois learn robust shown simpl way encod geometr invari network train though use must construct invari achiev restrict allow network independ learn rule form sigmoid threshold invari encod entir although individu easi build one invari layer differ layer satisfi differ use oper intern represent invari learn learn rule gener must simul use learn rule train consist input output note shown one encod invari layer analysi paper impli invari depend form sigmoid invari encod neural number interconnect requir usual reduc order power size net singl output would order similar net made shift order reduc number multipli still order limit discuss paper geometr seem reason tempor could encod similar ballard comput vision ie first neural san june biolog cybernet gile optic joint artifici physica parallel rumelhart ie octob pitt minski perceptron,0
34,34,"310 
PROBABILISTIC CHARACTERIZATION OF 
NEURAL MODEL COMPUTATIONS 
Richard M. Golden ' 
University of Pittsburgh, Pittsburgh, Pa. 15260 
ABSTRACT 
Information retrieval in a neural network is viewed as a procedure in 
which the network computes a ""most probable"" or MAP estimate of the unk- 
nown information. This viewpoint allows the class of probability distributions, 
P, the neural network can acquire to be explicitly specified. Learning algorithms 
for the neural network which search for the ""most probable"" member of P can 
then be designed. Statistical tests which decide if the ""true"" or environmental 
probability distribution is in P can also be developed. Example applications of 
the theory to the highly nonlinear back-propagation learning algorithm, and the 
networks of Hop field and Anderson are discussed. 
INTRODUCTION 
A connectionist system is a network of simple neuron-like computing 
elements which can store and retrieve information, and most importantly make 
generalizations. Using terminology suggested by Rumelhart & McClelland 1, 
the computing elements of a connectionist system are called units, and each unit 
is associated with a real number indicating its activity level. The activity level 
of a given unit in the system can also influence the activity level of another unit. 
The degree of influence between two such units is often characterized by a 
parameter of the system known as a connection strength. During the informa- 
tion retrieval process some subset of the units in the system are activated, and 
these units in turn activate neighboring units via the inter-unit connection 
strengths. The activation levels of the neighboring units are then interpreted as 
' Correspondence should be addressed to the author at the Department 
of Psychology, Stanford University, Stanford, California, 94305, USA. 
@ American Institute of Physics 1988 
311 
the retrieved information. During the learning process, the values of the inter- 
unit connection strengths in the system are slightly modified each time the units 
in the system become activated by incoming information. 
DERIVATION OF THE SUBJECTWE PF 
2 
Smolensky demonstrated how the class of possible probability distri- 
butions that could be represented by a Harmony theory neural network model 
can be derived from basic principles. Using a simple variation of the arguments 
made by Smolensky, a procedure for deriving the class of probability distribu- 
tions associated with any connectionist system whose information retrieval 
dynamics can be summarized by an additive energy function is briefly sketched. 
A rigorous presentation of this proof may be found in Golden 3 
Let a sample space, Sp, be a subset of the activation pattern state space, 
Sa, for a particular neural network model. For notational convenience, define the 
term probability function (pf) to indicate a function that assigns numbers 
between zero and one to the elements of Sp. For discrete random variables, the 
pf is a probability mass function. For continuous random variables, the pf is a 
probability density function. Let a particular stationary stochastic environment 
be represented by the scalar-valued pf, Pe(X), where X is a particular activation 
pattern. The pf, Pe(X), indicates the relative frequency of occurrence of activa- 
tion pattern X in the network model's environment. A second pf defined with 
respect to sample space Sv also must be introduced. This probability function, 
Ps(X), is called the network's subjective pf. The pf Ps(X) is interpreted as the 
network's belief that X will occur in the network's environment. 
The subjective pf may be derived by making the assumption that the 
information retrieval dynamical system, D s , is optimal. That is, it is assumed 
that D s is an algorithm designed to transform a less probable state X into a more 
probable state X* where the probability of a state is defined by the subjective pf 
Ps(X;A), and where the elements of A are the connection strengths among the 
units. Or in traditional engineering terminology, it is assumed that D s is a MAP 
(maximum a posteriori) estimation algorithm. The second assumption is that an 
energy function, V(X), that is minimized by the system during the information 
retrieval process can be found with an additivity property. The additivity pro- 
perty says that if the neural network were partitioned into two physically 
312 
unconnected subnetworks, then V(X) can be rewritten as Vi(X 1) + V2(X 2) 
where V 1 is the energy function minimized by the first subnetwork and V 2 is 
the energy function minimized by the second subnetwork. The third assumption 
is that V(X) provides a sufficient amount of information to specify the probabil- 
ity of activation pattern X. That is, Ps(X) = G(V(X)) where G is some continu- 
ous function. And the final assumption (following $molensky 2) is that statisti- 
cal and physical independence are equivalent. 
To derive Ps(X), it is necessary to characterize G more specifically. Note 
that if probabilities are assigned to activation patterns such that physically 
independent substates of the system are also statistically independent, then the 
additivity property of V(K) forces G to be an exponential function since the only 
continuous function that maps addition into multiplication is the exponential -. 
After normalization and the assignment of unity to an irrelevant free parameter 
2 
, the unique subjective pf for a network model that minimizes V(K) during the 
information retrieval process is: 
p$(X;A) = Z 'lexp [ - V(X;A)] 
Z = $exp[ - V(X;A)]dX 
(2) 
provided that Z < C < oo. Note that the integral in (2) is taken over Sp. Also note 
that the pf, Ps' and sam5Ple space, S,, specify a Markov Random Field since (1) 
is a Gibbs distribution . 
Example 1: Subjective pfs for associative back-propagation networks 
The information retrieval equation for an associative back-propagation 6 
network can be written in the form O=[I;A] where the elements of the vector O 
are the activity levels for the output units and the elements of the vector I are the 
activity levels for the input units. The parameter vector A specifies the values 
313 
of the ""connection strengths"" among the units in the system. The function 
specifies the architecture of the network. 
A natural additive energy function for the information retrieval dynam- 
ics of the least squares associative back-propagation algorithm is: 
v(o) = IO-(I;A) 
(3) 
If $, is defined to be a real vector space such that O e $,, then direct substitu- 
tion of V(O) for Vd(X;A) into (1) and (2) yields a multivariate Gaussian density 
function with mean (I)(I;A) and covariance matrix equal to the identity matrix 
multiplied by 1/2. This multivariate Gaussian density function is Ps(OlI;A). 
That is, with respect to Ps(OlI;A), information retrieval in an associative back- 
propagation network involves retrieving the ""most probable"" output vector, O, 
for a given input vector, I. 
Example 2: Subjective pfs for Hopfield and BSB networks. 
The Hopfield 7 and BSB model 8,9 neural network models minimize the 
following energy function during information retrieval: 
vo0 = - xTM X (4) 
where the elements of X are the activation levels of the units in the system, and 
the elements of M are the connection strengths among the units. Thus, the sub- 
jective pf for these networks is: 
314 
Ps(X) = Z -1 exp [xTM X] where Z = Eexp [xTM XI 
(5) 
where the summation is taken over $,. 
APPLICATIONS OF THE THEORY 
If the subjective pf for a given connectionist system is known, then tradi- 
tional analyses from the theory of statistical inference are immediately applica- 
ble. In this section some examples of how these analyses can aid in the design 
and analysis of neural networks are provided. 
Evaluating Learning Algorithms 
Learning in a neural network model involves searching for a set of con- 
nection strengths or parameters that obtain a global minimum of a learning 
energy function. The theory proposed here explicitly shows how an optimal 
learning energy function can be constructed using the model's subjective pf and 
the environmental pf. In particular, optimal learning is defined as searching for 
the most probable connection strengths, given some set of observations (sam- 
ples) drawn from the environmental pf. Given some mild restrictions upon the 
form of the a priori pf associated with the connection strengths, and for a 
sufficiently large set of observations, estimating the most probable connection 
strengths (MAP estimation) is equivalent to maximum likelihood estimation 10 
11 
A well-known result is that if the parameters of the subjective pf are 
represented by the parameter vector A, then the maximum likelihood estimate of 
A is obtained by finding the A* that minimizes the function: 
315 
E(A) =- <LOG [p(X;A)]> 
( 
where < > is the expectation operator taken with respect to the environmental pf. 
Also note that (6) is the Kullback-Leibler 12 distance measure plus an irrelevant 
constant. Asymptotically, E(A) is the logarithm of the probability of A given 
some set of observations drawn from the environmental pf. 
Equation (6) is an important equation since it can aid in the evaluation 
and design of optimal learning algorithms. Substitution of the multivariate 
Gaussian associated with (3) into (6) shows that the back-propagation algorithm 
is doing gradient descent upon the function in (6). On the other hand, substitu- 
tion of (5) into (6) shows that the Hebbian and Widrow-Hoff learning rules pro- 
posed for the Hopfield and BSB model networks are not doing gradient descent 
upon (6). 
Evaluating Network Architectures 
The global minimum of t62) occurs if and only if the subjective and 
environmental pfs are equivalent . Thus, one crucial issue is whether any set 
of connection strengths exists such that the neural network's subjective pf can 
be made equivalent to a given environmental pf. If no such set of connection 
strengths exists, the subjective pf, Ps' is defined to be misspecified. White 11 
and Lancaster 13 have introduced a statistical test designed to reject the null 
hypothesis that the subjective pf, Ps' is not misspecified. Golden suggests a 
version of this test that is suitable for subjective pfs with many parameters. 
REFERENCES 
1. D. E. Rumelhart, J. L. McClelland, and the PDP Research Group, Parallel 
distributed processing: Explorations in the microstructure of cognition, 1, 
(MIT Press, Cambridge, 1986). 
2. P. Smolensky, In D. E. Rumelhart, J. L. McClelland and the PDP Research 
Group (Eds.), Parallel distributed processing: Explorations in the micros- 
tructure of cognition, 1, (MIT Press, Cambridge, 1986), pp. 194-281. 
316 
3. R. M. Golden, A unified framework for connectionist systems. Unpublished 
manuscript. 
4. C. Goffman, Introduction to real analysis. (Harper and Row, N.Y., 1966), p. 
65. 
5. J. L. Marroquin, Probabilistic solution of inverse problems. A.I. Memo 860, 
MIT Press (1985). 
6. D. E. Rumelhart, G. E. Hinton, & R. J. Williams, In D. E. Rumelhart, J. L. 
McClelland, and the PDP Research Group (Eds.), Parallel distributed pro- 
cessing: Explorations in the microstincture of cognition, 1, (MIT Press, 
Cambridge, 1986), pp. 318-362. 
7. J. J. Hopfield, Proceedings of the National Academy of Sciences, USA, 79, 
2554-2558 (1982). 
8. J. A. Anderson, R. M. Golden, & G. L. Murphy, In H. Szu (Ed.), Optical and 
Hybrid Computing, SPIE, 634, 260-276 (1986). 
9. R. M. Golden, Journal of Mathematical Psychology, 30, 73-80 (1986). 
10. H. L. Van Trees, Detection, estimation, and modulation theory. (Wiley, N. 
Y., 1968). 
11. H. White, Econometrica, 50, 1-25 (1982). 
12. S. Kullback & R. A. Leibler, Annals of Mathematical Statistics, 22, 79-86 
(1951). 
13. T. Lancaster, Econometrica, 52, 1051-1053 (1984). 
ACKNOWLEDGEMENTS 
This research was supported in part by the Mellon foundation while the 
author was an Andrew Mellon Fellow in the Psychology Department at the 
University of Pittsburgh, and partly by the Office of Naval Research under Con- 
tract No. N-0014-86-K-0107 to Walter Schneider. This manuscript was revised 
while the author was an NIH postdoctoral scholar at Stanford University. This 
research was also supported in part by grants from the Office of Naval Research 
(Contract No. N00014-87-K-0671), and the System Development Foundation to 
David Rumelhart. I am very grateful to Dean C. Mumme for comments, criti- 
cisms, and helpful discussions concerning an earlier version of this manuscript. 
I would also like to thank David B. Cooper of Brown University for his sugges- 
tion that many neural network models might be viewed within a unified statisti- 
cal framework. 
", character model comput golden retriev neural network view procedur network comput map estim viewpoint allow class probabl neural network acquir explicitli learn algorithm neural network search member statist test decid environment distribut also exampl applic theori highli nonlinear learn hop field anderson connectionist system network simpl comput store retriev importantli make use terminolog suggest rumelhart clelland comput element connectionist system call unit associ real number indic activ activ level given unit system also influenc activ level anoth degre influenc two unit often character system known connect retriev process subset unit system unit turn activ neighbor unit via connect activ level neighbor unit interpret correspond address author depart stanford american institut physic retriev learn valu connect strength system slightli modifi time unit system becom activ incom subjectw pf demonstr class possibl probabl could repres harmoni theori neural network model deriv basic use simpl variat argument procedur deriv class probabl associ connectionist system whose inform retriev summar addit energi function briefli rigor present proof may found golden sampl subset activ pattern state particular neural network notat defin probabl function indic function assign number zero one element discret random probabl mass continu random pf densiti let particular stationari stochast environ repres particular activ indic rel frequenc occurr pattern network second pf defin sampl space sv also must probabl call subject pf interpret belief occur subject pf may deriv make assumpt retriev dynam assum algorithm design transform less probabl state state probabl state defin subject pf element connect strength among tradit engin assum map estim second assumpt minim system inform process found addit addit say neural network partit two physic rewritten energi function minim first subnetwork energi function minim second third assumpt provid suffici amount inform specifi activ pattern final assumpt physic independ deriv necessari character note probabl assign activ pattern physic substat system also statist properti forc exponenti function sinc function map addit multipl exponenti normal assign uniti irrelev free paramet uniqu subject pf network model minim retriev process note integr taken also note specifi markov random field sinc gibb distribut subject pf associ network inform retriev equat associ written form element vector activ level output unit element vector level input paramet vector specifi valu among unit function architectur natur addit energi function inform retriev least squar associ algorithm defin real vector space direct yield multivari gaussian densiti mean covari matrix equal ident matrix multivari gaussian densiti function respect inform retriev associ network involv retriev output given input subject pf hopfield bsb hopfield bsb model neural network model minim energi function inform tm element activ level unit element connect strength among pf network exp tm eexp tm xi summat taken theori subject pf given connectionist system analys theori statist infer immedi section exampl analys aid design analysi neural network learn algorithm neural network model involv search set strength paramet obtain global minimum learn theori propos explicitli show optim energi function construct use subject pf environment optim learn defin search probabl connect given set observ drawn environment given mild restrict upon priori pf associ connect larg set estim probabl connect equival maximum likelihood estim result paramet subject pf paramet vector maximum likelihood estim obtain find minim expect oper taken respect environment note distanc measur plu irrelev logarithm probabl given set observ drawn environment import equat sinc aid evalu design optim learn substitut multivari associ show algorithm gradient descent upon function show hebbian learn rule hopfield bsb model network gradient descent network architectur global minimum occur subject pf equival one crucial issu whether set connect strength exist neural subject pf made equival given environment set connect subject defin white lancast introduc statist test design reject null subject golden suggest test suitabl subject pf mani pdp research parallel explor microstructur clelland pdp research parallel distribut explor unifi framework connectionist unpublish introduct real probabilist solut invers memo press pdp research group parallel distribut explor microstinctur proceed nation academi szu optic journal mathemat van modul kullback annal mathemat research support part mellon foundat andrew mellon fellow psycholog depart partli offic naval research walter manuscript revis author nih postdoctor scholar stanford also support part grant offic naval research system develop foundat grate dean mumm help discuss concern earlier version would also like thank david cooper brown univers mani neural network model might view within unifi,1
35,35,"317 
PARTITIONING OF SENSORY DATA BY A COPTICAI, NETWOPK  
Richard Granger, Jos Ambros-Ingerson, Howard Henry, Gary Lynch 
Center for the Neurobiology of Learning and Memory 
University of California 
Irvine, CA, 91717 
ABSTRACT
To process sensory data, sensory brain areas must preserve information about both 
the similarities and differences among learned cues: without the latter, acuity would 
be lost, whereas without the former, degraded versions of a cue would be erroneously 
thought to be distinct cues, and would not be recognized. We have constructed a 
model of piriform cortex incorporating a large number of biophysical, anatomical and 
physiological parameters, such as two-step excitatory firing thresholds, necessary and 
suicient conditions for long-term potentiation (LTP) of synapses, three distinct types 
of inhibitory currents (short IPSPs, long hyperpolarizing currents (LHP) and long cell- 
specific afterhyperpolarization (AHP)), sparse connectivity between bulb and layer-II 
cortex, caudally-fiowing excitatory collateral fibers, nonlinear dendritic summation, etc. 
We have tested the model for its ability to learn similarity- and difference-preserving 
encodings of incoming sensory cues; the biological characteristics of the model enable it 
to produce multiple encodings of each input cue in such a way that different readouts of 
the cell firing activity of the model preserve both similarity and difference-iuiormation. 
In particular, probabilistic quant al transmitter-release properties of pitiform synapses 
give rise to probabilistic postsynaptic voltage levels which, in combination with the ac- 
tivity of local patches of inhibitory interneurons in layer H, differentially select bursting 
rs. single-pulsing layer-II cells. Time-locked firing to the theta rhythm (Larson and 
Lynch, 1986) enables distinct spatial patterns to be read out against a relatively quies- 
cent background firing rate. raining trials using the physiological rules for induction of 
LTP yield stable layer-II-cell spatial firing patterns for learned cues. Multiple simulated 
olfactory input patterns (i.e., those that share many chemical features) will give rise 
to strongly-overlapping bulb firing patterns, activating many shared lateral olfactory 
tract (LOT) axons innervating layer Ia of pitiform cortex, which in turn yields highly 
overlapping layer-H-cell excitatory potentials, enabling this spatial layer-II-cell encod- 
ing to preserve the overlap (similarity) among similar inputs. At the same time, those 
synapses that are enhanced by the learning process cause stronger cell firing, yielding 
strong, cell-specific afterhyperpolarizing (AHP) currents. Local inhibitory interneurons 
effectively select alternate cells to fire once strongly-firing cells have undergone AHP. 
These alternate cells then activate their caudally-fiowing recurrent collaterals, activat- 
ing distinct populations of synapses in caudal layer Ib. Potentiation of these synapses 
in combination with those of still-active LOT axons selectively enhance the response of 
caudal cells that tend to accentuate the differences among even very-similar cues. 
Empirical tests of the computer simulation have shown that, after training, the 
initial spatial layer II cell firing responses to similar cues enhance the similarity of 
the cues, such that the overlap in response is equal to or greater than the overlap in 
Thls research was supported in part by the Otce of Naval lesearch under grants N00014-84-K-0391 
and N00014-87-K-0838 and by the National Science Foundation under grant IST-85-12419. 
� American Institute of Physics 1988 
318 
input cell firing (in the bulb): e.g., two cues that overlap by 65% give rise to response 
patterns that overlap by 80% or more. Reciprocally, later cell firing patterns (after 
AHP), increasingly enhance the differences among even very-similar patterns, so that 
cues with 90% input overlap give rise to output responses that overlap by less than 10%. 
This difference-enhancing response can be measured with respect to its acuity; since 90% 
input overlaps are reduced to near zero response overlaps, it enables the structure to 
distinguish between even very-similar cues. On the other hand, the similarity-enhancing 
response is properly viewed as a partitioning mechanism, mapping quite-distinct input 
cues onto nearly-identical response patterns (or category indicators). We therefore use 
a statistical metric for the information value of categorizations to measure the value of 
partitionings produced by the pitiform simulation network. 
INTRODUCTION 
The three primary dimensions along which network processing models vary are their 
learning rules, their performance rules and their architectural structures. In practice, 
perfornxance rules are much the same across different models, usually being some variant 
of a 'weighted-sum' rule (in which a unit's output is calculated as some function of the 
sum of its inputs multiplied by their 'synaptic' weights). Perfornxance rules are usually 
either 'static' rules (calculating unit outputs and halting) or 'settling' rules (iteratively 
calculating outputs until a convergent solution is reached). Most learning rules are 
either variants of a 'correlation' rule, loosely based on Hebb's (1949) postulate; or a 
'delta' rule, e.g., the perceptron rule (Rosenblatt, 1962), the adaline rule (Widrow and 
Hoff, 1960) or the generalized delta or 'backpropagation' rule (Parker, 1985; Rumelhart 
et al., 1986). Finally, architectures vary by and large with learning rules: e.g., multi- 
layered feedforward nets require a generalized delta rule for convergence; bidirectional 
connections usually imply a variant of a Hebbian or correlation rule, etc. 
Architectures and learning and performance rules are typically arrived at for reasons 
of their convenient computational properties and analytical tractability. These rules 
are sometimes based in part on some results borrowed from neurobiology: e.g., 'units' 
in some network models are intended to correspond loosely to neurons, and 'weights' 
loosely to synapses; the notions of parallelism and distributed processing are based on 
metaphors derived from neural processes. 
An open question is how much of the rest of the rich literature of neurobiological 
results should or could profitably be incorporated into a network model. lrom the 
point of view of constructing mechanisms to perform certain pre-specified computatonal 
functions (e.g., correlation, optimization), there are varying answers to this question. 
However, the goal of understanding brain circuit function introduces a fundamental 
problem: there are no known, pre-specifled functions of any given cortical structures. 
We have constructed and studied a physiologically- and anatomically-accurate model of 
a particular brain structure, olfactory cortex, that is strictly based on biological data, 
with the goal of elucidating the local function of this circuit from its perforinance in a 
bottom-up' fashion. We measure our progress by the accuracy with which the model 
corresponds to known data, and predicts novel physiological results (see, e.g., Lynch 
and Granger, 1988; Lynch et al., 1988). 
Our initial analysis of the circuit reveals a mechanism consisting of a learning rule 
that is notably simple and restricted compared to most network models, a relatively 
novel architecture with some unusual properties, and a performance rule that is ex- 
319 
traordinarily complex compared to typical network-model performance rules. Taken 
together, these rules, derived directly from the known biology of the olfactory cortex, 
generate a coherent mechanism that has interesting computational properties. This pa- 
per describes the learning and performance rules and the architecture of the model; the 
relevant physiology and anatomy underlying these rules and structures, respectively; 
and an analysis of the coherent mechanism that results. 
LEARNING RULES DERIVED FROM LONG-TERM POTENTIATION 
Long-term potentiation (LTP) of synapses is a phenomenon in which a brief series 
of biochemical events gives rise to an enhancement of synaptic efficacy that is extraordi- 
narily long-lasting (Bliss and Lzmo, 1973; Lynch and Baudry, 1984; Staubli and Lynch, 
1987); it is therefore a candidate mechanism underlying certain forms of learning, in 
which few triniug trials are required for long-lasting memory. The physiological char- 
acteristics of LTP form the basis for a straightforward network learning rule. 
It is known that simultaneous pre- and post-synaptic activity (i.e., intense depolar- 
ization) result in LTP (e.g., WigstrZm et al., 1986). Since excitatory cells are embedded 
in a meshwork of inhibitory interneurons, the requisite induction of adequate levels of 
pre- and postsynaptic activity is achieved by stimulation of large numbers of afferents 
for prolonged periods, by voltage clamping the postsynaptic cell, or by chemically block- 
ing the activity of inhibitory interneurons. In the intact animal, however, the question 
of how simultaneous pre- and postsynaptic activity rnght be induced has been an open 
question. Recent work (Larson and Lynch, 1986) has shown that when hippocampal 
afferents are subjected to patterned stimulation with particular temporal and frequency 
parameters, inhibition is naturally eliminated within a specific time window, and LTP 
can arise as a result. Figure I shows that LTP naturally occurs using short (3-4 pulse) 
bursts of high-frequency (100Hz) stimulation with a 200ms interburst interval; only the 
second of a pair of two such bursts causes potentiation. This occurs because the normal 
short inhibitory currents (IPSPs), which prevent the first burst from depolarizing the 
postsynaptic cell sufficiently to produce LTP, are maximally refractory at 200ms after 
being stimulated, and therefore, although the second burst arrives against a hyperpolar- 
ized background resulting from the long hyperpolarizing currents (LHP) initiated by the 
first burst, the second burst does not initiate its own IPSPs, since they are then refrac- 
tory. The studies leading to these conclusions were performed in in vitro hippocampal 
slices; LTP induced by this patterned stimulation technique in intact animals shows no 
measurable decrement prior to the time at which recording arrangements deteriorate: 
more than a month in some cases (see Staubli and Lynch, 1987). 
PERFORMANCE RULES DERIVED FROM 
OLFACTORY PHYSIOLOGY AND BEHAVIOR 
From the above data we may infer that LTP itself depends on simultaneous pre- and 
postsynaptic activity, as Hebb postulated, but that a sufficient degree of the latter occurs 
only under particular conditions. Those conditions (patterned stimulation) suggest the 
beginnings of a performance rule for the network. Drawing this out requires a review 
of the inhibitory currents active in hippocampus and in pitiform cortex. Three classes 
of such currents are known to be present: short IPSPs, long LHPs and extremely long, 
cell-specific afterhyperpolarization, or AHP (see Figure 2). Short IPSPs arise from both 
feedforward and feedback activation of inhibitory interneurons which in turn synapse 
320 
on excitatory cells (e.g., layer II cells, which are primary excitatory cells in pitiform). 
IPgPs develop more slowly than excitatory postsynaptic potentials (EP SPs) But quickly 
shunt the EPSP, thus reversing the depolarization that arises from EPSPs, and bringing 
the cell voltage down below its original resting potential. IPSPs last approximately 50- 
lOOms, and then enter a refractory period during which they cannot be reactivated 
from about 100-300ms after they have been once activated. Longer hyperpolarization 
(LHP) is presumably dependent on a distinct type of inhibitory interneuron or inhibitory 
receptor, and arises in much the same way; however, these cells are apparently not 
refractory once hctivated. LHP lasts for 300-500ms. 
Taken together, IPSPs and LHP constitute a form of high-pass frequency filter: 
200ms after an input burst, a subsequent input will arrive against a background of 
hyperpolarization due to LHP, yet this input will not initiate its own IPSP due to 
the refractory period. If the input is a single pulse, its EPSP will fail to trigger the 
postsynaptic cell, since it will not be able to overcome the LHP-induced hyperpolarized 
potential of the cell. Yet if the input is a high-frequency burst, the pulses comprising 
the burst will give rise to different behavior. Ordinarily, the first EPSP would have Been 
driven back to resting potentialby its accompanying IPSP, before the second pulse in the 
burst could arrive. But when the IPSP is absent, the first EPSP is not driven rapidly 
down to resting potential, and the second pulse sums with it, raising the voltage of 
the postsynaptic cell and allowing voltage-dependent channels to open, thereby further 
alepolarizing the cell, and causing it to spike (Figure 3). Hence these high-frequency 
bursts fire the cell, while single pulses or lower-frequency bursts would not do so. When 
these cells fire, then active synapses can be potentiated. 
The third inhibitory mechanism, AHP, is a current that causes an excitatory cell 
to become refractory after it has fired strongly or rapidly. This mechanism is therefore 
specific to those cells that have fired, unlike the first two mechanisms. AHP can prevent 
a cell from firing again for as long as 1000ms (1 second). 
It has long been observed that EEG waves in the hippocampi of learning animals are 
dominated By the theta rhythm, i.e., activity occuring at about 4-SHz. This is now seen 
to correspond to the optimal rate for firing postsynaptic cells and for enhancing synapses 
via LTP; i.e., this rhythmic aspect of the performance rules of these networks is suggested 
by the physiology of LTP. The resulting activation patterns may take the following form: 
relatively synchronized cell firing occurring approximately once every 200ms, i.e., spatial 
patterns of induced activity occurring at the rate of one new spatial cell-firing pattern 
every 200ms. The cells most strongly participating in any one firing pattern will not 
participate in subsequent patterns (at least the next 4-5 patterns, i.e., 800-1000ms), 
due to AHP. This raises the interesting possibility that different spatial patterns (at 
different times) may be conveying different information about their inputs. In summary, 
postsynaptic cells fire in pulses or bursts depending on the synaptically-weighted sums 
of their active axonal inputs; this firing is synchronized across the cells in a structure, 
giving rise to a spatial pattern of activity across these cells; once cells fire they will 
not fire again in subsequent patterns; each pattern (occuring at the theta rhythm, i.e., 
approrrately once every 200ms) will therefore consist of extremely different spatial 
patterns of cell activity. Hence the 'output' of such a network is a sequence of spatial 
patterns. 
In an animal engaged in an olfactory discrimination learning task, the theta rhythm 
321 
dominates the animals behavior: the animals literally sniff at theta. We have been 
able to sustitute direct stimulation (in theta-burst mode) of the lateral olfactory tract 
(LOT), which is the input to the olfactory cortex, for odors: these 'electrical odors' 
are learned and discrimbtated by the animals, either from other electrical odors (via 
different stimulating electrodes) or from real odors. Furthermore, behavioral learning 
in this paradigm is accompanied by LTP of pitiform synapses (Roman et al., 1987). 
This experimental paradigm thus provides us with a known set of behaviorally-relevant 
inputs to the olfactory cortex that give rise to synaptic potentiation that apparently 
underlies the learnlng of the stimuli. 
ARCHITECTURE OF OLFACTORY CORTEX 
Nasal receptor cells respond differentially to different chemicals; these cells topo- 
graphically innervate the olfactory bulb, which is arranged such that combinations of 
specific spatial 'patches' of bulb characteristically respond to specific odors. Bulb also 
receives a number of centrifugal afferents from brain, most of which terminate on the 
inhibitory granule cells. The excitatory mitral cells in bulb send out axons that fornx 
the lateral olfactory tract (LOT), which constitutes the only major input to olfactory 
(pitiform) cortex. This cortex in turn has some feedback connections to bulb via the 
anterior olfactory nucleus. 
Figure 4 illustrates the anatomy of the superficial layers of olfactory cortex: the 
LOT axons flow across layer Ia, synapsing with the dendrites of pitiform layer-H cells. 
Those cells in turn give rise to collateral axon outputs which flow, in layer Ib, parallel 
and subjacent to the LOT, in a predominantly rostral-to-caudal direction, eventually 
terminating in entorhinal cortex. Layer Ia is very sparsely connected; the probability 
of synapses between LOT axons and layer-H cell dendrites is less than 0.10 (Lynch, 
1986), and decreases candally. Layer Ib (where collaterals synapse with dendrites) is 
also sparse, but its density increases caudally, as the number of collaterals increases; the 
overall connectivity density on layer-H-cell dendrites is approximately constant through- 
out most of pitiform. Layer II also contains, in addition to the principal excitatory cells 
(modified stellates), inhibitory interneurons which synapse on excitatory cells within a 
specified radius, forming a 'patchwork' of cells affected by a particular inhibitory cell; 
the spheres of influence of inhibitory cells almost certainly overlap somewhat. There are 
approximately 50,000 LOT axons, 500,000 pitiform layer H cells, and a much smaller 
number of inhibitory cells that divide layer II roughly into functional patches. (See 
Price, 1973; Luskin and Price, 1983; Krettek and Price, 1977; Price and Slotnick, 1983; 
Haberly and Price, 1977, 1978a, 1978b). 
The layer II cell collateral axons flow through layer II-I for a distance before rising 
up to layer Ib (Haberly, 1985); taken in combination with the predominantly caudal 
directionality of these collaterals, this means that rostral pitiform will be dominated by 
LOT inputs. Extreme caudal pitiform (and all of lateral entorhinal cortex) is dominated 
by collaterals from more rostral cells; moving from rostral to caudal pitiform, cells 
increasingly can be thought of as 'hybrid cells': cells receiving inputs from both the 
bulb (via the LOT) and from rostral pitiform (via collateral axons). The architectural 
characteristics of rostral pitiform is therefore quite different from that of caudal pirifornx, 
and differential analysis must be performed of rostral cells vs. hybrid cells, as will be 
seen later in the paper. 
322 
SIMULATION AND FORMAL ANALYSIS: INTRODUCTION 
We have conducted several simulations of olfactory cortex incorporating many of 
the physiological features discussed earlier. Two hundred layer H cells are used with 
100 input (LOT) lines and 200 collateral axons; both the LOT and collateral axons 
flow caudally. LOT axons connect with rostral dendrites with a probability of 0.2, 
which decreases linearly to 0.05 by the caudal end of the model. The connectivity is 
arranged randomly, subject to the constraint that the number of contacts for axons and 
dendrites is fixed within certain narrow boundaries (in the most severe case, each axon 
forms 20 synapses and each dendrite receives 20 contacts). The resulting matrix is thus 
hypergeometric in both dimensions. There are 20 simulated inhibitory interneurons, 
such that the layer H cells are arranged in 20 overlapping patches, each within the 
influence of one such inldbitory cell. Inhibition rules are approximately as discussed 
above; i.e., the short IPSP is longer than an EPSP but only one fifth the length of the 
LHP; cell-specific AHP in turn is twice as long as LHP. 
Synaptic activity in the model is probabilistic and quantal: for any presynaptic 
activation, there is a fixed probability that the synapse will allow a certain amount 
of conductance to be contributed to the postsynaptic cell. Long-term potentiation 
was represented by a 40% increase in contact strength, as well as an increase in the 
probability of conductance being transmitted. These effects would be expected to arise, 
in sit, from modifying existing synapses as well as adding new ones (Lynch, 1986), 
two results obtained in electron microscopic studies (Lee et al., 1980). Only excitatory 
cell synapses are subject to LTP. LTP occurred when a cell was activated twice at a 
simulated 200ms interval: the first input 'primes' the synapse so that a subsequent 
burst input can drive it past a threshold value; following from the physiological results, 
previously potentiated synapses were much less different from ""naive"" synapses when 
driven at high frequency (see Lynch et al., 1988). The simulation used theta burst 
activation (i.e., bursts of pulses with the bursts occurring at 5Hz) of inputs during 
learning, and operated according to these synchronized fixed time steps, as discussed 
above. 
The network was trained on sets of ""odors"", each of which was represented as a group 
of active LOT lines, as in the ""electric odor"" experiments already described. Usually 
three or four ""components"" were used in an odor, with each component consisting of a 
group of contiguous LOT lines. We assumed that the bulb normalized the output signal 
to about 20% of all LOT fibers. In some cases, more specific bulb rules were used and 
in particular inhibition was assumed to be greatest in areas surrounding an active bulb 
""patch"". 
The network exhibited several interesting behaviors. Learning, as expected, in- 
creased the robustness of the response to specific vectors; thus adding or subtracting 
LOT lines from a previously learned input did not, within limits, greatly change the 
response. The model, like most network simulations, dealt reasonably well with de- 
graded or noisy known signals. An unexpected result developed after the network had 
learned a succession of cues. In experiments of this type, the simulation would begin to 
generate two quite distinct output signals within a given sampling episode; that is, a sin- 
gle previously learned cue would generate two successive responses in successive 'sniffs' 
presented to an ""experienced"" network. The first of these response patterns proved to 
be common to several signals while the second was specific to each learned signal. The 
323 
common signal was found to occur when the network had learned 3-5 inputs which 
had substantial overlap in their components (e.g., four odors that shared 70% of their 
components). It appeared then that the network had begun to produce ""category"" or 
""clustering"" responses, on the first sniff of a simulated odor, and ""individual"" or ""dif- 
ferentiation"" responses on subsequent sniffs of that same odor. When presented with a 
novel cue which contained elements shared with other, previously learned signals, the 
network produced the cluster response but no subsequent individual or specific output 
signal. Four to five cluster response patterns and 20 - 25 individual responses were 
produced in the network without distortion. 
In retrospect, it was clear that the model accomplished two necessary and in some 
senses opposing operations: 1) it detected similarities in the members of a cue category 
or cluster, and, 2) it nonetheless distinguished between cues that were quite similar. Its 
first response was to the similarity-based category and its second to the specific signal. 
ANALYSIS OF CATEGOPIZATION IN POSTRAL PIRIFOPM 
Assume that a set of input cues (or 'simulated odors') X a, Xt... X � differ from each 
other in the firing of dx LOT input lines; similarly, inputs �a,�t ...�� differ in d� 
lines, but that inputs from the sets X and Y differ from each other in Dx,�  d lines, 
such that the Xs and the Ys form distinct natural categories. Then the performance of 
the network should give rise to output (layer H cell) firing patterns that are very similar 
among members of either category, but different for members of different categories; 
i.e., there should be a single spatial pattern of response for members of X, with little 
variation in response across members, and there should be a distinct spatial pattern of 
response for members of Y. 
Considering a matrix constructed by uniform selection of neurons, each with a hy- 
pergeometric distribution for its synapses, as an approiraation of the bidimensional 
hypergeometric matrix described above, the following results can be derived. The ex- 
pected value of , the Hamming distance between responses for two input cues differing 
by 2d LOT lines (input Hamming distance of d) is: 
where No is the number of postsynaptic cells, each $i is the probability that a cell will 
have precisely i active contacts from one of the two cues, and I(i, j) is the probability 
that the number of contacts on the cell will increase (or decrease) from i to j with 
the change in d LOT lines; i.e., changing from the first cue to the second. Hence, the 
first term denotes the probability of a cell decreasing its number of active contacts from 
above to below some threshold, , such that that cell fired in response to one cue but not 
the other (and therefore is one of the cells that will contribute to the difference between 
responses to the two cues). Reciprocally, the second term is the probability that the 
cell increases its number of active synapses such that it is now over the threshold; this 
cell also will contribute to the difference in response. We restrict our analysis for now 
to rostral pitiform, in which there are assumed to be few if any collateral axons. We 
will return to this issue in the next subsection. 
324 
The value for each $8, the probability of a active contacts on a cell, is a hypergeo- 
metric function, since there are a fixed number of contacts anatomically between LOT 
and (rostral) phiform cells: 
$, = p(a active ynape) = 
where N is the number of LOT lines, A is the number of active (firing) LOT lines, n is 
the number of synapses per dendrite formed by the LOT, and a is the number of active 
such synapses. The formula can be read by noting that the first binomial indicates 
the number of ways of choosing a active synapses on the dendrite from the A active 
incoming LOT lines; for each of these, the next expression calculates the number of 
ways in which the remaining n - a (inactive) synapses on the dendrite are chosen from 
the N - A inactive incoming LOT lines; the probability of active synapses on a dendrite 
depends on the sparseness of the matrix (i.e., the probability of connection between any 
given LOT line and dendrite); the solution must be normalized by the number of ways 
in which n synapses on a dendrite can be chosen from N incoming LOT lines. 
The probability of a cell changing its number of contacts from a to h is: 
[(a, &) =  I. d - l g , g 
where N, n, A, and a are as above, I is the ""loss"" or reduction in the number of active 
synapses, and g is the gain or increase. Hence the left expression is the probability of 
losing l active synapses by changing d LOT lines, and the right-hand expression is the 
probability of gaining g active synapses. The product of the expressions are suxnmed 
over all the ways of choosing I and g such that the net change g - I is the desired 
difference a - &. 
If training on each cue induces only fractional LTP, then over trials, synapses con- 
tacted by any overlapping parts of the input cues should become stronger than those 
contacted only by unique parts of the cue. Comparing two cues from within a category, 
rs. two cues from between categories, there may be the same number of active synapses 
lost across the two cues in either case, but the expected strength of the synapses lost in 
the former case (within category) should be significantly lower than in the latter case 
(across categories). Hence, for a given threshold, the difference J between output firing 
patterns will be smaller for two within-category cues than for cues from two different 
categories. 
It is important to note that clustering is an operation that is quite distinct from 
stimulus generalization. Observing that an object is a car does not occur because of a 
comparison with a specific, previously learned car. Instead the category ""car"" emerges 
from the learning of many different cars and may be based on a ""prototype"" that has 
no necessary correspondence with a specific, real object. The same could be said of 
the network. It did not produce a categorical response when one cue had been learned 
325 
and second similar stimulus was presented. Category or cluster responses, as noted, 
required the learning of several exemplars of a similarity-based cluster. It is the process 
of extracting commonalities from the environment that defines clustering, not the simple 
noting of similarities between two cues. 
An essential question in clustering concerns the location of the boundaries of a given 
group; i.e., what degree of similarity must a set of cues possess to be grouped together? 
This issue has been discussed from any number of theoretical positions (e.g., information 
theory); all these analyses incorporate the point that the breadth of a category must 
reflect the overall homogeneity or heterogeneity of the environment. In a world where 
things are quite similar, useful categories will necessarily be composed of objects with 
much in common. Suppose, for instance, that subjects were presented with a set of 
four distinct coffee cups of different colors, and asked later to recall the objects. The 
subjects might respond by listing the cups as a blue, red, yellow and green coffee cup, 
reflecting a relatively specific level of description in the hierarchy of objects that are 
coffee cups. In contrast, if presented with four different objects, a blue coffee cup, a 
drinking glass, a silver fork and a plastic spoon, the cup would be much more likely 
to be recalled as simply a cup, or a coffee cup, and rarely as a blue coffee cup; the 
specificity of encoding chosen depends on the overall heterogeneity of the environment. 
The categories lornted by the simulation were quite appropriate when judged by an 
information theoretic measure, but how well it does across a wide range of possible 
worlds has not been addressed. 
ANALYSIS OF PROBLEMS ARISING FROM CAUDAL AXON FLOW 
The anatomical feature of directed flow of collateral axons gives rise to an immediate 
problem in principle. In essence, the more rostral cells that fire in response to an input, 
the more active inputs there are from these cells to the caudal cells, via collateral axons, 
such that the probability of caudal cell firing increases precipitously with probability of 
rostral cell firing. Conversely, reducing the number of rostral cells from firing, either 
by reducing the number of active input LOT axons or by raising the layer II cell firing 
threshold, prevents sufficient input to the caudal cells to enable their probability of 
firing to be much above zero. 
This problem can be stated formally, by making assumptions about the detailed 
nature of the connectivity of LOT and collateral axons in layer I as these axons proceed 
from rostral to caudal pitiform. The probability of contact between LOT axons and 
layer-H-cell dendrites decreases caudally, as the number of collateral axons is increasing, 
given their rostral to caudal flow tendency. This situation is depicted in Figure 4. 
Assuming that probability of LOT contact tends to go to zero, we may adopt a labelling 
scheme for axons and synaptic contacts, as in the diagram, in which some combination 
of LOT axons (z) and collateral axons (h,) contact any particular layer II cell dendrite 
(h,), each of which is itself the source of an additional collateral axon flowing to cells 
more caudal than itself. Then the cell firing function for layer H cell h, is: 
where the za denote LOT axon activity of those axons still with nonzero probability 
of contact for layer H cell h,, the hm denote activity of layer H cells rostral of h,, t is 
326 
the cell firing threshold, w,., is the synaptic strength between axon m and dendrite n, 
and H is the Heaviside step function, equal to 1 or 0 according to whether its argument 
is positive or negative. If we assume instead that probability of cell firing is a graded 
function rather than a step function, we may eliminate the H step function and calculate 
the firing of the cell (hn) from it", sensori data howard gari lynch neurobiolog learn memori california process sensori sensori brain area must preserv inform similar differ among learn without acuiti would wherea without degrad version cue would erron distinct would construct piriform cortex incorpor larg number anatom excitatori fire necessari condit potenti three distinct type inhibitori current long hyperpolar current long afterhyperpolar spars connect bulb excitatori collater nonlinear dendrit test model abil learn incom sensori biolog characterist model enabl produc multipl encod input cue way differ readout cell fire activ model preserv similar probabilist quant al properti pitiform synaps rise probabilist postsynapt voltag level combin local patch inhibitori interneuron layer differenti select burst fire theta rhythm enabl distinct spatial pattern read rel background fire trial use physiolog rule induct yield stabl spatial fire pattern learn multipl simul input pattern share mani chemic give rise bulb fire activ mani share later olfactori axon innerv layer ia pitiform turn yield highli excitatori enabl spatial preserv overlap among similar enhanc learn process caus stronger cell yield afterhyperpolar local inhibitori interneuron select altern cell fire cell undergon altern cell activ recurr distinct popul synaps caudal layer potenti synaps combin lot axon select enhanc respons cell tend accentu differ among even test comput simul shown spatial layer ii cell fire respons similar cue enhanc similar overlap respons equal greater overlap research support part naval grant nation scienc foundat grant american institut physic cell fire two cue overlap give rise respons overlap later cell fire pattern increasingli enhanc differ among even input overlap give rise output respons overlap less respons measur respect sinc overlap reduc near zero respons enabl structur even properli view partit map input onto respons pattern categori therefor use statist metric inform valu categor measur valu produc pitiform simul three primari dimens along network process model vari perform rule architectur rule much across differ usual variant rule output calcul function input multipli perfornx rule usual rule unit output rule output converg solut learn rule variant loos base perceptron rule adalin rule gener delta rule rumelhart architectur vari larg learn feedforward net requir gener delta rule bidirect usual impli variant hebbian correl learn perform rule typic arriv reason conveni comput properti analyt rule sometim base part result borrow network model intend correspond loos notion parallel distribut process base deriv neural open question much rest rich literatur neurobiolog could profit incorpor network view construct mechan perform certain computaton vari answer goal understand brain circuit function introduc fundament function given cortic construct studi model particular brain olfactori strictli base biolog goal elucid local function circuit perforin measur progress accuraci model known predict novel physiolog result lynch lynch et initi analysi circuit reveal mechan consist learn rule notabl simpl restrict compar network rel architectur unusu perform rule complex compar typic perform taken deriv directli known biolog olfactori coher mechan interest comput describ learn perform rule architectur physiolog anatomi underli rule analysi coher mechan rule deriv potenti potenti synaps phenomenon brief seri biochem event give rise enhanc synapt efficaci lynch staubli therefor candid mechan underli certain form trial requir physiolog ltp form basi straightforward network learn known simultan activ intens result ltp zm et sinc excitatori cell embed meshwork inhibitori requisit induct adequ level postsynapt activ achiev stimul larg number affer prolong voltag clamp postsynapt chemic activ inhibitori intact question simultan postsynapt activ induc open recent work shown hippocamp subject pattern stimul particular tempor frequenc inhibit natur elimin within specif time ltp aris figur show ltp natur occur use short stimul interburst pair two burst caus occur normal inhibitori current prevent first burst depolar cell suffici produc maxim refractori although second burst arriv background result long hyperpolar current initi second burst initi sinc studi lead conclus perform vitro hippocamp ltp induc pattern stimul techniqu intact anim show decrement prior time record arrang month case staubli rule deriv physiolog behavior data may infer ltp depend simultan hebb suffici degre latter occur particular condit suggest perform rule draw requir review inhibitori current activ hippocampu pitiform three class current known short long lhp extrem ahp figur short ipsp aris feedback activ inhibitori interneuron turn synaps excitatori cell layer ii primari excitatori cell ps develop slowli excitatori postsynapt potenti quickli thu revers depolar aris bring cell voltag origin rest ipsp last approxim enter refractori period can not reactiv longer hyperpolar presum depend distinct type inhibitori interneuron inhibitori aris much cell appar lhp last ipsp lhp constitut form frequenc input subsequ input arriv background due yet input initi ipsp due refractori input singl epsp fail trigger sinc abl overcom hyperpolar yet input puls compris burst give rise differ first epsp would back rest potentialbi accompani second puls could ipsp first epsp driven rapidli rest second puls sum rais voltag postsynapt cell allow channel therebi caus spike henc fire singl puls burst would cell activ synaps third inhibitori current caus excitatori cell becom refractori fire strongli mechan therefor cell unlik first two ahp prevent cell fire long long observ eeg wave hippocampi learn anim theta activ occur seen correspond optim rate fire postsynapt cell enhanc synaps rhythmic aspect perform rule network suggest physiolog result activ pattern may take follow synchron cell fire occur approxim everi spatial induc activ occur rate one new spatial pattern cell strongli particip one fire pattern subsequ pattern least next rais interest possibl differ spatial pattern may convey differ inform cell fire puls burst depend sum activ axon fire synchron across cell rise spatial pattern activ across cell fire fire subsequ pattern theta everi therefor consist extrem differ spatial cell henc network sequenc spatial anim engag olfactori discrimin learn theta rhythm anim anim liter sniff sustitut direct stimul later olfactori tract input olfactori learn discrimbt either electr odor stimul real behavior learn paradigm accompani ltp pitiform synaps et experiment paradigm thu provid us known set olfactori cortex give rise synapt potenti appar learnlng olfactori cortex receptor cell respond differenti differ cell innerv olfactori arrang combin spatial bulb characterist respond specif bulb also number centrifug affer termin granul excitatori mitral cell bulb send axon fornx later olfactori tract constitut major input olfactori cortex turn feedback connect bulb via olfactori illustr anatomi superfici layer olfactori axon flow across layer synaps dendrit pitiform cell turn give rise collater axon output layer parallel subjac predominantli eventu entorhin layer ia spars probabl synaps lot axon cell dendrit less decreas layer ib collater synaps densiti increas number collater connect densiti dendrit approxim constant layer ii also addit princip excitatori cell inhibitori interneuron synaps excitatori cell within form cell affect particular inhibitori sphere influenc inhibitori cell almost certainli overlap lot pitiform layer much smaller inhibitori cell divid layer ii roughli function luskin krettek price layer ii cell collater axon flow layer distanc rise layer ib taken combin predominantli caudal mean rostral pitiform domin extrem caudal pitiform later entorhin domin collater rostral move rostral caudal cell thought cell receiv input rostral pitiform collater architectur rostral pitiform therefor quit differ caudal differenti analysi must perform rostral cell hybrid later formal introduct conduct sever simul olfactori cortex incorpor mani physiolog featur discuss two hundr layer cell use input line collater lot collater axon lot axon connect rostral dendrit probabl decreas linearli caudal end connect subject constraint number contact axon fix within certain narrow boundari sever axon synaps dendrit receiv result matrix thu simul inhibitori layer cell arrang overlap within one inldbitori inhibit rule approxim discuss short ipsp longer epsp one fifth length ahp turn twice long activ model probabilist presynapt fix probabl synaps allow certain amount conduct contribut postsynapt potenti repres increas contact well increas conduct effect would expect modifi exist synaps well ad new one result obtain electron microscop studi et excitatori synaps subject ltp occur cell activ twice first input synaps subsequ input drive past threshold follow physiolog potenti synaps much less differ synaps high frequenc lynch et simul use theta burst burst puls burst occur input oper accord synchron fix time discuss network train set repres group activ lot experi alreadi usual four use compon consist contigu lot assum bulb normal output signal lot specif bulb rule use particular inhibit assum greatest area surround activ bulb network exhibit sever interest robust respons specif thu ad subtract line previous learn input within greatli chang like network dealt reason well noisi known unexpect result develop network success experi simul would begin two quit distinct output signal within given sampl previous learn cue would gener two success respons success first respons pattern prove common sever signal second specif learn signal found occur network learn input substanti overlap compon four odor share appear network begun produc first sniff simul respons subsequ sniff present cue contain element share previous learn produc cluster respons subsequ individu specif output four five cluster respons pattern individu respons network without clear model accomplish two necessari oppos detect similar member cue categori nonetheless distinguish cue quit respons categori second specif set input cue differ fire dx lot input input differ input set differ xs ys form distinct natur perform network give rise output fire pattern similar member either differ member differ singl spatial pattern respons member littl respons across distinct spatial pattern member matrix construct uniform select distribut bidimension matrix describ follow result valu ham distanc respons two input cue differ lot line ham distanc number postsynapt probabl cell precis activ contact one two probabl number contact cell increas chang lot chang first cue term denot probabl cell decreas number activ contact cell fire respons one cue therefor one cell contribut differ two second term probabl increas number activ synaps also contribut differ restrict analysi rostral assum collater return issu next valu probabl activ contact sinc fix number contact anatom lot phiform activ number lot number activ lot number synaps per dendrit form number activ formula read note first binomi indic number way choos activ synaps dendrit activ lot next express calcul number remain synaps dendrit chosen inact incom lot probabl activ synaps dendrit spars matrix probabl connect lot line solut must normal number way synaps dendrit chosen incom lot probabl cell chang number contact reduct number activ gain henc left express probabl activ synaps chang lot express gain activ product express suxnm way choos net chang desir train cue induc fraction synaps overlap part input cue becom stronger uniqu part compar two cue within two cue may number activ synaps across two cue either expect strength synaps lost former case significantli lower latter case given differ output fire smaller two cue cue two differ import note cluster oper quit distinct observ object car occur previous learn instead categori emerg learn mani differ car may base necessari correspond real could said produc categor respons one cue learn second similar stimulu categori cluster learn sever exemplar process extract common environ defin simpl similar two essenti question cluster concern locat boundari given degre similar must set cue possess group issu discuss number theoret posit inform analys incorpor point breadth categori must overal homogen heterogen world quit use categori necessarili compos object subject present set distinct coffe cup differ ask later recal might respond list cup yellow green coffe rel specif level descript hierarchi object present four differ blue coffe silver fork plastic cup would much like recal simpli coffe rare blue coffe encod chosen depend overal heterogen categori lornt simul quit appropri judg theoret well across wide rang possibl problem aris caudal axon flow anatom featur direct flow collater axon give rise immedi rostral cell fire respons activ input cell caudal via collater probabl caudal cell fire increas precipit probabl cell reduc number rostral cell either reduc number activ input lot axon rais layer ii cell fire prevent suffici input caudal cell enabl probabl much problem state make assumpt detail connect lot collater axon layer axon proceed rostral caudal probabl contact lot axon dendrit decreas number collater axon rostral caudal flow situat depict figur probabl lot contact tend go may adopt label axon synapt combin lot axon collater axon contact particular layer ii cell dendrit sourc addit collater axon flow cell caudal cell fire function layer cell za denot lot axon activ axon still nonzero probabl contact layer cell hm denot activ layer cell rostral cell fire synapt strength axon dendrit heavisid step equal accord whether argument posit assum instead probabl cell fire grade rather step may elimin step function calcul fire cell,1
36,36,"338 
The Connectivity Analysis of Simple Association 
How Many Connections Do You Need? 
Dan Hammerstrom * 
Oregon Graduate Center, Beaverton, OR 97006 
ABSTRACT 
The efficient realization, using current silicon technology, of Very Large Connection 
Networks (VLCN) with more than a billion connections requires that these networks exhibit 
a high degree of communication locMity. Real neural networks exhibi't significant locality, 
yet most connectionist/neurM network models have little. In this paper, the connectivity 
requirements of a simple associative network are analyzed using communication theory. 
Several techniques based on communication theory are presented that improve the robust- 
ness of the network in the face of sparse, local interconnect structures. Also discussed are 
some potential problems when information is distributed too widely. 
INTRODUCTION 
Connectionist/neural network researchers are learning to program networks that exhi- 
bit a broad range of cognitive behavior. Unfortunately, existing computer systems are lim- 
ited in their ability to emulate such networks efficiently. The cost of emulating a network, 
whether with special purpose, highly parallel, silicon-based architectures, or with traditional 
parallel architectures, is directly proportional to the number of connections in the network. 
This number tends to increase geometrically as the number of nodes increases. Even with 
large, massively parallel architectures, connections take time and silicon area. Many exist- 
ing neural network models scale poorly in learning time and connections, precluding large 
implementations. 
The connectivity 'costs of a network are directly related to its locality. A network 
exhibits locality of communication 1 if most of its processing elements connect to other physi- 
cally adjacent processing elements in any reasonable mapping of the elements onto a planar 
surface. There is much evidence that real neural networks exhibit locality 2 . In this paper, 
a technique is presented for analyzing the effects of locality on the process of association. 
These networks use a complex node similar to the higher-order learning units of Maxwell et 
al. 3 
NETWORK MODEL 
The network model used in this paper is now defined (see Figure 1). 
Definition 1: A recursive neural network, called a c-graph is 
F( V,E, C), where: 
� 
a graph structure, 
There is a set of CNs (network nodes), V, whose outputs can take a range of positive 
real values, vi, between 0 and 1. There are N nodes in the set. 
There is a set of codohs, E, that can take a range of positive real values, eii (for 
codon ] of node i), between 0 and 1. There are N� codons dedicated to each CN (the 
output of each codon is only used by its local CN), so there are a total of N� N codohs 
in the network. The fan-in or order of a codon is re. It is assumed that f� is the 
same for each codon, and N� is the same for each CN. 
*This work was supported in part by the Semiconductor Research Corporation contract no. 86-10-097, and 
jointly by the Office of Naval Research and Air Force Office of Scientific Research, ONR contract no. N00014 87 K 
0259. 
� American Institute of Physics 1988 
339 
f� i codon 
v 
Figure 1 - A CN 
� ciik 6 C is a set of connections of CNs to codons, l<i,k_<N, and i<_j<_N�, ciik can 
take two values {0,1} indicating the existence of a connection from CN k to codon j 
of CN i. [] 
Definition �: The value of CN i is 
v, = F 0+e// (1) 
The function, F, is a continuous non-linear, monotonic function, such as the sigmoid func- 
tion. [] 
Definition 3: Define a mapping, D(i,j,T)--*', where T is an input vector to F and ' is 
the f� element input vector of codon j of CN i. That is, ' has as its elements those ele- 
ments of x} of  where cii}=l , V k. [] 
The D function indicates the subset of  seen by codon j of CN i. Different input vec- 
tors may map to the same codon vectors, e.g., D(i,j,T)--* and D(i,j,z--., where TT. 
Definition 6: The codon values e�i are determined as follows. Let -rn) be input vector 
m of the M learned input vectors for CN i. For codon eii of CN i, let Tq be the set of f�- 
dimensional vectors such that Tii(m)ETii , and D(i,j,-m))-.Tq(m). That is, each vector, 
Tq(m) in Tq consists of those subvectors of -rn) that are in codon ij's receptive field. 
The variable I indexes the L(i,]) vectors of Tii. The number of distinct vectors in 
may be less than the total number of learned vectors (L(i,j)_<M). Though the -rn) are 
distinct, the subsets, Tii(rn), need not be, since there is a possible many to one mapping of 
the T vectors onto each vector 
Let X 1 be the subset of vectors where vi=l (CN i is supposed to output a 1), and X � be 
those vectors where vl--O , then define 
n.(/) = size_of{D(i,j,x-m))st vi=q} (2) 
for q=0,1, and t m that map to this I. That is, %�.(l) is the number of ' vectors that map 
340 
into 'q(!) where v�-0 and ni.(/) is the number of Y vectors that map into '/j(l), where vi---1. 
The compression of a codon for a vector'q(l) then is defined as 
= (s) 
(HCq(!)O when both n , n�=0.) The output of codon ij, q, is the maximum-likelyhd 
decoding 
= (4) 
ere HC indicates the likelyhd of vi=l when  vector Y that mps to g is input, nd g 
is that vector g) where min[d(g),] V l, D(i,j,)y, nd Y is the current input vec- 
tor.  other words, g is that vector (of the set of subset learned vectors that codon ij 
receives) that is closest (using distance measure d) to  (the subset input vector). n 
The output of  eodon is the ""most-likely"" output ccording to its inputs. For exm- 
pie, when there is no code compreion t  codon, ff=l, if the ""closest"" (in ter of some 
measure of vector distance, e.g. Hmming distance) subvector in the receptive field of the 
eodon belongs to  learned vector where the CN is to output  1. The codons described here 
re ve similar to those propped by Marr 4 and implement nearest-neighbor classification. 
It is umed that eodon function is determined stticlly prior to network operation, that 
is, the desired ctegofies hve lredy been learned. 
To measure performance, network epacity is used. 
Definition 5: The input noie, fl, is the verge d between n input vector nd the 
eldest (nimum d) learned vector, where d is  measure of the ""difference"" between two 
vectors - for bit vectors this cn be Hmming distance. The output nois, flo, is the verge 
distance between network output nd the learned output vector ssocited with the closest 
learned input vector. The information gain, G, is just 
Definition 6: The capacity of a network is the maximum number of learned vectors such 
that the information gain, Gi, is strictly positive (0). [] 
COMMUNICATION ANALOGY 
Consider a single connection network node, or CN. (The remainder of this paper will 
be restricted to a single CN.) Assume that the CN output value space is restricted to two 
values, 0 and 1. Therefore, the CN must decide whether the input it sees belongs to the 
class of ""0"" codes, those codes for which it remains off, or the class of ""1"" codes, those codes 
for which it becomes active. The inputs it sees in its receptive field constitute a subset of 
the input vectors (the D(...) function) to the network. It is also assumed that the CN is an 
ideal 1-NN (Nearest Neighbor) classifier or feature detector. That is, given a particular set 
of learned vectors, the CN will classify an arbitrary input according to the class of the 
nearest (using d h as a measure of distance) learned vector. This situation is equivalent to 
the case where a single CN has a single codon whose receptive field size is equivalent to that 
of the CN. 
Imagine a sender who wishes to send one bit of information over a noisy channel. The 
sender has a probabilistic encoder that choses a code word (learned vector) according to 
some probability distribution. The receiver knows this code set, though it has no knowledge 
of which bit is being sent. Noise is added to the code word during its transmission over the 
341 
channel, which is analogous to applying an input vector to a network's inputs, where the 
vector lies within some learned vector's region. The ""noise"" is represented by the distance 
(dh) between the input vector and the associated learned vector. 
The code word sent over the channel consists of those bits that are seen in the recep- 
tive field of the CN being modeled. In the associative mapping of input vectors to output 
vectors, each CN must respond with the appropriate output (0 or 1) for the associated 
learned output vector. Therefore, a CN is a decoder that estimates in which class the 
received code word belongs. This is a classic block encoding problem, where increasing the 
field size is equivalent to increasing code length. As the receptive field size increases, the 
performance of the decoder improves in the presence of noise. Using communication theory 
then, the trade-off between interconnection costs as they relate to field size and the func- 
tionality of a node as it relates to the correctness of its decision making process (output 
errors) can be characterized. 
As the receptive field size of a node increases, so does the redundancy of the input, 
though this is dependent on the particular codes being used for the learned vectors, since 
there are situations where increasing the field size provides no additional information. 
There is a point of diminishing returns, where each additional bit provides ever less reduc- 
tion in output error. Another factor is that interconnection costs increase exponentially 
with field size. The result of these two trends is a cost performance measure that has a sin- 
gle global maximum value. In other words, given a set of learned vectors and their proba- 
bilities, and a set of interconnection costs, a ""best"" receptive field size can be determined, 
beyond which, increasing connectivity brings diminishing returns. 
SINGLE CODON, WITH NO CODE COMPRESSION 
A single neural element with a single codon and with no code compression can be 
modelled exactly as a communication channel (see Figure 2). Each network node is assumed 
to have a single codon whose receptive field size is equal to that of the receptive field size of 
the node. 
noisy  
sender receiver 
encoder transmitter receiver 
decoder 
CN 
Figure 2 - A Transmission Channel 
342 
The operation of the channel is as follows. A bit is input into the channel encoder, 
which selects a random code of length N and transmits that code over the channel The 
receiver then, using nearest neighbor classification, decides if the original message was either 
a0oral. 
Let M be the number of code words used by the encoder. The rate* then indicates the 
density of the code space. 
Definition 7: The rate, R, of a communication channel is 
1oM 
R -- N (6) 
The block length, N, corresponds directly to the receptive field size of the codon, i.e., 
N=f�. The derivations in later sections use a related measure: 
Definition 8: The code utilization, b, is the number of learned vectors assigned to a par- 
ticular code or 
M 
b ----- 2N (7) 
b can be written in terms of R 
b = 2N(R-) (S) 
As b approaches 1, code compression increases. b is essentially unbounded, since M may be 
significantly larger than 2 N. [] 
The decode error (information loss) due to code compression is a random variable that 
depends on the compression rate and the a priori probabilities, therefore, it will be different 
with different learned vector sets and codons within a set. As the average code utilization 
for all codons approaches 1, code compression occurs more often and codon decode error is 
unavoidable. 
Let  be the vector output of the encoder, and the input to the channel, where each 
element of // is either a 1 or 0. Let  be the vector output of the channel, and the input to 
the decoder, where each element is either a 1 or a 0. The Noisy Channel Coding Theorem is 
now presented for a general case, where the individual M input codes are to be dis- 
tinguished. The result is then extended to a CN, where, even though M input codes are 
used, the CN need only distinguish those codes where it must output a 1 from those where it 
must output a 0. The theorem is from Gallager (5.6.1) 5 . Random codes are assumed 
throughout. 
Theorem i: Let a discrete memoryless channel have transition probabilities P(j/k) 
and, for any positive integer N and positive number R, consider the ensemble of (N,R) 
block codes in which each letter of each code word is independently selected according to 
the probability assignment Q(k). Then, for each message m, lm[eR], and all p, 
0_p_l, the ensemble average probability of decoding error using maximum-likelyhood 
decoding satisfies 
where 
*In the definitions given here and the theorems below, the notation of Ga]]ager 5 is used. Many of the 
definitions and theorems are also from Gallager. 
343 
k P 
Q() (Y/ 
(lO) 
These results are now adjusted for our special case. 
Theorem 2: For a single CN, the average channel error rate for random code vectors is 
P�_<2q(1-q )t.m (11) 
where q=Q(k) V k is the probability of an input vector bit being a 1. 121 
These results cover a wide range of models. A more easily computable expression can 
be derived by recognizing some of the restrictions inherent in the CN model. First, assume 
that all channel code bits are equally likely, that is,  k, Q(k)--q, that the error model is 
the Binary Symmetric Channel (BSC), and that the errors are identically distributed and 
independent -- that is, each bit has the same probability, e, of being in error, independent 
of the code word and the bit position in the code word. 
A simplified version of the above theorem can be derived. Maximizing p gives the 
tightest bounds: 
Pc, < 0.5 max?(p) (12 
-- 0_p< 
where (letting codon input be the block length, N=f�) 
lz(p) _ exp{-f �[Eo(p)-pR] } (13) 
The minimum value of this expression is obtained when p=l (for q=0.5): 
E o = --log 2 0.5N/-+0.5 (14) 
SINGLE-CODON WITH CODE COMPRESSION 
Unfortunately, the implementation complexity of a codon grows exponentially with the 
size of the codon, which limits its practical size. An alternative is to approximate single 
codon function of a single CN with many smaller, overlapped codohs. The goal is to main- 
tain performance and reduce implementation costs, thus improving the cost/performance of 
the decoding process. As codohs get smaller, the receptive field size becomes smaller relative 
to the number of CNs in the network. When this happens there is codon compression, or 
vector aliasing, that introduces its own errors into the decoding process due to information 
loss. Networks can overcome this error by using multiple redundant codohs (with overlap- 
ping receptive fields) that tend to correct the compression error. 
Compression occurs when two code words requiring different decoder output share the 
same representation (within the receptive field of the codon). The following theorem gives 
the probability of incorrect codon output with and without compression error. 
Theorem 3: For a BSC model where q=0.5, the codon receptive field is re, the code util- 
ization is b, and the channel bits are selected randomly and independently, the probability 
of a codon decoding error when b>l is approximately 
Pc,,, --< (1-e)/:r�- [1-(1-6)1'] 0.5 (15) 
where the expected compression error per eodon is approximated by 
344 
� = 0.5- 2'X/bq(1-q) 
nd from equations 13-14, when b<l 
Proof is given in Hmmerstrom � . [] 
As b grows, � approaches 0.5 sympoically. Thus, he performance of a single codon 
degrades rapidly in the presence of even small amounts of compreion. 
MULTIPLE CODONS WITH CODE COMPRESSION 
The use of multiple small codons is more efficient thn a few large codons, but there 
are some fundamental performance constraints. When a codon is split into two or more 
smaller codohs (and the original receptive field is subdivided accordingly), there are several 
effects to be considered. First, the error rate of each new codon increases due to a decrease 
in receptive field size (the codoh'S block code length). The second effec is ha the code 
uilizaion, b, will increase for each codon, since he same number of learned vectors is 
mapped ino a smaller receptive field. This change al increases he error rae per codon 
due o code compreion. In fc, as he individual codon receptive fields ge smaller, 
significan code compreion occurs. For higher-order inpu codes, here is an added error 
tha occurs when he order of he individual codohs is decreased (since random codes are 
being umed, his effec is no considered here). The hird effec is he ma action of 
large numbers of codons. Even hough individual codohs may be in error, if he majority 
are correct, hen he CN will have correc output. This effec decreases he oal error rae. 
ume ha ech CN hs more han one codon, c 1. The union of he receptive fields 
for hese codohs is the receptive field for he CN wih no no restrictions on he degree of 
overlap of he vrious codon receptive fields within or between CNs. For a CN wih a large 
number of codohs, he codon overlap will generally be random and uniformly distributed. 
 assume ha he ransion errors seen by differen receptive fields are independent. 
Now consider wha happens o a codon's compreion error rae (ignoring ransmission 
error for he ime being) when a codon is replaced by wo or more smaller codohs covering 
he same receptive field. This replacemen process cn continue until here are only 1- 
codohs, which, incidenMly, is analogous o mos curren neural models. For  multiple 
codon CN, aume ha each codon voes a I or 0. The summation uni hen otals his 
information and outputs a I if he majority of codohs voe for a 1, ec. 
Theorem 4: The probability of a CN error due o compreion error is 
f 
V(-) 
where  is given in equation 16 and q=0.5. 
P incorporates the wo effects of moving o multiple smaller codohs and adding more 
codohs. Using equation 17 gives he oal error probability (per bi), Po: 
Pon= P,+P-P,P (19) 
Prf i in Hmmerrom  .  
345 
For networks that perform association as defined in this paper, the connection weights 
rapidly approach a single uniform value as the size of the network grows. In information 
theoretic terms, the information content of those weights approaches zero as the compres- 
sion increases. Why then do simple non-conjunctive networks (1-codon equivalent) work at 
all? In the next section I define connectivity cost constraints and show that the answer to 
the first question is that the general associative structures defined here do not scale cost- 
effectively and more importantly that there are limits to the degree of distribution of infor- 
mation. 
CONNECTIVITY COSTS 
It is much easier to assess costs if some implementation medium is assumed. I have 
chosen standard silicon, which is a two dimensional surface where CN's and codohs take up 
surface area according to their receptive field sizes. In addition, there is area devoted to 
the metal lines that interconnect the CNs. A specific VLSI technology need not be assumed, 
since the comparisons are relative, thus keeping CNs, codohs, and metal in the proper pro- 
portions, according to a standard metal width, m (which also includes the inter-metal 
pitch). For the analyses performed here, it is assumed that m e levels of metal are possible. 
In the previous section I established the relationship of network performance, in terms 
of the transmission error rate, , and the network capacity, M. In this section I present an 
implementation cost, which is total silicon area, A. This figure can then be used to derive a 
cost/performance figure that can be used to compare such factors as codon size and recep- 
tive field size. There are two components to the total area: AcN , the area of a CN, and 
AMi , the area of the metal interconnect between CNs. AcN consists of the silicon area 
requirements of the codons for all CNs. The metal area for local, intra-CN interconnect is 
considered to be much smaller than that of the codohs themselves and of that of the more 
global, inter-CN interconnect, and is not considered here. The area per CN is roughly 
AN-- cLmc(--, ) 2 (20) 
where me is the maximum number of vectors that each codon must distinguish, for b_l, 
me = 2 
Theorem 5: Assume a rectangular, unbounded* grid of CNs (all CNs are equi-distant 
from their four nearest neighbors), where each CN has a bounded receptive field of its 
cf� 
nearest CNs, where nc v is the receptive field size for the CN, nc v - R ' where c is the 
number of codons, and R is the intra-CN redundancy, that is, the ratio of inputs to 
synapses (e.g., when R=I each CN input is used once at the CN, when R--2 each input is 
used on the average at two sites). The metal area required to support each CN's receptive 
field 
is (proof is giving by Hammerstrom ): 
m. 
AM! = '--""--+ 2 '+9nCN2 
The total area per CN, A, then is 
*Another implementation strategy is to place all CNs along a diagonal, which gives n 2 area. However, this 
technique only works for a bounded number of CNs and when dendritic computation can be spread over a large 
area, which limits the range of possible CN implementations. The theorem stated here covers an infinite plane of 
CNs each with a bounded receptive field. 
346 
A -- (AMi+AcN) = O(nN ) (22) 
Even with the assumption of maximum locality, the total metal interconnect area 
increases as the cube of the per CN receptive field size! 
SINGLE CN SIMULATION 
What do the bounds tell us about CN connectivity requirements? From simulations, 
increasing the CN's receptive field size improves the performance (increases capacity), but 
there is also an increasing cost, which increases faster than the performance! Another 
observation is that redundancy is quite effective as a means for increasing the effectiveness 
of a CN with constrained connectivity. (There are some limits to R, since it can reach a 
point where the intra-CN connectivity approaches that of inter-CN for some situations.) 
With a fixed ncv, increasing cost-effectiveness (A/m) is possible by increasing both order 
and redundancy. 
In order to verify the derived bounds, I also wrote a discrete event simulation of a CN, 
where a random set of learned vectors were chosen and the CN's codohs were programmed 
according to the model presented earlier. Learned vectors were chosen randomly and sub- 
jected to random noise, e. The CN then attempted to categorize these inputs into two 
major groups (CN output = I and CN output = 0). For the most part the analytic bounds 
agreed with the simulation, though they tended to be optimistic in slightly underestimating 
the error. These differences can be easily explained by the simplifying assumptions that 
were made to make the analytic bounds mathematically tractable. 
DISTRIBUTED �S. LOCALIZED 
Throughout this paper, it has been tacitly assumed that representations are distributed 
across a number of CNs, and that any single CN participates in a number of representa- 
tions. In a local representation each CN represents a single concept or feature. It is the dis- 
tribution of representation that makes the CN's decode job difficult, since it is the cause of 
the code compression problem. 
There has been much debate in the connectionist/neuromodelling community as to the 
advantages and disadvantages of each approach; the interested reader is referred to Hin- 
ton ? , Baum et al. s, and Ballard 9 . Some of the results derived here are relevant to this 
debate. As the distribution of representation increases, the compression per CN increases 
accordingly. It was shown above that the mean error in a codoh's response quickly 
approaches 0.5, independent of the input noise. This result also holds at the CN level. For 
each individual CN, this error can be offset by adding more codohs, but this is expensive 
and tends to obviate one of the arguments in favor of distributed representations, that is, 
the multi-use advantage, where fewer CNs are needed because of more complex, redundant 
encodings. As the degree of distribution increases, the required connectivity and the code 
compression increases, so the added information that each codon adds to its CN's decoding 
process goes to zero (equivalent to all weights approaching a uniform value). 
SUMMARY AND CONCLUSIONS 
In this paper a single CN (node) performance model was developed that was based on 
Communication Theory. Likewise, an implementation cost model was derived. 
The communication mode] introduced the codon as a higher-order decoding element 
and showed that for small codons (much less than total CN fan-in, or convergence) code 
compression, or vector aliasing, within the codon's receptive field is a severe problem for 
347 
large networks. As code compression increases, the information added by any individual 
codon to the CN's decoding task rapidly approaches zero. 
The cost model showed that for 2-dimensional silicon, the area required for inter-node 
metal connectivity grows as the cube of a CN's fan-in. 
The combination of these two trends indicates that past a certain point, which is 
highly dependent on the probability structure of the learned vector space, increasing the 
fan-in of a CN (as is done, for example, when the distribution of representation is increased) 
yields diminishing returns in terms of total cost-performance. Though the rate of diminish- 
ing returns can be decreased by the use of redundant, higher-order connections. 
The next step is to apply these techniques to ensembles of nodes (CNs) operating in a 
competitive learning or feature extraction environment. 
[3] 
[4] 
[5] 
[9] 
REFERENCES 
J. Bailey, ""A VLSI Interconnect Structure for Neural Networks,"" Ph.D. 
Dissertation, Department of Computer Science/Engineering, OGC. In Preparation. 
V. B. Mountcastle, ""An Organizing Principle for Cerebral Function: The Unit 
Module and the Distributed System,"" in The Mindful Brain, MIT Press, Cambridge, 
M_A, 1977. 
T. Maxwell, C. L. Giles, Y. C. Lee and H. H. Chen, ""Transformation Invariance 
Using High Order Correlations in Neural Net Architectures,"" Proceedings 
International Conf. on Systems, Man, and Cybernetics, 1986. 
D. Marr, ""A Theory for Cerebral Neocortex,"" Proc. Roy. Soc. London, vol. 
176(1970), pp. 161-234. 
R. G. Gallager, Information Theory and Reliable Communication, John Wiley and 
Sons, New York, 1968. 
D. Hammerstrom, ""A Connectivity Analysis of Recursice, Auto-Associative 
Connection Networks,"" Tech. Report CS/E-86-009, Dept. of Computer 
Science/Engineering, Oregon Graduate Center, Beaverton, Oregon, August 1986. 
G. E. Hinton, ""Distributed Representations,"" Technical Report CMU-CS-84-157, 
Computer Science Dept., Carnegie-Mellon University, Pittsburgh, PA 15213, 1984. 
E. B. Baum, J. Moody and F. Wilczek, ""Internal Representations for Associative 
Memory,"" Technical Report NSF-ITP-86-138, Institute for Theoretical Physics, 
Santa Barbara, CA, 1986. 
D. H. Ballard, ""Cortical Connections and Parallel Processing: Structure and 
Function,"" Technical Report 133, Computer Science Department, Rochester, NY, 
January 1985. 
", connect analysi simpl associ mani connect graduat effici use current silicon larg connect billion connect requir network exhibit high degre commun real neural network signific network model connect simpl associ network analyz use commun techniqu base commun theori present improv network face local interconnect also discuss potenti problem inform distribut network research learn program network broad rang cognit exist comput system abil emul network cost emul special highli tradit directli proport number connect number tend increas geometr number node even massiv parallel connect take time silicon mani neural network model scale poorli learn time preclud larg connect network directli relat network local commun process element connect adjac process element reason map element onto planar much evid real neural network exhibit local techniqu present analyz effect local process network use complex node similar learn unit maxwel et model network model use paper defin figur recurs neural call graph set cn whose output take rang posit node set take rang posit real eii node codon dedic cn codon use local total codoh order codon assum work support part semiconductor research corpor contract offic naval research air forc offic scientif onr contract american institut physic codon cn ciik set connect cn ciik two valu indic exist connect cn codon cn valu cn continu monoton sigmoid defin input vector element input vector codon cn element function indic subset seen codon cn differ input may map codon codon valu determin let input vector learn input vector cn codon eii cn let tq set vector tq consist subvector codon recept variabl index vector number distinct vector less total number learn vector though need sinc possibl mani one map vector onto vector subset vector suppos output vector defin map number vector map number vector map compress codon defin output codon hc indic vector vector current input vector set subset learn vector codon ij closest distanc measur subset input output eodon output code vector subvector recept field belong learn vector cn output codon describ similar prop marr implement eodon function determin prior network desir measur network input input vector learn measur two bit vector output network output learn output vector closest input inform capac network maximum number learn vector inform strictli posit analog singl connect network remaind paper restrict singl assum cn output valu space restrict two cn must decid whether input see belong code remain class code becom input see recept field constitut subset input vector also assum cn classifi featur given particular set learn cn classifi arbitrari input accord class measur learn situat equival case singl cn singl codon whose recept field size equival sender wish send one bit inform noisi probabilist encod chose code word accord probabl receiv know code though knowledg bit nois ad code word transmiss analog appli input vector lie within learn repres distanc input vector associ learn code word sent channel consist bit seen field cn associ map input vector output cn must respond appropri output associ output cn decod estim class code word classic block encod increas size equival increas code recept field size decod improv presenc use commun theori interconnect cost relat field size node relat correct decis make process recept field size node redund depend particular code use learn sinc situat increas field size provid addit point diminish addit bit provid ever less output anoth factor interconnect cost increas exponenti field result two trend cost perform measur global maximum given set learn vector set interconnect recept field size increas connect bring diminish code compress singl neural element singl codon code compress exactli commun channel figur network node assum singl codon whose recept field size equal recept field size receiv transmitt receiv transmiss channel oper channel bit input channel select random code length transmit code channel use nearest neighbor decid origin messag either number code word use indic code commun channel block correspond directli recept field size deriv later section use relat code number learn vector assign code written term approach code compress essenti sinc may larger decod error due code compress random variabl compress rate priori differ differ learn vector set codon within averag code util codon approach code compress occur often codon decod error vector output input either let vector output input element either noisi channel code theorem present gener individu input code result extend even though input code cn need distinguish code must output output theorem gallag random code assum let discret memoryless channel transit probabl posit integ posit number consid ensembl code letter code word independ select accord probabl assign messag ensembl averag probabl decod error use satisfi definit given theorem notat mani theorem also result adjust special singl averag channel error rate random code vector probabl input vector bit result cover wide rang easili comput express deriv recogn restrict inher cn assum channel code bit equal error model binari symmetr channel error ident distribut bit independ code word bit posit code simplifi version theorem maxim give codon input block minimum valu express obtain code compress implement complex codon grow exponenti limit practic altern approxim singl function singl cn mani overlap goal perform reduc implement thu improv decod codoh get recept field size becom smaller rel number cn happen codon introduc error decod process due inform network overcom error use multipl redund codoh recept tend correct compress occur two code word requir differ decod output share represent recept field follow theorem give probabl incorrect codon output without compress bsc model codon recept field code channel bit select randomli probabl codon decod error approxim expect compress error per eodon approxim equat given approach perform singl codon rapidli presenc even small amount codon code compress use multipl small codon effici larg fundament perform codon split two codoh origin recept field subdivid sever error rate new codon increas due decreas recept field size block code second code increas sinc number learn vector smaller recept chang increas error per codon code individu codon recept field code ad error occur order individu codoh decreas random code consid action number even individu codoh may major cn decreas error cn one union recept field codoh recept field cn restrict degre codon recept field within cn larg codon overlap gener random uniformli assum error seen recept field consid happen error codon replac smaller codoh cover recept process continu analog neural multipl codon summat output major codoh probabl cn error due error given equat incorpor effect move multipl smaller codoh ad use equat give error probabl network perform associ defin connect weight approach singl uniform valu size network inform inform content weight approach zero simpl network work next section defin connect cost constraint show answer first question gener associ structur defin scale importantli limit degre distribut cost much easier assess cost implement medium standard two dimension surfac codoh take area accord recept field area devot metal line interconnect specif vlsi technolog need comparison thu keep metal proper accord standard metal also includ analys perform assum level metal previou section establish relationship network term transmiss error network section present total silicon figur use deriv figur use compar factor codon size field two compon total area area metal interconnect consist silicon area codon metal area interconnect much smaller codoh consid area per cn roughli maximum number vector codon must assum grid cn cn four nearest cn bound recept field recept field size ratio input cn input use input averag two metal area requir support recept give hammerstrom total area per anoth implement strategi place cn along give work bound number cn dendrit comput spread larg limit rang possibl cn theorem state cover infinit plane bound recept assumpt maximum total metal interconnect area cube per cn recept field cn simul bound tell us cn connect recept field size improv perform also increas increas faster anoth redund quit effect mean increas effect cn constrain limit sinc reach connect approach fix increas possibl increas order order verifi deriv also wrote discret event simul random set learn vector chosen codoh program model present learn vector chosen randomli random cn attempt categor input two group output cn output part analyt bound though tend optimist slightli underestim differ easili explain simplifi assumpt made make analyt bound mathemat local tacitli assum represent distribut number singl cn particip number local represent cn repres singl concept represent make decod job sinc caus code compress much debat commun disadvantag interest reader refer baum et ballard result deriv relev distribut represent compress per cn increas shown mean error respons quickli independ input result also hold cn individu error offset ad expens tend obviat one argument favor distribut fewer cn need redund degre distribut requir connect code ad inform codon add decod goe zero weight approach uniform conclus paper singl cn perform model develop base implement cost model commun introduc codon decod element show small codon less total cn code vector within recept field sever problem code compress inform ad individu decod task rapidli approach cost model show area requir connect grow cube combin two trend indic past certain depend probabl structur learn vector increas cn distribut represent diminish return term total though rate return decreas use next step appli techniqu ensembl node oper learn featur extract vlsi interconnect structur neural depart comput organ principl cerebr unit distribut mind mit lee invari high order correl neural net proceed theori cerebr inform theori reliabl john wiley new connect analysi report comput oregon graduat august technic report scienc pa moodi represent associ technic report institut theoret connect parallel structur technic report comput scienc,0
37,37,"348 
Minkowski-r Back-Propagation: Learning in Connectionist 
Models with Non-Euclidian Error Signals 
Stephen Jos6 Hanson and David J. Burr 
Bell Communications Research 
Morristown, New Jersey 07960 
Abstract 
Many connectionist learning models are implemented using a gradient descent 
in a least squares error function of the output and teacher signal. The present model 
generalizes, in particular, back-propagation [1] by using Minkowski-r power metrics. 
For small r's a ""city-block"" error metric is approximated and for large r's the 
""maximum"" or ""suprcmum"" metric is approached, while for r=2 the standard back- 
propagation model results. An implementation of Minkowski-r back-propagation is 
described, and several experiments are done which show that different values of r 
may be desirable for various purposes. Different r values may be appropriate for the 
reduction of the effects of outliers (noise), modeling the input space with more 
compact clusters, or modeling the statistics of a particular domain more naturally or 
in a way that may be more perccptually or psychologically meaningful (e.g. speech or 
vision). 
1. Introduction 
The recent resurgence of connectionist models can be traced to their ability to 
do complex modeling of an input domain. It can be shown that neural-like networks 
containing a single hidden layer of non-linear activation units can learn to do a 
piece-wise linear partitioning of a feature space [2]. One result of such a partitioning 
is a Complex gradient surface on which decisions about new input stimuli will be 
made. The generalization, categorization and clustering properties of the network arc 
therefore determined by this mapping of input stimuli to this gradient surface in the 
output space. This gradient surface is a function of the conditional probability 
distributions of the output vectors given the input feature vectors as well as a function 
of the error relating the teacher signal and output. 
349 
Presently many of the models have been implemented using least squares error. 
In  paper we describe a new model of gradient descent back-propagation [1] using 
Minkowski-r power error metrics. For small r's a ""city-block"" error measure (r=l) is 
approximated and for larger r's a ""maximum"" or supremum error measure is 
approached, while the standard case of Euclidian back-propagation is a special case 
with r=2. First we derive the general case and then discuss some of the implications 
of varying the power in the general metric. 
2. Derivation of Minkowski-r Back-propagation 
The standard back-propagation is derived by minimizing least squares error as 
a function of connection weights within a completely connected layered network. 
The error for the Euclidian case is (for a single input-output pair), 
1 
= (yi-i) 2. O) 
i 
where y is the activation of a unit and  represents an independent teacher signal. 
The activation of a unit 0') is typically computed by normalizing the input from other 
units (x) over the interval (0,1) while compressing the high and low end of this range. 
A common function used for this normalization is the logistic, 
1 
yi = (2) 
l+e- 
The input to a unit (x) is found by summing products of the weights and 
corresponding activations from other units, 
h 
where Yn represents units in the fan in of unit i and wa represents the strength of the 
connection between unit i and unit h. 
A gradient for the Euclidian or standard back-propagation case could be found 
by finding the partial of the error with respect to each weight, and can be expressed in 
this three term differential, 
350 
which from the equations before turns out to be, 
= O) 
Generalizing the error for Minkowski-r power metrics (see Figure 1 for the 
family of curves), 
r i 
Figure 1: Minkow$'-r Family 
Using equations 2-4 above with equation 6 we can easily find an expression for the 
gradient in the general Minkowski-r case, 
OE = ( l yi - i l )r-lyi(1-yi)y, sgn (Yi - i) (7) 
This gradient is used in the weight update role proposed by Rumelhart, Hinton and 
Williams [1], 
351 
wu.(n+l) = a i}"" + wai(n) 
(8) 
Since the gradient computed for the hidden layer is a function of the gradient for the 
output, the hidden layer weight updating proceeds in the same way as in the 
Euclidian case [1], simply substituting this new Minkowski-r gradient. 
It is also possible to define a gradient over r such that a minimum in error 
would be sought. Such a gradient was suggested by White [3, see also 4] for 
maximum likelihood estimation of r, and can be shown to be, 
dlog(E) = (1-1/r)(1/r) + (1/r)21og (r) + (l/r) 2(1/r) + (l/r) 2 lyi-il 
-( 1 / r )( I Yi - i I )r log ( I Yi - i I ) 
(9) 
An approximation of this gradient (using the last term of equation 9) has been 
implemented and investigated for simple problems and shown to be fairly robust in 
recovering similar r values. However, it is important that the r update rule changes 
slower than the weight update rule. In the simulations we ran r was changed once for 
every 10 times the weight values were changed. This rate might be expected to va-D' 
with the problem and rate of convergence. Local minima may be expected in larger 
problems while seeking an optimal r. It may be more informative for the moment to 
examine different classes of problems with fixed r and consider the specific rationale 
for those classes of problems. 
3. Variations in r 
Various r values may be useful for various aspects of representing information 
in the feature domain. Changing r basically results in a reweighting of errors from 
output bits I. Small r's give less weight for large deviations and tend to reduce the 
influence of outlier points in the feature space during learning. In fact, it can be 
shown that if the distributions of feature vectors are non-gaussian, then the r=2 case 
It is possible to entertain r values that are negative, which would give largest weight to small errors 
close to zero and smallest weight to very large errs. Values of r less than I generally are non-metric, 
i,e. they violate at least one of the metric axioms. For example. r<O violates the triangle inequality. 
For aome problems this may make sense and the need for a metric error weighting may be urmege. 
These issues are not explored in this paper. 
352 
will not be a maximum likelihood estimator of the weights [5]. The city block case, 
r=-l, in fact, arises if the underlying conditional probability distributions are Laplace 
[5]. More generally, r's less than two will tend to model non-gaussian distributions 
where the tails of the distributions are more pronounced than in the gaussian. Better 
estimators can be shown to exist for general noise reduction and have been studied in 
the area of robust estimation procedures [5] of which the Minkowski-r metric is only 
one possible case to consider. 
r<2. It is generally recommended that r=l.5 may be optimal for many noise 
reduction problems [6]. However, noise reduction may also be expected to vary with 
the problem and nature of the noise. One example we have looked at involves the 
recovery of an arbitrary 3 dimensional smooth surface as shown in Figure 2a, after 
the addition of random noise. This surface was generated from a gaussian curve in the 
2 dimensions. Uniform random noise equal to the width (standard deviation) of the 
surface shape was added point-wise to the surface producing the noise plus surface 
shape shown in Figure 2b. 
Figure 2: Shape surface (2a), Shape plus noise surface (2b) and recovered Shape 
surface (2c) 
The shape in Figure 2a was used as target points for Minkowski-r back-propagation 2 
and recovered with some distortion of the slope of the shape near the peak of the 
All simulation runs, unless otherwise staled, used the same learning rate (.05) and smoothing value (.9) 
and stopping criterion defined in terms of absolute mean deviation. The number of iterations to meet 
the stopping criterion varied considerably as r was changed (see below). 
353 
surface (see Figure 2c). Next the noise plus shape surface was used as target points 
for the learning procedure with r=2. The shape shown in Figure 3a was recovered, 
however, with considerable distortion iaround the base and peak. The value of r was 
reduced to 1.5 (Figure 3b) and then finally to 1.2 (Figure 3c) before shape distortions 
were eliminated. Although, the major properties of the shape of the surface were 
recovered, the scale seems distorted (however, easily restored with tenorrealization 
into the 0,1 range). 
Figure 3: Shape surface recovered with r=2 (3a), r=l.5 (3b) and r=12 (3c) 
r>2. Large r's tend to weight large deviations. When noise is not possible in 
the feature space (as in an arbitrary boolean problem) or where the token clusters are 
compact and isolated then simpler (in the sense of the number and placement of 
partition planes) genei'alizafion surfaces may be created with larger r values. For 
example, in the simple XOR problem, the main effect of increasing r is to pull the 
decision boundaries closer into the non-zero targets (compare high activation regions 
in Figure 4a and 4b). 
In this particular problem clearly such compression of the target regions does not 
constitute simpler decision surfaces. However, if more hidden units are used than are 
needed for pattern class separation, then increasing r during training will tend to 
reduce the number of cuts in the space to the minimum needed. This seems to be 
primarily due to the sensitivity of the hyper-plane placement in the feature space to 
the geometry of the targets. 
A more complex case illustrating the same idea comes from an example 
suggested by Minsky & Papert [7] called ""the mesh"". This type of pattern 
recognition problem is also, like XOR, a non-linearly separable problem. An optimal 
354 
I( 
Ol 
oo 
i! 
Figure 4: XOR solved with r=2 (4a) and r=4 (4b) 
olution involves only three cuts in feature space to meparate the two ""meshed"" 
clusm's (see Figure 5a). 
feature I 
Mesh (Mly & Paperr, 1969) 
o � 
o 
Figure 5: Mesh problem with minimum cut solution (5a) and Performance Surface(5b) 
Typical solutions for r=2 in this case tend to use a large number of hidden units to 
separate the two sets of exemplars (see Figure 5b for a performance surface). For 
example, in Figure 6a notice that a typical (based on several runs) Euclidian back- 
prop starting with 16 hidden units has found a solution involving five decision 
boundaries (lines shown in the plane also representing hidden units) while the r=3 
case used primarily three decision boundaries and placed a number of other 
355 
boundaries redundanfiy near the center of the meshed region (see Figure 6b) where 
there is maximum uncertainty about the cluster identification. 
0.0 0.2 0.4 0.6 0.8 1.0  
0.0 0.2 0.4 0.6 0.8 1.0 
Figure 6: Mesh solved with r=2 (6a) and r=3 (6b) 
Speech Recognition. A final case in which large r's may be appropriate is data 
that has been previously processed with a transformation that produced compact 
regions requiring separation in the feature space. One example we have looked at 
involves spoken digit recognition. The first 10 cepstral coefficients of spoken digits 
(""one"" through ""ten"") were used for input to a network. In this case an advantage is 
shown for larger r's with smo_ 11er training set sizes. Shown in Figure 7 are transfer 
data for 50 spoken digits replicated in ten different runs per point (bars show standard 
error of the mean). Transfer shows a training set size effect for both r=-2 and r=3, 
however for the larger r value at smaller training set sizes (10 and 20) note that 
transfer is enhanced. 
We speculate that this may be due to the larger r bacp creating discrimination 
regions that are better able to capture the compactness of the clusters inherent in a 
small number of training points. 
4. Convergence Properties 
It should be generally noted that as r increases, convergence time tends to grow 
roughly linearly (although this may be problem dependenO. Consequenfiy, 
decreasing r can significantly improve convergence, without much change to the 
nature of solution. Further, if noise is present decreasing r may reduce it 
dramatically. Note finally that the gradient for the Minkowski-r back-propagation is 
nonlinear and therefore more complex for irnplemcnting learning procedures. 
356 
/ R=2 .,.' '""'J. 
10 replications of 50 transfer points 
0 10 20 30 40 50 
TRAINING SET SIZE 
Figure 7: Digit Recognition Set Size Effect 
$. Summary and Conclusion 
A new procedure which is a variation on the Back-propagation algorithm is 
derived and simulated in a number of different problem domains. Noise in the target 
domain may be reduced by using power values less than 2 and the sensitivity of 
partition planes to the geomeu7 of the problem may be increased with increasing 
power values. Other types of objective functions should be explored for their 
potential consequences on network resources and ensuing pattern recognition 
capabilities. 
References 
1. Rumelhart D. E., Hinton G. E., Williams R., Learning Internal Representations by 
error propagation. Nature, 1986. 
2. Burr D. J. and Hanson S. J., Knowledge Representation in Connectionist Networks, 
Bellcore, Technical Report, 
3. White, H. Personal Communication, 1987. 
4. White, H. Some Asymptotic Results for Learning in Single Hidden Layer 
Feedforward Network Models, Unpublished Manuscript, 1987. 
357 
5. Most�llcr, F. & Tukcy, $. Robust Estimation Procedures, Addison Wesley, 1980. 
6. Tukcy, $. Personal Communication, 1987. 
7. Minsky, M. & Papeft, S., Percepttons: An Introduction to Computational 
Geometry, MIT Press, 1969. 
", learn connectionist error signal hanson david burr commun research new jersey connectionist learn model implement use gradient descent least squar error function output teacher present model use power small error metric approxim larg metric standard model implement sever experi done show differ valu desir variou differ valu may appropri effect outlier model input space model statist particular domain natur way may perccptual psycholog meaning speech introduct recent resurg connectionist model trace abil complex model input shown network singl hidden layer activ unit learn linear partit featur space one result partit complex gradient surfac decis new input stimuli categor cluster properti network arc determin map input stimuli gradient surfac gradient surfac function condit probabl output vector given input featur vector well function error relat teacher signal mani model implement use least squar paper describ new model gradient descent use power error small error measur larger supremum error measur standard case euclidian special case first deriv gener case discuss implic vari power gener deriv standard deriv minim least squar error function connect weight within complet connect layer error euclidian case singl activ unit repres independ teacher activ unit typic comput normal input interv compress high low end common function use normal input unit found sum product weight activ yn repres unit fan unit repres strength unit unit gradient euclidian standard case could found find partial error respect express three term equat turn error power metric figur famili equat equat easili find express gener yi sgn gradient use weight updat role propos hinton gradient comput hidden layer function gradient hidden layer weight updat proce way case simpli substitut new also possibl defin gradient minimum error gradient suggest white see also likelihood estim shown yi log yi approxim gradient last term equat investig simpl problem shown fairli robust similar import updat rule chang weight updat simul ran chang time weight valu rate might expect problem rate local minima may expect larger seek optim may inform moment differ class problem fix consid specif rational class variat valu may use variou aspect repres inform featur chang basic result reweight error bit small give less weight larg deviat tend reduc outlier point featur space distribut featur vector case possibl entertain valu would give largest weight small error zero smallest weight larg valu less gener violat least one metric violat triangl aom problem may make sens need metric error weight may issu explor maximum likelihood estim weight citi block aris underli condit probabl distribut laplac less two tend model distribut tail distribut pronounc better shown exist gener nois reduct studi area robust estim procedur metric possibl case gener recommend may optim mani nois problem nois reduct may also expect vari problem natur one exampl look involv arbitrari dimension smooth surfac shown figur addit random surfac gener gaussian curv uniform random nois equal width shape ad surfac produc nois plu surfac shown figur shape surfac shape plu nois surfac recov shape shape figur use target point recov distort slope shape near peak simul unless otherwis use learn rate smooth valu stop criterion defin term absolut mean number iter meet stop criterion vari consider chang figur next nois plu shape surfac use target point learn procedur shape shown figur consider distort iaround base valu final shape distort major properti shape surfac scale seem distort easili restor tenorr shape surfac recov larg tend weight larg nois possibl featur space arbitrari boolean token cluster isol simpler sens number placement surfac may creat larger simpl xor main effect increas pull boundari closer target high activ region figur particular problem clearli compress target region simpler decis hidden unit use pattern class increas train tend number cut space minimum seem due sensit placement featur space geometri complex case illustr idea come exampl minski papert call type pattern problem like separ optim xor solv involv three cut featur space mepar two figur mesh problem minimum cut solut perform solut case tend use larg number hidden unit two set exemplar figur perform figur notic typic sever euclidian start hidden unit found solut involv five decis shown plane also repres hidden use primarili three decis boundari place number redundanfiy near center mesh region figur maximum uncertainti cluster mesh solv final case larg may appropri data previous process transform produc compact requir separ featur one exampl look spoken digit first cepstral coeffici spoken digit use input case advantag larger train set shown figur transfer spoken digit replic ten differ run per point show standard transfer show train set size effect larger valu smaller train set size note specul may due larger creat discrimin better abl captur compact cluster inher number train converg properti gener note converg time tend grow linearli may problem significantli improv without much chang nois present decreas may reduc note final gradient therefor complex irnplemcnt learn replic transfer point set size digit recognit set size effect summari conclus new procedur variat algorithm simul number differ problem nois target may reduc use power valu less sensit plane problem may increas increas type object function explor consequ network resourc ensu pattern recognit rumelhart hinton william learn intern represent burr hanson knowledg represent connectionist technic person asymptot result learn singl hidden layer network unpublish robust estim addison person introduct comput mit,2
38,38,"358 
LEARNING REPRESENTATIONS BY RECIRCULATION 
Geoffrey E. Hinton 
Computer Science and Psychology Departments, University of Toronto, 
Toronto M5S 1A4, Canada 
James L. McClelland 
Psychology and Computer Science Departments, Carnegie-Mellon University, 
Pittsburgh, PA 15213 
ABSTRACT 
We describe a new learning procedure for networks that contain groups of non- 
linear units arranged in a closed loop. The aim of the learning is to discover codes 
that allow the activity vectors in a ""visible"" group to be represented by activity 
vectors in a ""hidden"" group. One way to test whether a code is an accurate 
representation is to try to reconstruct the visible vector from the hidden vector. The 
difference between the original and the reconstructed visible vectors is called the 
reconstruction error, and the learning procedure aims to minimize this error. The 
learning procedure has two passes. On the first pass, the original visible vector is 
passed around the loop, and on the second pass an average of the original vector and 
the reconstructed vector is passed around the loop. The learning procedure changes 
each weight by an amount proportional to the product of the ""presynaptic"" activity 
and the difference in the post-synaptic activity on the two passes. This procedure is 
much simpler to implement than methods like back-propagation. Simulations in 
simple networks show that it usually converges rapidly on a good set of codes, and 
analysis shows that in certain restricted cases it performs gradient descent in the 
squared reconstruction error. 
INTRODUCTION 
Supervised gradient-descent learning procedures such as back-propagation I 
have been shown to construct interesting internal representations in ""hidden"" units 
that are not part of the input or output of a connectionist network. One criticism of 
back-propagation is that it requires a teacher to specify,the desi[,,ed output vectors. It 
is possible to dispense with the teacher in the case of'encoder' networks 2 in which 
the desired output vector is identical with the input vector (see Fig. 1). The purpose 
of an encoder network is to learn good ""codes"" in the intermediate, hidden units. If 
for, example, there are less hidden units than input units, an encoder network will 
perform data-compression 3. It is also possible to introduce other kinds of constraints 
on the hidden units, so we can view an encoder network as a way of ensuring that the 
input can be reconstructed from the activity in the hidden units whilst also making 
This research was supported by contract N00014-86-K-00167 from the Office of Naval Research 
and a grant from the Canadian National Science and Engineering Research Council. Geoffrey Hinton 
is a fellow of the Canadian Institute for Advanced Research. We thank Mike Franzini, Conrad 
Galland and Geoffrey Goodhill for helpful discussions and help with the simulations. 
� American Institute of Physics 1988 
359 
the hidden units satisfy some other constraint. 
A second criticism of back-propagation is that it is neurally iraplausible (and 
hard to implement in hardware) because it requires all the connections to be used 
backwards and it requires the units to use different input-output functions for the 
forward and backward passes. Recirculation is designed to overcome this second 
criticism in the special case of encoder networks. 
output units 
t 
[ hidden units [ 
input units 
Fig. 1. A diagram of a three layer encoder network that learns good codes using 
back-propagation. On the forward pass, activity flows from the input units in the 
bottom layer to the output units in the top layer. On the backward pass, error- 
derivatives flow from the top layer to the bottom layer. 
Instead of using a separate group of units for the input and output we use the 
very same group of ""visible"" units, so the input vector is the initial state of this group 
and the output vector is the state after information has passed around the loop. The 
difference between the activity of a visible unit before and after sending activity 
around the loop is the derivative of the squared reconstruction error. So, if the 
visible units are linear, we can perform gradient descent in the squared error by 
changing each of a visible unit's incoming weights by an amount proportional to the 
product of this difference and the activity of the hidden unit from which the 
connection emanates. So learning the weights from the hidden units to the output 
units is simple. The harder problem is to learn the weights on connections coming 
into hidden units because there is no direct specification of the desired states of these 
units. Back-propagation solves this problem by back-propagating error-derivatives 
from the output units to generate error-derivatives for the hidden units. 
Recirculation solves the problem in a quite different way that is easier to implement 
but much harder to analyse. 
360 
THE RECIRCULATION PROCEDURE 
We introduce the recirculation procedure by considering a very simple 
architecture in which there is just one group of hidden units. Each visible unit has a 
directed connection to every hidden unit, and each hidden unit has a directed 
connection to every visible unit. The total input received by a unit is 
xj = . YiWji - 9j 
(1) 
where Yi is the state of the i th unit, wji is the weight on the connection from the i th to 
the jh unit and 0j is the threshold of the fh unit. The threshold term can be 
eliminated by giving every unit an extra input connection whose activity level is 
fixed at 1. The weight on this special connection is the negative of the threshold, and 
it can be learned in just the same way as the other weights. This method of 
implementing thresholds will be assumed throughout the paper. 
The functions relating inputs to outputs of visible and hidden units are smooth 
monotonic functions with bounded derivatives. For hidden units we use the logistic 
function: 
1 (2) 
YJ = - +e-Xj 
Other smooth monotonic functions would serve as well. For visible units, our 
mathematical analysis focuses on the linear case in which the output equals the total 
input, though in simulations we use the logistic function. 
We have already given a verbal description of the learning role for the hidden- 
to-visible connections. The weight, wij, from the ./h hidden unit to the i th visible 
unit is changed as follows: 
Awq = e yj(1 ) [Yi(O)-Yi(2)] (3) 
where Yi(O) is the state of the i th visible unit at time 0 and Yi(2) is its state at time 2 
after activity has passed around the loop once. The rule for the visible-to-hidden 
connections is identical: 
Awji = eYi(2) [y./(1)-y.t(3)] 
(4) 
where yj(1) is the state of the jth hidden unit at time 1 (on the first pass around the 
loop) and yi{3) is its state at time 3 (on the second pass around the loop). Fig. 2 
shows the network exploded in time. 
In general, this role for changing the visible-to-hidden connections does not 
perform steepest descent in the squared reconstruction error, so it behaves differently 
from back-propagation. This raises two issues: Under what conditions does it work, 
and under what conditions does it approximate steepest descent? 
361 
time = 3 
time = 0 time = 2 
Fig. 2. A diagram showing the states of the visible and hidden units exploded in 
time. The visible units are at the bottom and the hidden units are at the top. Time 
goes from left to right. 
CONDITIONS UNDER WHICH RECIRCULATION 
APPROXIMATES GRADIENT DESCENT 
For the simple architecture shown in Fig. 2, the recirculation learning procedure 
changes the visible-to-hidden weights in the direction of steepest descent in the 
squared reconstruction error provided the following conditions hold: 
1. The visible units are linear. 
2. The weights are symmetrical (i.e. wji=wij for all i,j). 
3. The visible units have high regression. 
""Regression"" means that, after one pass around the loop, instead of setting the 
activity of a visible unit, i, to be equal to its current total input, xi(2), as determined 
by Eq 1, we set its activity to be 
Yi(2) = 3Yi(O ) + (1-3)xi(2) (5) 
where the regression, 3, is close to 1. Using high regression ensures that the visible 
units only change state slightly so that when the new visible vector is sent around the 
loop again on the second pass, it has very similar effects to the first pass. In order to 
make the learning rule for the hidden units as shnilar as possible to the rule for the 
visible units, we also use regression in computing the activity of the hidden units on 
the second pass 
yj(3) = 3yj(1) + (1-X)((x(3)) 
(6) 
For a given input vector, the squared reconstruction error, E, is 
1 
E =  [yt:(2)-yt:(O)] 2 
For a hidden unit, j, 
362 
0� ayg2) Og2) 
Oyt,(2) axg2) ayj(1) 
-- -  [yk(2)-y(0)] y[(2) wkj 
k 
(7) 
where 
dyg2) 
yt'(2) - -- 
dxk(2) 
For a visible-to-hidden weight wji 
E E 
ivji - yf (1) Yi(O) iyj( l'-- 
So, using Eq 7 and the assumption that wkj=wjl c for all k,j 
- y/'(1) yi(0) [ yk(2) y(2) wik-  yk(0) y[(2) wid 
k k 
The assumption that the visible units are linear (with a gradient of 1) means that 
for all k, y/i(2) = 1. So using Eq 1 we have 
E 
i)wj i - h'(1) Yi(O) [ xj( 3 )-xj(1)] 
(8) 
Now, with sufficiently high regression, we can assume that the states of units 
only change slightly with time so that 
1 
yf (1) [x.(3)-xj(1)]  <(xj(3)) - c(xj(1)) - (1- 30 [yj(3) - yj(1)] 
and Yi(O) = yi(2) 
So by substituting in Eq 8 we get 
E 1 
i)wfi - ( 1 - 3.) yi(2)[yj(3)- yj(1)] 
(9) 
An interesting property of Eq 9 is that it does not contain a term for the gradient 
of the input-output function of unit j so recirculation learning can be applied even 
when unit j uses an unknown non-linearity. To do back-propagation it is necessary to 
know the gradient of the non-linearity, but recirculation measures the gradient by 
measuring the effect of a small difference in input, so the term yj(3)-yj(1) implicitly 
contains the gradient. 
363 
A SIMULATION OF RECIRCULATION 
From a biological standpoint, the symmetry requirement that wij=wji is 
unrealistic unless it can be shown that this symmetry of the weights can be learned. 
To investigate what would happen if symmetry was not enforced (and if the visible 
units used the same non-linearity as the hidden units), we applied the recirculation 
learning procedure to a network with 4 visible units and 2 hidden units. The visible 
vectors were 1000, 0100, 0010 and 0001, so the 2 hidden units had to learn 4 
different codes to represent these four visible vectors. All the weights and biases in 
the network were started at small random values uniformly distributed in the range 
-0.5 to +0.5. We used regression in the hidden units, even though this is not strictly 
necessary, but we ignored the term 1/(1 -) in Eq 9. 
Using an s of 20 and a  of 0.75 for both the visible and the hidden units, the 
network learned to produce a reconstruction error of less than 0.1 on every unit in an 
average of 48 weight updates (with a maxhnum of 202 in 100 simulations). Each 
weight update was performed after trying all four training cases and the change was 
the sum of the four changes prescribed by Eq 3 or 4 as appropriate. The final 
reconstruction error was measured using a regression of 0, even though high 
regression was used dm-ing the learning. The learning speed is comparable with 
back-propagation, though a precise comparison is hard because the optimal values of 
� are different in the two cases. Also, the fact that we ignored the term 1/(1-) 
when modifying the visible-to-hidden weights means that recirculation tends to 
change the visible-to-hidden weights more slowly than the hidden-to-visible weights, 
and this would also help back-propagation. 
It is not immediately obvious why the recirculation learning procedure works 
when the weights are not constrained to be symmetrical, so we compared the weight 
changes prescribed by the recirculation procedure with the weight changes that 
would cause steepest descent in the sum squared reconstruction error (i.e. the weight 
changes prescribed by back-propagation). As expected, recirculation and back- 
propagation agree on the weight changes for the hidden-to-visible connections, even 
though the gradient of the logistic function is not taken into account in weight 
adjustments under recirculation. (Conrad Galland has observed that this agreement 
is only slightly affected by using visible units that have the non-linear input-output 
function shown in Eq 2 because at any stage of the learning, all the visible units tend 
to have similar slopes for their input-output functions, so the non-linearity scales all 
the weight changes by approximately the same amount.) 
For the visible-to-hidden connections, recirculation initially prescribes weight 
changes that are only randomly related to the direction of steepest descent, so these 
changes do not help to improve the performance of the system. As the learning 
proceeds, however, these changes come to agree with the direction of steepest 
descent. The crucial observation is that this agreement occurs after the hidden-to- 
visible weights have changed in such a way that they are approximately aligned 
(symmetrical up to a constant factor) with the visible-to-hidden weights. So it 
appears that changing the hidden-to-visible weights in the direction of steepest 
descent creates the conditions that are necessary for the recirculation procedure to 
cause changes in the visible-to-hidden weights that follow the direction of steepest 
descent. 
It is not hard to see why this happens if we start with random, zero-mean 
364 
visible-to-hidden weights. If the visible-to-hidden weight wji is positive, hidden unit 
j will tend to have a higher than average activity level when the i th visible unit has a 
higher than average activity. So yj will tend to be higher than average when the 
reconstructed value of Yi should be higher than average -- i.e. when the term 
[Yi(O)-Yi(2)] in Eq 3 is positive. It will also be lower than average when this term is 
negative. These relationships will be reversed if wji is negative, so wij will grow 
faster when wfi is positive than it will when wji is negative. Smolensky 4 presents a 
mathematical analysis that shows why a similar learning procedure creates 
symmetrical weights in a purely linear system. Williams 5 also analyses a related 
leaming rule for linear systems which he calls the ""symmetric error correction"" 
procedure and he shows that it performs principle components analysis. In our 
simulations of recirculation, the visible-to-hidden weights become aligned with the 
corresponding hidden-to-visible weights, though the hidden-to-visible weights are 
generally of larger magnitude. 
A PICTURE OF RECIRCULATION 
To gain more insight into the conditions under which recirculation learning 
produces the appropriate changes in the visible-to-hidden weights, we introduce the 
pictorial representation shown in Fig. 3. The initial visible vector, A, is mapped into 
the reconstructed vector, C, so the error vector is AC. Using high regression, the 
visible vector that is sent around the loop on the second pass is P, where the 
difference vector AP is a small fraction of the error vector AC. If the regression is 
sufficiently high and all the non-linearities in the system have bounded derivatives 
and the weights have bounded magnitudes, the difference vectors AP, BQ, and CR 
will be very small and we can assume that, to first order, the system behaves linearly 
in these difference vectors. If, for example, we moved P so as to double the length 
of AP we would also double the length of BQ and CR. 
'""7 c a 
Fig. 3. A diagram showing some vectors (A, P) over the visible units, their 
""hidden"" images (B, Q) over the hidden units, and their ""visible"" images (C, R) 
over the visible units. The vectors B' and C' are the hidden and visible images of 
A after the visible-to-hidden weights have been changed by the learning procedure. 
365 
Suppose we change the visible-to-hidden weights in the manner prescribed by 
Eq 4, using a very small value of �. Let Q' be the hidden image of P (i.e. the image 
of P in the hidden units) after the weight changes. To first order, Q' will lie between 
B and Q on the line BQ. This follows from the observation that Eq 4 has the effect 
of moving each yj(3) towards yj(1) by an amount proportional to their difference. 
Since B is close to Q, a weight change that moves the hidden image of P from Q to 
Q' will move the hidden image of A from B to B', where B' lies on the extension of 
the line BQ as shown in Fig. 3. If the hidden-to-visible weights are not changed, the 
visible image of A will move from C to C', where C' lies on the extension of the line 
CR as shown in Fig. 3. So the visible-to-hidden weight changes will reduce the 
squared reconstruction error provided the vector CR is approxhnately parallel to the 
vector AP. 
But why should we expect the vector CR to be aligned with the vector AP? In 
general we should not, except when the visible-to-hidden and hidden-to-visible 
weights are approximately aligned. The leaming in the hidden-to-visible 
connections has a tendency to cause this alignment. In addition, it is easy to modify 
the recirculation learning procedure so as to increase the tendency for the leaming in 
the hidden-to-visible connections to cause alignment. Eq 3 has the effect of moving 
the visible image of A closer to A by an amount proportional to the magnitude of the 
error vector AC. If we apply the same rule on the next pass around the loop, we 
move the visible image of P closer to P by an amount proportional to the magnitude 
of PR. If the vector CR is anti-aligned with the vector AP, the magnitude of AC will 
exceed the magnitude of PR, so the result of these two movements will be to 
improve the aligmnent between AP and CR. We have not yet tested this modified 
procedure through simulations, however. 
This is only an informal argument and much work remains to be done in 
establishing the precise conditions under which the recirculation learning procedure 
approximates steepest descent. The informal argument applies equally well to 
systems that contain longer loops which have several groups of hidden units 
arranged in series. At each stage in the loop, the same learning procedure can be 
applied, and the weight changes will approximate gradient descent provided the 
difference of the two visible vectors that are sent around the loop aligns with the 
difference of their images. We have not yet done enough simulations to develop a 
clear picture of the conditions under which the changes in the hidden-to-visible 
weights produce the required aligmnent. 
USING A HIERARCHY OF CLOSED LOOPS 
Instead of using a single loop that contains many hidden layers in series, it is 
possible to use a more modular system. Each module consists of one ""visible"" group 
and one ""hidden"" group connected in a closed loop, but the visible group for one 
module is actually composed of the hidden groups of several lower level modules, as 
shown in Fig. 4. Since the same learning rule is used for both visible and hidden 
units, there is no problem in applying it to systems in which some units are the 
visible units of one module and the hidden units of another. Ballard 6 has 
experimented with back-propagation in this kind of system, and we have run some 
simulations of recirculation using the architecture shown in Fig. 4. The network 
366 
learned to encode a set of vectors specified over the bottom layer. After learning, 
each of the vectors became an attractor and the network was capable of completing a 
partial vector, even though this involved passing information through several layers. 
oo 
oo 
oooo 
oo 
oooo 
Fig 4. A network in which the hidden units of the bottom two modules are the 
visible units of the top module. 
CONCLUSION 
We have described a simple learning procedure that is capable of forming 
representations in non-linear hidden units whose input-output functions have 
bounded derivatives. The procedure is easy to implement in hardware, even if the 
non-linearity is unknown. Given some strong assumptions, the procedure performs 
gradient descent in the reconstruction error. If the symmetry assumption is violated, 
the learning procedure still works because the changes in the hidden-to-visible 
weights produce symmetry. If the assumption about the linearity of the visible units 
is violated, the procedure still works in the cases we have simulated. For the general 
case of a loop with many non-linear stages, we have an informal picture of a 
condition that must hold for the procedure to approximate gradient descent, but we 
do not have a formal analysis, and we do not have sufficient experience with 
simulations to give an empirical description of the general conditions under which 
the learning procedure works. 
REFERENCES 
1. D. E. Rumelhart, G. E. Hinton and R. J. Williams, Nature 323, 533-536 (1986). 
2. D. H. Ackley, G. E. Hinton and T. J. Sejnowski, Cognitive Science 9,147-169 
(1985). 
3. G. Cottrell, J. L. Elman and D. Zipser, Proc. Cognitive Science Society, Seattle, 
WA (1987). 
4. P. Smolensky, Technical Report CU-CS-355-87, University of Colorado at 
Boulder (1986). 
5. R. J. Williams, Technical Report 8501, Institute of Cognitive Science, University 
of California, San Diego (1985). 
6. D. H. Ballard, Proc. American Association for Artificial Intelligence, Seattle, WA 
(1987). 
", represent recircul hinton scienc psycholog univers canada clelland comput scienc pa describ new learn procedur network contain group unit arrang close aim learn discov code allow activ vector group repres activ one way test whether code accur tri reconstruct visibl vector hidden origin reconstruct visibl vector call learn procedur aim minim procedur two first origin visibl vector around second pass averag origin vector reconstruct vector pass around learn procedur chang weight amount proport product activ differ activ two procedur simpler implement method like simul network show usual converg rapidli good set show certain restrict case perform gradient descent reconstruct learn procedur shown construct interest intern represent unit part input output connectionist one critic requir teacher output possibl dispens teacher case network desir output vector ident input vector purpos encod network learn good hidden less hidden unit input encod network also possibl introduc kind constraint hidden view encod network way ensur reconstruct activ hidden unit whilst also make research support contract offic naval research grant canadian nation scienc engin research geoffrey hinton fellow canadian institut advanc thank mike conrad geoffrey goodhil help discuss help american institut physic hidden unit satisfi second critic neural iraplaus implement requir connect use requir unit use differ function backward recircul design overcom second special case encod unit hidden unit unit diagram three layer encod network learn good code use forward activ flow input unit layer output unit top backward flow top layer bottom use separ group unit input output use group input vector initi state group output vector state inform pass around activ visibl unit send activ loop deriv squar reconstruct unit perform gradient descent squar error visibl incom weight amount proport differ activ hidden unit learn weight hidden unit output harder problem learn weight connect come hidden unit direct specif desir state solv problem output unit gener hidden solv problem quit differ way easier implement much harder recircul procedur introduc recircul procedur consid simpl one group hidden visibl unit connect everi hidden hidden unit direct everi visibl total input receiv unit wji yi state th wji weight connect th unit threshold fh threshold term give everi unit extra input connect whose activ level weight special connect neg learn way method threshold assum throughout function relat input output visibl hidden unit smooth function bound hidden unit use logist smooth monoton function would serv visibl analysi focus linear case output equal total though simul use logist alreadi given verbal descript learn role hidden unit th visibl chang state th visibl unit time state time activ pass around loop rule state jth hidden unit time first pass around state time second pass around network explod role chang connect steepest descent squar reconstruct behav differ rais two condit condit approxim steepest time diagram show state visibl hidden unit explod visibl unit bottom hidden unit time left recircul gradient descent simpl architectur shown recircul learn procedur weight direct steepest descent reconstruct error provid follow condit visibl unit weight symmetr visibl unit high mean one pass around instead set visibl equal current total determin eq set activ close use high regress ensur visibl chang state slightli new visibl vector sent around second similar effect first order learn rule hidden unit shnilar possibl rule also use regress comput activ hidden unit second pass given input squar reconstruct hidden wkj weight wji yf use eq assumpt wid assumpt visibl unit linear gradient mean use eq suffici high assum state unit chang slightli time substitut eq get interest properti eq contain term gradient function unit recircul learn appli even unit use unknown necessari gradient recircul measur gradient effect small differ term implicitli simul recircul biolog symmetri requir unless shown symmetri weight investig would happen symmetri enforc visibl use hidden appli recircul procedur network visibl unit hidden visibl hidden unit learn code repres four visibl weight bias network start small random valu uniformli distribut rang use regress hidden even though strictli ignor term eq visibl hidden learn produc reconstruct error less everi unit weight updat maxhnum updat perform tri four train case chang sum four chang prescrib eq final error measur use regress even though high use learn speed compar though precis comparison hard optim valu differ two fact ignor term modifi weight mean recircul tend weight slowli would also help immedi obviou recircul learn procedur work weight constrain compar weight prescrib recircul procedur weight chang caus steepest descent sum squar reconstruct error weight prescrib recircul agre weight chang even gradient logist function taken account weight galland observ agreement slightli affect use visibl unit shown eq stage visibl unit tend similar slope scale weight chang approxim recircul initi prescrib weight randomli relat direct steepest help improv perform learn chang come agre direct steepest crucial observ agreement occur weight chang way approxim align constant chang weight direct steepest creat condit necessari recircul procedur chang weight follow direct steepest hard see happen start weight wji hidden unit tend higher averag activ level th visibl unit averag yj tend higher averag valu yi higher averag term eq also lower averag term relationship revers wji wij grow wfi posit wji smolenski present analysi show similar learn procedur creat weight pure linear william also analys relat rule linear system call error show perform principl compon weight becom align though weight larger pictur recircul gain insight condit recircul learn appropri chang introduc represent shown initi visibl map reconstruct error vector use high vector sent around loop second pass vector ap small fraction error vector regress high system bound deriv weight bound differ vector cr small assum first system behav linearli differ move doubl length ap would also doubl length bq diagram show vector visibl imag hidden imag visibl vector hidden visibl imag weight chang learn chang weight manner prescrib use small valu let hidden imag imag hidden weight first lie line follow observ eq effect move toward amount proport close weight chang move hidden imag move hidden imag lie extens line bq shown weight imag move lie extens line shown weight chang reduc reconstruct error provid vector cr approxhn parallel expect vector cr align vector except approxim leam tendenc caus easi modifi recircul learn procedur increas tendenc leam connect caus eq effect move visibl imag closer amount proport magnitud vector appli rule next pass around visibl imag closer amount proport magnitud vector cr vector magnitud ac magnitud result two movement aligmn ap yet test modifi inform argument much work remain done precis condit recircul learn procedur steepest inform argument appli equal well contain longer loop sever group hidden unit stage learn procedur weight chang approxim gradient descent provid two visibl vector sent around loop align yet done enough simul develop pictur condit chang produc requir hierarchi close loop use singl loop contain mani hidden layer use modular modul consist one group one group connect close visibl group one actual compos hidden group sever lower level sinc learn rule use visibl hidden problem appli system unit unit one modul hidden unit ballard kind run recircul use architectur shown network encod set vector specifi bottom vector becam attractor network capabl complet even though involv pass inform sever network hidden unit bottom two modul unit top describ simpl learn procedur capabl form hidden unit whose function procedur easi implement even given strong procedur perform descent reconstruct symmetri assumpt learn procedur still work chang produc assumpt linear visibl unit procedur still work case gener loop mani inform pictur must hold procedur approxim gradient formal suffici experi give empir descript gener condit learn procedur hinton natur hinton cognit scienc elman cognit scienc technic report univers colorado technic report institut cognit univers san diego american associ artifici wa,0
39,39,"367 
SCHEMA FOR MOTOR CONTROL 
UTILIZING A NETWORK MODEL OF THE CEREBELLUM 
James C. Houk, Ph.D. 
Northwestern University Medical School, Chicago, Illinois 
60201 
ABSTRACT 
This paper outlines a schema for movement control 
based on two stages of signal processing. The higher stage 
is a neural network model that treats the cerebellum as an 
array of adjustable motor pattern generators. This network 
uses sensory input to preset and to trigger elemental 
pattern generators and to evaluate their performance. The 
actual patterned outputs, however, are produced by intrin- 
sic circuitry that includes recurrent loops and is thus 
capable of self-sustained activity. These patterned 
outputs are sent as motor commands to local feedback 
systems called motor servos. The latter control the forces 
and lengths of individual muscles. Overall control is thus 
achieved in two stages: (1) an adaptive cerebellar network 
generates an array of feedforward motor commands and (2) a 
set of local feedback systems translates these commands 
into actual movements. 
INTRODUCTION 
There is considerable evidence that the cerebellum is 
involved in the adaptive control of movement 1, although the 
manner in which this control is achieved is not well under- 
stood. As a means of probing these cerebellar mechanisms, 
my colleagues and I have been conducting microelectrode 
studies of the neural messages that flow through the inter- 
mediate division of the cerebellum and onward to limb 
muscles via the rubrospinal tract. We regard this cerebel- 
lorubrospinal pathway as a useful model system for studying 
general problems of sensorimotor integration and adaptive 
brain function. A summary of our findings has been pub- 
lished as a book chapter 2. 
On the basis of these and other neurophysiological 
results, I recently hypothesized that the cerebellum func- 
tions as an array of adjustable motor pattern generators 3. 
The outputs from these pattern generators are assumed to 
function as motor commands, i.e., as neural control signals 
that are sent to lower-level motor systems where they 
produce movements. According to this hypothesis, the 
cerebellum uses its extensive sensory input to preset the 
@ American Institute of Physics 1988 
368 
pattern generators, to trigger them to initiate the 
production of patterned outputs and to evaluate the success 
or failure of the patterns in controlling a motor behavior. 
However, sensory input appears not to play a major role in 
shaping the waveforms of the patterned outputs. Instead, 
these waveforms seem to be produced by intrinsic circuity. 
The initial purpose of the present paper is to provide 
some ideas for a neural network model of the cerebellum 
that might be capable of accounting for adjustable motor 
pattern generation. Several previous authors have 
described network models of the cerebellum that, like the 
present model, are based on the neuroanatomical organiza- 
tion of this brain structure4,5, 6. While the present model 
borrows heavily from these previous models, it has some 
additional features that may explain the unique manner in 
which the cerebellum processes sensory input to produce 
motor commands. A second purpose of this paper is to 
outline how this network model fits within a broader schema 
for motor control that I have been developing over the past 
several years 3,7. Before presenting these ideas, let me 
first review some basic physiology and anatomy of the 
cerebellum 1 . 
SIGNALS AND CIRCUITS IN THE CEREBELLUM 
There are three main categories of input fibers to the 
cerebellum, called mossy fibers, climbing fibers and 
noradrenergic fibers. As illustrated in Fig. 1, the mossy 
fiber input shows considerable fan-out via granule cells 
and parallel fibers. The parallel fibers in turn are 
arranged to provide a high degree of fan-in to individual 
Purkinje cells (P). These P cells are the sole output 
elements of the cortical portion of the cerebellum. Via 
the parallel fiber input, each P cell is exposed to 
approximately 200,000 potential messages. In marked 
contrast, the climbing fiber input to P cells is highly 
focused. Each climbing fiber branches to only 10 P cells, 
and each cell receives input from only one climbing fiber. 
Although less is known about input via noradrenergic 
fibers, it appears to be diffuse and even more divergent 
than the mossy fiber input. 
Mossy fibers originate from several brain sites trans- 
mitting a diversity of information about th external world 
and the internal state of the body. Some mossy fiber 
inputs are clearly sensory. They come fairly directly from 
cutaneous, muscle or vestibular receptors. Others are 
routed via the cerebral cortex where they represent highly 
processed visual, auditory or somatosensory information. 
Yet another category of mossy fiber transmits information 
about central motor commands (Fig. 1 shows one such path- 
way, from collaterals of the rubrospinal tract relayed 
369 
through the lateral reticular nucleus (L)). The discharge 
rates of mossy fibers are modulated over a wide dynamic 
range which permits them to transmit detailed parametric 
information about the state of the body and its external 
environment. 
noradrenergic 
fibers 
climbing 
fiber 
granule 
cells  
mossy fibers  
Sensory 
Inputs 
sensorimotor 
cortex 
rubrospinal tract 
Motor 
Commands 
Figure 1: Pathways through the cerebellum. This diagram, 
which highlights the cerebellorubrospinal system, also 
constitutes a circuit diagram for the model of an 
elemental pattern generator. 
The sole source of climbing fibers is from cells 
located in the inferior olivary nucleus. Olivary neurons 
are selectively sensitive to sensory events. These cells 
have atypical electrical properties which limit their 
discharge to rates less than 10 impulses/sec, and usual 
rates are closer to 1 impulse/sec. As a consequence, 
370 
individual climbing fibers transmit very little parametric 
information about the intensity and duration of a stimulus; 
instead, they appear to be specialized to detect simply the 
occurrences of sensory events. There are also motor inputs 
to this pathway, but they appear to be strictly inhibitory. 
The motor inputs gate off responsiveness to self-induced 
(or expected) stimuli, thus converting olivary neurons into 
detectors of unexpected sensory events. 
Given the abundance of sensory input to P cells via 
mossy and climbing fibers, it is remarkable that these 
cells respond so weakly to sensory stimulation. Instead, 
they discharge vigorously during active movements. P cells 
send abundant collaterals to their neighbors, while their 
main axons project to the cerebellar nuclei and then onward 
to several brain sites that in turn relay motor commands to 
the spinal cord. 
Fig. 1 shows P cell projections to the intermediate 
cerebellar nucleus (I), also called the interpositus 
nucleus. The red nucleus (R) receives its main input from 
the interpositus nucleus, and it then transmits motor 
commands to the spinal cord via the rubrospinal tract. 
Other premotor nuclei that are alternative sources of motor 
commands receive input from alternative cerebellar output 
circuits. Fig. 1 thus specifically illustrates the 
cerebellorubrospinal system, the portion of the cerebellum 
that has been emphasized in my laboratory. 
Microelectrode recordings from the red nucleus have 
demonstrated signals that appear to represent detailed 
velocity commands for distal limb movements. Bursts of 
discharge precede each movement, the frequency of discharge 
within the burst corresponds to the velocity of movement, 
and the duration of the burst corresponds to the duration 
of movement. These velocity signals are not shaped by 
continuous feedback from peripheral receptors; instead, 
they appear to be produced centrally. An important goal of 
the modelling effort outlined here is to explain how these 
velocity commands might be produced by cerebellar circuits 
that function as elemental pattern generators. I will then 
discuss how an array of these pattern generators might 
serve well in an overall schema of motor control. 
ELEMENTAL PATTERN GENERATORS 
The motivation for proposing pattern generators rather 
than more conventional network designs derives from the 
experimental observation that motor commands, once initiat- 
ed, are not affected, or are only minimally affected, by 
alterations in sensory input. This observation indicates 
that the temporal features of these motor commands are 
produced by self-sustained activity within the neural 
network rather than by the time courses of network inputs. 
371 
Two features of the intrinsic circuitry of the cere- 
bellum may be particularly instrumental in explaining self- 
sustained activity. One is a recurrent pathway from cere- 
bellar nuclei that returns back to cerebellar nuclei. In 
the case of the cerebellorubrospinal system in Fig. 1, the 
recurrent pathway is from the interpositus nucleus to red 
nucleus to lateral reticular nucleus and back to interposi- 
tus, what I will call the IRL loop. The other feature of 
intrinsic cerebellar circuitry that may be of critical 
importance in pattern generation is mutual inhibition 
between P cells. Fig. 1 shows how mutual inhibition 
results from the recurrent collaterals of P-cell axons. 
Inhibitory interneurons called basket and stellate cells 
(not shown in Fig. 1) provide additional pathways for 
mutual inhibition. Both the IRL loop and mutual inhibition 
between P cells constitute positive feedback circuits and, 
as such, are capable of self-sustained activity. 
Self-sustained activity in the form of high-frequency 
spontaneous discharge has been observed in the IRL loop 
under conditions in which the inhibitory P-cell input to I 
cells is blocked 3. Trace A in Fig. 2 shows this unre- 
strained discharge schematically, and the other traces 
illustrate how a motor command might be sculpted out of 
this tendency toward high-frequency, repetitive discharge. 
Trace B shows a brief burst of input presumed to be 
sent from the sensorimotor cortex to the R cell in Fig. 1. 
This burst serves as a trigger that initiates repetitive 
discharge in an IRL loop, and trace D illustrates the 
discharge of an I cell in the active loop. The intraburst 
discharge frequency of this cell is presumed to be 
determined by the summed magnitude of inhibitory input 
(shown in trace C) from the set of P cells that project to 
it (Fig. 1 shows only a few P cells from this set). Since 
the inhibitory input to I was reduced to an appropriate 
magnitude for controlling this intraburst frequency some 
time prior to the arrival of the trigger event, this 
example illustrates a mechanism for presetting the pattern 
generator. Note that the same reduction of inhibition that 
presets the intraburst frequency would bring the loop 
closer to the threshold for repetitive firing, thus serving 
to enable the triggering operation. The I-cell burst, 
after continuing for a duration appropriate for the desired 
motor behavior, is assumed to be terminated by an abrupt 
increase in inhibitory input from the set of P cells that 
project to I (trace C). 
The time course of bursting discharge illustrated in 
Fig. 2D would be expected to propagate throughout the IRL 
loop and be transmitted via the rubrospinal tract to the 
spinal cord where it could serve as a motor command. 
Bursts of R-cell discharge similar to this are observed to 
precede movements in trained monkey subjects 2. 
372 
Illlllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll!lllllll 
I I 
time 
Figure 2: Signals Contributing to Pattern Generation. A. 
Repetitive discharge of I cell in the absence of P- 
cell inhibition. B. Trigger burst sent to the IRL 
loop from sensorimotor cortex. C. Summed inhibition 
produced by the set of P cells projecting to the I 
cell. D. Resultant motor pattern in I cell. 
The sculpting of a motor command out of a repetitive 
firing tendency in the IRL loop clearly requires timed 
transitions in the discharge rates of specific P cells. 
The present model postulates that the latter result from 
state transitions in the network of P cells. Bell and 
Grimm 8 described spontaneous transitions in P-cell firing 
that occur intermittently, and I have frequently observed 
them as well. These transitions appear to be produced by 
intrinsic mechanisms and are difficult to influence with 
sensory stimulation. The mutual recurrent inhibition 
between P cells might explain this tendency toward state 
transitions. 
Recurrent inhibition between P cells is mediated by 
synapses near the cell bodies and primary dendrites of the 
P cells whereas parallel fiber input extends far out on the 
dendritic tree. This arrangement may explain why sensory 
input via parallel fibers does not have a strong, continu- 
ous effect on P cell discharge. This sensory input may 
serve mainly to promote state transitions in the network of 
P cells, perhaps by modulating the likelihood that a given 
P cell would participate in a state transition. Once the 
373 
transition starts, the activity of the P cell may be domi- 
nated by the recurrent inhibition close to the cell body. 
The mechanism responsible for the adaptive adjustment 
of these elemental pattern generators may be a change in 
the synaptic strengths of parallel fiber input to P cells 9. 
Such alterations in the efficacy of sensory input would 
influence the state transitions discussed in the previous 
paragraph, thus mediating adaptive adjustments in the 
amplitude and timing of patterned output. Elsewhere I have 
suggested that this learning process is analogous to oper- 
ant conditioning and includes both positive and negative 
reinforcement 3. Noradrenergic fibers might mediate posi- 
tive reinforcement, whereas climbing fibers might mediate 
negative reinforcement. For example, if the network were 
controlling a limb movement, negative reinforcement might 
occur when the limb bumps into an object in the work space 
(climbing fibers fire in response to unexpected somatic 
events such as this), whereas positive reinforcement might 
occur whenever the limb successfully acquires the desired 
target (the noradrenergic fibers to the cerebellum are 
thought to receive input from reward centers in the brain). 
Positive reinforcement may be analogous to the associative 
reward-punishment algorithm described by Barto 10 which 
would fit with the diffuse projections of noradrenergic 
fibers. Negative reinforcement might be capable of a 
higher degree of credit assignment in view of the more 
focused projections of climbing fibers. 
In summary, the previous paragraphs outline some ideas 
that may be useful in developing a network model of the 
cerebellum. This particular set of ideas was motivated by 
a desire to explain the unique manner in which the cerebel- 
lum uses sensory input to control patterned output. The 
model deals explicitly with small circuits within a much 
larger network. The small circuits are considered elemen- 
tal pattern generators, whereas the larger network can be 
considered an array of these pattern generators. The 
assembly of many elements into an array may give rise to 
some emergent properties of the network, due to 
interactions between the elements. However, the highly 
compartmentalized anatomical structure of the cerebellum 
fosters the notion of relatively independent elemental 
pattern generators as hypothesized in the schema for 
movement control presented in the next section. 
SCHEMA FOR MOTOR CONTROL 
A major aim in developing the elemental pattern 
generator model described in the previous section was to 
explain the intriguing manner in which the cerebellum uses 
sensory input. Stated succinctly, sensory input is used to 
preset and to trigger each elemental pattern generator and 
374 
to evaluate the success of previous output patterns in 
controlling motor behavior. However, sensory input is not 
used to shape the waveform of an ongoing output pattern. 
This means that continuous feedback is not available, at 
the level of the cerebellum, for any immediate adjustments 
of motor commands. 
Is this kind of behavior actually advantageous in the 
control of movement? I would propose the affirmative, 
particularly on the grounds that this strategy seems to 
have withstood the test of evolution. Elsewhere I have 
reviewed the global strategies that are used to control 
several different types of body function 11. A common 
theme in each of these physiological control systems is the 
use of negative feedback only as a low-level strategy, and 
this coupled with a high-level stage of adaptive 
feedforward control. It was argued that this particular 
two-stage control strategy is well suited for utilizing the 
advantageous features of feedback, feedforward and adaptive 
control in combination. 
The adjustable pattern generator model of the cerebel- 
lum outlined in the previous section is a prime example of 
an adaptive, feedforward controller. In the subsequent 
paragraphs I will outline how this high-level feedforward 
controller communicates with low-level feedback systems 
called motor servos to produce limb movements (Fig. 3). 
The array of adjustable pattern generators (PGn) in 
the first column of.Fig. 3 produce an array of elemental 
commands that are transmitted via descending fibers to the 
spinal cord. The connectivity matrix for descending fibers 
represents the consequences of their branching patterns. 
Any given fiber is likely to branch to innervate several 
motor servos. Similarly, each member of the array of motor 
servos (MSm) receives convergent input from a large number 
of pattern generators, and the summed total of this input 
constitutes its overall motor command. 
A motor servo consists of a muscle, its stretch recep- 
tors and the spinal reflex pathways back to the same mus- 
cle 12. These reflex pathways constitute negative feedback 
loops that interact with the motor command to control the 
discharge of the motor neuron pool innervating the 
particular muscle. Negative feedback from the muscle 
receptors functions to maintain the stiffness of the muscle 
relatively constant, thus providing a spring-like interface 
between the body and its mechanical environment 13. The 
motor command acts to. set the slack length of this 
equivalent spring and, in this way, influences motion of 
the limb. Feedback also gives rise to an unusual type of 
damping proportional to a low fractional power of 
velocity 14. The individual motor servos interact with each 
other and with external loads via the trigonometric 
relations of the musculoskeletal matrix to produce 
resultant joint positions. 
375 
Cerebellar 
Network 
elemental 
commands 
motor forces, 
commands lengths 
Motor joint 
Sewos positions 
I External 
Load 
shoulder 
elbow 
wrist 
finger 
Figure 3: Schema for Motor Control Utilizing Pattern Gen- 
erator Model of Cerebellum. An array of elemental 
pattern generators (PGn) operate in an adaptive, feed- 
forward manner to produce motor commands. These out- 
puts of the high-level stage are sent to the spinal 
cord where they serve as inputs to a low-level array 
of negative feedback systems called motor servos 
(MSm). The latter regulate the forces and lengths of 
individual muscles to control joint angles. 
While the schema for motor control presented here is 
based on a considerable body of experimental data, and it 
also seems plausible as a strategy for motor control, it 
will be important to explore its capabilities for human 
limb control with simulation studies. It may also be 
fruitful to apply this schema to problems in robotics. 
Since I am mainly an experimentalist, my authorship of this 
paper is meant as an entr for collaborative work with 
neural network modelers that may be interested in these 
problems. 
376 
REFERENCES 
1. M. Ito, The Cerebellum and Neural Control (Raven 
Press, N.Y., 1984). 
2. J. C. Houk & A. R. Gibson, In: J. S. King, New 
Concepts in Cerebellar Neurobiology (Alan R. Liss, 
Inc., N.Y., 1987), p. 387. 
3. J. C. Houk, In: M. Glickstein & C. Yeo, Cerebellum and 
Neuronal Plasticity (Plenum Press, N.Y., 1988), in 
press. 
4. D. Marr, J. Physiol. (London) 202, 437 (1969). 
5. J. S. Albus, Math. Biosci. 10, 25 (1971). 
6. C. C. Boylls, A Theory of Cerebellar Function with 
Applications to Locomotion (COINS Tech. Rep., U. Mass. 
Amherst), 76-1. 
7. J. C. Houk, In: J. E. Desmedt, Cerebral Motor Control 
in Man: Long Loop Mechanisms (Karger, Basel, 1978), p. 
193. 
8. C. C. Bell & R. J. Grimm, J. Neurophysiol., 32, 1044 
(1969). 
9 C.-F. Ekerot & M. Kano, Brain Res., 342, 357 (1985). 
10. A. G. Barto, Human Neurobiol., 4, 229 (1985). 
11. J. C. Houk, FASEB J., 2, 97-107 (1988). 
12. J. C. Houk & W. Z. Rymer, In: V. B. Brooks, Handbook 
of Physiology, Vol. 1 of Sect. 1 (American Physiologi- 
cal Society, Bethesda, 1981), p.257. 
13. J. C. Houk, Annu. Rev. Physiol., 41, 99 (1979). 
14. C. C. A.M. Gielen & J. C. Houk, Biol. Cybern., 57, 
217 (1987). 
", motor control network model cerebellum univers medic illinoi paper outlin schema movement control two stage signal higher stage neural network model treat cerebellum adjust motor pattern network sensori input preset trigger element gener evalu pattern produc circuitri includ recurr loop thu pattern sent motor command local feedback call motor latter control forc length individu overal control thu two adapt cerebellar network array feedforward motor command local feedback system translat command actual consider evid cerebellum adapt control movement although control achiev well mean probe cerebellar colleagu conduct microelectrod neural messag flow divis cerebellum onward limb via rubrospin regard pathway use model system studi problem sensorimotor integr adapt summari find book chapter basi neurophysiolog recent hypothes cerebellum array adjust motor pattern gener output pattern gener assum motor neural control signal sent motor system accord use extens sensori input preset american institut physic trigger initi pattern output evalu success failur pattern control motor sensori input appear play major role waveform pattern waveform seem produc intrins initi purpos present paper provid idea neural network model cerebellum might capabl account adjust motor sever previou author network model cerebellum like base neuroanatom brain present model heavili previou featur may explain uniqu manner cerebellum process sensori input produc second purpos paper network model fit within broader schema motor control develop past year present let review basic physiolog anatomi circuit cerebellum three main categori input fiber call mossi climb fiber illustr mossi input show consider via granul cell parallel parallel fiber turn provid high degre individu cell cell sole output cortic portion via parallel fiber cell expos potenti mark climb fiber input cell highli climb fiber branch cell receiv input one climb less known input via noradrenerg appear diffus even diverg mossi fiber fiber origin sever brain site divers inform extern world intern state mossi fiber clearli come fairli directli muscl vestibular other via cerebr cortex repres highli auditori somatosensori anoth categori mossi fiber transmit inform central motor command show one collater rubrospin tract relay later reticular nucleu discharg mossi fiber modul wide dynam permit transmit detail parametr state bodi extern fiber tract pathway highlight cerebellorubrospin also circuit diagram model pattern sole sourc climb fiber cell inferior olivari olivari neuron select sensit sensori cell atyp electr properti limit rate less usual closer climb fiber transmit littl parametr intens durat appear special detect simpli sensori also motor input appear strictli motor input gate respons thu convert olivari neuron unexpect sensori abund sensori input cell via climb remark respond weakli sensori discharg vigor activ cell abund collater axon project cerebellar nuclei onward sever brain site turn relay motor command spinal show cell project intermedi nucleu also call interpositu red nucleu receiv main input interpositu transmit motor spinal cord via rubrospin premotor nuclei altern sourc motor receiv input altern cerebellar output thu specif illustr portion cerebellum emphas record red nucleu signal appear repres detail command distal limb burst preced frequenc discharg burst correspond veloc durat burst correspond durat veloc signal shape feedback peripher appear produc import goal model effort outlin explain command might produc cerebellar circuit function element pattern array pattern gener might well overal schema motor pattern gener motiv propos pattern gener rather convent network design deriv observ motor minim sensori observ indic tempor featur motor command activ within neural rather time cours network featur intrins circuitri may particularli instrument explain one recurr pathway nuclei return back cerebellar case cerebellorubrospin system pathway interpositu nucleu red later reticular nucleu back call irl featur cerebellar circuitri may critic pattern gener mutual inhibit show mutual inhibit recurr collater interneuron call basket stellat cell shown provid addit pathway irl loop mutual inhibit cell constitut posit feedback circuit capabl activ form discharg observ irl loop condit inhibitori input block trace show discharg trace motor command might sculpt tendenc toward repetit show brief burst input presum sensorimotor cortex cell burst serv trigger initi repetit irl trace illustr cell activ intraburst frequenc cell presum sum magnitud inhibitori input trace set cell project show cell sinc inhibitori input reduc appropri control intraburst frequenc prior arriv trigger illustr mechan preset pattern note reduct inhibit intraburst frequenc would bring loop threshold repetit thu serv enabl trigger continu durat appropri desir assum termin abrupt inhibitori input set cell time cours burst discharg illustr would expect propag throughout irl transmit via rubrospin tract cord could serv motor discharg similar observ movement train monkey subject signal contribut pattern discharg cell absenc trigger burst sent irl sensorimotor sum inhibit set cell project result motor pattern sculpt motor command repetit tendenc irl loop clearli requir time discharg rate specif present model postul latter result transit network bell describ spontan transit fire occur frequent observ transit appear produc mechan difficult influenc mutual recurr inhibit cell might explain tendenc toward state inhibit cell mediat near cell bodi primari dendrit cell wherea parallel fiber input extend far arrang may explain sensori via parallel fiber effect cell sensori input may mainli promot state transit network perhap modul likelihood given cell would particip state activ cell may recurr inhibit close cell mechan respons adapt adjust element pattern gener may chang synapt strength parallel fiber input cell alter efficaci sensori input would state transit discuss previou thu mediat adapt adjust time pattern elsewher learn process analog condit includ posit neg noradrenerg fiber might mediat wherea climb fiber might mediat network limb neg reinforc might limb bump object work space fiber fire respons unexpect somat wherea posit reinforc might whenev limb success acquir desir noradrenerg fiber cerebellum receiv input reward center reinforc may analog associ algorithm describ barto fit diffus project noradrenerg neg reinforc might capabl degre credit assign view project climb previou paragraph outlin idea may use develop network model particular set idea motiv desir explain uniqu manner use sensori input control pattern deal explicitli small circuit within much small circuit consid pattern wherea larger network array pattern mani element array may give rise emerg properti due highli anatom structur cerebellum notion rel independ element gener hypothes schema control present next motor control major aim develop element pattern model describ previou section intrigu manner cerebellum use state sensori input use trigger element pattern gener evalu success previou output pattern motor sensori input shape waveform ongo output mean continu feedback level immedi adjust motor kind behavior actual advantag would propos ground strategi seem withstood test elsewher global strategi use control differ type bodi function common physiolog control system neg feedback coupl stage adapt argu particular control strategi well suit util featur feedforward adapt adjust pattern gener model outlin previou section prime exampl feedforward subsequ outlin feedforward commun feedback system motor servo produc limb movement array adjust pattern gener first column produc array element transmit via descend fiber connect matrix descend fiber consequ branch given fiber like branch innerv sever member array motor receiv converg input larg number pattern sum total input overal motor motor servo consist stretch spinal reflex pathway back reflex pathway constitut neg feedback interact motor command control motor neuron pool innerv neg feedback muscl function maintain stiff muscl thu provid interfac bodi mechan environ command act set slack length spring influenc motion feedback also give rise unusu type proport low fraction power individu motor servo interact extern load via trigonometr musculoskelet matrix produc joint length joint posit extern schema motor control util pattern model array element gener oper manner produc motor stage sent spinal serv input array neg feedback system call motor servo latter regul forc length muscl control joint schema motor control present consider bodi experiment seem plausibl strategi motor import explor capabl human control simul may also appli schema problem mainli authorship meant collabor work network model may interest cerebellum neural control houk new cerebellar neurobiolog glickstein cerebellum plastic theori cerebellar function locomot cerebr motor control long loop mechan bell ekerot brain human faseb houk handbook gielen,0
40,40,"377 
EXPERIMENTAL DEMONSTRATIONS OF 
OPTICAL NEURAL COMPUTERS 
Ken Hsu, David Brady, and Demetri Psaltis 
Department of Electrical Engineering 
California Institute of Technology 
Pasadena, CA 91125 
ABSTRACT 
We describe two expriments in optical neural computing. In the first 
a closed optical feedback loop is used to implement auto-associative image 
recall. In the second a perceptron-like learning algorithm is implemented with 
photorefractive holography. 
INTRODUCTION 
The hardware needs of many neural computing systems are well matched 
with the capabilities of optical systems '2's The high interconnectivity 
required by neural computers can be simply implemented in optics because 
channels for optical signals may be superimposed in three dimensions with 
little or no cross coupling. Since these channels may be formed holographically, 
optical neural systems can be designed to create and maintain interconnections 
very simply. Thus the optical system designer can to a large extent 
avoid the analytical and topological problems of determining individual 
interconnections for a given neural system and constructing physical paths 
for these interconnections. 
An archetypical design for a single layer of an optical neural computer is 
shown in Fig. 1. Nonlinear thresholding elements, neurons, are arranged on 
two dimensional planes which are interconnected via the third dimension by 
holographic elements. The key concerns in implementing this design involve 
the need for suitable nonlinearities for the neural planes and high capacity, 
easily modifiable holographic elements. While it is possible to implement the 
neural function using entirely optical nonlinearities, for example using etaIon 
arrays 4, optoelectronic two dimensional spatial light modulators (2D SLMs) 
suitable for this purpose are more readily available. and their properties, 
i.e. speed and resolution, are well matched with the requirements of neural 
computation and the limitations imposed on the system by the holographic 
interconnections 5,6. Just as the main advantage of optics in connectionist 
machines is the fact that an optical system is generally linear and thus 
allows the superposition of connections, the main disadvantage of optics is 
that good optical nonlinearities are hard to obtain. Thus most SLMs are 
optoelectronic with a non-linearity mediated by electronic effects. The need for 
optical nonlinearities arises again when we consider the formation of modifiable 
optical interconnections, which must be an all optical process. In selecting 
American Institute of Physics 1988 
378 
a holographic material for a neural computing application we would like to 
have the capability of real-time recording and slow erasure. Materials such 
as photographic film can provide this only with an impractical fixing process. 
Photorefractive crystals are nonlinear optical materials that promise to have 
a relatively fast recording response and long term memory 4'5'6'7'8 
neural Fourier 
Fourier neural 
plane lens holographic Medium lens plane 
Figure 1. Optical neural computer architecture. 
In this paper we describe two experimental implementations of optical 
neural computers which demonstrate how currently available optical devices 
may be used in this application. The first experiment we describe involves an 
optical associative loop which uses feedback through a neural plane in the form 
of a pinhole array and a separate thresholding plane to implement associate 
regeneration of stored patterns from correlated inputs. This experiment 
demonstrates the input-output dynamics of an optical neural computer similar 
to that shown in Fig. 1, implemented using the Hughes Liquid Crystal Light 
Valve. The second experiment we describe is a single neuron optical perceptron 
implemented with a photorefractive crystal. This experiment demonstrates 
how the learning dynamics of long term memory may be controlled optically. 
By combining these two experiments we should eventually be able to construct 
high capacity adaptive optical neural computers. 
OPTICAL ASSOCIATIVE LOOP 
A schematic diagram of the optical associative memory loop is shown in 
Fig. 2. It is comprised of two cascaded Vander Lugt corrclators 9. The input 
section of the system from the threshold device P1 through the first hologram 
P2 to the pinhole array P3 forms the first correlator. The feedback section 
from P3 through the second hologram P4 back to the threshold device P1 
forms the second corrclator. An array of pinholes sits on the back focal plane 
of L2, which coincides with the front focal plane of L3. The purpose of the 
pinholes is to link the first and the second (reversed) correlator to form a closed 
optical feedback loop �. 
There are two phases in operating this optical loop, the learning phase 
and the recal phase. In the learning phase, the images to be stored are 
spatially multiplexcd and entered simultaneously on the threshold device. The 
379 
thresholded images are Fourier transformed by the lens L1. The Fourier 
spectrum and a plane wave reference beam interfere at the plane P2 and 
record a Fourier transform hologram. This hologram is moved to plane P4 
as our stored memory. We then reconstruct the images from the memory to 
form a new input to make a second Fourier transform hologram that will stay 
at plane P2. This completes the 
learning phase. In the recalling phase 
an input is imaged on the threshold 
device. This image is correlated with 
the reference images in the hologram 
at P2. If the correlation between the 
input and one of the stored images is 
high a bright peak appears at one of 
the pinholes. This peak is sampled by 
the pinhole to reconstruct the stored 
image from the hologram at P4. The 
reconstructed beam is then imaged 
back to the threshold device to form a 
closed loop. If the overall optical gain 
in the loop exceeds the loss the loop 
signal will grow until the threshold 
device is saturated. In this case, we 
can cutoff the external input image 
and the optical loop will be latched at 
the stable memory. 
Threshold  
Device uulput 
npm / . 
Hologram 
Pe Second 
Holonrom PKhole 
L 
Figure. 2. All-optical associative 
loop. The threshold device is a LCLV, 
and the holograms are thermoplastic 
plates. 
The key elements in this optical loop arc the holograms, the pinhole array, 
and the threshold device. If we put a mirror � or a phase conjugate mirror TM  
at the pinhole plane P3 to reflect the correlation signal back through the 
system then we only need one hologram to form a closed loop. The use of two 
holograms, however, improves system performance. We make the hologram at 
P2 with a high pass characteristic so that the input section of the loop has 
high spectral discrimination. On the other hand we want the images to be 
reconstructed with high fidelity to the original images. Thus the hologram at 
plane P4 must have broadband characteristics. We use a diffuser to achieve 
this when making this hologram. Fig. 3a shows the original images. Fig. 3b 
and Fig. 3c are the images reconstructed from first and second holograms, 
respectively. As desired, Fig. 3b is a high pass version of the stored image 
while Fig. 3c is broadband. 
Each of the pinholes at the correlation plane P3 has a diameter of 60 
/ra. The separations between the pinholes correspond to the separations of 
the input images at plane P1. If one of the stored images appears at PI there 
will be a bright spot at the corresponding pinhole on plane P3. If the input 
image shifts to the position of another image the correlation peak will also 
380 
a. b. c. 
Figure 3. (a) The original images. (b)The reconstructed images from the high- 
pass hologram P2. (c) The reconstructed images from the band-pass hologram 
P4. 
shift to another pinhole. But if the shift is not an exact image spacing the 
correlation peak can not pass the pinhole and we lose the feedback signal. 
Therefore this is a loop with ""discrete"" shift invariance. Without the pinholes 
the cross-correlation noise and the auto-correlation peak will be fed back to 
the loop together and the reconstructed images won't be recognizable. There 
is a compromise between the pinhole size and the loop performance. Small 
pinholes allow good memory discrimination and sharp reconstructed images, 
but can cut the signal to below the level that can be detected by the threshold 
device and reduce the tolerance of the system to shifts in the input. The 
function of the pinhole array in this system might also be met by a nonlinear 
spatial light modulator, in which case we can achieve full shift invariance 2. 
The threshold device at plane P1 is a Hughes Liquid Crystal Light Valve. 
The device has a resolution of 16 lp/mm and uniform aperture of I inch 
diameter. This gives us about 160,000 neurons at P1. In order to compensate 
for the optical loss in the loop, which is on the order of 10 -5 , we need the 
neurons to provide gain on the order of 105 . In our system this is achieved 
by placing a Hamamatsu image intensifier at the write side of the LCLV. 
Since the microchannel plate of the image intensifier can give gains of 104, the 
combination of the LCLV and the image intensifier can give gains of 106 with 
sensitivity down to nW/cm 2. The optical gain in the loop can be adjusted by 
changing the gain of the image intensifier. 
Since the activity of neurons and the dynamics of the memory loop is 
a continuously evolving phenomenon, we need to have a real time device to 
monitor and record this behavior. We do this by using a prism beam splitter 
to take part of the read out beam from the LCLV and image it onto a CCD 
camera. The output is displayed on a CRT monitor and also recorded on a 
video tape recorder. Unfortunately, in a paper we can only show static pictures 
taken from the screen. We put a window at the CCD plane so that each time 
we can pick up one of the stored images. Fig. 4a shows the read out image 
381 
a. b. c. 
Figure 4. (a) The external input to the optical loop. (b) The feedback image 
superimposed with the input image. (c) The latched loop image. 
from the LCLV which comes from the external input shifted away from its 
stored position. This shift moves its correlation peak so that it does not match 
the position of the pinhole. Thus there is no feedback signal going through 
the loop. If we cut off the input image the read out image will die out with a 
characteristic time on the order of 50 to 100 ms, corresponding to the response 
time of the LCLV. Now we shift the input image around trying to search for 
the correct position. Once the input image comes close enough to the correct 
position the correlation peak passes through the right pinhole, giving a strong 
feedback signal superimposed with the external input on the neurons. The 
total signal then goes through the feedback loop and is amplified continuously 
until the neurons are saturated. Depending on the optical gain of the neurons 
the time required for the loop to reach a stable state is between 100 ms and 
several seconds. Fig. 4b shows the superimposed images of the external input 
and the loop images. While the feedback signal is shifted somewhat with 
respect to the input, there is sufficient correlation to induce recall. If the 
neurons have enough gain then we can cut off the input and the loop stays in 
its stable state. Otherwise we have to increase the neuron gain until the loop 
can sustain itself. Fig. 4c shows the image in the loop with the input removed 
and the memory latched. If we enter another image into the system, again 
we have to shift the input within the window to search the memory until we 
are close enough to the correct position. Then the loop will evolve to another 
stable state and give a correct output. 
The input images do not need to match exactly with the memory. Since 
the neurons can sense and amplify the feedback signal produced by a partial 
match between the input and a stored image, the stored memory can grow 
in the loop. Thus the loop has the capability to recall the complete memory 
from a partial input. Fig. 5a shows the image of a half face input into the 
system. Fig. 5b shows the overlap of the input with the complete face from 
the memory. Fig. 5c shows the stable state of the loop after we cut off the 
external input. In order to have this associative behavior the input must have 
enough correlation with the stored memory to yield a strong feedback signal. 
For instance, the loop does not respond to the the presentation of a picture of 
382 
a. b. c. 
Figure 5. (a) Partial face used as the external input. (b) The superimposed 
images of the partial input with the complete face recalled by the loop. (c) 
The complete face latched in the loop. 
a. b. c. 
Figure 6. (a) Rotated image used as the external input. (b) The superimposed 
images of the input with the recalled image from the loop. (c) The image 
latched in the optical loop. 
a person not stored in memory. 
Another way to demonstrate the associative behavior of the loop is to use 
a rotated image as the input. Experiments show that for a small rotation the 
loop can recognize the image very quickly. As the input is rotated more, it 
takes longer for the loop to reach a stable state. If it is rotated too much, 
depending on the neuron gain, the input won't be recognizable. Fig. 6a shows 
the rotated input. Fig. 6b shows the overlap of loop image with input after 
we turn on the loop for several seconds. Fig. 6c shows the correct memory 
recalled from the loop after we cut the input. There is a trade-off between the 
degree of distortion at the input that the system can tolerate and its ability 
to discriminate against patterns it has not seen before. In this system the 
feedback gain (which can be adjusted through the image intensifier) controls 
this trade-off. 
PHOTOREFRACTIVE PERCEPTRON 
Holograms are recorded in photorefractive crystals via the electrooptic 
modulation of the index of refraction by space charge fields created by 
the migration of photogenerated charge 3'4. Photorefractive crystals are 
attractive for optical neural applications because they may be used to store 
383 
long term interactions between a very large number of neurons. While 
photorefractive recording does not require a development step, the fact that 
the response is not instantaneous allows the crystal to store long term traces 
of the learning process. Since the photorefractive effect arises from the 
reversible redistribution of a fixed pool of charge among a fixed set of optically 
addressable trapping sites, the photorefractive response of a crystal does not 
deteriorate with exposure. Finally, the fact that photorefractive holograms 
may extend over the entire volume of the crystal has previously been shown to 
imply that as many as 10 l� interconnections may be stored in a single crystal 
with the independence of each interconnection guaranteed by an appropriate 
spatial arrangement of the interconnected neurons 6,s. 
In this section we consider a rudimentary optical neural system which uses 
the dynamics of photorefractive crystals to implement perceptron-like learning. 
The architecture of this system is shown schematically in Fig. 7. The input 
to the system, , corresponds to a two dimensional pattern recorded from a 
video monitor onto a liquid crystal light valve. The light valve transfers this 
pattern on a laser beam. This beam is split into two paths which cross in a 
photorefractive crystal. The light propagating along each path is focused such 
that an image of the input pattern is formed on the crystal. The images along 
both paths are of the same size and are superposed on the crystal, which is 
assumed to be thinner than the depth of focus of the images. The intensity 
diffracted from one of the two paths onto the other by a hologram stored in 
the crystal is isolated by a polarizer and spatially integrated by a single output 
detector. The thresholdcd output of this detector corresponds to the output 
of a neuron in a perceptron. 
PB LCLV TV 
L1 .- 
1 
/P, , / 
pM'V 
computer 
Figure 7. Photorefractive perceptton. PB is a polarizing beam splitter. L1 
and L2 are imaging lenses. WP is a quarter waveplate. PM is a piezoelectric 
mirror. P is a polarizer. D is a detector. Solid lines show electronic control. 
Dashed lines show the optical path. 
The i th component of the input to this system corresponds to the intensity 
in the i th pixel of the input pattern. The interconnection strength, wi, between 
the i t input and the output neuron corresponds to the diffraction efficiency 
of the hologram taking one path into the other at the i  pixel of the image 
plane. While the dynamics of wi can be quite complex in some geometries 
384 
and crystals, it is possible to show from the band transport model for the 
photorefractive effect that under certain circumstances the time development 
of wi may be modeled by 
 m(s)e ( )e;dsl 2 (1) 
wi(t) = w,,, I r 
where re(s) and b(s) are the modulation depth and phase, respectively, of the 
interference pattern formed in the crystal between the light in the two paths ls. 
r is a characteristic time constant for crystal. r is inversely proportional to 
the intensity incident on the i th pixel of the crystal. Using Eqn. 1 it is possible 
to make wi(t) take any value between 0 and wm,x by properly exposing the 
i th pixel of the crystal to an appropriate modulation depth and intensity. The 
modulation depth between two optical beams can be adjusted by a variety of 
simple mechanisms. In Fig. 7 we choose to control rn(t) using a mirror mounted 
on a piezoelectric crystal. By varying the frequency and the amplitude of 
oscillations in the piezoelectric crystal we can electronically set both rn(t) and 
b(t) over a continuous range without changing the intensity in the optical 
beams or interrupting readout of the system. With this control over rn(t) it 
is possible via the dynamics described in Eqn. (1) to implement any learning 
algorithm for which wi can be limited to the range (0, win,z). 
The architecture of Fig. 7 classifies input patterns into two classes 
according to the thresholded output of the detector. The goal of a learning 
algorithm for this system is to correctly classify a set of training patterns. The 
perceptron learning algorithm involves simply testing each training vector and 
adding training vectors which yield too low an output to the weight vector 
and subtracting training vectors which yield too high an output from the 
weight vector until all training vectors are correctly classified 16. This training 
algorithm is described by the equation Awi= exi where alpha is positive 
(negative) if the output for � is too low (high). An optical analog of this 
method is implemented by testing each training pattern and exposing the 
crystal with each incorrectly classified pattern. Training vectors that yield 
a high output when a low output is desired are exposed at zero modulation 
depth. Training vectors that yield a low output when high output is desired 
are exposed at a modulation depth of one. 
The weight vector for the k 4- i th iteration when erasure occurs in the k th 
iteration is given by 
--2At 
wi(k + 1) -- e , wi(k)  (1 2At)wi(k) (2) 
where we assume that the exposure time, At, is much less than r. Note that 
since r is inversely proportional to the intensity in the i th pixel, the change in 
385 
w i is proportional to the i th input. The weight vector at the k + I th iteration 
when recording occurs in the k h iteration is given by 
-2, X/''/( -' -' -' ) 
wi(k+l)=e  wi(k)+2 k)wmaxe  (1-e  )+wmax(1-e  )2 (3 
To lowest order in -- and w Eqn. (3) yields 
wi(k 1) wi(k) 2V/wi(k)w.az At 
= ( 
(4) 
Once again the change in wi is proportional to the i t input. 
We have implemented the architecture of Fig. 7 using a SBN60:Ce crystal 
provided by the Rockwell International Science Center. We used the 488 nm 
line of an argon ion laser to record holograms in this crystal. Most of the 
patterns we considered were laid out on 10 x 10 grids of pixels, thus allowing 
100 input channels. Ultimately, the number of channels which may be achieved 
using this architecture is limited by the number of pixels which may be imaged 
onto the crystal with a depth of focus sufficient to isolate each pixel along the 
length of the crystal. 
Figure 8. Training patterns. 
0 & 
Figure 9. Output in the second training cycle. 
Using the variation on the perceptron learning algorithm described above 
with a fixed exposure times Atr and Ate for recording and erasing, we have 
been able to correctly classify various sets of input patterns. One particular 
set which we used is shown in Fig. $. In one training sequence, we grouped 
patterns i and 2 together with a high output and patterns 3 and 4 together 
with a low output. After all four patterns had been presented four times, 
the system gave the correct output for all patterns. The weights stored in 
the crystal were corrected seven times, four times by recording and three by 
erasing. Fig. 9a shows the output of the detector as pattern i is recorded in 
the second learning cycle. The dashed line in this figure corresponds to the 
threshold level. Fig. 9b shows the output of the detector as pattern 3 is erased 
in the second learning cycle. 
386 
CONCLUSION 
The experiments described in this paper demonstrate how neural network 
architectures can be implemented using currently available optical devices. By 
combining the recall dynamics of the first system with the learning capability 
of the second, we can construct sophisticated optical neural computers. 
ACKNOWLEDGEMENTS 
The authors thank Ratnakar Neurgaonkar and Rockwell International for 
supplying the SBN crystal used in our experiments and Hamamatsu Photonics 
K.K. for assistance with image intesifiers. We also thank Eung Gi Paek and 
Kelvin Wagner for their contributions to this research. 
This research is supported by the Defense Advanced Research Projects 
Office, and the Air Force Office of Scientific 
Agency, the Army Research 
Research. 
REFERENCES 
1. Y. S. Abu-Mostafa and D. Psaltis, Scientific American, pp.88-95, March, 
1987. 
2. D. Psaltis and N.H. Farhat, Opt. Lett., 10,(2), 98(1985). 
3. A.D. Fisher, R. C. Fukuda, and J. N. Lee, Pro�. SPIE 625, 196(1986). 
4. K. Wagner and D. Psaltis, Appl. opt., 26(23), pp.5061-5076(1987). 
5. D. Psaltis, D. Brady, and K. Wagner, Applied optics, March 1988. 
6. D. Psaltis, J. Yu, X. G. Gu, and H. Lee, Second Topical Meeting on 
Optical Computing, Incline Village, Nevada, March 16-18,1987. 
7. A. Yariv, S.-K. Kwong, and K. Kyuma, SPIE proc. 613-01,(1986). 
8. D. Z. Anderson, Proceedings of the International Conference on Neural 
Networks, San Diego, June 1987. 
9. A. B. Vander Lugt, IEEE Trans. Inform. Theory, IT-10(2), pp.139- 
145(1964). 
10. E.G. Paek and D. Psaltis, Opt. Eng., 26(5), pp.428-433(1987). 
11. Y. Owechko, G. J. Dunning, E. Marom, and B. H. Softer, Appl. Opt. 
26,(10),1900(1987). 
12. D. Psaltis and 3. Hong, Opt. Eng. 26,10(1987). 
13. N. V. Kuktarev, V. B. Markov, S. G. Odulov, M. S. Soskin, and V. L. 
Vinetskii, Ferroelectrics, 22,949(1979). 
14. J. Feinberg, D. Heiman, A. R. Tanguay, and R. W. Hellwarth, J. Appl. 
Phys. 51,1297(1980). 
15. T. J. Hall, R. Jaura, L. M. Connors, P. D. Foote, Prog. Quan. Electr. 
10,77(1985). 
16. F. Rosenblatt,'Principles of Neurodynamics: Perceptton and the Theory 
of Brain Mechanisms, Spartan Books, Washington,(1961). 
", demonstr neural comput david demetri psalti electr engin institut technolog ca describ two expriment optic neural first close optic feedback loop use implement imag second learn algorithm implement hardwar need mani neural comput system well match capabl optic system high interconnect neural comput simpli implement optic optic signal may superimpos three dimens cross sinc channel may form neural system design creat maintain interconnect thu optic system design larg extent analyt topolog problem determin individu given neural system construct physic path archetyp design singl layer optic neural comput nonlinear threshold arrang dimension plane interconnect via third dimens key concern implement design involv need suitabl nonlinear neural plane high modifi holograph possibl implement function use entir optic exampl use ion optoelectron two dimension spatial light modul purpos readili speed well match requir neural limit impos system holograph main advantag optic connectionist fact optic system gener linear thu superposit main disadvantag optic good optic nonlinear hard thu slm mediat electron need nonlinear aris consid format modifi must optic select institut physic holograph materi neural comput applic would like capabl record slow materi photograph film provid impract fix crystal nonlinear optic materi promis rel fast record respons long term memori fourier neural len holograph medium len plane optic neural comput paper describ two experiment implement optic comput demonstr current avail optic devic use first experi describ involv associ loop use feedback neural plane form pinhol array separ threshold plane implement associ store pattern correl experi dynam optic neural comput similar shown implement use hugh liquid crystal light second experi describ singl neuron optic perceptron photorefract experi demonstr learn dynam long term memori may control combin two experi eventu abl construct capac adapt optic neural associ loop schemat diagram optic associ memori loop shown compris two cascad vander lugt corrclat input system threshold devic first hologram pinhol array form first feedback section second hologram back threshold devic second array pinhol sit back focal plane coincid front focal plane purpos link first second correl form close feedback loop two phase oper optic learn phase recal learn imag store multiplexcd enter simultan threshold imag fourier transform len fourier plane wave refer beam interfer plane fourier transform hologram move plane store reconstruct imag memori new input make second fourier transform hologram stay plane complet recal phase input imag threshold imag correl refer imag hologram correl one store imag bright peak appear one peak sampl pinhol reconstruct store hologram beam imag threshold devic form overal optic gain loop exce loss loop grow threshold cutoff extern input imag optic loop latch stabl uulput second associ threshold devic hologram thermoplast key element optic loop arc pinhol threshold put mirror phase conjug mirror tm pinhol plane reflect correl signal back need one hologram form close use two improv system make hologram high pass characterist input section loop spectral hand want imag high fidel origin thu hologram must broadband use diffus achiev make show origin imag reconstruct first second high pass version store imag pinhol correl plane diamet separ pinhol correspond separ input imag plane one store imag appear pi bright spot correspond pinhol plane input shift posit anoth imag correl peak also origin reconstruct imag hologram reconstruct imag hologram anoth shift exact imag space peak pass pinhol lose feedback loop shift without pinhol nois peak fed back loop togeth reconstruct imag compromis pinhol size loop small allow good memori discrimin sharp reconstruct cut signal level detect threshold reduc toler system shift pinhol array system might also met nonlinear light case achiev full shift invari threshold devic plane hugh liquid crystal light devic resolut uniform apertur inch give us neuron order compens optic loss order need provid gain order system achiev place hamamatsu imag intensifi write side microchannel plate imag intensifi give gain lclv imag intensifi give gain optic gain loop adjust gain imag activ neuron dynam memori loop continu evolv need real time devic record use prism beam splitter take part read beam lclv imag onto ccd output display crt monitor also record tape paper show static pictur put window ccd plane time pick one store show read imag extern input optic feedback imag input latch loop lclv come extern input shift away shift move correl peak match posit thu feedback signal go cut input imag read imag die time order correspond respons shift input imag around tri search correct input imag come close enough correct correl peak pass right give strong signal superimpos extern input signal goe feedback loop amplifi continu neuron depend optic gain neuron time requir loop reach stabl state ms show superimpos imag extern input loop feedback signal shift somewhat suffici correl induc enough gain cut input loop stay stabl otherwis increas neuron gain loop sustain show imag loop input remov memori enter anoth imag shift input within window search memori close enough correct loop evolv anoth state give correct input imag need match exactli sinc neuron sens amplifi feedback signal produc partial input store store memori grow thu loop capabl recal complet memori partial show imag half face input show overlap input complet face show stabl state loop cut order associ behavior input must correl store memori yield strong feedback loop respond present pictur partial face use extern superimpos partial input complet face recal complet face latch rotat imag use extern superimpos input recal imag imag optic person store way demonstr associ behavior loop use rotat imag experi show small rotat recogn imag input rotat longer loop reach stabl rotat neuron input show rotat show overlap loop imag input turn loop sever show correct memori loop cut distort input system toler abil discrimin pattern seen system gain adjust imag control perceptron record photorefract crystal via electroopt index refract space charg field creat migrat photogener charg photorefract crystal optic neural applic may use store term interact larg number record requir develop fact respons instantan allow crystal store long term trace learn sinc photorefract effect aris redistribut fix pool charg among fix set optic trap photorefract respons crystal fact photorefract hologram extend entir volum crystal previous shown mani interconnect may store singl crystal independ interconnect guarante appropri arrang interconnect neuron section consid rudimentari optic neural system use dynam photorefract crystal implement architectur system shown schemat input correspond two dimension pattern record monitor onto liquid crystal light light valv transfer laser beam split two path cross light propag along path focus imag input pattern form imag along path size superpos thinner depth focu intens one two path onto hologram store crystal isol polar spatial integr singl output thresholdcd output detector correspond output neuron lclv tv photorefract pb polar beam imag wp quarter pm piezoelectr solid line show electron line show optic th compon input system correspond intens th pixel input interconnect input output neuron correspond diffract effici hologram take one path pixel imag dynam wi quit complex geometri possibl show band transport model effect certain circumst time develop wi may model modul depth pattern form crystal light two path characterist time constant invers proport intens incid th pixel use possibl make take valu properli expos th pixel crystal appropri modul depth depth two optic beam adjust varieti choos control use mirror mount piezoelectr vari frequenc amplitud piezoelectr crystal electron set continu rang without chang intens optic interrupt readout control possibl via dynam describ implement learn wi limit rang architectur classifi input pattern two class threshold output goal learn system correctli classifi set train learn algorithm involv simpli test train vector train vector yield low output weight vector subtract train vector yield high output vector train vector correctli classifi train describ equat alpha posit output low optic analog implement test train pattern expos incorrectli classifi train vector yield high output low output desir expos zero modul train vector yield low output high output desir expos modul depth weight vector th iter erasur occur th given assum exposur much less note invers proport intens th chang proport th weight vector th iter record occur iter given lowest order yield chang wi proport implement architectur use crystal rockwel intern scienc use nm argon ion laser record hologram consid laid grid thu allow input number channel may achiev architectur limit number pixel may imag crystal depth focu suffici isol pixel along train output second train variat perceptron learn algorithm describ fix exposur time atr ate record abl correctli classifi variou set input one particular use shown one train group togeth high output pattern togeth low four pattern present four system gave correct output weight store crystal correct seven four time record three show output detector pattern record second learn dash line figur correspond show output detector pattern eras second learn experi describ paper demonstr neural network implement use current avail optic recal dynam first system learn capabl construct sophist optic neural author thank ratnakar neurgaonkar rockwel intern sbn crystal use experi hamamatsu photon assist imag also thank eung gi paek wagner contribut research support defens advanc research project air forc offic scientif armi research scientif psalti spie wagner appli march second topic meet inclin march spie proceed intern confer neural san june vander ie paek psalti perceptton theori brain spartan,2
41,41,"652 
Scaling Properties of Coarse-Coded Symbol Memories 
Ronald Rosenfeld 
David S. Touretzky 
Computer Science Department 
Carnegie Mellon University 
Pittsburgh, Pennsylvania 15213 
Abstract
Coarse-coded symbol memories have appeared in several neural network 
symbol processing models. In order to determine how these models would scale, one 
must first have some understanding of the mathematics of coarse-coded representa- 
tions. We define the general structure of coarse-coded symbol memories and derive 
mathematical relationships among their essential parameters: memort size, slmbol-set 
size and capacitor. The computed capacity of one of the schemes agrees well with actual 
measurements of the coarse-coded working memory of DCPS, Touretzky and Hinton's 
distributed connectionist production system. 
1 Introduction 
A dstributed representation is a memory scheme in which each entity (concept, symbol) 
is represented by a pattern of activity over many units [3]. If each unit participates 
in the representation of many entities, it is said to be coarsell tuned, and the memory 
itself is called a coarse-coded memorl. 
Coarse-coded memories have been used for storing symbols in several neural network 
symbol processing models, such as Touretzky and Hinton's distributed connectionist 
production system DCPS [8,9], Touretzky's distributed implementation of linked list 
structures on a Boltzmann machine, BoltzCONS [10], and St. John and McClelland's 
PDP model of case role defaults [6]. In all of these models, memory capacity was mea- 
sured empirically and parameters were adjusted by trial and error to obtain the desired 
behavior. We are now able to give a mathematical foundation to these experiments by 
analyzing the relationships among the fundamental memory parameters. 
There are several paradigms for coarse-coded memories. In a feature-based repre- 
sentation, each unit stands for some semantic feature. Binary units can code features 
with binary values, whereas more complicated units or groups of units are required to 
code more complicated features, such as multi-valued properties or numerical values 
from a continuous scale. The units that form the representation of a concept define 
an intersection of features that constitutes that concept. Similarity between concepts 
composed of binary features can be measured by the Hamming distance between their 
representations. In a neural network implementation, relationships between concepts 
are implemented via connections among the units forming their representations. Certain 
types of generalization phenomena thereby emerge automatically. 
A different paradigm is used when representing points in a multidimensional contin- 
uous space [2,3]. Each unit encodes values in some subset of the space. Typically the 
American Institute of Physics 1988 
653 
subsets are hypercubes or hyperspheres, but they may be more coarsely tuned along 
some dimensions than others [1]. The point to be represented is in the subspace formed 
by the intersection of all active units. As more units are turned on, the accuracy of the 
representation improves. The density and degree of overlap of the units' receptive fie]ds 
determines the system's resolution [7]. 
Yet another paradigm for coarse-coded memories, and the one we will deal with 
exclusive]y, does not involve features. Each concept, or symbol, is represented by an 
arbitrary subset of the units, called its pattern. Unlike in feature-based representations, 
the units in the pattern bear no relationship to the meaning of the symbol represented. A 
symbol is stored in memory by turning on all the units in its pattern. A symbol is deemed 
present if all the units in its pattern are active.  The receptive field of each unit is defined 
as the set of all symbols in whose pattern it participates. We call such memories coarse- 
coded symbol memories (CCSMs). We use the term ""symbol"" instead of ""concept"" to 
emphasize that the internal structure of the entity to be represented is not involved in 
its representation. In CCSMs, a short Hamming distance between two symbols does 
not imply semantic similarity, and is in general an undesirable phenomenon. 
The efficiency with which CCSMs handle sparse memories is the major reason they 
have been used in many connectionist systems, and hence the major reason for studying 
them here. The unit-sharing strategy that gives rise to efficient encoding in CCSMs 
is also the source of their major weakness. Symbols share units with other symbols. 
As more symbols are stored, more and more of the units are turned on. At some 
point, some symbol may be deemed present in memory because all of its units are 
turned on, even though it was not explicitly stored: a ""ghost"" is born. Ghosts are 
an unwanted phenomenon arising out of the overlap among the representations of the 
various symbols. The emergence of ghosts marks the limits of the system's capacity: 
the number of symbols it can store simultaneously and reliably. 
2 Definitions and Fundamental Parameters 
A coarse coded symbol memory in its most general form consists of.' 
set of N binary state units. 
An alphabet of c symbols to be represented. Symbols in this context are atomic 
entities: they have no constituent structure. 
A memory scheme, which is a function that maps each symbol to a subset of 
the units - its pattern. The receptive field of a unit is defined as the set of 
all symbols to whose pattern it belongs (see Figure 1). The exact nature of the 
This criterion can be generalized by introducing a visibility threshold: a fraction of 
the pattern that should be on in order for a symbol to be considered present. Our analy- 
sis deals only with a visibility criterion of 100%, but can be generalized to accommodate 
noise. 
654 
Figure 1: A memory scheme (N = 6, c -- 8) defined in terms of units Ui and symbols 
Sj. The columns are the symbols' patterns. The rows are the units' receptive fields. 
memory scheme mapping determines the properties of the memory, and is the 
central target of our investigation. 
As symbols are stored, the memory fills up and ghosts eventually appear. It is not 
possible to detect a ghost simply by inspecting the contents of memory, since there is 
no general way of distinguishing a symbol that was stored from one that emerged out of 
overlaps with other symbols. (It is sometimes possible, however, to conclude that there 
are no ghosts.) Furthermore, a symbol that emerged as a ghost at one time may not be 
a ghost at a later time if it was subsequently stored into memory. Thus the definition 
of a ghost depends not only on the state of the memory but also on its history. 
Some memory schemes guarantee that no ghost will emerge as long as the number of 
symbols stored does not exceed some specified limit. In other schemes, the emergence 
of ghosts is an ever-present possibility, but its probability can be kept arbitrarily low 
by adjusting other parameters. We analyze systems of both types. First, two more bits 
of notation need to be introduced: 
Pghost: Probability of a ghost. The probability that at least one ghost will appear 
after some number of symbols have been stored. 
k: Capacity. The maximum number of symbols that can be stored simultaneously 
before the probability of a ghost exceeds a specified threshold. If the threshold is 
0, we say that the capacity is guaranteed. 
A localist representation, where every symbol is represented by a single unit and 
every unit is dedicated to the representation of a single symbol, can now be viewed as 
a special case of coarse-coded memory, where k -- N -- c and pghost -- 0. Localist 
representations are well suited for memories that are not sparse. In these cases, coarse- 
coded memories are at a disadvantage. In designing coarse-coded symbol memories we 
are interested in cases where k  N  c. The permissible probability for a ghost in 
these systems should be low enough so that its impact can be ignored. 
655 
3 Analysis of Four Memory Schemes 
3.1 Bounded Overlap (guaranteed capacity) 
If we want to construct the memory scheme with the largest possible c (given N and 
k) while guaranteeing Pghost - 0, the problem can be stated formally as: 
Given a set of size N, find the largest collection of subsets of it such that no 
union of k such subsets subsumes any other subset in the collection. 
This is a well known problem in Coding Theory, in slight disguise. Unfortunately, 
no complete analytical solution is known. We therefore simplify our task and consider 
only systems in which all symbols are represented by the same number of units (i.e. all 
patterns are of the same size). In mathematica] terms, we restrict ourselves to constant 
weight codes. The problem then becomes: 
Given a set of size N, find the largest collection of subsets of size exactlt 
L such that no union of k such subsets subsumes any other subset in the 
collection. 
There are no known complete analytical solutions for the size of the largest collection 
of patterns even when the patterns are of a fixed size. Nor is any efficient procedure 
for constructing such a collection known. We therefore simplify the problem further. 
We now restrict our consideration to patterns whose pairwise overlap is bounded by a 
given number. For a given pattern size L and desired capacity k, we require that no 
two patterns overlap in more than rn units, where: 
Memory schemes that obey this constraint are guaranteed a capacity of at least k 
symbols, since any k symbols taken together can overlap at most L- 1 units in the 
pattern of any other symbol - one unit short of making it a ghost. Based on this 
constraint, our mathematical problem now becomes: 
Given a set of size N, find the largest collection of subsets of size exactly L 
such that the intersection of any two such subsets is of size _ rn (where rn 
is given by equation 1.) 
Coding theory has yet to produce a complete solution to this problem, but several 
methods of deriving upper bounds have been proposed (see for example [4]). The simple 
formula we use here is a variant of the Johnson Bound. Let abo denote the maximum 
number of symbols attainable in memory schemes that use bounded overlap. Then 
abo(N,L, rn) < (') (2) 
-- L 
656 
The Johnson bound is known to be an exact solution asymptotically (that is, when 
N, L, m --* oo and their ratios remain finite). 
Since we are free to choose the pattern size, we optimize our memory scheme by 
maximizing the above expression over all possible values of L. For the parameter sub- 
space we are interested in here (N < 1000, k < 50) we use numerical approximation to 
N 
= max L < max < (3) 
Li,N] m 
obtain: 
(Recall that m is a function of L and k.) Thus the upper bound we derived depicts a 
simple exponential relationship between c and N/k. Next, we try to construct memory 
schemes of this type. A Common Lisp program using a modified depth-first search 
constructed memory schemes for various parameter values, whose c's came within 80% 
to 90% of the upper bound. These results are far from conclusive, however, since only 
a small portion of the parameter space was tested. 
In evaluating the viability of this approach, its apparent optimality should be con- 
trasted with two major weaknesses. First, this type of memory scheme is hard to 
construct computationally. It took our program several minutes of CPU time on a 
Symbolics 3600 to produce reasonable solutions for cases like N = 200, k = 5, m = 1, 
with an exponential increase in computing time for larger values of m. Second, if CC- 
SMs are used as models of memory in naturally evolving systems (such as the brain), 
this approach places too great a burden on developmental mechanisms. 
The importance of the bounded overlap approach lies mainly in its role as an upper 
bound for all possible memory schemes, subject to the simplifications made earlier. All 
schemes with guaranteed capacities can be measured relative to equation 3. 
3.2 Random Fixed Size Patterns (a stochastic approach) 
Randomly produced memory schemes are easy to implement and are attractive because 
of their natura]ness. However, if the patterns of two symbols coincide, the guaranteed 
capacity will be zero (storing one of these symbols will render the other a ghost). We 
therefore abandon the goal of guaranteeing a certain capacity, and instead establish a 
tolerance level for ghosts, Pghost' For large enough memories, where stochastic behavior 
is more robust, we may expect reasonable capacity even with very small Pghost' 
In the first stochastic approach we analyze, patterns are randomly selected subsets 
of a fixed size L. Unlike in the previous approach, choosing k does not bound a. We 
may define as many symbols as we wish, although at the cost of increased probability 
of a ghost (or, alternatively, decreased capacity). The probability of a ghost appearing 
after k symbols have been stored is given by Equation 4: 
Pghost (N, L, k, c) = 1 - 
 TN, I,(k,c)' 1 (4) 
657 
TN, L(k, c) is the probability that exactly c units will be active after k symbols have 
been stored. It is defined recursively by Equation  
TN, L(O, O) = 1 
TN, n(k,c)=O for eitherk=OandcO, ork>Oandc<L 
T v, z; ( k , c ) 1; 
.... 
We have constructed various coarse-coded memories with random fixed-size receptive 
fields and measured their capacities. The experimental results show good agreement 
with the above equation. 
The optimal pattern size for fixed values of N, k, and a can be determined by 
binary search on Equation 4, since Pghost(L) has exactly one maximum in the interval 
[1, N]. However, this may be expensive for large N. A computational shortcut can be 
achieved by estimating the optimal L and searching in a small interval around it. A 
good initial estimate is derived by replacing the summation in Equation 4 with a single 
term involving E[c]: the expected value of the number of active units after k symbols 
have been stored. The latter can be expressed as: 
E[c] -- N. [I-(I-L/N) :] 
The estimated L is the one that maximizes the following expression: 
An alternative formula, developed by Joseph Tebeiskis, produces very good approx- 
imations to Eq. 4 and is much more efficient to compute. After storing k symbols in 
memory, the probability Pz that a single arbitrary symbol x has become a ghost is given 
by: 
P::( N, L, k, o 0 -- (-1) j  / (6) 
j=0 
If we now assume that each symbol's P is independent of that of any other symbol, 
we obtain: 
Pghost  1 - (1 - P)-: (7) 
This assumption of independence is not strictly true, but the relative error was less 
than 0.1% for the parameter ranges we considered, when Pghost was no greater than 
0.01. 
We have constructed the two-dimensional table TN,L(k, c) for a wide range of (N, L) 
values (70 _ N _ 1000, 7 _ L _ 43), and produced graphs of the relationships between 
N, k, a, and Pghost for optimum pattern sizes, as determined by Equation 4. The 
658 
results show an approximately exponential relationship between a and N/k [5]. Thus, 
for a fixed number of symbols, the capacity is proportional to the number of units. Let 
Oirf p denote the maximum number of symbols attainable in memory schemes that use 
random fixed-size patterns. Some typical relationships, derived from the data, are: 
a'/p(Pghost = 0.01)  0.0086. �0.468- 
a,/p(Pghost = 0.001)  0.0008. eo.4,s- 
3.3 Random Peceptors (a stochastic approach) 
A second stochastic approach is to have each unit assigned to each symbol with an 
independent fixed probability s. This method ]ends itself to easy mathematical analysis, 
resulting in a closed-form analytical solution. 
After storing k symbols, the probability that a given unit is active is 1 - (1 - s) k 
(independent of any other unit). For a given symbol to be a ghost, every unit must 
either be active or else not belong to that symbo]'s pattern. That will happen with a 
probability [1-s. (1- s)'] r and thus the probability of a ghost is: 
, 
Pghost (a, N, k, s) 
(o) 
simplified to: 
Pghost ( a, N, k, s) 
from which a can be extracted: 
Assuming Pghost << 1 and k < a (both hold in our case), the expression can be 
_- 
art(N, k, s, Pghost) 
Pghost 
[1 - s' (1 - s):] N 
(10) 
We can now optimize by finding the value of s that maximizes a, given any desired 
upper bound on the expected value of Pghost' This is done straightforwardly by solving 
8a/8s - 0. Note that s. N corresponds to L in the previous approach. The solution is 
s -- 1/(k-- 1), which yields, after some algebraic manipulation: 
rr = Pghost' eNl�g[(k+l)4+/((k+l)k+-kk)] 
(11) 
A comparison of the results using the two stochastic approaches reveals an interesting 
similarity. For large k, with Pghost - 0.01 the term 0.468/k of Equation 8 can be seen 
as a numerical approximation to the log term in Equation 11, and the multiplicative 
factor of 0.0086 in Equation 8 approximates Pghost in Equation 11. This is hardly 
surprising, since the Law of Large Numbers implies that in the limit (N, k -- ee, with 
s fixed) the two methods are equivalent. 
659 
Finally, it should be-noted that the stochastic approaches we analyzed generate 
a family of memory schemes, with non-identical ghost-probabilities. Pghost in our 
formulas is therefore better understood as an expected value, averaged over the entire 
family. 
3.4 Partitioned Binary Coding (a reference point) 
The last memory scheme we analyze is not strictly distributed. Rather, it is somewhere 
in between a distributed and a localist representation, and is presented for comparison 
with the previous results. For a given number of units N and desired capacity k, the 
units are partitioned into k equal-size ""slots,"" each consisting of N/k units (for simplicity 
we assume that k divides N). Each slot is capable of storing exactly one symbol. 
The most efficient representation for all possible symbols that may be stored into 
a slot is to assign them binary codes, using the N/k units of each slot as bits. This 
would allow 2 N/k symbols to be represented. Using binary coding, however, will not 
give us the required capacity of I symbol, since binary patterns subsume one another. 
For example, storing the code '10110' into one of the slots will cause the codes '10010', 
'10100' and '00010' (as well as several other codes) to become ghosts. 
A possible solution is to use only half of the bits in each slot for a binary code, and 
set the other half to the binary complement of that code (we assume that N/k is even). 
This way, the codes are guaranteed not to subsume one another. Let pbc denote the 
number of symbols representable using a partitioned binary coding scheme. Then, 
Opb  = 2/v/2: = e�'S47 ' (12) 
Once again, c is exponential in N/k. The form of the result closely resembles the 
estimated upper bound on the Bounded Overlap method given in Equation 3. There is 
also a strong resemblance to Equations 8 and 11, except that the fractional multiplier in 
front of the exponential, corresponding to Pghost, is missing. Pghost is 0 for the Parti- 
tioned Binary Coding method, but this is enforced by dividing the memory into disjoint 
sets of units rather than adjusting the patterns to reduce overlap among symbols. 
As mentioned previously, this memory scheme is not really distributed in the sense 
used in this paper, since there is no one pattern associated with a symbol. Instead, a 
symbol is represented by any one of a set of k patterns, each N/k bits long, corresponding 
to its appearance in one of the k slots. To check whether a symbol is present, all k slots 
must be examined. To store a new symbol in memory, one must scan the k slots until an 
empty one is found. Equation 12 should therefore be used only as a point of reference. 
4 Measurement of DCPS 
The three distributed schemes we have studied all use unstructured patterns, the only 
constraint being that patterns are at least roughly the same size. Imposing more com- 
plex structure on any of these schemes may is likely to reduce the capacity somewhat. In 
660 
Memory Scheme 
Bounded Overlap 
Random Fixed-size Patterns 
Random Receptors 
Partitioned Binary Coding 
Result 
abo(N, k) < e�'S67 - 
Table 1 Summary of results for various memory schemes. 
order to quantify this effect, we measured the memory capacity of DCPS (BoltzCONS 
uses the same memory scheme) and compared the results with the theoretical models 
analyzed above. 
DCPS' memory scheme is a modified version of the Random Receptors method [5]. 
The symbol space is the set of all triples over a 25 letter alphabet. Units have fixed-size 
receptive fields organized as 6 x 6 x 6 subspaces. Patterns are manipulated to minimize 
the variance in pattern size across symbols. The parameters for DCPS are: N = 2000, 
a = 25 s = 15625, and the mean pattern size is (6/25) 3 x 2000 = 27.65 with a standard 
deviation of 1 5 When P - - = 0.01 the measured capacity was k = 48 symbols. By 
� � gnos 
substituting for N in Equation 11 we find that the highest k value for which czrr _> 15625 
is 51. There does not appear to be a significant cost for maintaining structure in the 
receptive fields. 
5 Summary and Discussion 
Table 1 summarizes the results obtained for the four methods analyzed. Some dif- 
ferences must be emphasized: 
Otbo and Otpbc deal with guaranteed capacity, whereas Otrf p and art are meaningful 
only for Pghost > 0. 
* abo is only an upper bound. 
* Oirf p is based on numerical estimates. 
* Otpb � is based on a scheme which is not strictly coarse-coded. 
The similar functional form of all the results, although not surprising, is aesthetically 
pleasing. Some of the functional dependencies among the various parameters. can be 
derived informally using qualitative arguments. Only a rigorous analysis, however, can 
provide the definite answers that are needed for a better understanding of these systems 
and their scaling properties. 
661 
Acknowledgments 
We thank Geoffrey Hinton, Noga Alon and Victor Wei for helpful comments, and Joseph 
Tebelskis for sharing with us his formula for approximating Pghost in the case of fixed 
pattern sizes. 
This work was supported by National Science Foundation grants IST-8516330 and 
EET-8716324, and by the Office of Naval Research under contract number N00014-86- 
K-0678. The first author was supported by a National Science Foundation graduate 
fellowship. 
References 
[1] Ballard, D H. (1986) Cortical connections and parallel processing: structure and 
function. Behavioral and Brain Sciences 9(1). 
[2] Feldman, J. A., and Ballard, D. H. (1982) Connectionist models and their proper- 
ties. Cognitive Science 6, pp. 205-254. 
[3] Hinton, G. E., McClelland, J. L., and Rumelhart, D. E. (1986) Distributed repre- 
sentations. In D. E. Rumelhart and J. L. McClelland (eds.), Parallel Distributed 
Processing: Ezplorations in the Microstructure of Cognition, volume 1. Cambridge, 
MA: MIT Press. 
[4] 
[5] 
[61 
[7] 
[8] 
[10] 
Macwilliams, F.J., and Sloane, N.J.A. (1978). The Theory of Error-Correcting 
Codes, North-Holland. 
Rosenreid, R. and Touretzky, D. S. (1987) Four capacity models for coarse-coded 
symbol memories. Technical report CMU-CS-87-182, Carnegie Mellon University 
Computer Science Department, Pittsburgh, PA. 
St. John, M. F. and McClelland, J. L. (1986) Reconstructive memory for sentences: 
a PDP approach. Proceedings of the Ohio University Inference Conference. 
Sullins, J. (1985) Value cell encoding strategies. Technical report TR-165, Com- 
puter Science Department, University of Rochester, Rochester, NY. 
Touretzky, D. S., and Hinton, G. E. (1985) Symbols among the neurons: details of 
a connectionist inference architecture. Proceedings of IJCAI-85, Los Angeles, CA, 
pp. 238-243. 
Touretzky, D. S., and Hinton, G. E. (1986) A distributed connectionist produc- 
tion system. Technical report CMU-CS-86-172, Computer Science Department, 
Carnegie Mellon University, Pittsburgh, PA. 
Touretzky, D. S. (1986) BoltzCONS: reconciling connectionism with the recursire 
nature of stacks and trees. Proceedings of the Eighth Annual Conference of the 
Cognitive Science Society, Amherst, MA, pp. 522-530. 
", properti symbol memori rosenfeld touretzki scienc depart mellon univers pennsylvania symbol memori appear sever neural network process order determin model would one first understand mathemat defin gener structur symbol memori deriv relationship among essenti comput capac one scheme agre well actual work memori touretzki connectionist product introduct represent memori scheme entiti repres pattern activ mani unit unit particip represent mani said memori call memori use store symbol sever neural network process touretzki distribut connectionist system dcp distribut implement link list boltzmann con john model case role default memori capac empir paramet adjust trial error obtain desir abl give mathemat foundat experi relationship among fundament memori sever paradigm unit stand semant binari unit code featur binari wherea complic unit group unit requir complic properti numer valu continu unit form represent concept defin intersect featur constitut similar concept binari featur measur ham distanc neural network relationship concept implement via connect among unit form certain gener phenomena therebi emerg differ paradigm use repres point multidimension space unit encod valu subset typic institut physic hypercub may coars tune along dimens other point repres subspac form intersect activ unit turn accuraci densiti degre overlap recept resolut anoth paradigm one deal involv repres subset call unlik unit pattern bear relationship mean symbol store memori turn unit symbol deem unit pattern recept field unit defin set symbol whose pattern call memori symbol memori use term instead intern structur entiti repres involv short ham distanc two symbol impli semant gener undesir effici ccsm handl spars memori major reason use mani connectionist henc major reason studi strategi give rise effici encod ccsm also sourc major symbol share unit symbol unit turn symbol may deem present memori unit even though explicitli ghost unwant phenomenon aris overlap among represent emerg ghost mark limit number symbol store simultan definit fundament paramet coars code symbol memori gener form consist binari state alphabet symbol symbol context atom constitu memori function map symbol subset unit recept field unit defin set symbol whose pattern belong figur exact natur criterion gener introduc visibl fraction pattern order symbol consid deal visibl criterion gener accommod memori scheme defin term unit ui symbol column row recept scheme map determin properti target symbol memori fill ghost eventu detect ghost simpli inspect content sinc gener way distinguish symbol store one emerg sometim conclud symbol emerg ghost one time may ghost later time subsequ store thu definit ghost depend state memori also memori scheme guarante ghost emerg long number store exceed specifi emerg ghost probabl kept arbitrarili low adjust analyz system two bit notat need probabl probabl least one ghost appear number symbol maximum number symbol store simultan probabl ghost exce specifi threshold say capac localist everi symbol repres singl unit unit dedic represent singl view special case pghost localist well suit memori memori design symbol memori interest case permiss probabl ghost system low enough impact analysi four memori scheme bound overlap want construct memori scheme largest possibl guarante pghost problem state formal set size find largest collect subset subset subsum subset well known problem code slight complet analyt solut therefor simplifi task consid system symbol repres number unit restrict constant problem set size find largest collect subset size union subset subsum subset known complet analyt solut size largest collect pattern even pattern fix effici procedur construct collect therefor simplifi problem restrict consider pattern whose pairwis overlap bound given pattern size desir capac requir pattern overlap rn scheme obey constraint guarante capac least sinc symbol taken togeth overlap unit symbol one unit short make base mathemat problem set size find largest collect subset size exactli intersect two subset size rn rn given equat theori yet produc complet solut sever deriv upper bound propos exampl simpl use variant johnson let abo denot maximum symbol attain memori scheme use bound johnson bound known exact solut asymptot oo ratio remain free choos pattern optim memori scheme express possibl valu paramet interest use numer approxim max max function thu upper bound deriv depict exponenti relationship tri construct memori common lisp program use modifi search memori scheme variou paramet whose came within upper result far sinc small portion paramet space evalu viabil appar optim two major type memori scheme hard took program sever minut cpu time produc reason solut case like exponenti increas comput time larger valu use model memori natur evolv system approach place great burden development import bound overlap approach lie mainli role upper possibl memori subject simplif made guarante capac measur rel equat random fix size pattern stochast produc memori scheme easi implement attract pattern two symbol guarante zero one symbol render abandon goal guarante certain instead establish level larg enough stochast behavior may expect reason capac even small first stochast approach pattern randomli select subset fix size unlik previou choos bound defin mani symbol although cost increas probabl ghost decreas probabl ghost appear symbol store given equat probabl exactli unit activ symbol defin recurs equat construct variou memori random recept measur experiment result show good agreement optim pattern size fix valu determin search equat sinc exactli one maximum interv may expens larg comput shortcut estim optim search small interv around initi estim deriv replac summat equat singl involv expect valu number activ unit symbol latter express estim one maxim follow altern develop joseph produc good much effici store symbol probabl pz singl arbitrari symbol becom ghost given assum independ assumpt independ strictli rel error less paramet rang pghost greater construct tabl wide rang produc graph relationship pghost optimum pattern determin equat show approxim exponenti relationship fix number capac proport number let denot maximum number symbol attain memori scheme use typic deriv random stochast second stochast approach unit assign symbol fix probabl method easi mathemat analyt store probabl given unit activ given symbol everi unit must activ els belong happen thu probabl ghost pghost hold express optim find valu maxim given desir bound expect valu done straightforwardli solv note correspond previou solut algebra comparison result use two stochast approach reveal interest larg pghost term equat seen numer approxim log term equat multipl equat approxim pghost equat hardli sinc law larg number impli limit two method stochast approach analyz gener famili memori pghost therefor better understood expect averag entir partit binari code refer last memori scheme analyz strictli somewher distribut localist present comparison previou given number unit desir capac partit consist unit simplic assum divid slot capabl store exactli one effici represent possibl symbol may store slot assign binari use unit slot allow symbol use binari us requir capac sinc binari pattern subsum one store code one slot caus code well sever becom possibl solut use half bit slot binari half binari complement code assum code guarante subsum one let denot symbol represent use partit binari code exponenti form result close resembl upper bound bound overlap method given equat strong resembl equat except fraction multipli correspond pghost binari code enforc divid memori disjoint unit rather adjust pattern reduc overlap among mention memori scheme realli distribut sens sinc one pattern associ repres one set bit correspond appear one check whether symbol slot store new symbol one must scan slot one equat therefor use point measur dcp three distribut scheme studi use unstructur pattern least roughli impos structur scheme may like reduc capac scheme overlap pattern receptor binari code summari result variou memori quantifi measur memori capac dcp con memori compar result theoret model memori scheme modifi version random receptor method symbol space set tripl letter unit field organ pattern manipul minim varianc pattern size across paramet dcp mean pattern size standard measur capac equat find highest valu czrr appear signific cost maintain structur summari discuss summar result obtain four method must otpbc deal guarante wherea otrf art meaning pghost abo upper oirf base numer otpb base scheme strictli similar function form although aesthet function depend among variou inform use qualit rigor definit answer need better understand system scale thank geoffrey noga alon victor wei help joseph share us formula approxim pghost case fix work support nation scienc foundat grant offic naval research contract number first author support nation scienc foundat graduat cortic connect parallel structur behavior brain scienc connectionist model cognit scienc distribut rumelhart clelland parallel distribut ezplor microstructur volum mit theori four capac model technic report carnegi mellon univers scienc reconstruct memori pdp proceed ohio univers infer valu cell encod technic report scienc univers symbol among detail connectionist infer proceed lo distribut connectionist technic report comput scienc mellon reconcil connection recursir stack proceed eighth annual confer scienc,1
42,42,"397 
AN OPTIMIZATION NETWORK FOR MATRIX INVERSION 
Ju-Seog Jang, Soo-Young Lee, and Sang-Yung Shin 
Korea Advanced Institute of Science and Technology, 
P.O. Box 150, Cheongryang, Seoul, Korea 
ABSTRACT 
Inverse matrix calculation can be considered as an optimization. We have 
demonstrated that this problem can be rapidly solved by highly interconnected 
simple neuron-like analog processors. A network for matrix inversion based on 
the concept of Hopfield's neural network was designed, and implemented with 
electronic hardware. With slight modifications, the network is readily applicable to 
solving a linear simultaneous equation efficiently. Notable features of this circuit 
are potential speed due to parallel processing, and robustness against variations of 
device parameters. 
INTRODUCTION 
Highly interconnected simple analog processors which mimic a biological 
neural network are known to excel at certain collective computational tasks. For 
example, Hopfield and Tank designed a network to solve the traveling salesman 
problem which is of the np-complete class, 1 and also designed an A/D converter 
of novel architecture 2 based on the Hopfield's neural network model?' 4 The net- 
work could provide good or optimum solutions during an elapsed time of only a 
few characteristic time constants of the circuit. 
The essence of collective computation is the dissipative dynamics in which ini- 
tial voltage configurations of neuron-like analog processors evolve simultaneously 
and rapidly to steady states that may be interpreted as optimal solutions. Hopfield 
has constructed the computational energy E (Liapunov function), and has shown 
that the energy function E of his network decreases in time when coupling coeffi- 
cients are symmetric. At the steady state E becomes one of local re'raima. 
In this paper we consider the matrix inversion as an optimization problem, 
and apply the concept of the Hopfield neural network model to this problem. 
CONSTRUCTION OF THE ENERGY FUNCTIONS 
Consider a matrix equation AV=I, where A is an input n Xn matrix, V is 
the unknown inverse matrix, and I is the identity matrix. Following Hopfield we 
define n energy functions Ek, k=l, 2, ..., n, 
E 1 = (I/2)[(EAljVjl-1) 2 + (EA2jVjl) 2 + � � � + (EAnjVjl) 2] 
j=l j= j= 
E 2 = (1/2)[(Z AijVj2) 2 + (Z A2jVj2-1) 2 + ' ' ' + (Z AnjVj2) 2] 
j= j= j=l 
American Institute of Physics 1988 
398 
)2 
E = (1/2)[(AuVj) 2 + (A2jVj + � � ' + (AjV.m-1) 2] (1) 
j =1 j --1 j--1 
where A.. and V.. are the elements of ith row and jth column of matrix A and 
sJ s 
V, respectively. hen A is a nonsingular matrix, the m'mimum value (=zero) of 
each energy function is unique and is located at a point in the corresponding 
hyperspace whose coordinates are {Vli:, V2I:, � � � , Vnt: }, k= 1, 2, ..., n. At 
this m'mimum value of each energy function the values of VH, V2, ..., Vnn 
become the elements of the inverse matrix A -1. When A is a singular matrix the 
minimum value (in general, not zero) of each energy function is not unique and is 
located on a contour line of the m'mimum value. Thus, if we construct a model 
network in which initial voltage configurations of simple analog processors, called 
neurons, converge simultaneously and rapidly to the minimum energy point, we can 
say the network have found the optimum solution of matrix inversion problem. 
The optimum solution means that when A is a nonsingular matrix the result is the 
inverse matrix that we want to know, and when A is a singular matrix the result 
is a solution that is optimal in a least-square sense of Eq. (1). 
DESIGN OF THE NETWORK AND THE HOPFIELD MODEL 
Designing the network for matrix inversion, we use the Hopfield model 
without inherent loss terms, that is, 
duik 0 
 = --.El: (VI:, V2I:, ' ' ' , VI:) 
dt OVk 
Vik = gik (Uik )' i, k = 1, 2, ..., n (2) 
where uii: is the input voltage of i th neuron in the k th network, Vii: is its output, 
and the function gik is the input-output relationship. But the neurons of this 
scheme operate in all the regions of gik differently from Hopfield's nonlinear 2- 
state neurons of associative memory models. 3' 4 
From Eq. (1) and Eq. (2), we can define coupling coefficients Tq between 
ith and jth neurons and rewrite Eq. (2) as 
dUik 
dt 
 = -T UVjk + Aki , Tij = ZAliAIj = Tj, , 
Vii: = gii: (uii: )' (3) 
It may be noted that Tij is independent of k and only one set of hardware is 
needed for all k. The implenmented network is shown in Fig. 1. The same set of 
hardware with bias levels,  A jib j, can be used to solve a linear simultaneous 
j=l 
399 
equation represented by Ax=b for a given vector b. 
INPUT 
AK'I AK2 AK, 
VIK V2K V3K 
OUTPUT 
Fig. 1. Implemented network for matrix inversion with externally 
controllable coupling coefficients. Nonlinearity between 
the input and the output of neurons is assumed to be 
distributed in the adder and the integrator. 
The application of the gradient Hopfield model to this problem gives the result 
that is similar to the steepest descent method? But the nonlinearity between the 
input and the output of neurons is introduced. Its effect to the computational 
capability will be considered next. 
CHARACTERISTICS OF THE NETWORK 
For a simple case of 3x3 input matrices the network is implemented with 
electronic hardware and its dynamic behavior is simulated by integration of the 
Eq. (3). For nonsingular input matrices, exact realization of Tq connection and 
bias Ani is an important factor for calculation accuracy, but the initial condition 
and other device parameters such as steepness, shape and uniformity of gin are 
not. Even a complex gik function shown in Fig. 2 can not affect the computa- 
tional capability. Convergence time of the output state is determined by the 
characteristic time constant of the circuit. An example of experimental results is 
shown in Fig. 3. For singular input matrices, the converged output voltage confi- 
guration of the network is dependent upon the initial state and the shape of gin- 
400 
gik(Uik ) 
Vm ,.,X. ik > 1 
..---:1 
-Vm U i k 
-Vm 
Fig. 2. gik functions used in computer simulations where 
kit , is the steepness of sigmoid function tanh (kiiuii ). 
matrix A= -I r 
I O- 
output 
V= 
matrix 
(cf) A-': I 
0.5 -, -,.sj 
0.50 -0.98 -0.49  
0.02 0.99 1.00 / 
0.53 -0.98 -1.50J 
0..5 
Fig. 3. An example of experimental results 
401 
COMPLEXITY ANALYSIS 
By counting operatiom we compare the neural net approach with other well- 
known methods such as Triangular-decomposition and Gauss-Jordan elimination. 6 
(1) Triangular-decomposition or Gains-Jordan elimination method takes 0(8n3/3) 
multi!icatiom/divisiom and additiom for large n Xn matrix inversion, and 
O (2n /3) multiplicatiom/divisiom and additiom for solving the linear simultaneous 
equation Ax=b. 
(2) The neural net approach takes the number of operatiom required to calculate 
Tii (nothing but matrix-matrix multiplication), that is, O (n3/2) multiplicatiom and 
additiom for both matrix inversion and solving the linear simultaneous equation. 
And the time required for output stablization is about a few times the charac- 
teristic time corotant of the network. The calculation of coupling coefficients can 
be directly executed without multiple iteratiom by a specially designed optical 
matrix-matrix multiplier, 7 while the calculation of bias values in solving a linear 
simultaneom equation can be done by an optical vector-matrix multiplier. 8 Thus, 
this approach has a definite advantage in potential calculation speed due to global 
interconnection of simple parallel analog processors, though its calculation accu- 
racy may be limited by the nature of analog computation. A large number of 
controllable Tij interconnectiota may be easily realized with optoelectronic dev- 
ices .9 
CONCLUSIONS 
We have designed and implemented a matrix inversion network based on the 
concept of the Hopfield's neural network model. This network is composed of 
highly interconnected simple neuron-like analog processors which process the infor- 
mation in parallel. The effect of sigmoid or complex nonlinearities on the compu- 
tational capability is unimportant in this problem. Steep sigmoid functiom reduce 
only the convergence time of the network. When a nomingular matrix is given as 
an input, the network converges spontaneously and rapidly to the correct inverse 
matrix regardless of initial conditiom. When a singular matrix is given as an 
input, the network gives a stable optimum solution that depends upon initial con- 
ditiom of the network. 
REFERENCES 
1. J. J. Hopfield and D. W. Tank, Biol. Cybern. 52, 141 (1985). 
2. D. W. Tank and J. J. Hopfield, IEEE Tram. Circ. Sys. CAS-33, 533 (1986). 
3. J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79, 2554 (1982). 
4. J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 81, 3088 (1984). 
5. G. A. Bekey and W. J. Karplus, Hybrid Computation (Wiley, 1968), P. 244. 
6. M. J. Maron, Numerical Analysis: A Practical Approach (Macmillan, 1982), 
p. 138. 
7. H. Nakano and K. Hotate, Appl. Opt. 26, 917 (1987). 
8. J. W. Goodman, A. R. Dias, and I. M. Woody, Opt. Lett. 2, 1 (1978). 
9. J. W. Goodman, F. J. Leonberg, S-Y. Kung, and R. A. Athale, IEEE Proc. 
72.., 850 (1984). 
", optim network matrix invers shin advanc institut scienc box korea matrix calcul consid problem rapidli solv highli interconnect analog network matrix invers base concept neural network implement slight network readili applic linear simultan equat notabl featur circuit potenti speed due parallel robust variat interconnect simpl analog processor mimic biolog network known excel certain collect comput hopfield tank design network solv travel salesman also design convert novel architectur base neural network could provid good optimum solut elaps time characterist time constant essenc collect comput dissip dynam voltag configur analog processor evolv simultan rapidli steadi state may interpret optim hopfield construct comput energi shown energi function network decreas time coupl steadi state becom one local paper consid matrix invers optim appli concept hopfield neural network model energi function matrix equat input xn unknown invers ident follow hopfield energi function institut physic element ith row jth column matrix nonsingular valu energi function uniqu locat point correspond whose coordin valu energi function valu vnn element invers matrix singular matrix valu energi function uniqu contour line construct model initi voltag configur simpl analog call converg simultan rapidli minimum energi network found optimum solut matrix invers optimum solut mean nonsingular matrix result matrix want singular matrix result solut optim sens network hopfield model network matrix use hopfield model inher loss gik input voltag th neuron th function gik neuron oper region gik differ nonlinear neuron associ memori defin coupl coeffici tq jth neuron rewrit uik uvjk aki tij aij may note tij independ one set hardwar implen network shown set bia jib use solv linear simultan repres given vector implement network matrix invers extern coupl nonlinear input output neuron assum adder applic gradient hopfield model problem give result similar steepest descent nonlinear output neuron effect comput consid network simpl case input matric network implement hardwar dynam behavior simul integr nonsingular input exact realiz tq connect ani import factor calcul initi condit devic paramet shape uniform gin even complex gik function shown affect converg time output state determin time constant exampl experiment result singular input converg output voltag network depend upon initi state shape ik gik function use comput simul steep sigmoid function tanh exampl experiment result analysi count operatiom compar neural net approach method elimin method take additiom larg xn matrix additiom solv linear simultan neural net approach take number operatiom requir calcul multiplicatiom matrix invers solv linear simultan time requir output stabliz time time corot calcul coupl coeffici directli execut without multipl iteratiom special design optic calcul bia valu solv linear equat done optic approach definit advantag potenti calcul speed due global simpl parallel analog though calcul may limit natur analog larg number tij interconnectiota may easili realiz optoelectron design implement matrix invers network base neural network network compos interconnect simpl analog processor process effect sigmoid complex nonlinear capabl unimport steep sigmoid functiom reduc converg time nomingular matrix given network converg spontan rapidli correct invers regardless initi singular matrix given network give stabl optimum solut depend upon initi hopfield tank ie bekey hybrid comput numer practic approach nakano ie,2
43,43,"402 
HOW THE CATFISH TRACKS ITS PREY: AN INTERACTIVE ""PIPELINED"" 
PROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS. 
Jagmeet S. Kanwal 
Dept. of Cellular & Structural Biology, Univ. of Colorado, Sch. of 
Medicine, 4200 East, Ninth Ave., Denver, CO 80262. 
ABSTRACT 
Ictalurid catfish use a highly developed gustatory system to 
localize, track and acquire food from their aquatic environment. 
The neural organization of the gustatory system illustrates well 
the importance of the four fundamental ingredients 
(representation, architecture, search and knowledge) of an 
""intelligent"" system. In addition, the ""pipelined"" design of 
architecture illustrates how a goal-directed system effectively 
utilizes interactive feedback from its environment. Anatomical 
analysis of neural networks involved in target-tracking 
indicated that reticular neurons within the medullary region of 
the brainstem, mediate connections between the gustatory 
(sensory) inputs and the motor outputs of the spinal cord. 
Ele ctrophysiological analysis suggested that these neurons 
integrate selective spatic-temporal patterns of sensory input 
transduced through a rapidly adapting-type peripheral filter 
(responding tonically only to a continuously increasing stimulus 
concentration ). The connectivity and response patterns of 
reticular cells and the nature of the peripheral taste response 
suggest a unique ""gustation-seeking"" function of reticulospinal 
cells, which may enable a catfish to continuously track a 
stimulus source once its directionality has been computed. 
INTRODUCTION 
Food search is an example of a broad class of behaviors 
generally classified as goal-directed behaviors. Goal-directed 
behavior is frequently exhibited by animals, humans and some 
machines. Although a preprogrammed, hard-wired machine may achieve 
a particular goal in a relatively short time, the general and 
heuristic nature of complex goal-directed tasks, however, is best 
exhibited by animals and best studied in some of the less advanced 
animal species, such as fishes, where anatomical, electro- 
physiological and behavioral analyses can be performed relatively 
accurately and easily. 
Food search, which may lead to food acquisition and ingestion, 
is critical for the survival of an organism and, therefore, only 
highly successful systems are selected during the evolution of a 
species. The act of food search may be classified into two distinct 
phases, (i) orientation, and (ii) tracking (navigation and homing). 
In the channel catfish (the animal model utilized for this study), 
locomotion (swimming) is primarily controlled by the large forked 
caudal fin, which also mediates turning and directional swimming. 
American Institute of Physics 1988 
403 
Both these forms of movement, which constitute the essential 
movements of target-tracking, involve control of the 
hypaxial/epiaxial muscles of the flank. The alternate contraction 
of these muscles causes caudal fin undulations. Each cycle of the 
caudal fin undulation provides either a symmetrical or an 
asymmetrical bilateral thrust. The former provides a net thrust 
forward, along the longitudinal axis of the fish causing it to move 
ahead, while the latter biases the direction of movement towards the 
right or left side of the fish. 
,,  HRP injection site 
  recording site 
..................................................................................... NEURODIOLOGY ...... I .................................... 
FEEDING BEHAVIOR MUSCLE SET MOTOR POOLS PREMOTOR NEURONS I GUSTATORY INPUTS 
Food Search Flank and Caudal Reticular I Facial Lobe 
Tail Fin Spinal Cord . ............ tl Formation - ......................... 
I Muscles i ..................................................................................................... 
Pick Up 
Selective 
Ingestion 
Flank 
Musculature 
Jaw Muscles 
Oral 'nd 
Pharyngeal 
Musculature 
� 
Rostral Rettcular Facial Lobe 
Spinal Cord . ........... 0 Formation . .......................... 0 
Facial and/or . ............................................................................ l 
Tri�eminal 
Motor Nucleus 
Ya�al Motor 
Nuclei 
Vagal Lobe 
I ntrt nsic 
I nterneurons 
Vagal Lobe 
Fig. I. Schematic representation of possible pathways for the 
gustatory modulation of foraging in the catfish. 
4O4 
Ictalurid catfishes possess a well developed gustatory system 
and use it to locate and acquire food from their aquatic 
environment l, 2,3. Behavioral evidence also indicates that ictalurid 
catfishes can detect small intensity (stimulus concentration) 
differences across their barbels (interbarbel intensity 
differences), and may use this or other extraoral taste information 
to compute the directionality in space and track a gustatory 
stimulus source 1. In other words, based upon the analysis of 
locomotion, it may be inferred that during food search, the 
gustatory sense of the catfish influences the duration and degree of 
asymmetrical or symmetrical undulations of the caudal fin, besides 
controlling reflex turns of the head and flank. Since directional 
swimming is ultimately dependent upon movement of the large caudal 
fin it may be postulated that, if the gustatory system is to 
coordinate food tracking, gustato-spinal connections exist upto the 
level of the caudal fin of the catfish (fig. 1). 
The objectives of this study were (i) to reconsider the 
functional organization of the gustatory system within the 
costraints of the four fundamental ingredients (representation, 
architecture, search and knowledge) of a naturally or artificially 
""intelligent"" agent, (ii) to test the existence of the postulated 
gustato-spinal connections, and (iii) to de lineate as far as 
possible, using neuroanatomical and electrophysiological techniques, 
the neural mechanism/s involved in the control of goal-directed 
(foraging) behavior. 
ORGANIZATIONAL CONSIDERATIONS 
I. REPRESENTATION 
Representation refers to the translation of a particular task 
into information structures and information processes and determines 
to a great extent the efficiency and efficacy with which a solution 
to the task can be generated4. The elaborate and highly sensitive 
taste system of an ictalurid catfish consists of an extensive array 
of chemo- and mechanosensory receptors distributed over most of the 
extraoral as well as oral regions of the epithelium2,5.. 
Peripherally, branches of the facial nerve (which innervates all 
extraoral taste buds resoond to a wide range of stimulus (amino 
acids) concentrationsO,7, .e. from 10-9M to 10-3M. The taste 
activity however, adapts rapidly (phasic response) to ongoing 
stimulation of the same concentration (Fig. 2) and responds 
tonically only to continuously increasing concentrations of stimuli, 
such as L-arginine and L-alanine. 
rp ros 
Fig. :fl. Integrated, facial taste recordings to continuous appli- 
cation of amine acids to the palate and nasal barbel showing the 
phasic nature of the taste responses of the ramus palatinus (rp) 
and ramus ephthalmicus superficialis (res), respectively. 
.L-ALA 
1( 4 
.L-ARG 
4O5 
Gustatory information from the extraoral and oral epithelium is 
""pipelined"" into two separate subsystems, facial and 
glossopharyngeal-vagal, respectively. Each subsystem processes a 
subset of the incoming information (extraoral or oral) and 
coordinates a different component of food acquisition. Food search 
is accomplished by the extraoral subsystem, while selective 
ingestion is accomplished by the oral subsystem 2 (Fig. 3). The 
extraoral gustatory information terminates in the facial lobe where 
it is represented as a well-defined topographic map 9, l0 , while the 
oral information terminates in the adjacent vagal lobe where it is 
represented as a relatively diffuse map ll. 
II. ARCHITECTURE 
The information represented in an information structure 
eventually requires an operating frame (architecture) within which 
to select and carry out the various processes. In ictalurid catfish, 
partially processed information from the primary gustatory centers 
(facial and vagal lobes) in the medullary region of the brainstem 
converges along ascending and descending pathways (Fig. 4). One of 
the centers in the ascending pathways is the secondary gustatory 
nucleus in the isthmic region which is connected to the 
corresponding nucleus of the opposite side via a large 
commissurel2,13. Facial and vagal gustatory information crosses 
over to the opposite side via this commissure thus making it 
possible for neurons to extract information about interbarbel or 
interflank intensity differences. _lthough neurons in this region 
are known to have large receptive fieldsl4, the exact function of 
this large commissural nucleus is not yet clearly established. 
It is quite clear, however, that gustatory information is at 
first ""ipelined"" into separate regions where it is processed in 
parallel �5 before converging onto neurons in the ascending (isthmic) 
and descending (reticular) processors as well as other regions 
within the medulla. The ""pipelined"" architecture underscores the 
need for differential processing of subsets of sensory inputs which 
are consequently integrated to coordinate temporal transitions 
between the various components of goal-directed behavior. 
III. SEARCH 
An important task underlying all ""intelligent"" goal directed 
activity is that of search. In artificial systems this involves 
application of several general problem-solving methods such as 
means-end analysis, generate and test methods and heuristic search 
methods. No attempt, as yet, has been made to fit any of these 
models to the food-tracking behavior of the catfish. However, 
behavioral observations suggest that the catfish uses a 
combinatorial approach resulting in a different yet optimal foraging 
strategy each time 3. 
What is interesting about biological models is that the 
intrinsic search strategy is expressed extrinsically by the behavior 
of the animal which, with a few precautions, can be observed quite 
easily. In addition, simple manipulations of either the animal  or 
its environment can provide interesting data about the search 
4O6 
Fig. 3. 
SENSORY 
FISH BEHAVIORAL 
INPUT BRAI N OUT PUT 
__ arp ix 
b 
ora U 
d X 
oChre I t food search 
and 
pmck uP 
va�al I 
lobe  ..... select,ve 
n�eston 
i ? 
L._ 
VII 
IX 
x 
Fig. 4. 
4O7 
strategy/ies being used by the animal, which in turn can highlight 
some of the computational (neuronal) search strategies adopted by 
the brain e.g. the catfish seems to minimize the probability of 
failure by continuously interacting with the environment so as to be 
able to correct any computational or knowledge-based errors. 
IV. KNOWLEDGE 
If an ""intelligent"" goal-directed system resets to zero 
knowledge before each search trial, its success would depend 
entirely upon the information obtained over the time period of a 
search. Such a system would also require a labile architecture to 
process the varying sets of information generated during each 
search. For such a system, the solution space can become very large 
and given the constraints of time (generally an important criterion 
in biological systems) this can lead to continuous failure. For 
these reasons, knowledge becomes an important ingredient of an 
""intelligent"" agent since it can keep the search under control. 
For the gustatory system of the catfish too, randomly 
accessable knowledge, in combination with the immediately available 
information about the target, may play a critical role in the 
adoption of a successful search strategy. Although a significant 
portion of this knowledge is probably learned, it is not yet clear 
where and how this knowledge is stored in the catfish brain. The 
reduction in the solution space for a catfish which has gradually 
learned to find food in its environment may be attributed to the 
increase in the amount of knowledge, which to some extent may 
involve a restructuring of the neural networks during development. 
EXPERIMENTAL METHODS 
The methods employed for the present study are only briefly 
introduced here. Neuroanatomical tracing techniques exploit the 
phenomenon of axonal transport. Crystals of the enzyme, horseradish 
peroxidase (HRP) or some other substance, when injected at a small 
locus in the brain, are taken up by the damaged neurons and 
transported anterogradely and retrogradely from cell bodies and/or 
axons at the injection site. In the present study, small 
superficial injections of HRP (Sigma, Type VI) were made at various 
loci in the facial lobe (FL) in separate animals. After a survival 
period of 3 to 5 days, the animals were sacrificed and the brains 
sectioned and reacted for visualization of the neuronal tracer. In 
this manner, complex neural circuits can be gradually delineated. 
Electrophysiological recordings from neurons in the central 
nervous system were obtained using heat-pulled glass micropipettes. 
These glass electrodes had a tip diameter of approximately 1 m and 
an impedance of less than 1 megohm when filled with an electrolyte 
(SM KC1 or 5M Nacl). 
Chemical stimulation of the receptive fields was accomplished 
by injection of stimuli (amino acids, amino acid mixtures and liver 
or bait-extract solutions) into a continuous flow of well-water over 
the receptive epithelium. Tactile stimulation was performed by 
gentle strokes of a sable hair brush or a glass probe. 
4O8 
EXPERIMENTAL OBSERVATIONS 
Injections of HRP into the spinal cord labelled two relevant 
populations of cells, (i) in the ipsilateral reticular formation at 
the level of the facial lobe (FL), and (ii) a few large scattered 
cells within the ipsilateral, rostral portion of the lateral lobule 
of the FL (Fig. 5). Injection of HRP at several sites within the FL 
resulted in the identification of a small region in the FL from 
where anterogradely filled fibers project to the reticular formation 
(Fig. 5). Superimposition of these injection sites onto the 
anatomical map of the extraoral surface of the catfish indicated 
that this small region, within the facial lobe, corresponds to the 
snout region of the extraoral surface. 
FACIO-RETICULAR PROJECTIONS 
FACIO- & RETICULO -SPINAL PROJECTIONS 
1 
injection site 
I SpC 
,-, 
� .'""-_';'i ' 
2 
injection site 
3 
CB =cerebellum 
LL =lateral line lobe 
Fig. 5. Schematic chartings showing 
labelled-cell bodies(squares) and fibers 
transverse sections through the medulla. 
(dots) in 
4O9 
FL = facial lobe 
 RF = reticular formation 
 !  SpC = spinal cord 
FLANK SNOUT 
Fig. 6A. 
WATER SQUIRT -HEAD 
GLIDING TOUCH -FLANK 
II! !111 I I I III 111111 ! IJ. iLl. _1. It I I!_ III 
ill II!i  Jill ill dl 11 
LIVER ERA -SND 
AHINO ACID HIURE  
(Receptive (Sample unit responses) 
' CONTROL ' 
,,I.,,h,l],il.l,ll,,[,lllJ,llll[,. !,I]!:, I lil. I, iI...l,.l I....I,..._L, .]]l 
AlIINO ACID I11XTURE  -SNOrt1"" 
Fig. 6B. 
410 
Multiunit electrophysiological recordings from various 
anteroposterior levels of the reticular formation indicated that the 
snout region (upper lip and proximal portion of the maxillary 
barbels) of the catfish project to a disproportionately large region 
of the reticular formation along with a mixed representation of the 
flank (Fig. 6A). 
Single unit recordings indicated that some neurons have 
receptive fields restricted to a bilateral portion of the snout 
region, while others had large receptive fields extending over the 
whole flank or over an anteroposterior half of the body (Fig. 6B). 
DISCUSSION 
The experimental results obtained here suggest that facial lobe 
projections to the reticular formation form a functional connection. 
The reticular neurons project to the spinal cord and, most likely, 
influence the general cycle of swimming-related activity of 
motoneurons within the spinal cord 16. 
The disproportionately large representation of the snout region 
within the medullary reticular formation, as determined 
electrophysiologically, is consistent with the anatomical data 
indicating that most of the fibers projecting to the reticular 
formation originate from cells in that portion of the facial lobe 
where the snout region is mapped. The lateral lobule of the spinal 
cord has a second pathway which projects directly into the spinal 
cord upto the level of the anterior end of the caudal fin and may 
coordinate reflexive turning. 
The significance of the present results is best understood when 
considered together with previously known information about the 
anatomy and electrophysiology of the gustatory system. The 
information presented above is used to propose a model (Fig. 7) for 
a mechanism that may be involved during the homing phase of target 
tracking by the catfish. During homing, which refers to the last 
phase of target-tracking during food search, it may be assumed that 
the fish is rapidly approaching its target or moving through a steep 
signal intensity (stimulus concentration) gradient. The data 
presented above suggest that a neuronal mechanism exists which helps 
the catfish to lock on to the target during homing. This proposal 
is based upon the following considerations: 
I. Owing to the rapidly adapting response of the peripheral filter, 
a tonic level of activity in the facial lobe input can occur only 
when the animal is moving through an increasing concentration 
gradient of the gustatory stimulus. 
2. Facial lobe neurons, which receive inputs from the snout region, 
project to a group of cells in the reticular formation. Activity in 
the facio-reticular pathway causes a suppression in the spontaneous 
activity of the reticular neurons. 
3. Direct and/or indirect spinal projections from the reticular 
neurons are involved in the modulation of activity of those spinal 
motoneurons which coordinate swimming. Thus, it may be hypothesized 
that during complete suppression of activity in a specific reticulo- 
spinal pathway, the fish swims straight ahead, but during excitation 
411 
of certain reticulospinal neurons the fish changes its direction as 
dictated bY the pattern �f activati�n' i 
Fig. 7. The snout region of 
the catfish has secial si-ificance 
because of its extensive 
represetto the 
formation. In same the fish makes a i ..',:] ' '  ."",,"". 
random or computational error, while .-'/ ':'ff I : '""'. 
approaching its target, the snout is -""/ /  ..""N '""': 
the first region to move out of the /: 
Thus, the spinal moroneurons, teleologically speaking, ""seek"" a 
statory stimulus in order to suppress activity of certain 
reticulospinal neurons, which in turn reduce variations in the 
pattem of activity of simming-related spinal moroneurons. 
tccordingly, in a situation where the fish is rapidly approaching a 
target, ie. under the specific conditions of a continuously rising 
stimulus concentration at the snout region and an absence of a 
stimulus intensity difference across the barbels, there is a locking 
of the movement of the body (of the fish) towards the stationary or 
moving target (food or prey). 
It should be pointed out, however, that the empirical data 
available so far, only offers clues to the target-tracking mechanism 
proposed here. Clearly, more research is needed to validate this 
proposal and to identify other mechanisms of target-tracking 
utilized by this biological system. 
This research was supported in part by NIH Grant NS15258 to 
T.E. Finger. 
REFERENCES 
1. P. B. Johnsen and J. H. Teeter, J. Comp. Physiol. 140, 95 (98). 
2. J. Atema, Brain Behav. and Evol. 4, 273-294, (197J). 
3. J. E. Bardash, et al., Science, 155, 1276-1278, (1967). 
4- A. Newell, Mc-Graw Hill Encyclopedia of Electronics and 
Computers, (1984), p.71-74. 
5. C. J. Herrick, Bull. US. Fish. Comm. 22, 237-272, (1904). 
6. J. Caprio, Comp. Bioshem. Physiol. 52A, 247-251, (1975). 
7. C. J. Davenport and J. Caprio, J. Comp. Physiol. 147, 217 (1982). 
8. J. S. Kanwal and J. Caprio, Brain Res. 406, 105-12, (1987). 
9. T. E. Finger, J. Comp. Neurol. 165, 513-526 (1976). 
10. T. Marui and J. Caprio, Brain Res. 23, 185-190 (J982). 
11. J. S. Kanwal and J. Caprio, J. Neurobiol. in press, (988). 
12. C. J. Herrick, J. Comp. Neurol. 15, 375-456 (1905). 
3. C. J. Herrick, J. Comp. Neurol. 16, 403-440 (1906). 
14. C. F. Lamb and J. Caprio, ISOT, #P70, (J986). 
15. T. E. Finger and Y. Motits, Science, 227, 776-778 (1985). 
16. P.S. G. Stein, Handbook of the Spinal Cord, (Marcel Dekker 
Inc., N.Y., 1984), p. 647. 
", catfish track interact system may direct forag via reticulospin kanwal cellular structur ninth co catfish use highli develop gustatori system track acquir food aquat neural organ gustatori system illustr well import four fundament ingredi search design illustr system effect interact feedback anatom neural network involv reticular neuron within medullari region mediat connect gustatori input motor output spinal ctrophysiolog analysi suggest neuron select pattern sensori input rapidli peripher filter tonic continu increas stimulu connect respons pattern cell natur peripher tast respons uniqu function reticulospin may enabl catfish continu track sourc direction search exampl broad class behavior classifi frequent exhibit human although machin may achiev particular goal rel short gener natur complex best anim best studi less advanc behavior analys perform rel may lead food acquisit critic surviv organ success system select evolut act food search may classifi two distinct track channel catfish anim model util primarili control larg fork also mediat turn direct institut physic form constitut essenti involv control muscl altern contract muscl caus caudal fin cycl fin undul provid either symmetr bilater former provid net thrust along longitudin axi fish caus move latter bias direct movement toward left side hrp inject site site neurodiolog behavior muscl set motor pool premotor neuron gustatori input search flank caudal reticular facial lobe fin spinal cord format muscl muscl rettcular facial lobe cord format nucleu motor lobe ntrt nsic nterneuron lobe schemat represent possibl pathway modul forag catfish possess well develop gustatori system use locat acquir food aquat behavior evid also indic ictalurid detect small intens across barbel intens may use extraor tast inform comput direction space track gustatori sourc base upon analysi may infer food sens catfish influenc durat degre symmetr undul caudal besid reflex turn head sinc direct ultim depend upon movement larg caudal may postul gustatori system food connect exist upto caudal fin catfish object studi reconsid organ gustatori system within four fundament ingredi search natur artifici test exist postul de lineat far use neuroanatom electrophysiolog neural involv control consider represent refer translat particular task inform structur inform process determin great extent effici efficaci solut task elabor highli sensit system ictalurid catfish consist extens array mechanosensori receptor distribut well oral region branch facial nerv innerv tast resoond wide rang stimulu tast adapt rapidli ongo concentr respond continu increas concentr ro facial tast record continu amin acid palat nasal barbel show natur tast respons ramu palatinu ramu ephthalmicu superficiali inform extraor oral epithelium two separ facial subsystem process incom inform differ compon food food search accomplish extraor select accomplish oral subsystem gustatori inform termin facial lobe repres topograph map inform termin adjac vagal lobe rel diffus map architectur inform repres inform structur requir oper frame within select carri variou ictalurid process inform primari gustatori center vagal medullari region brainstem along ascend descend pathway one center ascend pathway secondari gustatori isthmic region connect nucleu opposit side via larg facial vagal gustatori inform cross opposit side via commissur thu make neuron extract inform interbarbel intens neuron region known larg recept exact function larg commissur nucleu yet clearli quit gustatori inform separ region process converg onto neuron ascend descend processor well region architectur underscor differenti process subset sensori input consequ integr coordin tempor transit variou compon search import task underli goal direct artifici system involv sever gener method gener test method heurist search made fit behavior observ suggest catfish use approach result differ yet optim forag time interest biolog model search strategi express extrins behavior anim observ quit simpl manipul either anim environ provid interest data search behavior brai put arp ix chre food search use turn highlight comput search strategi adopt brain catfish seem minim probabl continu interact environ correct comput knowledg system reset zero search success would depend upon inform obtain time period system would also requir labil architectur vari set inform gener solut space becom larg given constraint time import criterion biolog lead continu knowledg becom import ingredi agent sinc keep search gustatori system catfish randomli combin immedi avail may play critic role success search although signific knowledg probabl yet clear knowledg store catfish solut space catfish gradual find food environ may attribut amount extent may restructur neural network method method employ present studi briefli neuroanatom trace techniqu exploit axon crystal horseradish inject small taken damag neuron anterograd retrograd cell bodi inject present small inject hrp type made variou facial lobe separ surviv anim sacrif brain react visual neuron complex neural circuit gradual record neuron central system obtain use glass glass electrod tip diamet approxim imped less megohm fill electrolyt stimul recept field accomplish inject stimuli amino acid mixtur liver continu flow recept tactil stimul perform stroke sabl hair brush glass observ hrp spinal cord label two relev ipsilater reticular format level facial lobe larg scatter within rostral portion later lobul fl inject hrp sever site within fl identif small region fl anterograd fill fiber project reticular format superimposit inject site onto map extraor surfac catfish indic small within facial correspond region extraor project reticulo project site site line lobe schemat chart show fiber section facial lobe rf reticular format spinal cord snout squirt touch jill ill dl acid unit control iino acid electrophysiolog record variou level reticular format indic region lip proxim portion maxillari catfish project disproportion larg region reticular format along mix represent unit record indic neuron field restrict bilater portion snout other larg recept field extend flank anteroposterior half bodi experiment result obtain suggest facial lobe reticular format form function reticular neuron project spinal cord gener cycl activ within spinal cord disproportion larg represent snout region medullari reticular determin consist anatom data fiber project reticular origin cell portion facial lobe snout region later lobul spinal second pathway project directli spinal upto level anterior end caudal fin may reflex signific present result best understood togeth previous known inform electrophysiolog gustatori present use propos model mechan may involv home phase target refer last food may assum fish rapidli approach target move steep intens data suggest neuron mechan exist help catfish lock target propos base upon follow owe rapidli adapt respons peripher tonic level activ facial lobe input occur anim move increas concentr gustatori facial lobe receiv input snout group cell reticular activ pathway caus suppress spontan reticular direct indirect spinal project reticular involv modul activ spinal coordin may hypothes complet suppress activ specif fish swim straight excit certain reticulospin neuron fish chang direct pattern snout region catfish extens fish make comput snout first region move spinal teleolog stimulu order suppress activ certain turn reduc variat activ spinal situat fish rapidli approach specif condit continu rise concentr snout region absenc intens differ across lock movement bodi toward stationari target point empir data offer clue mechan research need valid identifi mechan biolog research support part nih grant johnsen brain et hill encyclopedia electron davenport kanwal brain marui brain kanwal lamb finger handbook spinal dekker,1
44,44,"412 
CAPACITY FOR PATTERNS AND SEQUENCES IN KANERVA'S SDM 
AS COMPARED TO OTHER ASSOCIATIVE MEMORY MODELS 
James D. Keeler 
Chemistry Department, Stanford University, Stanford, CA 94305 
and RIACS, NASA-AMES 230-5 Moffett Field, CA 94035. 
e.rnail: jdk hydra.riacs. edu 
ABSTRACT 
The information capacity of Kanerva's Sparse, Distributed Memory (SDM) and Hopfield-type 
neural networks is investigated. Under the approximations used here, it is shown that the to- 
tal information stored in these systems is proportional to the number connections in the net- 
work. The proportionality constant is the same for the SDM and Hopfield-type models in- 
dependent of the particular model, or the order of the model. The approximations are 
checked numerically. This same analysis can be used to show that the SDM can store se- 
quences of spatiotemporal patterns, and the addition of time-delayed connections allows the 
retrieval of context dependent temporal patterns. A minor modification of the SDM can be 
used to store correlated patterns. 
INTRODUCTION 
Many different models of memory and thought have been proposed by scientists over the 
years. In (1943) McCulloch and Pitts proposed a simple model neuron with two states of activity 
(on and off) and a large number of inputs.  Hebb (1949) considered a network of such neurons and 
postulated mechanisms for changing synaptic strengths 2 to learn memories. The learning rule 
considered here uses the outer-product of patterns of +Is and -Is. Anderson (1977) discussed the 
effect. of iterative feedback in such a system) Hopfield (1982) showed that for symmetric connec- 
tions, ' the dynamics of such a network is governed by an energy function that is analogous to the 
energy function of a spin glass? Numerous investigations have been carried out on similar 
modelsfi --a 
Several limitations of these binary interaction, outer-product models have been pointed out. 
For example, the number of patterns that can be stored in the system (its capacity) is limited to a 
fraction of the length of the pattern vectors. Also, these models are not very successful at storing 
correlated patterns or temporal sequences. 
Other models have been proposed to overcome these limitations. For example, one can 
allow higher-order interactions among the neurons. 9't� In the following, I focus on a model 
developed by Kanerva (1984) called the Spame, Distributed Memory (SDM) model.  The SDM 
can be viewed as a three layer network that uses an outer-product learning between the second and 
third layer. As discussed below, the SDM is more versatile than the above mentioned networks 
because the number of stored patterns can increased independent of the length of the pattern, and 
the SDM can be used to store spatiotemporal patterns with context retrieval, and store correlated 
patterns. 
The capacity limitations of outer-product models can be alleviated by using higher-order 
interaction models or the SDM, but a price must be paid for this added capacity in terms of an 
increase in the number of connections. How much information is gained per connection? It is 
shown in the following that the total information stored in each system is proportional to the 
number of connections in the network, and that the proportionality constant is independent of the 
particular model or the order of the model. This result also holds if the connections are limited to 
one bit of precision (clipped weights). The analysis presented here requires certain simplifying 
assumptions. The approximate results are compared numerically to an exact calculation developed 
by Chou.2 
SIMPLE OUTER-PRODUCT NEURAL NETWORK MODEL 
As an example or a simple first-order neural network Model, I consider in detail the model 
developed by Hopfieldfi This model will be used to introduce the mathematics and the concepts 
that will be generalized for the analysis of the $DM. The ""neurons"" are simple two-state 
American Institute of Physics 1988 
413 
threshold devices: The state of the i 'h neuron, ui, is either either +1 (on), or -1 (off). Consider a 
set of n such neurons with net input (local field), hi, to the i 'h neuron given by 
hi = Tii uj, (1) 
where T././ represents the interaction suength between the i ' neuron and the j''. The state of each 
neuron is updated asynchronously (at random) according to the rule 
Ui ('--g (hi), (2) 
where the function g is a simple threshold function g (x) = sign (x). 
Suppose we are given M randomly chosen patterns (strings of length n of :iris) which we 
wish to store in this system. Denote these M memory patterns as pattern vectors: 
p,X = (p  ,pX ..... pp), a -- 1,2,3 ..... M. For example, p might look like 
(+1,-1,+1,-I,-1 ..... +1). One method of storing these patterns is the outer-product (Hebbian) learn- 
ing rule: Start with T-0, and accumulate the outer-products of the pattern vectors. The resulting 
connection matrix is given by 
M 
r:j = rii = 0. (3) 
a=l 
The system described above is a dynamical system with attracting fixed points. To obtain 
an approximate upper bound on the total information stored in this network, we sidestep the issue 
of the basins of attraction, and we check to see if each of the pattsms stored by Eq. (3) is actually 
a fixed point of (2). Suppose we are given one of the patterns, p�, say, as the initial configuration 
of the neurons. I will show that p is expected to be a fixed point of Eq. (2). After inserting (3) 
for T into (1), the net input to the i""' neuron becomes 
h: = f,pix[  p?p?]. (4) 
a= j 
The important term in the sum on a is the one for which a = [3. This term represents the ""sig- 
nal"" between the input p and the desired output. The rest of the sum represents ""noise"" result- 
ing from crosstalk with all of the other stored patterns. The expression for the net input becomes 
h i = signall + noisei where 
signali = p,.[' p? p?], (5) 
J 
noisei = ' plaX[ ' p? PPl. (6) 
Summing on all of the j} in (6) yields signall = (n-1)pi . Since n is positive, the sign of 
the signal term and pi It will be the same. Thus, ff the noise term were exacfiy zero, the signal 
would give the same sign as �: with a magnitude of = n a, and p would be a fixed point of (2). 
Moreover, patterns close to pVwould give nearly the same signal, so that p shotfid be an attract- 
ing fixed point. 
For randomly chosen patterns, <noise > = 0, where < > indicates statistical expectation, and 
its variance will be o 2 = (n-1)a(M-1). The probability that there will be an error on recall ofpi  
is given by the probability that the noise is greater than the signal. For n large, the noise distribu- 
tion is approximately gaussian, and the probability that there is an error in the i t' bit is 
1 
P' = 2do I e-2r:�edx' (7) 
I signal I 
INFORMATION CAPACITY 
The number of paRems that can be stored in the network is known as its capacity. 3'v* How- 
ever, for a fair comparison between all of the models discussed here, it is more relevant to com- 
pare the total number of bits (total information) stored in each model rather than the number of 
414 
patterm. This allows comparison of information storage in models with different lengths of the 
pattern vectors. If we view the memory model as a black box which receives input bit strings and 
outputs them with some small probability of error in each bit, then the definition of bit-capacity 
used here is exactly the definition of channel capacity used by Shannon? 
Define the bit-capacity as the number of bits that can be stored in a network with fixed pro- 
bability of getting an error in a recalled bit, i.e. Pe = constant in (10). Explicitly, the bit-capacity 
is given by TM 
B = bit capacity = nMq, (8) 
where q = (1 + pelog2p, + (1-p,)log2(1-p,)). Note that rl=l for p,=0. Setting p, to a constant is 
tantamount to keeping the signal-to-noise ratio (fidelity) constant, where the fidelity, R, is given by 
R = Isignal I/. Explicitly, the relation between (constant) pe and R, is just R = -l(1 -p,), 
where 
R 
I(R ) = (1/2Jr) 'A I e-t2/2dt' (9) 
Hence, the bit-capacity of these networks can be investigated by examining the fidelity of the 
models as a function of n, M, and R. From (8) and (9) the fidelity of the Hopfield model is is 
R 2 = n/(n(M-1)) � (n>l). Solving for M in terms of (fixed) R and q, the bit-capacity becomes 
B = q[(n 2/R 2)+n ]. 
The results above can be generalized to models with d '' order interactions? 't8 The resulting 
expression for the bit-capacity for d '' order interaction models is just 
It d+l 
B = (10) 
Hence, we see that the number of bits stored in the system increases with the order d. However, 
to store these bits, one must pay a price by including more connections in the connection tensor. 
To demonstrate the relationship between the number of connections and the information stored, 
define the information capacity, 7, to be the total information stored in the network divided by the 
number of bits in the connection tensor (note that thi.q is different than the definition used by Abu- 
Mostafa et al.)? Thus � is just the bit-capacity divided by the number of bits in the tensor T, 
and represents the efficiency with which information is stored in the network. Since T has n 
elements, the information capacity is found to be 
rl (11) 
�= R2b , 
where b is the number of bits of precision used per tensor element (b > 10g2M for no clipping of 
the weights). For large n, the information stored per neuronal coimection is �. q/R 2b, indepen- 
dent of the order of the model (compare this result to that of Peretto, et al.). ' To illustrate this 
point, suppose one decides that the maximum allowed probability of getting an error in a recalled 
bit is p, = 1/1000, then this would fix the !!ainirnum value of R at 3.1. Thus, to store 10,000 bits 
with a probability of getting an error of a recalled bit of 0.001, equation (15) states that it would 
take --'96,000b bits, independent of the order of the model, or =0.1n patterm can be stored with 
probability 1/1000 of getting an error in a recalled bit. 
KANERVA'S SDM 
Now we focus our attention on Kanerva's Sparse, Distributed Memory model (SDM). n The 
SDM can be viewed as a 3-layer network with the middle layer playing the role of hidden units. 
To get an autoassociative network, the output layer can be fed back into the input layer, effectively 
making thi.q a two layer network. The first layer of the SDM is a layer of n, :kl input units (the 
input address, a), the middle layer is a layer of m, hidden units, s, and the third layer consists of 
the n +1 output units (the data, d). The connections between the input units and the hidden units 
are random weights of :t:1 and are given by the rn xn matrix A. The connections between the hid- 
den units and the output units are given by the n xm connection matfix C, and these matrix ele- 
ments are modified by an outer-product learning rule (C ill analogous to the matrix T of the 
Hopfield model). 
415 
Given an input pattern a, the hidden unit activations are determined by 
s = 0,(Aa), 
(12) 
where 0, is the Hamming-distance threshold function: The k h element is 1 if the input a is at 
most r Hamming units away from the k""' row in A, and 0 if it is further than r units away, i.e., 
l if A(n-xi) <-0 
0(x); = 0 if A(n-xi)>r. (13) 
The hidden-units vector, or select vector, s, is mostly Os with an average of 15m Is, where 15 is 
some small number dependent on r; 15n:1. Hence, s represents a large, sparsely coded vector of Os 
and �ls representing the input address. The net input, h, to the final layer can be simply expressed 
as the product of C with s: 
h = C s. (14) 
F'mally, the output data is given by d = g(h), where gi (hi) = sign (hi). 
To store the M patterns, pt,p2,... pt, form the outer-product of these pattern vectors and 
their correspooding select vectors, 
M 
C = p%=r, (15) 
where T denotes the transpose of the vector, and where each select vector is formed by the 
corresponding address, s'= 0(Ap'). The storage algorithm (15) is an outer-product learning rule 
similar to (3). 
Suppose that the M patterns (p,p2,... pSt) have been stored according to (15). Follow, ing 
the analysis presented for the Hopfield model, I show that if the system is presented with pP as 
input, the output will be p, (i.e. p is a fixed point). Setting a = p in (16) and separating terms 
as before, the net input (18) becomes 
M 
h = dl(s-s ) +  p=(s=-s). (16) 
where the first term represents the signal and the second is the noise. Recall that the select vectors 
have an average of �m ls and the remainder Os, so that the expected value of the signal is &n s 0. 
Assuming that the addresses and data are randomly chosen, the expected value of the noise 
is zero. To evaluate the fidelity, I make certain approximations. First, I assume that the select vec- 
tors are independent of each other. Second, I assume that the variance of the signal alone is zero 
or small compared to the variance of noise term alone. The first assumption will be valid for 
m152<I, and the second assumption will be valid for MS>l. With these assumptions, we can 
easily calculate the variance of the noise term, because each of the select vectors are i.i.d. vectors 
of length rn with mostly Os and =m Is. With these assumptions, the fidelity is given by 
R 2 = (17) 
[(M-l)(l+152m (1-1/m))]' 
In the limit of large m, with 15m = constant, the number of stored bits scales as 
mn 
B = q[R2(l+152 m + n]. (18) 
) 
If we divide this by the number of elements in C, we find the information capacity, � = q/R 2b, 
just as before, so the information capacity is the same for the two models. (If we divide the bit 
capacity by the number of elements in C and A then we get �=q/Re(b+l), which is about the 
same for large M.) 
A few comments before we continue. First, it should be pointed out that the assumption 
made by Kanerva t and Keeler TM that the variance of the signal term is much less than that of 
the noise is not valid over the entire range. If we took this in.to account, then the magnitude of the 
denominator would be increased by the variance of the signal tenn. Further, if we read at a dis- 
tance I away from the write address, then it is easy to see that the signal changes to be m S(1), 
where (1) the overlap of two spheres of radius r length I apart in the binomial space n 
416 
(8 -- (0) ). The fidelity for reading at a distance I away from the write address is 
R: = m282(1) 
m (l )(1---(l )) + (M-1)m 82+(M-1 'm 2(1-1/m )' 
(19) 
Compare this to the formula derived by Chou, t2 for the exact signal-to-noise ratio: 
R z = m28:(1) 
m (l )(1-(1 )) + (M-1)m gn +(M-1)nm2( 1-1/m ))' 
(20) 
where g r is e average overlap of the spheres of radius r bmomially distributed with parameters 
(n,1/2) '-'arid o  is the square of this overlap. The difference in these two formulas lies in the 
denominator in the terms 82 verses g. and 8 ' rs. c.. The difference comes from the fact that 
Chou correctly calculates the overlap of the spheres without using the independence assumption. 
How do these formula's differ? First of all, it is found numerically that 82 is identical with 
I1 .. Hence, the only difference comes from 8 ' verses c.. For m 8: < 1, the 8 ' term is negligi- 
ble compared to the other terms in the denominator. In addition, 8 a and c 2 are approximately 
equal for large n and r=n/2. Hence, in the limit n-oo the two formulas agree over most of the 
range ifM=O. lm, m:2  . However, for finite n, the two formulas can disagree when m8Z=l (see 
Figure 1). 
Signal-to-Noise 
2O 
Ratios 
zq. 
zq. 
Zq. (ao) 
20 40 60 
Hamming Radius 
Figure 1: A comparison of the fidelity calculations of the SDM for typical n, M, andre 
values. Equation (17) was derived assuming no variance of the signal term, and is shown 
by the + line. Equation (19) uses the approximation that all of the select vectors are 
indep.e.ndent denoted by the o line. Equation (20) (*'s) is the exact derivation done by 
Chou t2. The values used here were n = 150, m = 2000, M = 100. 
417 
Equation (20) suggests that flrl i is a best read-write Hamming radius for the SDM. By set- 
ting I = 0 in (19) and by setting ..d5 = 0, we get an approximate expression for the best Ham- 
ming radius: 8 ={2Mrr -1/3. This trend is qualitatively shown in Figure 2. 
49.0 
dLsLomce 
52.� 
SS. g 
Figure 2: Numerical investigation of the capacity of the SDM. The vertical axis is the per- 
cent of recovered patterns with no errors. The x-axis (left to right) is the Hamming dis- 
tance used for reading and writing. The y-axis (back to forwar. d) is the number of patterns 
that were written into the memory. For this investigation, n = 128, rn = 1024, and M 
ranges from 1 to 501. Note the similarity of a cross-section of this graph at constant M 
with Figure 1. This calculation was performed by David Colan at RIACS, NASA-Ames. 
Figure 1 indicates that the formula (17) that neglected the variance of the signal term is 
incorrect over much of the range. However, a variant of the SDM is to constrain the number of 
selected locations to be constant; circuitry for doing this is easily built. n The variance of the sig- 
nal term would be zero in that case, and the approximate expression for the fidelity is given by Eq. 
(17). There are certain problems where it would be better to keep 8 = constant, as in the case of 
correlated patterns (see below). 
The above analysis was done assuming that the elements (weights) in the outer-product 
matrix are not clipped i.e. that there are enough bits to store the largest value of any matrix ele- 
menL It is interesting to consider what happens if we allow these values to be represented by only 
a few bits. If we consider the case case b = 1, i.e. the weights are clipped at one bit, it is easy 
to show t7 that y2q/.R z for the d 'h order models and for thd SDM, which yields � = 0.07 for rea- 
sonable R, (this is substantially less than Willshaw's 0.69). 
418 
SEQUENCES 
In an autoassociative memory, the system relaxes to one of the stored patterns and stays 
fixed in time until a new input is presented. However, there are many problems where the recalled 
panems must change sequenfially in time. For example, a song can be remembered as a string of 
notes played in the correct sequence; cyclic panems of muscle contractions axe essential for walk- 
ing, riding a bicycle, or dribbling a basketball. As a first step we consider the very simplisfic 
sequence production as put forth by Hopfield (1982) and Kanerva (1984). 
Suppose that we wished to store a sequence of panems in the SDM. Let the pattern vectors 
be given by (pl,p2 ..... pSt). This sequence of patterns could be stored by having each pattem 
point to the next pattern in the sequence. Thus, for the SDM, the panems would be stored as 
input-output pairs (a"",d'z), where a ' = p' and d'x= pi for tz = 1,2,3,...34-1. Convergence to 
this sequence works as follows: If the SDM is presented with an address that is close to p the 
read data will be close to p2. Iterating the system with p2 as the new input address, the read data 
will be even closer to pa. As this itemfive process continues, the read data will converge to the 
stored sequence, with the next pattern in the sequence being presented at each time step. 
The convergence statisfics are essenfially the same for sequential patterns as that shown 
above for autoassociative panems. Presented with p,X as an input address, the signal for the stored 
sequence is found as before 
<signal> = &n p=+. (21) 
Thus, given p"", the read data is expected to be p,X+. Assuming that the patterns in the sequence 
are randomly chosen, the mean value of the noise is zero, with variance 
<oa> = (M-1)5'-rn (l+52(rn -1)). (22) 
Hence, the length of a sequence t_hat can be stored in the SDM increases linearly with m for large 
/9l. 
Attempting to store sequences like this in the Hopfield model is not very successful due to 
the asynchronous updating use in the Hopfield model. A synchronously updated outer-product 
model (for example [6]) would work just as described for the SDM, but it would still be limited to 
storing fraction of the word size as the maximum sequence length. 
Another method for storing sequences in Hop. field-like networks has been proposed indepen- 
dently by Kleinfeld  and Sompolinsky and Kanter. 23 These models relieve the problem created by 
asynchronous updating by using a time-delayed sequential term. This time-delay storage algorithm 
has different dynamics than the synchronous SDM model. In the time-delay algorithm, the system 
allows time for the units to relax to the first pattern before proceeding on to the next pattern, 
whereas in the synchronous algorithms, the sequence is recalled imprecisely from imprecise input 
for the first few iterations and then correctly after that. In other words, convergence to the 
sequence takes place ""on the fly"" in the synchronous models -- the system does not wait to zero 
in on the fast pattern before proceeding on to recover the following panems. This allows the syn- 
chronous algorithms to proceed k times as fast as the asynchronous time-delay algorithms with 
half as many (variable) matrix elements. This difference should be able to be detected in biological 
systems. 
TIME DELAYS AND HYSTERESIS: FOLDS 
The above scenario for storing sequences is inadequate to explain speech recognifion or pat- 
tern generation. For example, the above algorithm cannot store sequences of the form ABAC, or 
overlapping sequences. In Kanerva's original work, he included the concept of time delays as a 
general way of storing sequences with hysteresis. The problem addressed by this is the following: 
Suppose we wish to store two sequences of panems that overlap. For example, the two pattern 
sequences (a,b,c,d,e,f,...) and (x,yz,d,w,v,...) overlap at the panera d. If the system only has 
knowledge of the present state, then when given the input d, it cannot decide whether to output w 
or e. To store two such sequences, the system must have some knowledge of the immediate past. 
Kanerva incorporates this idea into the SDM by using ""folds."" A system with F+I folds has a 
time history of F past states. These F states may be over the past F time steps or they may go 
even further back in time, skipping some time steps. The algorithm for reading from the SDM with 
folds becomes 
d(t+l) = g(C�'s(t) + C t's(t-x) + � � � + C F's(t--xt:)), (23) 
419 
where s(t---= 0(Aa(t---l)). 
I 2 .. 2x t...t 2, 
(P/,P ..... m  .... ,v ... 
C  +t  
=wEEp , 
M 1 
To store the Q pattem sequences (p,p ..... Pt ), 
,p{2e), construct the matrix of the [yh fold as follows: 
(24) 
= 0(Ap ), and w is a 
where any vector with a superscript less than 1 is taken to be zero, 
weighting factor that would normally decrease with increasing 13. 
Why do these folds work? Suppose that the system is presented with the pattern sequence 
1 2 114'I ' h 
(Pt,Pt ..... p ), wth eac pattern presented sequentially as input until the zl, time step. For 
simplicity, assme that wl = 1 for all 13. Each term in Eq. (39) will conuibute a signal similar to 
the signal for the single-f61d system. Thus, on the z 'h time step, the signal term coming firore Eq. 
(39) is <signal(t+l)> =F�rnp +t. The signal will have this value until the end of the pattem 
sequence is reached. The mean of the noise terms is zero, with variance 
<noise2> = F(M-1)82m(l+82(m-1)). Hence, the signal-to-noise ratio is 4' times as strong as it 
is for the SDM without folds. 
Suppose further that the second stored pattern sequence happens to match the first stored 
sequence at t = '. The signal term would then be 
signal(t+l) = FiSrn p-t + &np-t. (25) 
With no history of the past (F = 1) the signal is split between p[+t and p+t, and the output is 
ambiguous. However, for F>I, the signal for the first pattern sequence dominates and allows 
retrieval of the remainder of the correct sequence. This formulation allows context to aid in the 
retrieval of stored sequences, and can differentiate between overlapping sequences by using time 
delays. 
The above formulation is still too simplistic in terms of being able to do real recognition 
problems such as speech recognition. First, the above algorithm can only recall sequences at a 
fixed time rate, whereas speech recognition occurs at widely varying rates. Second, the above 
algorithm does not allow for deletions in the incoming data. For example ""seqnce"" can be recog: 
nized as ""sequence"" even though some letters are missing. Third, as pointed out by Lashley"""" 
speech processing relies on hierarchical structures. 
Although Kanerva's original algorithm is too simplistic, a straightforward modification 
allows retrieval at different rates with deletions. To achieve this, we can add on the time-delay 
terms with weights which are smeared out in time. Kanerva's (1984) formulation can thus be 
viewed as a discrete-time formulation of that put forth by Hopfield and Tank, (1987)? Explicitly 
we could write 
h =   W�s(t-_), (26) 
[= t =- 
where the coefficients W. are a discrete approximation to a smooth function which spreads the 
delayed signal out over ume. As a further step, we could modify these weights dynamically to 
optimize the signal coming out. The time-delay patterns could also be placed in a hierarchical 
structure as in the matched filter avalanche structure put forth by Grossberg et al. (1986). 26 
CORRELATED PATTERNS 
In the above associative memories, all of the patterns were taken to be randomly chosen, 
uniformly distributed binary vectors of length n. However, there are many applications where the 
set of input paRems is not uniformly disuibuted; the input patterns are correlated. In mathematical 
terms, the set < of input patterns would not be uniformly distributed over the entire space of 2"" 
possible patterns. Let the probabfli.ty distribution function for the Hamming distance between two 
randomly chosen vectors pX and p from the distribution : be given by the function p(d(pX-pl)), 
where d(x-y) is the Hamming distance between x and y. 
The SDM can be generalized from Kanerva's original formulation so that correlated input 
patterns can be associated with output paRems. For the moment, assume that the distribution set 
c and the probability density function p(x) are known a priori. Instead of constructing the rows 
of the matrix A from the entire space of 2"" patterns, construct the rows of A from the distribution 
r,. Adjust the Hamming distance r so that  = bn = constant number of locations are selected. 
420 
In other words, adjust r so that the value of 8 is the same as given above, where � is determined 
by 
 = (27) 
2  
This implies that r would have to be adjusted dynamically. This could be done, for example, by a 
feedback loop. Circuitry for doing this is easily built,"" and a similar structure appears in the 
Golgi cells in the Cerebellum?. 
Using the same distribution for the rows of A as the distribution of the patterns in  and 
using (27) to specify the choice of r, all of the above analysis is applicable (assuming randomly 
chosen output patterns). If the outputs do not have equal Is and -Is the mean of the noise is not 
0. However, if the distribution of outputs is also known, the system can still be made to work by 
storing l/p+ and l/p_ for Is and -Is respectively, where p� is the probability of getting a 1 or a -1 
respectively. Using this storage algorithm, all of the above formulas hold, (as long as the distribu- 
tion is smooth enough and not extremely dense). The SDM will be able to recover data stored 
with correlated inputs with a fidelity given by Equation (17). 
What if the distribution function : is not known a priori? In that case, we would need to 
have the matrix A learn the distribution p(x). There are many ways to build A to mimic p. One 
such way is to start with a random A matrix and modify the entries of  randomly chosen rows of 
A at each step according to the statistics of the most recent input patterns. Another method is to 
use competitive learning zs-3� to achieve the proper distribution of A. 
The competitive learning algorithm is a method for adjusting the weights Ai; between the 
first and second layer to match this probability density functton, p(x). The t 'n row of the address 
matrix A can be viewd as a vector A,. The competitive learning algorithm holds a competition 
between these vectors, and a few vectors that are the closest (within the Hamming sphere r) to the 
input pattern x are the winners. Each of these winners are then modified slightly in the direction 
of x. For large enou m, this algorithm almost always converges to a distribution of the Ai that 
is the same as p(x)/' The updating equation for the selected addresses is just 
A? = nf - X(A? - x) (28) 
Note for . = 1, this reduces to the so-called unary representation of Baum et al. 3 Vfnich gives 
the maximum efficiency in terms of capacity. 
DISCUSSION 
The above analysis said nothing about the basins of attraction of these memory states. A 
measure of the performance of a content addressable memory shotlid also say something about the 
average radius of convergence of the basin of attraction. The basins are in general quite compli- 
cated �' and have been investigated numerically for the unclipped models and values of n and m 
ranging in the 100s. 2 The basins of attraction for the SDM and the d=l model are very similar in 
their characteristics and their average radius of convergence. However, the above results give an 
upper bound on the capacity by looking at the fixed points of the system (if there is no fixed point, 
there is no basin). 
In summary, the above arguments show that the total information stored in outer-product 
neural networks is a constant times the number of connections between the neurons. This constant 
is independent of the order of the model and is the same (q/R2b) for the SDM as well as higher- 
order Hopfield-type networks. The advantage of going to an architecture like the SDM is that the 
number of patterns that can be stored in the network is independent of the size of the pattern, 
whereas the number of stored patterns is limited to a fraction of the word size for the Willshaw or 
Hopfield architecture. The point of the above analysis is that the efficiency of the SDM in terms 
of information stored per bit is the same as for Hopfield-type models. 
It was also demonstrated how sequences of patterns can be stored m the SDM, and how time 
delays can be used to recover contextual information. A minor modification of the SDM could be 
used to recover time sequences at slightly different rates of presentation. Moreover, another minor 
modification allows the storage of correlated patterns in the SDM. With these modifications, the 
SDM presents a versatile and efficient tool for investigating properties of associative memory. 
421 
Acknowledgements: 
howledged. This work was supported by DARPA contract # 86-A227500-000. 
Discussions with John Hopfield and Pentti Kanerva are gratefully ack- 
REFERENCES 
[1] McCulloch, W. S. & Pitts, W. (1943), Bull. Math. Biophys. $, 115-133. 
[2] Hebb, D. O. (19,19) The Organization of Behavior. John Wiley, New York. 
[3] Anderson, J. A., Solverstein, J. W., Ritz, S. A. & Jones, R. S. (1977) Psych. Rev., 84, 
,112-,151. 
[4] Hopfield, J. J. (1982) Proc. Natn'l. Acad. Sci. USA 79 255,1-2558. 
[5] Kirkpatrick, S. & Sherrington, D. (1978) Phys Rev. 17,138,1-4405. 
[6] Little, W. A. & Shaw, G. L.(1978)Math. Biosci. 39, 281-289. 
[7] Nakano, K. (1972), Association - A model of associative memory, IEEE Trans. Sys. Man 
Cyber. 2, 
[8] Willshaw, D. J., Buneman, O. P. & Longuet-Higgins, H. C., (1969) Nature, 222 960-962. 
[9] Lee, Y. C.; Doolen, G.; Chen, H. H.; Sun, G. Z.; Maxwell, T.; Lee, H. Y.; & Giles, L. 
(1985) Physica, 22D, 276-306. 
[10] Baldi, P., and Venkatesh, S.S., (1987) Phys. Rev. Lett. $8, 913-916. 
[11] Kanerva, P. (1984) Self-propagating Search: A Unified Theory of Memory, Stanford 
University Ph.D. Thesis, and Bradford Books (M1T Press). In press (1987 es0. 
[12] Chou, P. A., The capacity of Kanerva's Associative Memory these proceedings. 
[13] McEliece, R. J., Posner, E. C., Rodemich, E. R., & Venkatesh, S.S. (1986), IEEE Trans. 
on Information Theory. 
[1,1] Amit, D. J., Gutfreund, H. & Sompolinsky, H. (1985) Phys. Rev. Lett. $$, 1530-1533. 
[15] Shannon, C. E., (19,18), Bell Syst. Tech. J., 27, 379,623 (Reprinted in Shannon and Weaver 
19,19). 
[16] Kleinfeld, D. & Pendergraft, D. B., (1987) Biophys. J. $1, ,17-53. ", pattern sequenc sdm compar associ memori model keeler stanford ca moffett ca edu inform capac distribut memori network approxim use shown inform store system proport number connect proportion constant sdm model particular order approxim analysi use show sdm store spatiotempor addit connect allow context depend tempor minor modif sdm store correl differ model memori thought propos scientist culloch pitt propos simpl model neuron two state activ larg number hebb consid network neuron mechan chang synapt strength learn learn rule use pattern anderson discuss iter feedback hopfield show symmetr dynam network govern energi function analog function spin numer investig carri similar limit binari model point number pattern store system limit length pattern model success store pattern tempor model propos overcom one interact among focu model kanerva call distribut memori sdm view three layer network use learn second discuss sdm versatil mention network number store pattern increas independ length sdm use store spatiotempor pattern context store correl capac limit model allevi use model price must paid ad capac term number much inform gain per follow total inform store system proport connect proportion constant independ model order result also hold connect limit bit precis analysi present requir certain simplifi approxim result compar numer exact calcul develop neural network model exampl simpl neural network consid detail model hopfieldfi model use introduc mathemat concept gener analysi simpl institut physic state either either consid neuron net input neuron given repres interact suength neuron state updat asynchron accord rule function simpl threshold function sign given randomli chosen pattern length store denot memori pattern pattern might look like one method store pattern start accumul pattern result matrix given rii system describ dynam system attract fix obtain approxim upper bound total inform store sidestep issu basin check see pattsm store actual fix point suppos given one initi configur show expect fix point insert net input neuron becom import term sum one term repres input desir rest sum repres crosstalk store express net input becom signal noisei yield signal sinc sign signal term pi ff nois term exacfiy signal give sign magnitud would fix point pattern close vwould give nearli shotfid fix randomli chosen indic statist varianc probabl error recal ofpi given probabl nois greater nois approxim probabl error bit signal capac number rem store network known fair comparison model discuss relev total number bit store model rather number allow comparison inform storag model differ length view memori model black box receiv input bit string small probabl error definit exactli definit channel capac use number bit store network fix get error recal pe constant given tm bit capac note set constant keep ratio given isign relat pe network investig examin fidel function fidel hopfield model solv term becom result gener model order result order interact model see number bit store system increas order store one must pay price includ connect connect demonstr relationship number connect inform inform total inform store network divid bit connect tensor differ definit use et thu divid number bit tensor repres effici inform store sinc inform capac found number bit precis use per tensor element clip larg inform store per neuron coimect order model result et illustr suppos one decid maximum allow probabl get error recal would fix valu store bit probabl get error recal bit equat state would independ order patterm store get error recal sdm focu attent distribut memori model view network middl layer play role hidden get autoassoci output layer fed back input effect two layer first layer sdm layer input unit middl layer layer hidden third layer consist output unit connect input unit hidden unit random weight given rn xn matrix connect unit output unit given xm connect matfix matrix modifi learn rule ill analog matrix input pattern hidden unit activ determin threshold element input ham unit away row unit select mostli os averag small number depend repres spars code vector os repres input net final layer simpli express product output data given gi sign store form pattern vector correspood select denot transpos select vector form storag algorithm learn rule pattern store accord ing analysi present hopfield show system present output fix set separ term net input becom first term repres signal second recal select vector averag ls remaind expect valu signal address data randomli expect valu nois evalu make certain assum select independ assum varianc signal alon zero small compar varianc nois term first assumpt valid second assumpt valid calcul varianc nois select vector vector length rn mostli os fidel given limit larg number store bit scale divid number element find inform inform capac two divid bit number element get larg comment point assumpt kanerva keeler tm varianc signal term much less nois valid entir took magnitud would increas varianc signal read away write easi see signal chang overlap two sphere radiu length apart binomi space fidel read distanc away write address formula deriv exact gn averag overlap sphere radiu bmomial distribut paramet squar differ two formula lie term vers differ come fact correctli calcul overlap sphere without use independ first found numer ident differ come vers term compar term approxim larg limit two formula agre finit two formula disagre radiu comparison fidel calcul sdm typic andr equat deriv assum varianc signal shown equat use approxim select vector denot equat exact deriv done valu use suggest best ham radiu set get approxim express best trend qualit shown figur lomc numer investig capac vertic axi recov pattern ham use read number pattern written rn note similar graph constant figur calcul perform david colan indic formula neglect varianc signal term much variant sdm constrain number locat circuitri easili varianc term would zero approxim express fidel given certain problem would better keep case pattern analysi done assum element clip enough bit store largest valu matrix interest consid happen allow valu repres consid case case weight clip one easi show order model thd yield substanti less autoassoci system relax one store pattern stay time new input mani problem recal must chang sequenfi song rememb string play correct cyclic panem muscl contract axe essenti ride dribbl first step consid simplisf product put forth hopfield kanerva wish store sequenc panem let pattern vector given sequenc pattern could store pattem next pattern panem would store pair tz converg sequenc work sdm present address close data close iter system new input read data even closer itemf process read data converg next pattern sequenc present time converg statisf essenfi sequenti pattern shown autoassoci present input signal store found given read data expect assum pattern sequenc randomli mean valu nois varianc length sequenc store sdm increas linearli larg store sequenc like hopfield model success due asynchron updat use hopfield synchron updat exampl would work describ would still limit fraction word size maximum sequenc method store sequenc network propos kleinfeld sompolinski model reliev problem creat updat use sequenti storag algorithm differ dynam synchron sdm system time unit relax first pattern proceed next synchron sequenc recal imprecis imprecis input first iter correctli converg take place synchron model system wait zero fast pattern proceed recov follow allow algorithm proceed time fast asynchron algorithm mani matrix differ abl detect biolog delay fold scenario store sequenc inadequ explain speech recognifion algorithm can not store sequenc form origin includ concept time delay way store sequenc problem address wish store two sequenc panem two pattern overlap panera system present given input can not decid whether output store two system must knowledg immedi incorpor idea sdm use system fold histori past state may past time step may go back skip time algorithm read sdm becom eep store pattem sequenc pt construct matrix fold vector superscript less taken factor would normal decreas increas fold suppos system present pattern sequenc eac pattern present sequenti input time assm term conuibut signal similar signal time signal term come firor signal valu end pattem mean nois term varianc ratio time strong sdm without second store pattern sequenc happen match first store signal term would srn histori past signal split output signal first pattern sequenc domin allow remaind correct formul allow context aid store differenti overlap sequenc use time formul still simplist term abl real recognit speech algorithm recal sequenc time wherea speech recognit occur wide vari allow delet incom exampl even though letter point process reli hierarch origin algorithm straightforward modif retriev differ rate achiev add weight smear formul thu formul put forth hopfield explicitli could write coeffici discret approxim smooth function spread signal could modifi weight dynam signal come pattern could also place hierarch match filter avalanch structur put forth grossberg et pattern associ pattern taken randomli distribut binari vector length mani applic input rem uniformli input pattern mathemat set input pattern would uniformli distribut entir space let distribut function ham distanc two chosen vector distribut given function ham distanc sdm gener origin formul correl input associ output assum distribut set probabl densiti function known instead construct row matrix entir space construct row distribut adjust ham distanc bn constant number locat adjust valu given determin impli would adjust could circuitri easili similar structur appear cell distribut row distribut pattern specifi choic analysi applic randomli output output equal mean nois distribut output also system still made work probabl get use storag formula long smooth enough extrem sdm abl recov data store correl input fidel given equat distribut function known would need matrix learn distribut mani way build mimic one way start random matrix modifi entri randomli chosen row step accord statist recent input anoth method competit learn achiev proper distribut competit learn algorithm method adjust weight second layer match probabl densiti row address viewd vector competit learn algorithm hold competit vector closest ham sphere pattern winner modifi slightli direct larg algorithm almost alway converg distribut ai updat equat select address nf reduc unari represent baum et vfnich give maximum effici term analysi said noth basin attract memori perform content address memori shotlid also say someth radiu converg basin basin gener quit investig numer unclip model valu basin attract sdm model similar characterist averag radiu result give bound capac look fix point system fix argument show total inform store network constant time number connect constant independ order model sdm well advantag go architectur like sdm pattern store network independ size number store pattern limit fraction word size willshaw point analysi effici sdm term inform store per bit also demonstr sequenc pattern store time use recov contextu minor modif sdm could recov time sequenc slightli differ rate anoth minor allow storag correl pattern present versatil effici tool investig properti associ work support darpa contract john hopfield pentti kanerva grate organ john new usa phi associ model associ ie man unifi theori stanford bradford book press capac associ memori ie inform bell shannon weaver,1
45,45,"422 
COMPUTING MOTION USING RESISTIVE NETWORKS 
Christof Koch, Jin Luo, Carver Mead 
California Institute of Technology, 216-76, Pasadena, Ca. 91125 
James Hutchinson 
Jet Propulsion Laboratory, California Institute of Technology 
Pasadena, Ca. 91125 
ABSTRACT
INTRODUCTION 
To us, and to other biological organisms, vision seems effortless. We open 
our eyes and we ""see"" the world in all its color, brightness, and movement. 
Yet, we have great difficulties when trying to endow our machines with similar 
abilities. In this paper we shall describe recent developments in the theory of 
early vision which lead from the formulation of the motion problem as an ill- 
posed one to its solution by minimizing certain ""cost"" functions. These cost 
or energy functions can be mapped onto simple analog and digital resistive 
networks. Thus, we shall see how the optical flow can be computed by injecting 
currents into resistive networks and recording the resulting stationary voltage 
distribution at each node. These networks can be implemented in cMOS VLSI 
circuits and represent plausible candidates for biological vision systems. 
APERTURE PROBLEM AND SMOOTHNESS ASSUMPTION 
In this study, we use intensity-based schemes for recovering motion. Let us 
derive an equation relating the change in image brightness to the motion of the 
image (seea). Let us assume that the brightness of the image is constant over 
time: d]'(z,y,t)/dt = 0. On the basis of the chain rule of differentiation, this 
transforms into 
OI da OI dy 
Om d- q Oy d-- + at = I,u + Iv + I, : V I. v + It = O, (1) 
where we define the velocity v as (u, v) = (da/dt, dy/dt). Because we assume 
that we can compute these spatial and temporal image gradients, we are now 
left with a single linear equation in two unknowns, u and v, the two components 
of the velocity vector (aperture problem). Any measuring system with a finite 
aperture, whether biological or artificial, can only sense the velocity component 
perpendicular to the edge or along the spatial gradient (-It/ ]V� ]). The 
component of motion perpendicular to the gradient cannot, in principle, be 
registered. The problem remains unchanged even if we measure these velocity 
components at many points throughout the image. 
How can this problem be made well-posed, that is, having a unique solu- 
tion depending continuously on the data? One form of ""regulari.ing"" ill-posed 
American Institute of Physics 1988 
423 
problerns is to restrict the class of admissible solutions by imposing appropriate 
constraints '. Applying this method to motion, we shall argue that in gen- 
eral objects are smoothmexcept at isolated discontinuitiesmundergoing smooth 
movements. Thus, in general, neighboring points in the world will have similar 
velocities and the projected velocity field should reflect this fact. We therefore 
impose on the velocity field the constraint that it should be the smoothest as well 
as satisfying the data. As measure of smoothness we choose, the square of the 
velocity field gradient. The final velocity field (u, v) is the one that minimizes 
E(u,v) = ff (I,,u + l',v + I) ' + 
kay,, J (2) 
(b) 
Fig. 1. (a) The location of the horizontal (I,) and vertical (I,3) line processes 
relative to the motion field nngrid. (b) The hybrid resistive network, computing 
the optical flow in the presence of discontinuities. The conductances Tc-j con- 
necting both grids depend on the brightness gradient, as do the conductances 
g and g connecting each node with the battery. For clarity, only two such 
elements are shown. The battery E 0 depends on both the temporal and the 
spatial gradient and is zero if no brightness change occurs. The :: (resp. y) com- 
ponent of the velocity is given by the voltage in the top (resp. bottom) network. 
Binary switches, which make or break the resistive connections between nodes, 
424 
implement motion discontinuities. These switches could be under the control of 
distributed digital processors. Analog cMOS implementations are also feasible s . 
The first term implements the constraint that the final solution should follow 
as closely as possible the measured data whereas the second term imposes the 
smoothness constraint on the solution. The degree to which one or the other 
terms are minimized is governed by the parameter ),. If the data is very ac- 
curate, it should be ""expensive"" to violate the first term and ), will be small. 
If, conversely, the data is unreliable (low signal-to-noise), much more emphasis 
will be placed on the smoothness term. Horn and Schunck x first formulated this 
variational approach to the motion problem. 
The energy E(u,v) is quadratic in the unknown u and v. It then follows 
from standard calculus of variation that the associated Euler-Lagrange equations 
will be linear in u and v: 
(3) 
We now have two linear equations at every point and our problem is therefore 
completely determined. 
ANALOG RESISTIVE NETWORKS 
Let us assume that we are formulating eqs. (2) and (3) on a discrete 2-D 
grid, such as the one shown in fig. la. Equation (3) then transforms into 
Iz2ijltij '4- Ia:ijlyijVij --  (Ui+lj q- Uij+l -- 4Ulj q- Ui--lj q- Uij-1) q- IijIij -- 0 
I, uIuuu + Iuvu - x (,.,i+i + vu+ - 4,.,u + vi-i + ,.,u-x) + IuI, u = o 
(4) 
where we replaced the Laplacian with its 5 point approximation on a rectangular 
grid. We shall now show that this set of linear equations can be solved naturally 
using a particular simple resistive network. Let us apply Kirchhoff's current law 
to the nodne i, j in the top layer of the resistive network shown in fig. lb. We 
then have the following update equation: 
c dt = T(ui+i + uU+ -4uu +ui-i + uu-) (5) 
+ai] (su - + Tc-uO, u - 
where vii is the voltage at node i,j in the bottom network. Once duij/dt = 0 
and dvii/dt -- O, this equation is seen to be identical with eq. (4), if we identify 
425 
T 
(6) 
(b) 
II 
(c) 
(d) 
(e) (f) 
Fig. 2. Motion sequence using synthetic data. (a) and (b) 
three high contrast squares on a homogeneous background. 
velocity data. The inside of both squares contain no data. (d) 
Two images of 
(c) The initial 
The final state 
426 
of the network after 240 iterations, corresponding to the smooth optical flow 
field. (e) Optical flow in the presence of motion discontinuities (indicated by 
solid lines). (f) Discontinuities are strongly encouraged to form at the location 
of intensity edges . Both (e) and (f) show the state of the hybrid network after 
six analog-digital cycles. 
Once we set the batteries and the conductances to the values indicated in 
eq. (6), the network will settlemfollowing Kirchhoff's lawsminto the state of 
least power dissipation. The associated stationary voltages correspond to the 
sought solution: uii is equivalent to the a: component and vii to the y component 
of the optical flow field. 
We simulated the behavior of these networks by solving the above circuit 
equations on parallel computers of the Hypercube family. As boundary condi- 
tions we copied the initial velocity data at the edge of the image into the nodes 
lying directly adjacent but outside the image. 
The sequences in figs. 2 and 3 illustrate the resulting optical flow for syn- 
thetic and natural images. As discussed by Horn and Schunck , the smoothness 
constraint leads to a qualitatively correct estimate of the velocity field. Thus, 
one undifferentiated blob appears to move to the lower right and one blob to 
the upper left. However, at the occluding edge where both squares overlap, the 
smoothness assumption results in a spatial average of the two opposing veloc- 
ities, and the estimated velocity is very small or zero. In parts of the image 
where the brightness gradient is zero and thus no initial velocity data exists (for 
instance, the interiors of the two squares), the velocity estimates are simply the 
spatial average of the neighboring velocity estimates. These empty areas will 
eventually fill in from the boundary, similar to the flow of heat for a uniform 
fiat plate with ""hot"" boundaries. 
MOTION DISCONTINUITIES 
The smoothness assumption of Horn and Schunck  regularizes the aperture 
problem and leads to the qualitatively correct velocity field inside moving ob- 
jects. However, this approach fails to detect the locations at which the velocity 
changes abruptly or discontinuously. Thus, it smoothes over the figure-ground 
discontinuity or completely fails to detect the boundary between two objects 
with differing velocities because the algorithm combines velocity information 
across motion boundaries. 
A quite successful strategy for dealing with discontinuities was proposed by 
Geman and Geman s. We shall not rigorously develop their approach, which is 
based on Bayesian estimation theory (for details seeS,e). Suffice it to say that 
a priori knowledge, for instance, that the velocity field should in general be 
smooth, can be formulated in terms of a Markov Random Field model of the 
image. Given such an image model, and given noisy data, we then estimate 
the ""best"" flow field by some likelihood criterion. The one we will use here 
427 
is the maximum a posterfort estimate, although other criteria are possible and 
have certain advantages 6. This can be shown to be equivalent to minimizing an 
expression such as eq. (2). 
In order to reconstruct images consisting of piecewise constant segments, 
Geman and Geman s further introduced the powerful idea of a line process I. 
For our purposes, we will assume that a line process can be in either one of two 
states: ""on"" (I = 1) or ""off"" (I = 0). They are located on a reg.ar lattice set 
between the original pixel lattice (see fig. la), such that each pixel i,j has a 
h and a vertical ""line process associated with it. If the appropriate 
horizontal Ii5 I 0 
line process is turned on, the smoothness term between the two adjacent pixels 
will be set to zero. In order to prevent line processes from forming everywhere 
and, furthermore, in order to incorporate additional knowledge regarding dis- 
continuities into the line processes, we must include an additional term Vc(I) 
into the new energy function: 
E(, v,h,  v) -  (-,J + v,j + )'- + 
i,j 
(7) 
Vc contains a number of different terms, penalizing or encouraging specific 
configurations of line processes: 
h h h h 
Vc(I) = Gc Z /i./+ Gv E Ii5 (/i./+1 +/i./+2) + G'V'(1), 
i,j i,j 
(8) 
plus the corresponding expression for the vertical line process Ii (obtained by in- 
terchanging i with j and li5 with The first term penalizes each introduction 
of a line process, since the cost C has to be ""payed"" every time a line process 
is turned on. The second term prevents the formation of parallel lines: if either 
h 
li+l or Ii5+2 is turned on, this term will tend to prevent I/ from turning on. 
The third term, GiVe, embodies the fact that in general, motion discontinuities 
occur along extended contours and rarely intersect (for more details see7). 
We obtain the optical flow by minimizing the cost function in eq. (7) with 
respect to both the velocity v and the line processes I a and l"". To find an 
optimal solution to this non-quadratic minimization problem, we follow Koch 
et al. ? and use a purely deterministic algorithm, based on solving Kirchhoff's 
equations for a mixed analog/digitM network (see also s). Our algorithm exploits 
the fact that for a fixed distribution of line processes, the energy function (7) 
is quadratic. Thus, we first initialize the analog resistive network (see fig. 2b) 
according to eq. (6) and with no line processes on. The network then converges to 
428 
the smoothest solution. Subsequently, we update the line processes by deciding 
at each site of the line process lattice whether the overall energy can be lowered 
by setting or breaking the line process; that is, li will be turned on if E(u, v, li = 
l,l"") < v,lj = 0,/v); otherwise, lij = 0. Line processes are switched on 
by breaking the appropriate resistive connection between the two neighboring 
nodes. After the completion of one such analog-digital cycle, we reiterate and 
computemfor the newly updated distribution of line processes--the smoothest 
state of the analog network. Although there is no guarantee that the system will 
converge to the global minimum, since we are using a gradient descent rule, it 
seems to find next-to-optimal solutions in about 10 to 15 analog-digital cycles. 
(a) (b) (a) 
(c) (d) (c) 
(e) 
(b) 
(d) 
(e) (f) 
Figure 3. Optical flow of a moving person. (a) and (b) Two 128 by 128 
pixel images captured by a video camera. The person in the foreground is 
moving toward the right while the person in the background is stationary. The 
noise in the lower part of the image is a camera artifact. (c) Zero-crossings 
superimposed on the initial velocity data. (d) The smooth optical flow after 1000 
iterations. Note that the noise in the lower part of both images is completely 
smoothed away. (e) The final piecewise smooth optical flow. The velocity 
field is subsampled to improve visibility. The evolution of the hybrid network is 
shown after the 1. (a), 3. (b), 5. (c), 7. (d), 10. (e), and 13. (f) analog-digital 
cycle in the right part of the figure. 
The synthetic motion sequence in fig. 2 demonstrates the effect of the line 
429 
processes. The optical flow outside the discontinuities approximately delineating 
the boundaries of the moving squares is zero, as it should be (fig. 2e). However, 
where the two squares overlap the velocity gradient is high and multiple inter- 
secting discontinuities exist. To restrict further the location of discontinuities, we 
adopt a technique used by Gamble and Poggio a to locate depth discontinuities 
by requiring that depth discontinuities coincide with the location of intensity 
edges. Our rationale behind this additional constraint is that with very few 
exceptions, the physical processes and the geometry of the 3-dimensional scene 
giving rise to the motion discontinuity will also give rise to an intensity edge. As 
edges we use the zero-crossings of & Laplacian of a Gaussian convolved with the 
original image 9. We now add a new term Yz_ci to our energy function E, such 
that Yz-ci is zero if lij is off or if Iij is on and a zero-crossing exists between 
locations i and j. If lij -- I in the absence of a zero-crossing, Yz_c i is set 
to 1000. This strategy effectively prevents motion discontinuities from forming 
at locations where no zero-crossings exist, unless the data strongly suggest it. 
Conversely, however, zero-crossings by themselves will not induce the formation 
of discontinuities in the absence of motion gradients (figs. 2f and 3). 
ANALOG VLSI NETWORKS 
Even with the approximations and optirnizations described above, the com- 
putations involved in this and similar early vision tasks require minutes to hours 
on computers. It is fortunate then that modern integrated circuit technology 
gives us a medium in which extremely complex, analog real-time implementa- 
tions of these computational metaphors can be realized 3. 
We can achieve a very compact implementation of a resistive network using 
an ordinary cMOS process, provided the transistors are run in the sub-threshold 
range where their characterstics are ideal for implementing low-current analog 
functions. The effect of a resistor is achieved by a circuit configuration, such as 
the one shown in fig. 4, rather than by using the resistance of a special layer in 
the process. The value of the resulting resistance can be controlled over three 
orders of magnitude by setting the bias voltages on the upper and lower current 
source transistors. The current-voltage curve saturates above about 100 mV; a 
feature that can be used to advantage in many applications. When the voltage 
gradients are small, we can treat the circuit just as if it were a linear resistor. 
Resistances with an effective negative resistance value can easily be realized. 
In two dimensions, the ideal configuration for a network implementation is 
shown in fig. 4. Each point on the hexagonal grid is coupled to six equivalent 
neighbors. Each node includes the resistor apparatus, and a set of sample-and- 
hold circuits for setting the confidence and signal the input and output voltages. 
Both the sample-and-hold circuits and the output buffer are addressed by a 
scanning mechanism, so the stored variables can be refreshed or updated, and 
the map of node voltages read out in real time. 
430 
10-SA 
Vott,: = 
l,z = 100nA 
( b Vr) 
(b) 
Figure 4. Circuit design for a resistive network for interpolating and smoothing 
noisy and sparsely sampled depth measurements. (a) Circuit--consisting of 8 
transistorsmimplementing a variable nonlinear resistance. (b) If the voltage 
gradient is below 100 mV its approximates a linear resistance. The voltage 
controls the maximum current and thus the slope of the resistance, which can 
vary between 1 Mfl and 1 02 3 This cMOS circuit contains 20 by 20 grid 
points on a hexagonal lattice. The individual resistive elements with a variable 
slope controlled by Vv correspond to the term governing the smoothness, ),. At 
those locations where a depth measurement dlj is present, the battery is set to 
this value (Vi,., = did) and the value of the conductance O is set to some fixed 
value. If no depth data is present at that node, O is set to zero. The voltage 
at each node corresponds to the discrete values of the smoothed surface fitted 
through the noisy and sparse measurements ? . 
A 48 by 48 silicon retina has been constructed that uses the hexagonal 
network of fig. 4 as a model for the horizontal cell layer in the vertebrate 
retina �. In this application, the input potentials were the outputs of loga- 
rithmic photoreceptorsmimplemented via phototransistors and the potential 
difference across the conductance T formed an excellent approximation to the 
Lapisclan operator. 
DISCUSSION 
We have demonstrated in this study that the introduction of binary motion 
431 
discontinuities into the algorithm of Horn and Schunck  leads to a dramatically 
improved performance of their method, in particular for the optical flow in the 
presence of a number of moving non-rigid objects. Moreover, we have shown 
that the appropriate computations map onto simple resistive networks. We are 
now implementing these resistive networks into VLSI circuits, using subtheshold 
cMOS technology. This approach is of general interest, because a great number 
of problems in early vision can be formulated in terms of similar non-convex 
energy functions that need to be minimized, such as binocular stereo, edge 
detection, surface interpolation, structure from motion, etc. 2'6's 
These networks share several features with biological neural networks. Spe- 
cifically, they do not require a system-wide clock, they rely on many connections 
between simple computational nodes, they converge rapidly--within several time 
constants--and they are quite robust to hardware errors. Another interesting 
feature is that our networks only consume very moderate amounts of power; the 
entire retina chip requires about 100 pW x0 
Acknowledgments: An early version of this model was developed and im- 
plemented in collaboration with A. L. Yuille s. M. Avalos and A. Hsu wrote the 
code for the Imaging Technology system and E. Staats for the NCUBE. C.K. 
is supported by an ONR Research Young Investigator Award and by the Sloan 
and the Powell Foundations. C.M. is supported by ONR and by the System 
Development Foundation. A portion of this research was carried out at the Jet 
Propulsion Laboratory and was sponsored by NSF grant No. EET-8714710, and 
by NASA. 
REFERENCES 
1. Horn, B. K. P. and Schunck, B. G. Artif. Intell. 17, 185-203 (1981). 
2. Poggio, T., Torre, V. and Koch, C. Nature 317, 314-319 (1985). 
3. Mead, C. Analog VLSI and Neural Systems. Addison-Wesley: Reading, 
MA (1988). 
4. Gamble, E. and Poggio, T. Artif. Intell. Lab. Memo. No. 970, MIT, Cam- 
bridge MA (1987). 
5. Geman, S. and Geman, D. IEEE Trans. PAMI 6, 721-741 (1984). 
6. Marroquin, J., Mitter, S. and Poggio, T. J. Am. Star. Assoc. 82, 76-89 
(X987). 
7. Koch, C., Marroquin, :l. and Yuille, A. Proc. Natl. Acad. Sci. USA 83, 
4263-4267 (1986). 
8. Yuille, A. L. Artif. Intell. Lab. Memo. No. 987, MIT, Cambridge, MA 
(1987). 
9. Mart, D. and Hildreth, E. C. Proc. R. Soc. Lond. B 207, 187-217 (1980). 
10. Sivilotti, M. A., Mahowald, M. A. and Mead, C. A. In: 1987 Stanford VLSI 
Conference, ed. P. Losleben, pp. 295-312 (1987). 
", motion use resist network jin carver mead institut hutchinson propuls california institut technolog biolog vision seem open eye world great difficulti tri endow machin similar paper shall describ recent develop theori vision lead formul motion problem one solut minim certain cost energi function map onto simpl analog digit resist shall see optic flow comput inject resist network record result stationari voltag network implement mo vlsi repres plausibl candid biolog vision problem smooth assumpt use scheme recov let us equat relat chang imag bright motion let us assum bright imag constant basi chain rule oi dy oy defin veloc assum comput spatial tempor imag singl linear equat two two compon veloc vector measur system finit whether biolog sens veloc compon edg along spatial gradient motion perpendicular gradient problem remain unchang even measur veloc mani point throughout problem made uniqu depend continu one form institut physic restrict class admiss solut impos appropri appli method shall argu object smoothmexcept isol discontinuitiesmundergo smooth neighbor point world similar project veloc field reflect therefor veloc field constraint smoothest well satisfi measur smooth squar field final veloc field one minim ff locat horizont vertic line process motion field hybrid resist comput optic flow presenc conduct grid depend bright conduct connect node two batteri depend tempor gradient zero bright chang veloc given voltag top make break resist connect motion switch could control digit analog mo implement also feasibl first term implement constraint final solut follow close possibl measur data wherea second term impos constraint degre one minim govern paramet data violat first term data unreli much emphasi place smooth horn schunck first formul approach motion energi quadrat unknown follow standard calculu variat associ equat linear two linear equat everi point problem therefor resist network us assum formul discret one shown equat transform vij replac laplacian point approxim rectangular shall show set linear equat solv natur particular simpl resist let us appli current law nodn top layer resist network shown follow updat dt vii voltag node bottom equat seen ident identifi motion sequenc use synthet high contrast squar homogen insid squar contain imag initi final state network correspond smooth optic flow optic flow presenc motion discontinu discontinu strongli encourag form locat intens edg show state hybrid network set batteri conduct valu indic network settlemfollow lawsminto state power associ stationari voltag correspond uii equival compon vii compon optic flow simul behavior network solv circuit parallel comput hypercub boundari copi initi veloc data edg imag node directli adjac outsid sequenc illustr result optic flow natur discuss horn schunck smooth lead qualit correct estim veloc undifferenti blob appear move lower right one blob upper occlud edg squar assumpt result spatial averag two oppos estim veloc small part imag bright gradient zero thu initi veloc data exist interior two veloc estim simpli averag neighbor veloc empti area fill similar flow heat uniform plate discontinu smooth assumpt horn schunck regular apertur lead qualit correct veloc field insid move approach fail detect locat veloc abruptli smooth complet fail detect boundari two object differ veloc algorithm combin veloc inform motion quit success strategi deal discontinu propos geman shall rigor develop bayesian estim theori detail suffic say priori veloc field gener formul term markov random field model given imag given noisi estim flow field likelihood one use maximum posterfort although criteria possibl certain advantag shown equival minim order reconstruct imag consist piecewis constant geman introduc power idea line process assum line process either one two locat lattic set origin pixel lattic pixel vertic process associ appropri process turn smooth term two adjac pixel set order prevent line process form everywher order incorpor addit knowledg regard line must includ addit term new energi contain number differ penal encourag specif line gc gv correspond express vertic line process first term penal introduct line sinc cost everi time line process turn second term prevent format parallel either turn term tend prevent turn third embodi fact motion discontinu along extend contour rare intersect detail obtain optic flow minim cost function veloc line process find solut minim follow koch use pure determinist base solv mix network also algorithm exploit fact fix distribut line energi function first initi analog resist network line process network converg smoothest updat line process decid site line process lattic whether overal energi lower set break line turn line process switch break appropri resist connect two neighbor complet one reiter newli updat distribut line smoothest analog although guarante system global sinc use gradient descent find solut optic flow move two imag captur video person foreground toward right person background lower part imag camera initi veloc smooth optic flow note nois lower part imag complet final piecewis smooth optic veloc subsampl improv evolut hybrid network right part synthet motion sequenc demonstr effect line optic flow outsid discontinu approxim delin boundari move squar two squar overlap veloc gradient high multipl discontinu restrict locat techniqu use gambl poggio locat depth discontinu requir depth discontinu coincid locat intens rational behind addit constraint physic process geometri scene rise motion discontinu also give rise intens use laplacian gaussian convolv imag add new term energi function zero lij iij exist lij absenc set strategi effect prevent motion discontinu form locat unless data strongli suggest induc format discontinu absenc motion gradient vlsi network approxim optirn describ involv similar earli vision task requir minut hour fortun modern integr circuit technolog us medium extrem analog comput metaphor realiz achiev compact implement resist network use ordinari mo provid transistor run characterst ideal implement analog effect resistor achiev circuit one shown rather use resist special layer valu result resist control three magnitud set bia voltag upper lower current curv satur use advantag mani voltag treat circuit linear effect neg resist valu easili two ideal configur network implement point hexagon grid coupl six equival node includ resistor set circuit set confid signal input output circuit output buffer address store variabl refresh map node voltag read real circuit design resist network interpol smooth spars sampl depth variabl nonlinear voltag approxim linear voltag maximum current thu slope mfl mo circuit contain grid hexagon individu resist element variabl control correspond term govern locat depth measur dlj batteri set valu valu conduct set fix depth data present set voltag node correspond discret valu smooth surfac fit noisi spars measur silicon retina construct use hexagon model horizont cell layer vertebr input potenti output photoreceptorsmimpl via phototransistor potenti across conduct form excel approxim demonstr studi introduct binari motion algorithm horn schunck lead dramat perform particular optic flow number move shown appropri comput map onto simpl resist implement resist network vlsi use subtheshold mo approach gener great number problem earli vision formul term similar function need binocular edg surfac structur network share sever featur biolog neural requir reli mani connect simpl comput converg sever time quit robust hardwar anoth interest network consum moder amount retina chip requir earli version model develop collabor yuill avalo hsu wrote imag technolog system staat support onr research young investig award sloan powel support onr system portion research carri jet laboratori sponsor nsf grant natur analog vlsi neural ie pami usa stanford vlsi,2
46,46,"432 
Performance Measures for Associative Memories 
that Learn and Forget 
Anthony Kuh 
Department of Electrical Engineering 
University of Hawaii at Manoa 
Honolulu HI, 96822 
ABSTRACT 
Recently, many modifications to the McCulloch/Pitts model have been proposed 
where both learning and forgetting occur. Given that the network never saturates (ceases 
to function effectively due to an overload of information), the learning updates can con- 
tinue indefinitely. For these networks, we need to introduce performance measures in addi- 
tion to the information capacity to evaluate the different networks. We mathematically 
define quantities such as the plasticity of a network, the efficacy of an information vector, 
and the probability of network saturation. From these quantities we analytically compare 
different networks. 
1. Introduction 
Work has recently been undertaken to quantitatively measure the computational 
aspects of network models that exhibit some of the attributes of neural networks. The 
McCulloch/Pitts model discussed in [1] was one of the earliest neural network models to be 
analyzed. Some computational properties of what we call a Hopfield Associative Memory 
Network (HAMN) similar to the McCulloch/Pitts model was discussed by Hopfield in [2]. 
The HAMN can be measured quantitatively by defining and evaluating the information 
capacity as [2-6] have shown, but this network fails to exhibit more complex computational 
capabilities that neural network have due to its simplified structure. The HAMN belongs 
to a class of networks which we call static. In static networks the learning and recall pro- 
cedures are separate. The network first learns a set of data and after learning is complete, 
recall occurs. In dynamic networks, as opposed to static networks, updated learning and 
associative recall are intermingled and continual. In many applications such as in adaptive 
communications systems, image processing, and speech recognition dynamic networks are 
needed to adaptively learn the changing information data. This paper formally develops 
and analyzes some dynamic models for neural networks. Some existing models [7-10] are 
analyzed, new models are developed, and measures are formulated for evaluating the per- 
formance of different dynamic networks. 
In [2-6], the asymptotic information capacity of the HAMN is defined and evaluated. 
In [4-5], this capacity is found by first assuming that the information vectors (IVs) to be 
stored have components that are chosen randomly and independently of all other com- 
ponents in all IVs. The information capacity then gives the maximum number of IVs that 
can be stored in the HAMN such that IVs can be recovered with high probability during 
retrieval. At or below capacity, the network with high probability, successfully recovers 
the desired IVs. Above capacity, the network quickly degrades and eventually fails to 
recover any of the desired IVs. This phenomena is sometimes referred to as the ""forgetting 
catastrophe"" [10]. In this paper we will refer to this phenomena as network saturation. 
There are two ways to avoid this phenomena. The first method involves learning a 
limited number of IVs such that this number is below capacity. After this learning takes 
place, no more learning is allowed. Once learning has stopped, the network does not 
change (defined as static) and therefore lacks many of the interesting computational 
American Institute of Physics 1988 
433 
capabilities that adaptive learning and neural network models have. The second method is 
to incorporate some type of forgetting mechanism in the learning structure so that the 
information stored in the network can never exceed capacity. This type of network would 
be able to adapt to the changing statistics of the IVs and the network would only be able 
to recall the most recently learned IVs. This paper focuses on analyzing dynamic networks 
that adaptively learn new information and do not exhibit network saturation phenomena 
by selectively forgetting old data. The emphasis is on developing simple models and much 
of the analysis is performed on a dynamic network that uses a modified Hebbian learning 
rule. 
Section 2 introduces and qualitatively discusses a number of network models that are 
classified as dynamic networks. This section also defines some pertinent measures for 
evaluating dynamic network models. These measures include the plasticity of a network, 
the probability of network saturation, and the efficacy of stored IVs. A network with no 
plasticity cannot learn and a network with high plasticity has interconnection weights that 
exhibit large changes. The efficacy of a stored IV as a function of time is another impor- 
tant parameter as it is used in determining the rate at which a network forgets informa- 
tion. 
In section 3, we mathematically analyze a simple dynamic network referred to as the 
Attenuated Linear Updated Learning (ALUL) network that uses linear updating and a 
modified Hebbian rule. Quantities introduced in section 3 are analytically determined for 
the ALUL network. By adjusting the attenuation parameter of the ALUL network, the 
forgetting factor is adjusted. It is shown that the optimal capacity for a large ALUL net- 
work in steady state defined by (2.13,3.1) is a factor of e less than the capacity of a 
HAMN. This is the tradeoff that must be paid for having dynamic capabilities. We also 
conjecture that no other network can perform better than this network when a worst case 
criterion is used. Finally, section 4 discusses further directions for this work along with pos- 
sible applications in adaptive signal processing. 
2. Dynamic Associative Memory Networks 
The network models discussed in this paper are based on the concept of associative 
memory. Associative memories are composed of a collection of interconnected elements 
that have data storage capabilities. Like other memory structures, there are two opera- 
tions that occur in associative memories. In the learning operation (referred to as a write 
operation for conventional memories), information is stored in the network structure. In 
the recall operation (referred to as a read operation for conventional memories), informa- 
tion is retrieved from the memory structure. Associative memories recall information on 
the basis of data content rather than by a specific address. The models that we consider 
will have learning and recall operations that are updated in discrete time with the activa- 
tion state X(j) consisting of N cells that take on the values {-1,1). 
2.1. Dynamic Network Measures 
General associative memory networks are described by two sets of equations. I1' we 
let X(j) represent the activation state at time j and W(k) represent the weight matrix or 
interconnection state at time k then the activation or recall equation is described by 
X(/+ 1)= f(X(j),W(k)), j>_0, k>_0, X(0)= _5( (2.1) 
where .r is the data probe vector used for recall. The learning algorithm or interconnec- 
tion equation is described by 
W(k+l)= g(V(i),O<i<k,W(O)) (2.2) 
where { V(i)} are the information vectors (IV)s to be stored and W(0)is the initial state of 
the interconnection matrix. Usually the learning algorithm time scale is much longer than 
434 
the recall equation time scale so that W in (2.1) can be considered time invariant. Often 
(2.1) is viewed as the equation governing short term memory and (2.2) is the equation 
governing long term memory. From the Hebbian hypothesis we note that the data probe 
vectors should have an effect on the interconnection matrix W. If a number of data probe 
vectors recall an IV V(1), the strength of recall of the IV V(i) should be increased by 
appropriate modification of W. If another IV is never recalled, it should gradually be for- 
gotten by again adjusting terms of W. Following the analysis in [4,5] we assume that all 
components of IVs introduced are independent and identically distributed Bernoulli random 
1 
variables with the probability of a I or -1 being chosen equal to . 
Our analysis focuses on learning algorithms. Before describing some dynamic learning 
algorithms we present some definitions. A network is defined as dynamic if given some 
period of time the rate of change of W is never nonzero. In addition we will primarily dis- 
cuss networks where learning is gradual and updated at discrete times as shown in (2.2). 
By gradual, we want networks where each update usually consists of one IV being learned 
and/or forgotten. IVs that have been introduced recently should have a high probability of 
recovery. The probability of recall for one IV should also be a monotonic decreasing func- 
tion of time, given that the IV is not repeated. The networks that we consider should also 
have a relatively low probability of network saturation. 
Quantitatively, we let e(k,l,i) be the event that an IV introduced at time I can be 
recovered at time k with a data probe vector which is of Hamming distance i from the 
desired IV. The efficacy of network recovery is then given as p(k,l,i) = ?r(e(k,l,i)). In 
the analysis performed we say a a vector V can recover V(l), if V(l)= A(V) where A(o) 
is a synchronous activation update of all cells in the network. The capacity for dynamic 
networks is then given by 
C(k,i,e)= maxm-Pr(r(e(k,l,i),O_<l<k)=m)> 1-e 0<i< ---N (2.3) 
-- 2 
where r(X) gives the cardinality of the number of events that occur in the set 35. Closely 
related to the capacity of a network is netsyork saturation. Saturation occurs when the 
network is overloaded with IVs such that few or none of the IVs can be successfully 
recovered. When a network at time 0 starts to learn Ivs, at some time l < j we have that 
C(l,i,e)_>C(j,i,e). For k_>l the network saturation probability is defined by S(k,rn) 
where $ describes the probability that the network cannot recover m Ivs. 
Another important measure in analyzing the performance of dynamic networks is the 
plasticity of the interconnections of the weight matrix W. Following definitions that are 
similar to [10], define 
N 
N(N-4) (2.4) 
as the incremental synaptic intensity and 
N 
E Ev^{ 
= (2.5) 
as the cumulative synaptic intensity. From these definitions we can define the plasticity of 
the network  
= 
When network plticity is zero, the network does not change and no learning takes place. 
When plticity is high, the network interconnections exhibit large changes. 
435 
When analyzing dynamic networks we are often interested if the network reaches a 
steady state. We say a dynamic network reaches steady state if 
lim H(k) = H (2.7) 
where H is a finite nonzero constant. If the IVs have stationary statistics and given that 
the learning operations are time invariant, then if a network reaches steady state, we have 
that 
limP(k)= P (2.8) 
k-*oo 
where P is a finite constant. It is also easily verified from (2.6) that if the plasticity con- 
verges to a nonzero constant in a dynamic network, then given the above conditions on the 
IVs and the learning operations the network will eventually reach steady state. 
Let us also define the synaptic state at time k for activation state V as 
(k,V) = W(k)V (2.9) 
From the synaptic state, we can define the SNR of V, which we show in section 3 is 
closely related to the efficacy of an IV and the capacity of the network. 
V)))"" 
SNR(k,V,i) = VAR(s,(k,V)) (2.10) 
Another quantity that is important in measuring dynamic networks is the complexity 
of implementation. Quantities dealing with network complexity are discussed in [12] and 
this paper focuses on networks that are memoryless. A network is memoryless if (2.2) can 
be expressed in the following form: 
W(k+ l) = g*(W(k),V(k)) (2.11) 
Networks that are not memoryless have the disadvantage that all IVs need to be saved dur- 
ing all learning updates. The complexity of implementation is greatly increased in terms of 
space complexity and very likely increased in terms of time complexity. 
2.2. Examples of Dynamic Associative Memory Networks 
The previous subsection discussed some quantities to measure dynamic networks. 
This subsection discusses some examples of dynamic associative memory networks and 
qualitatively discusses advantages and disadvantages of different networks. All the net- 
works considered have the memoryless property. 
The first network that we discuss is described by the following diffcrence equation 
(k+l) = ()(') + S(k)(V(X')) k> (2..) 
with W(0) being the initial value of weights before any learning has taken place. Networks 
with these learning rules will be labeled as Linear Updated Learning (LUL) networks and 
in addition if 0<a(k)<l for k_>0 the network is labeled as an Attenuated Linear Updated 
Learning (ALUL) network. We ,viii primarily deal with ALUL where 0<a(k)<l and b(k) 
do not depend on the position in W. This model is a specialized version of Grossberg's 
Passive Decay LTM equation discussed in [11]. If the learning algorithm is of the correla- 
tion type then 
(V('))= V(k)V(k) ? - k>  (�-.la) 
This learning scheme has similarities to the marginalist learning schemes introduced in [10]. 
One of the key parameters in the ALUL network is the value of the attenuation coefficient 
a. From simulations and intuition we know that if the attenuation coefficient is to high, 
the network will saturate and if the attenuation parameter is to low, the network will 
436 
forget all but the most recently introduced Fvrs. Fig. 1 uses Monte Carlo methods to show 
a plot of the number of 1Vs recoverable in a 64 cell network when a= 1, (the HAMN) as a 
function of the learning time scale. From this figure we clearly see that network saturatiou 
is exhibited and for the time k>_ 25 no IV are recoverable with high probability. Section 3 
further analyzes the ALUL network and derives the value of different measures introduced 
in section 2.1. 
Another learning scheme called bounded learning (BL) can be described by 
V�) re.) r _,r F(W()> X, 
L(V(k)) = 0 F(W(k))< (2.14) 
By setting the attenuation parameter a = 1 and letting 
F(W(k)) = max W,,j.(k) (2.15) 
this is identical to the learning with bounds scheme discussed in [10]. Unfortunately there 
is a serious drawbacks to this model. If  is too large the network will saturate with high 
probability. If A is set such that the probability of network saturation is low then the net- 
work has the characteristic of not learning for almost all values of 
k  k()-- min 1-F(W(I))_.. Therefore we have that the efficacy of network 
recovery, p(k,l,O)  0 for all k _ l _ k(A ). 
In order for the (BL) scheme to be classified as dynamic learning, the attenuation 
parameter a must have values between 0 and 1. This learning scheme is just a more com- 
plex version of the learning scheme derived from (2.10,2.11). Let us qualitatively analyze 
the learning scheme when a and b are constant. There are two cases to consider. When 
A H, then the network is not affected by the hounds and the network behaves as the 
ALUL network. When A <H, then the netxvork accepts IVs until the bound is reached. 
When the hound is reached, the network waits until the values of the interconnection 
matrix have attenuated to the prescribed levels where learning can continue. If A is judi- 
ciously chosen, BL with a <1 provides a means for a network to avoid saturation. By 
holding an IV until H(k)<., it is not too difficult to show that this learning scheme is 
equivalent to an ALUL network with b(k) time varying. 
A third learning scheme called refresh learning (RL) can be described by (2.12) with 
b(k)= 1, W(O)= O, and 
a(k)= 1-5(kmod(l)) (2.16) 
This learning scheme learns a set of IV and periodically refreshes the weighting matrix so 
that all interconnections are 0. RL can be classified as dynamic learning, but learning is 
not gradual during the periodic refresh cycle. Another problem with this learning scheme is 
that the efficacy of the Ivs depend on where during the period they were learned. IVs 
learned late in a period are quickly forgotten where as IVs learned early in a period have a 
longer time in which they are recoverable. 
In all the learning schemes introduced, the network has both learning and forgetting 
capabilities. A network introduced in [7,8] separates the learning and forgetting tasks by 
using the standard HA_MN algorithm to learn IV and a random selective forgetting algo- 
rithm to unlearn excess information. The algorithm which we call random selective forget- 
ting (RSF) can be described formally as follows. 
where 
W(k+ 1)= �(k) + L(V(k)) k_>l (2.17) 
Y(k)-- W(k)-y(k)  (V(k,i)V(k,i)r--n(F(W(k)))I) (2.18) 
437 
Each of the vectors V(k,i) are obtained by choosing a random vector V in the same 
manner IVs are chosen and letting V be the initial state of the HAMN with interconnection 
matrix W(k). The recall operation described by (2.1) is repeated until the activation has 
settled into a local minimum state. V(k,i) is then assigned this state. /t(k) is the rate at 
which the randomly selected local minimum energy states are forgotten, W(k) is given by 
(2.15), and n (X) is a nonnegative integer valued function that is a monotonically increasing 
function of X. 
The analysis of the RSF algorithm is difficult, because the energy manifold that 
describes the energy of each activation state and the updates allowable for (2.1) must be 
well understood. There is a simple transformation between the weighting matrix and the 
energy of an activation state given below, 
Ew,,;x,.(i)x;(k) (2.19) 
but aggregately analyzing all local minimum energy activation states is complex. Through 
computer simulations and simplified assumptions [7,8] have come up with a qualitative 
explanation of the RSF algorithm based on an eigenvalue approach. 
3. Analysis of the ALUL Network 
Section 2 focused on defining properties and analytical measures for dynamic AMN 
along with presenting some examples of some learning algorithms for dynamic AMN. This 
section will focus on the analysis of one of the simpler algorithms, the ALUL network. 
From (2.12) we have that the time invariant ALUL network can be described by the fol- 
lowing interconnection state equation. 
we+ 1)= + 1 (3.1) 
where a and b are nonnegative real numbers. Many of the measures introduced in section 
2 can easily be determined for the ALUL network. 
To calculate the incremental synaptic intensity h(k) and the cumulative synaptic 
intensity H(k) let the initial condition of the interconnection state W,i(0) be independent 
of all other interconnections states and independent of all IVs. If EWi,y(0)= 0 and 
VAR W,i(O ) -- '7 then 
and 
h(k)= (l-a)2{ b21-a2(}'4) } 
l_a2 + a2(k-1)q + b 2 (3.2) 
H(k): b 2 1-a2-----} 
1-- a 2 + a2k (3.3) 
In steady state when a < 1 we have that 
/> = 2(l-a) (3.4) 
From this simple relationship between the attenuation parameter a and the plasticity 
measure ?, we can directly relate plasticity to other measures such as the capacity of the 
network. 
We define the steady state capacity as C(i,e)= lim C(k,i,e) for networks where 
steady state exists. To analytically determine the capacity first assume that 
S(k,V(j)) = S(k-j) is a jointly Gaussian random vector. Further assume that S:(l) for 
1<( i<( N, 1<( l<( rn are all independent and identically distributed. Then for N sufficiently 
large, f(a)= a'(}'q)(1--a '), and 
438 
SNR(k,V(j))= SNR(k')- (N-1)f(a) 
1 --f(a) 
= c(a)logN >> 1 j<k 
we have that 
N-5-- 
p(k,i,o) = - 
N 
 1 - 'V'2rc(a)logN j<k 
Given a we first find the largest m=k>O where 
lim p(k,j,O)= I when c(a)> 2. By letting c(a)= 2 the mimum m 
N 
f(a) _ 21ogN 
Solving for rn we get that 
log [ 21ogN 
 (N+ 2logN)(1-a 2) 
m --- 
 loga 
It is also possible to find the value of a that maximizes m. 
21ogN 
log [(N+ 21ogN)e 
2 � logN 
m is at a maximum value when e  or when m  
N 
2m-1 
lim p(k,i,O)  1. 
N--<x 
is given when 
+1 
If we lete = 1--a �',then 
N 
2elogN' 
(3.6) 
Note that 
(3.7) 
(3.s) 
a  -- Note that this is a factor of � less than the maximum number of IVs allowable 
2m 
in a static HAMN [4,5], such that one of the IVs is recoverable. By following the analysis 
in [5], the independence assumption and the Gaussian assumptions used earlier can be 
removed. The arguments involve using results from exchangeability theory and normal 
approximation theory. 
A similar and somewhat more cumbersome analysis can be performed to show that in 
2m-4 
steady state the maximum capacity achievable is when a  -- and given by 
2m 
N 
lim C(k,O,e): (3.10) 
N-o 4 � logN 
This again is a factor of e less than the maximum number of IVs allowable in a static 
HAMN [4,5], such that all IVs are recoverable. Fig. 2 shows a Monte Carlo simulation of 
the number of IVs recoverable in a 64 cell network versus the learning time scale for a 
varying between .5 and .99. We can see that the network reaches approximate steady state 
when k_ 35. The maximum capacity achievable is when a , .9 and the capacity is around 
5. This is slightly more than the theoretical value predicted by the analysis just shown 
when we compare to Fig. 1. For smaller simulations conducted with larger networks the 
simulated capacity was closer to the predicted value. From the simulations and the 
analysis we observe that when a is too small IVs are forgotten at too high a rate and when 
This corresponds to 
439 
a is too high network saturation occurs. 
Using the same arguments, it is possible to analyze the capacity of the network and 
2m-1 
efficacy of IVs when k is small. Assuming zero initial conditions and a   we can 
2m 
summarize the learning behavior of the ALUL network. The learning behavior can be 
N 
divided into three phases. In the first phase for k< all IVs are remembered and 
-- 4e logN 
the characteristics of the network are similar to the HAMN below saturation. In the 
second phase some IVs are forgotten as the rate of forgetting becomes nonzero. During this 
phase the maximum capacity is reached as shown in fig. 2. At this capacity the network 
cannot dynamically recall all IVs so the network starts to forget more information then it 
receives. This continues until steady state is reached where the learning and forgetting 
rates are equal. If initial conditions are nonzero the network starts in phase 1 or the begin- 
ning of phase 2 if H(k) is below the value corresponding to the maximum capacity and at 
the end of phase 2 for larger H(k). 
The calculation of the network saturation probabilities $(k,m) is trivial for large net- 
works when the capacity curves have been found. When ,n_ C(k,O,e) then S(k,,n) 0 
otherwise $(k,m)  1. 
Before leaving this section let us briefly examine ALUL networks where a(k) and 
b(k) are time varying. An example of a time varying network is the marginMist learning 
scheme introduced in [10]. The network is defined by fixing the value of the 
SNR(k,k--1,i) = D(N) for all k. This value is fixed by setting a= 1 and varying b. Since 
the VAREi(k,V(k-1))is a monotonic increasing function of k, b(k)must also be a mono- 
tonic increasing function of k. It is not too difficult to show that when k is large, the mar- 
ginalist learning scheme is equivalent to the steady state ALUL defined by (3.1). The argu- 
ment is based on noting that the steady state SNR depends not on the update time, but 
on the difference between the update time and when the IV was stored as is the case with 
the marginMist learning scheme. 
when D(N) = 4�logN and 
The optimal value of D(N) giving the highest capacity is 
2m 
b(k+ 1)= 2m--b(k) (3.11) 
N 
where m = 
4e logN' 
If performance is defined by a worst case criterion with the criterion being 
J(l,N) = min(C(k,O,e),k_ l) (3.12) 
then we conjecture that for l large, no ALUL as defined in (2.12,2.13) can have larger 
J(l,N) than the optimal ALUL defined by (3.1). If we consider average capacity, we note 
N 
that the RL network has an average capacity of -- which is larger than the optimal 
81ogN 
ALUL network defined in (3.1). However, for most envisioned applications a worst case 
criterion is a more accurate measure of performance than a criterion based on average 
capacity. 
4. Summary 
This paper has introduced a number of simple dynamic neural network models and 
defined several measures to evaluate the performance of these models. All parameters for 
the steady state ALUL network described by (3.1) were evaluated and the attenuation 
parameter a giving the largest capacity was found. This capacity was found to be a factor 
of e less than the static HAMN capacity. Furthermore we conjectured that if we consider 
a worst case performance criteria that no ALUL network could perform better than the 
440 
optimal ALUL network defined by (3.1). Finally, a number of other dynamic models 
including BL, RL, and marginalist learning were stated to be equivalent to ALUL networks 
under certain conditions. 
The network models that were considered in this paper all have binary vector valued 
activation states and may be to simplistic to be considered in many signal processing appli- 
cation. By generalizing the analysis to more complicated models with analog vector valued 
activation states and continuous time updating it may be possible to use these generalized 
models in speech and image processing. A specific example would be a controller for a 
moving robot. The generalized network models would learn the input data by adaplively 
changing the interconnections of the network. Old data would be forgotten and data that 
was repeatedly being recalled would be reinforced. These network models could also be 
used when the input data statistics are nonstationary. 
References 
[1] W.S. McCulloch and W. Pitts, ""A Logical Calculus of the Ideas Iminent in Nervous 
Activity"", Bulletin of Mathematical Biophysics, 5, 115-133, 1943. 
[2] 
J. J. Hopfield, ""Neural Networks and Physical Systems with Emergent Collective Com- 
putational Abilities"", Proc. Natl. Acad. Sci. USA 79, 2554-2558, 1982. 
[3] Y.S. Abu-Mostafa and J. M. St. Jacques, ""The Information Capacity of the Hop field 
Model"", IEEE Trans. Inform. Theory, vol. IT-31,461-464, 1985. 
[4] 
R. J. McEliece, E.C. Posner, E. R. Rodemich and S.S. Venkatesh, ""The Capacity of 
Ithe Hopfield Associative Memory"", IEEE Trans. Inform. Theory, vol. IT-33, 461-482, 
1987. 
[5] A. Kuh and B. W. Dickinson, ""Information Capacity of Associative Memories"", to be 
published IEEE Trans. Inform. Theory. 
[6] D.J. Amir, H. Gutfreund, and H. Sompolinsky, ""Spin-Glass Models of Neural Net- 
works"", Phys. Rev. A, vol. 32, 1007-1018, 1985. 
[7] 
J. J. Hopfield, D. I. Feinstein, and R. G. Palmer, ""'Unlearning' has a Stabilizing 
effect in Collective Memories"", Nature, vol. 304, 158-159, 1983. 
[8] R.J. Sasiela, ""Forgetting as a way to Improve Neural-Net Behavior"", AlP Confer- 
ence Proceedings 151, 386-392, 1986. 
[9] J.D. Keeler, ""Basins of Attraction of Neural Network Models"", AIP Conference 
Proceedings 151,259-265, 1986. 
[10] 
J.P. Nadal, G. Toulouse, J.P. Changeux, and S. Dehaene, ""Networks of Formal 
Neurons and Memory Palimpsests"", Europhysics Let., Vol. 1,535-542, 1986. 
[11] S. Grossberg, ""Nonlinear Neural Networks: Principles, Mechanisms, and Architec- 
tures"", Neural Networks in press. 
[12] 
S.S. Venkatesh and D. Psaltis, ""Information Storage and Retrieval in Two Associa- 
tive Nets"", California Institute of Technology Pasadena, Dept. of Elect. Eng., pre- 
print, 1986. 
441 
lO 
8 
2 
""HAMN Capacity"" 
o 
N=64, 1024 trials 
-a- Average # of IV 
10 20 30 40 
Update Time 
""ALUL Capacity"" 
101 N=64, 1024 trials  a=.5 
t  --*- a=. 
I -, + a=.g I 
6 =' 
< 2 
o 
0 10 20 30 
Update Time 
Fig. 2 
40 
", measur associ memori learn forget kuh electr engin hawaii manoa mani modif model propos learn forget given network never satur function effect due overload learn updat need introduc perform measur inform capac evalu differ mathemat quantiti plastic efficaci inform probabl network quantiti analyt compar introduct recent undertaken quantit measur comput network model exhibit attribut neural model discuss one earliest neural network model comput properti call hopfield associ memori similar model discuss hopfield hamn measur quantit defin evalu inform network fail exhibit complex comput neural network due simplifi hamn belong class network call static network learn recal network first learn set data learn dynam oppos static updat learn recal intermingl mani applic adapt imag speech recognit dynam network adapt learn chang inform paper formal develop analyz dynam model neural exist model new model measur formul evalu differ dynam asymptot inform capac hamn defin capac found first assum inform vector compon chosen randomli independ inform capac give maximum number iv store hamn iv recov high probabl network high success recov desir network quickli degrad eventu fail desir phenomena sometim refer paper refer phenomena network two way avoid first method involv learn number iv number learn take learn learn network therefor lack mani interest comput institut physic adapt learn neural network model second method incorpor type forget mechan learn structur store network never exceed type network would abl adapt chang statist iv network would abl recal recent learn paper focus analyz dynam network adapt learn new inform exhibit network satur phenomena select forget old emphasi develop simpl model much analysi perform dynam network use modifi hebbian learn introduc qualit discuss number network model dynam section also defin pertin measur dynam network measur includ plastic probabl network efficaci store network can not learn network high plastic interconnect weight larg efficaci store iv function time anoth paramet use determin rate network forget section mathemat analyz simpl dynam network refer linear updat learn network use linear updat hebbian quantiti introduc section analyt determin alul adjust attenu paramet alul factor shown optim capac larg alul steadi state defin factor less capac tradeoff must paid dynam also network perform better network worst case section discuss direct work along applic adapt signal dynam associ memori network network model discuss paper base concept associ associ memori compos collect interconnect element data storag like memori two occur associ learn oper write convent inform store network recal oper read oper convent retriev memori associ memori recal inform basi data content rather specif model consid learn recal oper updat discret time state consist cell take valu dynam network measur associ memori network describ two set repres activ state time repres weight matrix state time activ recal equat describ data probe vector use learn algorithm equat describ inform vector store initi state interconnect usual learn algorithm time scale much longer recal equat time scale consid time often view equat govern short term memori equat long term hebbian hypothesi note data probe effect interconnect matrix number data probe recal iv strength recal iv increas modif anoth iv never gradual adjust term follow analysi assum iv introduc independ ident distribut bernoulli random probabl chosen equal analysi focus learn describ dynam learn present network defin dynam given time rate chang never addit primarili network learn gradual updat discret time shown want network updat usual consist one iv learn iv introduc recent high probabl probabl recal one iv also monoton decreas given iv network consid also rel low probabl network let event iv introduc time time data probe vector ham distanc efficaci network recoveri given analysi perform say vector recov synchron activ updat cell capac dynam given give cardin number event occur set close capac network netsyork satur occur overload iv none iv success network time start learn time network satur probabl defin describ probabl network can not recov import measur analyz perform dynam network interconnect weight matrix follow definit defin increment synapt intens cumul synapt definit defin plastic network network network chang learn take network interconnect exhibit larg analyz dynam network often interest network reach say dynam network reach steadi state finit nonzero iv stationari statist given learn oper time network reach steadi oo finit also easili verifi plastic nonzero constant dynam given condit learn oper network eventu reach steadi us also defin synapt state time activ state synapt defin snr show section relat efficaci iv capac quantiti import measur dynam network complex quantiti deal network complex discuss paper focus network network memoryless express follow memoryless disadvantag iv need save learn complex implement greatli increas term complex like increas term time exampl dynam associ memori network previou subsect discuss quantiti measur dynam subsect discuss exampl dynam associ memori network discuss advantag disadvantag differ consid memoryless first network discuss describ follow diffcrenc equat initi valu weight learn taken network learn rule label linear updat learn network addit network label attenu linear updat primarili deal alul depend posit model special version decay ltm equat discuss learn algorithm type learn scheme similar marginalist learn scheme introduc key paramet alul network valu attenu coeffici simul intuit know attenu coeffici network satur attenu paramet network recent introduc use mont carlo method show plot number recover cell network learn time figur clearli see network saturati exhibit time iv recover high section analyz alul network deriv valu differ measur introduc section learn scheme call bound learn describ set attenu paramet let max ident learn bound scheme discuss unfortun seriou drawback larg network satur high set probabl network satur low characterist learn almost valu min therefor efficaci network order scheme classifi dynam attenu must valu learn scheme version learn scheme deriv let us qualit analyz learn scheme two case network affect hound network behav netxvork accept iv bound hound network wait valu interconnect attenu prescrib level learn bl provid mean network avoid iv difficult show learn scheme alul network time third learn scheme call refresh learn describ learn scheme learn set iv period refresh weight matrix interconnect rl classifi dynam learn gradual period refresh anoth problem learn scheme efficaci iv depend period iv late period quickli forgotten iv learn earli period time learn scheme network learn forget network introduc separ learn forget task standard algorithm learn iv random select forget unlearn excess algorithm call random select describ formal vector obtain choos random vector iv chosen let initi state hamn interconnect recal oper describ repeat activ local minimum assign rate randomli select local minimum energi state given nonneg integ valu function monoton increas analysi rsf algorithm energi manifold energi activ state updat allow must simpl transform weight matrix activ state given aggreg analyz local minimum energi activ state simul simplifi assumpt come qualit rsf algorithm base eigenvalu analysi alul network focus defin properti analyt measur dynam amn present exampl learn algorithm dynam focu analysi one simpler alul time invari alul network describ interconnect state nonneg real mani measur introduc section easili determin alul calcul increment synapt intens cumul synapt let initi condit interconnect state independ interconnect state independ steadi state simpl relationship attenu paramet plastic directli relat plastic measur capac defin steadi state capac lim network state analyt determin capac first assum jointli gaussian random assum rn independ ident suffici first find largest let rn get loga also possibl find valu maxim maximum valu given lete note factor less maximum number iv allow static hamn one iv follow analysi independ assumpt gaussian assumpt use earlier argument involv use result exchang theori normal similar somewhat cumbersom analysi perform show state maximum capac achiev given factor less maximum number iv allow static iv show mont carlo simul number iv recover cell network versu learn time scale see network reach approxim steadi state maximum capac achiev capac around slightli theoret valu predict analysi shown compar smaller simul conduct larger network capac closer predict simul observ small iv forgotten high rate correspond high network satur possibl analyz capac network iv assum zero initi condit learn behavior alul learn behavior three first phase iv rememb characterist network similar hamn phase iv forgotten rate forget becom maximum capac reach shown capac network dynam recal iv network start forget inform continu steadi state reach learn forget initi condit nonzero network start phase phase valu correspond maximum capac end phase larger calcul network satur probabl trivial larg capac curv leav section let us briefli examin alul network time exampl time vari network mist learn introduc network defin fix valu valu fix set vari sinc monoton increas function also increas function difficult show learn scheme equival steadi state alul defin base note steadi state snr depend updat differ updat time iv store case mist learn optim valu give highest capac perform defin worst case criterion criterion conjectur alul defin larger optim alul defin consid averag note rl network averag capac larger optim network defin envis applic worst case accur measur perform criterion base averag summari paper introduc number simpl dynam neural network model sever measur evalu perform paramet steadi state alul network describ evalu attenu give largest capac capac found factor less static hamn furthermor conjectur consid worst case perform criteria alul network could perform better alul network defin number dynam model marginalist learn state equival alul network certain network model consid paper binari vector valu state may simplist consid mani signal process gener analysi complic model analog vector valu state continu time updat may possibl use gener speech imag specif exampl would control gener network model would learn input data adapl interconnect old data would forgotten data repeatedli recal would network model could also input data statist culloch logic calculu idea imin nervou bulletin mathemat network physic system emerg collect usa inform capac hop field ie rodemich capac hopfield associ ie kuh capac associ ie model neural stabil collect way improv proceed attract neural network aip confer formal memori europhys neural neural network venkatesh storag retriev two california institut technolog trial averag iv time trial time,0
47,47,"442 
How Neural Nets Work 
Alan Lapedes 
Robert Father 
Theoretical Division 
Los Alamos National Laboratory 
Los Alamos, NM 87545 
Abstract: 
There is presently great interest in the abilities of neural networks to mimic 
""qualitative reasoning""by manipulating neural incodings of symbols. Less work 
has been performed on using neural networks to process floating point nurnbers 
and it is sometimes stated that neural networks are somehow inherently inaccu- 
rate and therefore best suited for ""fuzzy""qualitative reasoning. Nevertheless, 
the potential speed of massively parallel operations make neural net ""number 
crunching""an interesting topic to explore. In this paper we discuss some of our 
work in which we demonstrate that for certain applications neural networks can 
achieve significantly higher numerical accuracy than more conventional tech- 
niques. In particular, prediction of future values of a chaotic time series can 
be performed with exceptionally high accuracy. We analyze how a neural net 
is able to do this , and in the process show that a large class of functions from 
R  -- R 'n may be accurately approximated by a backpropagation neural net 
with just two ""hidden""layers. The network uses this functional approximation 
to perform either interpolation (signal processing applications) or extrapolation 
(symbol processing applications I. Neural nets therefore use quite familiar meth- 
ods to perform their tasks. The geometrical viewpoint advocated here seems to 
be a useful approach to analyzing neural network operation and relates neural 
networks to well studied topics in functional approximation. 
1. Introduction 
Although a great deal of interest has been displayed in neural network's 
capabilities to perform a kind of qualitative reasoning, relatively little work has 
been done on the ability of neural networks to process floating point nurnbers 
in a massively parallel fashion. Clearly, this is an important ability. In this 
paper we discuss some of our work in this area and show the relation between 
numerical, and symbolic processing. We will concentrate on the the subject of 
accurate prediction in a time series. Accurate prediction has applications in 
many areas of signal processing. It is also a useful, and fascinating ability, when 
dealing with natural, physical systems. Given some data from the past history 
of a system, can one accurately predict what it will do in the future? 
Many conventional signal processing tests, such as correlation function anal- 
ysis, cannot distinguish deterministic chaotic behavior from from stochastic 
noise. Particularly difficult systems to predict are those that are nonlinear and 
chaotic. Chaos has a technical definition based on nonlinear, dynamical systems 
theory, but intuitivly means that the system is deterministic but ""random,""in 
a rather similar manner to deterministic, pseudo random number generators 
used on conventional computers. Examples of chaotic systems in nature include 
turbulence in fluids (D. Ruelie, 1971; H. Swinney, 1978), chemical reactions (K. 
Tomira, 1979), lasers (H. Haken, 1975), plasma physics (D. Russel, 1980) to 
name but a few. Typically, chaotic systems also display the full range of non- 
linear behavior (fixed points, limit cycles etc.) when parameters are varied, and 
therefore provide a good testbed in which to investigate techniques of nonlinear 
signal processing. Clearly, if one can uncover the underlying, deterministic al- 
gorithm from a chaotic time series, then one may be able to predict the future 
time series quite accurately. 
@ American Institute of Physics 1988 
443 
In this paper we review and extend our work (Lapedes and Farber,1987) 
on predicting the behavior of a particular dynamical system, the Glass-Mackey 
equation. We feel that the method will be fairly general, and use the Glass- 
Mackey equation solely for illustrative purposes. The Glass-Mackey equation 
has a strange attractor with fractal dimension controlled by a constant param- 
eter appearing in the differential equation. We present results on a neural net- 
work's ability to predict this system at two values of this parameter, one value 
corresponding to the onset of chaos, and the other value deeply in the chaotic 
regime. We also present the results of more conventional predictive methods and 
show that a neural net is able to achieve significantly better numerical accuracy. 
This particular system was chosen because of D. Farmer's and J. Sidorowich's 
(D. Farmer, J. Sidorowich, 1987) use of it in developing a new, non-neural net 
method for predicting chaos. The accuracy of this non-neural net method, and 
the neural net method, are roughly equivalent, with various advantages or dis- 
advantages accruing to one method or the other depending on one's point of 
view. We are happy to acknowledge many valuable discussions with Farmer and 
Sidorowich that has led to further improvements in each method. 
We also show that a neural net never needs more than two hidden layers to 
solve most problems. This statement arises from a more general argument that 
a neural net can approximate functions from R a - R m with only two hidden 
layers, and that the accuracy of the approximation is controlled by the number 
of neurons in each layer. The argument assumes that the global minimum to the 
backpropagation minimization problem may be found, or that a local minima 
very close in value to the global minimum may be found. This seems to be 
the case in the examples we considered, and in many examples considered by 
other researchers, but is never guaranteed. The conclusion of an upper bound 
of two hidden layers is related to a similar conclusion of R. Lipman (R. Lipman, 
1987) who has previously analyzed the number of hidden layers needed to form 
arbitrary decision regions for symbolic processing problems. Related issues are 
discussed by J. Denker (J. Denker et.al. 1987) It is easy to extend the argument 
to draw similar conclusions about an upper bound of two hidden layers for 
symbol processing and to place signal processing, and symbol processing in a 
common theoretical framework. 
2. Backpropagation 
Backpropagation is a learning algorithm for neural networks that seeks to 
find weights, TQ., such that given an input pattern from a training set of pairs 
of Input/Output patterns, the network will produce the Output of the training 
set given the Input. Having learned this mapping between I and O for the 
training set, one then applies a new, previously unseen Input, and takes the 
Output as the ""conclusion""drawn by the neural net based on having learned 
fundamental relationships between Input and Output from the training set. A 
popular configuration for backpropagation is a totally feedforward net (Figure 
1) where Input feeds up through ""hidden layers""to an Output layer. 
444 
OUTPUT 
Figure 1. 
A feedforward neural 
HDEN net. Arrows schemat- 
ically indicate full 
feedforward connect- 
ivity 
PUT 
Ech neuron form a weighted sum of the inputs from previous layers to 
which it is connected, adds a threshold value, and produces a nonlinear function 
of this sum s its output value. This output value serves m input to the future 
layers to which the neuron is connected, and the proces is repeated. Ultimately 
a value is produced for the outputs of the neurons in the Output layer. Thus, 
each neuron perform.: 
(1) 
where T i are continuous valued, positive or negative weights, 8i is a constant, 
� nd g(x) is a nonlinear function that is often chosen to be of a sigmoidal form. 
For example, one may choose 
1 
g(x): (1 + ,a.hx) (2) 
where tanh is the hyperbolic tangent, although the exact formula of the sigmoid 
is irrelevant to the results. 
If i are the target output values for the pO, Input pattern then ones trains 
the network by minire!zing 
p 
(3) 
where t is the target output values (taken from the training set) and 0 i 
is the output of the network when the pth Input pattern of the training set is 
presented on the Input layer. i indexes the number of neurons in the Output 
layer. 
An iterative procedure is used to minimize E. For example, the commonly 
used steepest descents procedure is implemented by changing Tii and 01 by AT O. 
and A0i where 
445 
E 
ATo' -- ----'. '  (4a) 
E 
Ai -- -qS-. ' e (4b) 
This implies that AE < 0 and hence E will decrease to a local minimum. 
Use of the chain rule and definition of some intermediate quantities allows the 
following expressions for ATi. to be obtained (Rumelhart, 1987): 
where 
if i is labeling a neuron in the Output layer; and 
(5b) 
(6) 
if i labels a neuron in the hidden layers. Therefore one computes 5r) for the 
Output layer first, then uses Eqn. (7) to computer 57) for the hidden layers, 
and finally uses Eqn. (5) to make an adjustment to the weights. We remark that 
the steepest descents procedure in common use is extremely slow in simulation, 
and that a better minimization procedure, such az the classic conjugate gradient 
procedure (W. Press, 1986), can offer quite significant speedups. Many appli- 
cations use bit representations (0,1) for symbols, and attempt to have a neural 
net learn fundamental relationships between the symbols. This procedure has 
been successfully used in converting text to speech (T. Sejnowski, 1986) and in 
determining whether a given fragment of DNA codes for a protein or not (A. 
Lapedes, R. Farber, 1987). 
There is no fundamental reason, however, to use integer's az values for Input 
and Output. If the Inputs and Outputs are instead a collection of floating point 
numbers, then the network, fter training, yields a specific continuous function 
in n variables (for n inputs) involving g(x) (i.e. hyperbolic tanh's) that provides 
a type of nonlinear, least mean square interpolant formula for the discrete set 
of data points in the training set. Use of this formula 0 -- f(lt,l,...l,) 
when given a new input not in the training set, is then either interpolation or 
extrapolation. 
Since the Output values, when azsurned to be floating point numbers may 
have a dynamic range great than [0,1], one may modify the g(x) on the Output 
layer to be a linear function, instead of sigmoidal, so as to encompass the larger 
dynamic range. Dynamic range of the Input values is not so critical, however we 
have found that numerical problems may be avoided by scaling the Inputs (and 
446 
also the Outputs) to [0,1], training the network, and then rescaling the Tiy, 8i 
to encompass the original dynamic range. The point is that scale changes in 
I and O may, for feedforward networks, always be absorbed in the TO. , 8i and 
vice versa. We use this procedure (backpropagation, conjugate gradient, linear 
outputs and scaling) in the following section to predict points in a chaotic time 
series. 
. Prediction 
Let us consider situations in Nature where a system is described by nonlin- 
ear differential equations. This is faily generic. We choose a particular nonlinear 
equation that has an infinite dimensional phase space, so that it is similar to 
other infinite dimensional systems such as partial differential equations. A differ- 
ential equation with an infinite dimensional phase space (i.e. an infinite number 
of values are necessary to describe the initial condition) is a delay, differential 
equation. We choose to consider the time series generated by the Glass-Mackey 
equation: 
i = ax(t-,') 
+ _ ,-) - (s) 
This is a nonlinear differential, delay equation with an initial condition specified 
by an initial function defined over a strip of width r (hence the infinite di- 
mensional phase space i.e. initial functions, not initial constants are required). 
Choosing this function to be a constant function, and a = .2, b = .1, and r = 17 
yields a time series, x(t), (obtained by integrating Eqn. (8)), that is chaotic with 
a fractal attractor of dimension 2.1. Increasing r to 30 yields more complicated 
evolution and a fractal dimension of 3.5. The time series for 500 time steps for 
r=30 (time in units of r} is plotted in Figure 2. The nonlinear evolution of the 
system collapses the infinite dimensional phase space down to a low (approxi- 
mately 2 or 3 dimensional) fractal, attracting set. Similar chaotic systems are 
not uncommon in Nature. 
Figure 2. Example time series at tau = 30. 
447 
The goal is to take a set of values of x 0 at discrete times in some time 
window containing times less than t, and use the values to accurately predict 
x(t + P}, where P is some prediction time step into the future. One may fix 
P, colledt statistics on accuracy for many prediction times t (by sliding the 
window along the time series), and then increase P and again collect statistics 
on accuracy. This one may observe how an average index of accuracy changes as 
P is increased. In terms of Figure 2 we will select various prediction time steps, 
P, that correspond to attempting to predict within a ""bump,"" to predicting 
a couple of ""bumps"" ahead. The fundamental nature of chaos dictates that 
prediction accuracy will decrease as P is increased. This is due to inescapable 
inaccuracies of finite precision in specifying the x(t) at discrete times in the past 
that are used for predicting the future. Thus, all predictive methods will degrade 
as P is increased - the question is ""How rapidly does the error increase with 
P?""We will demonstrate that the neural net method can be orders of magnitude 
more accurate than conventional methods at large prediction time steps, P. 
Our goal is to use backpropagation, and a neural net, to construct a function 
O(t + P) = f (Ix(t),l(t - A)...I,(t - rnA)) 
(9) 
where O(t + P) is the output of a single neuron in the Output layer, and I1 -- I,n 
are input neurons that take on values z(t),z(t - ) z(t - rnA), where A s 
a time delay. O(t + P) takes on the value x(t il We chose the network 
configuation of Figure 1. 
We construct a training set by selecting a set of input values: 
= z(to) 
(10) 
1', = x(to - rnA ) 
with associated output values 0 = x(t 0 + P), for a collection of discrete times 
that are labelled by t 0. Typically we used 500 I/O pairs in the training set 
so that p ranged from 1--+ 500. Thus we have a collection of 500 sets of 
{[?),[?,...,I};0 (�}} to use in training the neural net. This procedure of 
using delayed sampled values of x(t) can be implemented by using tapped de- 
lay lines, just as is normally done in linear signal processing applications, {B. 
Widrow, 1985). Our prediction procedure is a straightforward nonlinear exten- 
sion of the linear Widrow Hoff algorithm. After training is completed, prediction 
is performed on a new set of times, t 0, not in the training set i.e. for p = 500. 
We have not yet specified what m or & should be, nor given any indication 
why a formula like Eqn. (9) should work at all. An important theorem of Takens 
(Takens, 1981) states that for flows evolving to compact attracting manifolds of 
dimension dA, that a functional relation like Eqn. (9) does exist, and that m 
lies in the range dA < m + 1 < 2dA + 1. We therefore choose m = 4, for r = 30. 
Takens provides no information on A and we chose & = 6 for both cases. We 
found that a few different choices of m and/x can affect accuracy by a factor of 2 - 
a somewhat significant but not overwhelming sensitivity, in view of the fact that 
neural nets tend to be orders of magnitude more accurate than other methods. 
Takens theorem gives no information on the form of f() in Eqn. (9). It therefore 
448 
is necessary to show that neural nets provide a robust approximating procedure 
for continuous f0, which we do in the following section. It is interesting to note 
that attempts to predict future values of a time series using past values of x(t) 
from a tapped delay line is a common procedure in signal processing, and yet 
there is little, if any, reference to results of nonlinear dynamical systems theory 
showing why any such attempt is reasonable. 
After training the neural net as described above, we used it to predict 500 
new values of x(t) in the future and computed the average accuracy for these 
points. The accuracy is defined to be the average root mean square error, divided 
by a constant scale factor, which we took to be the standard deviation of the 
data. It is necessary to remove the scale dependence of the data and dividing by 
the standard deviation of the data provides a scale to use. Thus the resulting 
'index of accuracy  is insensitive to the dynamic range of x(t). 
As just described, if one wanted to use a neural net to continuously predict 
x(t) values at, say, 6 time steps past the last observed value (i.e. wanted to 
construct a net predicting x(t + 6)) then one would train one network, at P 
-- 6, to do this. If one wanted to always predict 12 time steps past the last 
observed x(t) then a separate, P -' 12, net would have to be trained. We, in 
fact, trained separate networks for P ranging between 6 and 100 in steps of 6. 
The index of accuracy for these networks (as obtained by computing the index 
of accuracy in the prediction phase) is plotted as curve D in Figure 3. There 
is however an alternate way to predict. If one wished to predict, say, x(t + 12) 
using a P = 6 net, then one can iterate the P = 6 net. That is, one uses the 
P = 6 net to predict the x(t +.6) values, and then feeds x(t .+6) back into the 
input line to predict x(t + 12J using the predicted x(t + 6) value instead of 
the observed x(t + 6) value. in fact, one can't use the observed x(t +6) value, 
because it hasn't been observed yet - the rule of the game is to use only data 
occurring at time t and before, to predict x(t +12). This procedure corresponds 
to iterating the map given by Eqn. (9) to perform prediction at multiples of P. 
Of course, the delays, x, must be chosen commensurate with P. 
This iterative method of prediction has potential dangers. Because (in our 
example of iterating the P = 6 map) the predicted x(t + 6) is always made 
with some error, then this error is compounded in iteration, because predicted, 
and not observed values, are used on the input lines. However, one may pre- 
dict more accurately for smaller P, so it may be the case that choosing a very 
accurate small P prediction, and iterating, can ultimately achieve higher accu- 
racy at the larger P's of interest. This turns out to be true, and the iterated 
net method is plotted as curve E in Figure 3. It is the best procedure to use. 
Curves A,B,C are alternative methods(iterated polynomial,Widrow-Hoff, and 
non-iterated polynomial respectively. More information on these conventional 
methods is in (Lapedes and Father, 1987) ). 
449 
.8 
.6 
.4 
.Z 
A C B O 
/ 
I 
I 
I 
I 
I 
I 
I 
I- 
] 
-rme P 
Figure 3. 
4. Why It Works 
Consider writing out explicitly Eqn. (g) for a two hidden layer network 
where the output is assumed to be a linear neuron. We conzider Input connects 
to Hidden Layer 1, Hidden Layer 1 to Hidden Layer 2, and Hidden Layer 2 to 
Output. Therefore: 
Recall that the output neurons a linear computing element so that only two g()s 
occur in formula (11), due to the two nonlinear hidden layers. For eaze in later 
analysis, let us rewrite this formula as 
Ot =  Twg (SUM + ) +  (12a) 
where 
450 
The T's and O's are specific numbers specified by the training algorithm, 
so that after training is finished one has a relatively complicated formula (12a, 
12b) that expresses the Output value as a specific, known, function of the Input 
values: 
A functional relation of this form, when there is only one output, may be 
viewed as surface in m + I dimensional space, in exactly the same manner 
one interprets the formula z - f(x,y) as a two dimensional surface in three 
J dimensional space. The general structure of f0 as determined by Eqn. (12a, 
12b) is in fact quite simple. From Eqn. (12b) we see that one first forrn a. sum 
of gO functions (where g0 is s sigmoidal function) and then from Eqn. (12a) 
one forms yet another sum involving g0 functions. It may at first be thought 
that this special, simple form of f() restricts the type of surface that may be 
represented by 0t -- f(I). This initial t,ought is wrong - the special form of 
Eqn. (12) is actually a general representation for quite arbitrary surfaces. 
To prove that Eqn. (12) is a reasonable representation for surfaces we 
first point out that surfaces may be approximated by adding up a series of 
""bumps"" that are appropriately placed. An example of this occurs in familiar 
Fourier analysis, where wave trains of suitable frequency and amplitude are 
added together to approximate curves (or surfaces). Each half period of each 
wave of fixed wavelength is a ""bump,"" and one adds all the bumps together to 
form the approximant. Let us now see how Eqn. (12) may be interpreted as 
adding together bumps of specified heights and positions. First consider SUM 
which is a sum of g( ) functions. In Figure (4) we plot an example of such a g() 
function for the case of two inputs. 
Figure 4. A sigmoidal surface. 
451 
The orientation of this sigmoidal surface is determined by Ty, the position by 
t., and height by T. Now consider another g() function that occurs in SUMs. 
The t. of the second g() function is chosen to displace it from the first, the T i 
is chosen so that it has the same orientation as the first, and Ti is chosen to 
have opposite sign to the first. These two g( ) functions occur in SUMs, and 
so to determine their contribution to SUM we sum them together and plot the 
result in Figure (5)..The result is a ridged surface. 
Figure 5. A ridge. 
Since our goal is to obtain localized bups we select another pair of g() functions 
in SUMs, add them together to get a ridged surface perpendicular to the first 
ridged surface, and then add the two perpendicular ridged surfaces together to 
see the contribution to SUMs. The result is plotted in Figure (6). 
Figure 6. A pseudo-bump. 
452 
We see that this almost worked, in so much as one obtains a local maxima by 
this procedure. However there are also saddle-like configurations at the corners 
which corrupt the bump we were trying to obtain. Note that one way to fix 
this is to take g(SUMk + tk) which will, if t is chosen appropriately, depress 
the local minima and saddles to zero while slmultaneously sending the central 
maximum towards 1. The result is plotted in Figure (7) and is the sought after 
b, 
Figure 7. A bump. 
Furthermore, note that the necessary g() function is supplied by Eqn. (12). 
Therefore Eqn. (12) is a procedure to obtain localized bumps of arbitrary height 
and position. For two inputs, the k �' bump is obtained by using four g() func- 
tions from SUM (two g() functions for each ridged surface and two ridged 
surfaces per bump) and then taking g() of the result in Eqn. (12a). The height 
of the k �' bump is determined by To in Eqn. (12a) and the k bumps are added 
together by that equation as well. The general network architecture which cor- 
responds to the above procedure of adding two g0 functions together to form a 
ridge, two perpendicular ridges together to form a pseudo-bump, and the final 
g0 to form the final bump is represented in Figure (8). To obtain any number 
of bumps one adds more neurons to the hidden layers by repeatedly using the 
connectivity of Figure (8) as a template (i.e. four neurons per bump in Hidden 
Layer 1, and one neuron per bump in Hidden Layer 2). 
453 
Figure 8. Connectivity needed 
to obtain one bump. Add four 
more neurons to Hidden layer 
1, and one more neuron to 
Hidden Layer 2, for each 
additional bump. 
One never needs more than two layers, or any other type of connectivity 
than that already schematically specified by Figure (8). The accuracy of the 
approximation depends on the number of bumps, which in turn is specified, 
by the number of neurons per layer. This result is easily generalized to higher 
dimensions (more than two Inputs) where one needs 2m hiddens in the first 
hidden layer, and one hidden neuron in the second layer for each bump. 
The argument given above also extends to the situation where one is pro- 
cessME symbolic information with a neural net. In this situation, the Input 
information is coded into bits (say Os and Is) and similarly for the Output. Or, 
the Inputs may still be real valued numbers, in which case the binary output 
is attempting to group the real valued Inputs into separate classes. To make 
the Output values tend toward 0 and 1 one takes a third and final g0 on the 
output layer, i.e. each output neuron is represented by g(0) where 0 is given 
in Eqn. (11). Recall that up until now we have used linear neurons on the 
output layer. In typical backpropagation examples, one never actually achieves 
a hard 0 or 1 on the output layers but achieves instead some value between 0.0 
and 1.0. Then typically any value over 0.5 is called 1, and values under 0.5 are 
called 0. This ""postprocessing""step is not really outside the framework of the 
network formalism, because it may be performed by merely increasing the slope 
of the sigmoidal function on the Output layer. Therefore the only effect of the 
third and final g0 function used on the Output layer in symbolic information 
processing is to pass a hyperplane through the surface we have just been dis- 
cussing. This plane cuts the surface, forming ""decision regions,""in which high 
values are called 1 and low values are called 0. Thus we see that the heart of the 
problem is to be able to form surfaces in a general manner, which is then cut 
by a hyperplane into general decision regions. We are therefore able to conclude 
that the network architecture consisting of just two hidden layers is sufficient for 
learning any symbol processing training set. For Boolean symbol mappings one 
need not use the second hidden layer to remove the saddles on the bump (c.f. 
Fig. 6). The saddles are lower than the central maximum so one may choose 
a threshold on the output layer to cut the bump at a point over the saddles to 
yield the correct decision region. Whether this representation is a reasonable 
one for subsequently achieving good prediction on a prediction set, as opposed 
to ""memorizing""a training set, is an issue that we address below. 
454 
We also note that use of Sigma IIi units (Rummelhart, 1986) or high order 
correlation nets (Y.-C. Lee, 1987) is an attempt to construct a surface by a 
general polynomial expansion, which is then cut by a hyperplane into decision 
regions, as in the above. Therefore the essential element of ail these neural net 
learning algorithms are identical (i.e. surface construction), only the particular 
method of parameterizing the surface varies from one algorithm to another. This 
geometrical viewpoint, which provides a unifying framework for many neural net 
algorithms, may provide a useful framework in which to attempt construction 
of new algorithms. 
Adding together bumps to approximate surfaces is a reasonable procedure 
to use when dealing with real valued inputs. It ties in to general approximation 
theory (c.f. Fourier series, or better yet, B splines), and can be quite successful 
as we have seen. Clearly some economy is gained by giving the neural net bumps 
to start with, instead of having the neural net form its own b-ps from sigmoids. 
One way to do this would be to use multidimensional Gaussian functions with 
adjustable parameters. 
The situation is somewhat different when processing symbolic (binary val- 
ued) data. When input symbols are encoded into N bit bit-strings then one has 
well defined input values in an N dimensional input space. As shown above, one 
can learn the training set of input patterns by appropriately forming and placing 
bump surfaces over this space. This is an effective method for memorizing the 
training set, but a very poor method for obtaining correct predictions on new 
input data. The point is that, in contrast to real valued inputs that come from, 
say, a chaotic time series, the input points in symbolic processing problem. are 
widely separated and the bumps do not add together to form smooth surfaces. 
Furthermore, each input bit string is a corner of an 2 N vertex hypercube, and 
there is no sense in which one corner of a hypercube is surrounded by the other 
corners. Thus the commonly used input representation for symbolic processing 
problems requires that the neural net extrapolate the surface to make a new 
prediction for a new input pattern (i.e. new corner of the hypercube) and not 
interpolate, as is commonly the case for real valued inputs. Extrapolation is 
a farmore dangerous procedure than interpolation, and in view of the separated 
bumps of the training set one might expect on the basis of this argument that 
neural nets would fail dismally at symbol processing. This is not the case. 
The solution to this apparent conundr-m, of course, is that although it is 
sufficient for a neural net to learn a symbol processing training set by forming 
bumps it is not necessary for it to operate in this manner. The simplest exam- 
ple of this occurs in the XOR problem. One can implement the input/output 
mapping for this problem by duplicating the hidden layer architecture of Figure 
(8) appropiately for two bump ( i.e. 8 hiddens in layer 1, 2 hiddens in layer 2). 
As discussed above, for Boolean mappings, one can even eliminate the second 
hidden layer. However the architecture of Figure (9) will also suffice. 
Figure 9. Connectivity for XOR 
OUTPUT 
H)DEN 
INPUT 
455 
Plotting the output of this network, Figure(9), as a function of the two inputs 
yields a ridge orientated to run between (0,1) and (1,0) Figure(10). Thus a 
neural net may learn a symbolic training set without using bumps, and a high 
dimensional version of this process takes place in more complex symbol pro- 
cessing tasks. Ridge/ravine representations of the training data are considerably 
more efficient than bumps (less hidden neurons and weights) and the extended 
nature of the surface allows reasonable predictions i.e. extrapolations. 
Figure 10 
XOR surface 
(0,0) 
(1,1) 
5. Conclusions 
Neural nets, in contraat to popular misconception, are capable of quite 
accurate number crunching, with an accuracy for the prediction problem we 
considered that exceeds conventional methods by orders of magnitude. Neural 
nets work by constructing surfaces in a high dimensional space, and their oper- 
ation when performing signal processing tasks on real valued inputs, is closely 
related to standard methods of functional approximation. One does not need 
more than two hidden layers for processing real valued input data, and the ac- 
curacy of the approximation is controlled by the number of neurons per layer, 
and not the number of layers. We emphasize that although two layers of hidden 
neurons are sufficient they may not be efficient. Multilayer architectures may 
provide very efficient networks (in the sense of n,mber of neurons and number 
of weights) that can perform accurately and with minimal cost. 
Effective prediction for symbolic input data is achieved by a slightly differ- 
ent method than that used for real value inputs. Instead of forming localized 
bumps (which would accurately represent the training data but would not pre- 
dict well on new inputs) the network can use ridge/ravine like surfaces(and 
generalizations thereof) to efficiently represent the scattered input data. While 
neural nets generally perform prediction by interpolation for real valued data, 
they must perform extrapolation for symbolic data if the usual bit representa- 
tions are used. An outstanding problem is why do tanh representations seem to 
extrapolate well in symbol processing problems? How do other functional bases 
do? How does the representation for symbolic inputs affect the ability to extrap- 
olate? This geometrical viewpoint provides a unifyin framework for examine 
456 
many neural net algorithms, for suggesting questions about neural net operation, 
and for relating current neural net approaches to conventional methods. 
Acknowledgments 
We thank Y. C. Lee, J. D. Farmer, and J. Sidorovich for a number of 
valuable discussions. 
References 
C. Barnes, C. Burks, R. Farbet, A. Lapedes, K. Sirorkin, Pattern Recognition 
by Neural Nets in Genetic Databases , manuscript in preparation 
3. Denker et. al.fAutomatic Learning, Rule Extraction,and Generalization"", 
ATT, Bell Laboratories preprint, 1987 
D. Farmer, .l.Sidorowich, Phys. Rev. Lett., 59(8), p. 845,1987 
H. Haken, Phys. Lett. A53, p77 (1975) 
A. Lapedes, R. Farher 'Nonlineax Signal Proce", neural net work laped father divis alamo nation laboratori nm present great interest abil neural network mimic manipul neural incod less work perform use neural network process float point nurnber sometim state neural network somehow inher therefor best suit potenti speed massiv parallel oper make neural net interest topic paper discuss demonstr certain applic neural network significantli higher numer accuraci convent predict futur valu chaotic time seri perform except high analyz neural net abl process show larg class function may accur approxim backpropag neural net two network use function approxim perform either interpol process extrapol process applic neural net therefor use quit familiar perform geometr viewpoint advoc seem use approach analyz neural network oper relat neural well studi topic function introduct great deal interest display neural perform kind qualit rel littl work done abil neural network process float point nurnber massiv parallel import discuss work area show relat symbol concentr subject predict time accur predict applic area signal also fascin physic given past histori one accur predict convent signal process correl function can not distinguish determinist chaotic behavior stochast particularli difficult system predict nonlinear chao technic definit base dynam system intuitivli mean system determinist rather similar manner pseudo random number gener convent exampl chaotic system natur includ fluid chemic reaction laser plasma physic chaotic system also display full rang behavior limit cycl paramet provid good testb investig techniqu nonlinear one uncov determinist chaotic time one may abl predict futur seri quit american institut physic paper review extend work predict behavior particular dynam feel method fairli use equat sole illustr equat strang attractor fractal dimens control constant appear differenti present result neural abil predict system two valu one valu onset valu deepli chaotic also present result convent predict method neural net abl achiev significantli better numer particular system chosen use develop net predict accuraci net neural net roughli variou advantag accru one method depend point happi acknowledg mani valuabl discuss farmer led improv also show neural net never need two hidden layer statement aris gener argument neural net approxim function two hidden accuraci approxim control number neuron argument assum global minimum minim problem may local minima close valu global minimum may seem case exampl mani exampl consid never conclus upper bound two hidden layer relat similar conclus lipman previous analyz number hidden layer need form decis region symbol process relat issu denker denker easi extend argument draw similar conclus upper bound two hidden layer process place signal symbol process theoret backpropag learn algorithm neural network seek given input pattern train set pair network produc output train given learn map one appli previous unseen take neural net base learn relationship input output train configur backpropag total feedforward net input feed output feedforward neural arrow indic full neuron weight sum input previou layer add threshold produc nonlinear function sum output output valu serv input futur neuron ultim valu produc output neuron output neuron continu posit neg nd nonlinear function often chosen sigmoid one may choos tanh hyperbol although exact formula sigmoid irrelev target output valu input pattern one train network target output valu train output network pth input pattern train set input index number neuron output iter procedur use minim commonli steepest descent procedur implement chang tii impli ae henc decreas local chain rule definit intermedi quantiti allow express obtain label neuron output label neuron hidden therefor one comput layer use comput hidden final use make adjust remark steepest descent procedur common use extrem slow better minim az classic conjug gradient offer quit signific mani use bit represent attempt neural learn fundament relationship procedur success use convert text speech whether given fragment dna code protein fundament use az valu input input output instead collect float point yield specif continu function variabl involv hyperbol provid type least mean squar interpol formula discret set data point train use formula given new input train either interpol output azsurn float point number may dynam rang great one may modifi output linear instead encompass larger dynam rang input valu howev found numer problem may avoid scale input train rescal encompass origin dynam point scale chang feedforward alway absorb use procedur conjug linear follow section predict point chaotic time predict us consid situat natur system describ differenti faili choos particular nonlinear infinit dimension phase similar infinit dimension system partial differenti equat infinit dimension phase space infinit number valu necessari describ initi differenti choos consid time seri gener nonlinear delay equat initi condit specifi initi function defin strip width infinit phase space initi initi constant function constant time integr chaotic fractal attractor dimens increas yield complic fractal dimens time seri time step unit plot figur nonlinear evolut collaps infinit dimension phase space low attract similar chaotic system uncommon exampl time seri tau goal take set valu discret time time contain time less use valu accur predict predict time step one may fix colledt statist accuraci mani predict time slide along time increas collect statist one may observ averag index accuraci chang term figur select variou predict time correspond attempt predict within predict coupl fundament natur chao dictat accuraci decreas due inescap finit precis specifi discret time past use predict predict method degrad increas question rapidli error increas demonstr neural net method order magnitud accur convent method larg predict time goal use neural construct function output singl neuron output input neuron take valu time take valu chose network figur construct train set select set input associ output valu collect discret time label typic use pair train set rang thu collect set use train neural procedur delay sampl valu implement use tap normal done linear signal process predict procedur straightforward nonlinear linear widrow hoff train predict perform new set train set yet specifi given indic formula like work import theorem taken state flow evolv compact attract manifold function relat like rang therefor choos provid inform chose differ choic affect accuraci factor somewhat signific overwhelm view fact net tend order magnitud accur theorem give inform form therefor necessari show neural net provid robust approxim procedur continu follow interest note attempt predict futur valu time seri use past valu tap delay line common procedur signal yet refer result nonlinear dynam system theori attempt train neural net describ use predict valu futur comput averag accuraci accuraci defin averag root mean squar divid constant scale took standard deviat necessari remov scale depend data divid standard deviat data provid scale thu result accuraci insensit dynam rang one want use neural net continu predict valu time step past last observ valu want net predict one would train one one want alway predict time step past last net would train separ network rang step index accuraci network obtain comput index accuraci predict plot curv figur howev altern way one wish one iter one use net predict feed back line predict use predict valu instead observ one use observ observ yet rule game use data time predict procedur correspond iter map given perform predict multipl must chosen commensur iter method predict potenti iter predict alway made error compound observ use input one may accur smaller may case choos small ultim achiev higher larger turn iter method plot curv figur best procedur altern polynomi inform convent work write explicitli two hidden layer network output assum linear conzid input connect hidden layer hidden layer hidden layer hidden layer output neuron linear comput element two formula due two nonlinear hidden eaz later let us rewrit formula twg specif number specifi train train finish one rel complic formula express output valu function input function relat one may surfac dimension exactli manner interpret formula two dimension surfac three dimension gener structur determin fact quit see one first sum function sigmoid form yet anoth sum involv may first thought simpl form restrict type surfac may initi wrong special form actual gener represent quit arbitrari prove reason represent surfac point surfac may approxim ad seri appropri exampl occur familiar wave train suitabl frequenc amplitud togeth approxim curv half period fix wavelength one add bump togeth let us see may interpret togeth bump specifi height first consid sum figur plot exampl case two sigmoid orient sigmoid surfac determin posit height consid anoth function occur second function chosen displac chosen orient chosen opposit sign two function occur determin contribut sum togeth plot figur result ridg goal obtain local bup select anoth pair function add togeth get ridg surfac perpendicular first add two perpendicular ridg surfac togeth contribut result plot figur see almost much one obtain local maxima howev also configur corner corrupt bump tri note one way fix take chosen depress local minima saddl zero slmultan send central toward result plot figur sought note necessari function suppli procedur obtain local bump arbitrari height two bump obtain use four function ridg surfac two ridg per take result height bump determin bump ad equat gener network architectur procedur ad two function togeth form two perpendicular ridg togeth form final form final bump repres figur obtain number bump one add neuron hidden layer repeatedli use figur templat four neuron per bump hidden one neuron per bump hidden layer connect need obtain one add four neuron hidden layer one neuron layer never need two type connect alreadi schemat specifi figur accuraci depend number turn number neuron per result easili gener higher two one need hidden first one hidden neuron second layer argument given also extend situat one symbol inform neural input code bit os similarli input may still real valu case binari output attempt group real valu input separ make output valu tend toward one take third final output neuron repres given recal use linear neuron typic backpropag one never actual achiev hard output layer achiev instead valu typic valu call valu realli outsid framework may perform mere increas slope sigmoid function output therefor effect final function use output layer symbol inform pass hyperplan surfac plane cut form high call low valu call thu see heart abl form surfac gener cut hyperplan gener decis therefor abl conclud network architectur consist two hidden layer suffici symbol process train boolean symbol map one use second hidden layer remov saddl bump saddl lower central maximum one may choos threshold output layer cut bump point saddl correct decis whether represent reason subsequ achiev good predict predict oppos train issu address also note use sigma unit high order net attempt construct surfac polynomi cut hyperplan decis therefor essenti element ail neural net algorithm ident surfac particular parameter surfac vari one algorithm provid unifi framework mani neural net may provid use framework attempt construct new togeth bump approxim surfac reason procedur use deal real valu tie gener approxim fourier better quit success clearli economi gain give neural net bump start instead neural net form way would use multidimension gaussian function situat somewhat differ process symbol input symbol encod bit one defin input valu dimension input shown one learn train set input pattern appropri form place surfac effect method memor poor method obtain correct predict new point contrast real valu input come chaotic time input point symbol process separ bump add togeth form smooth input bit string corner vertex sens one corner hypercub surround thu commonli use input represent symbol process requir neural net extrapol surfac make new new input pattern new corner commonli case real valu extrapol farmor danger procedur view separ train set one might expect basi argument net would fail dismal symbol solut appar although neural net learn symbol process train set form necessari oper simplest occur xor one implement problem duplic hidden layer architectur figur appropi two hidden layer hidden layer discuss boolean one even elimin second howev architectur figur also connect xor output function two input ridg orient run thu net may learn symbol train set without use high version process take place complex symbol represent train data consider effici bump hidden neuron extend surfac allow reason predict surfac conclus contraat popular capabl quit number accuraci predict problem exce convent method order neural work construct surfac high dimension perform signal process task real valu close standard method function one need two hidden layer process real valu input approxim control number neuron per number emphas although two layer hidden suffici may multilay architectur may effici network sens neuron number perform accur minim predict symbol input data achiev slightli method use real valu instead form local would accur repres train data would well new network use like effici repres scatter input net gener perform predict interpol real valu must perform extrapol symbol data usual bit outstand problem tanh represent seem well symbol process function base represent symbol input affect abil geometr viewpoint provid framework examin neural net suggest question neural net relat current neural net approach convent thank sidorovich number recognit neural net genet databas manuscript prepar denker automat rule bell laboratori farher signal proce,0
48,48,"457 
DISTRIBUTED NEURAL INFORMATION PROCESSING 
IN THE VESTIBULO-OCULAR SYSTEM 
Clifford Lau 
Office of Naval Research Detachment 
Pasadena, CA 91106 
Vicente Honrubia* 
UCLA Division of Head and Neck Surgery 
Los Angeles, CA 90024 
ABSTRACT 
A new distributed neural information-processing 
model is proposed to explain the response characteristics 
of the vestibulo-ocular system and to reflect more 
accurately the latest anatomical and neurophysiological 
data on the vestibular afferent fibers and vestibular nuclei. 
In this model, head motion is sensed topographically by hair 
cells in the semicircular canals. Hair cell signals are then 
processed by multiple synapses in the primary afferent 
neurons which exhibit a continuum of varying dynamics. The 
model is an application of the concept of ""multilayered"" 
neural networks to the description of findings in the 
bullfrog vestibular nerve, and allows us to formulate 
mathematically the behavior of an assembly of neurons 
whose physiological characteristics vary according to their 
anatomical properties. 
INTRODUCTION 
Traditionally the physiological properties of 
individual vestibular afferent neurons have been modeled as 
a linear time-invariant system based on Steinhausen's 
description of cupular motion. 1 The vestibular nerve input 
to different parts of the central nervous system is usually 
represented by vestibular primary afferents that have 
*Work supported by grants NS09823 and NS08335 from the National 
Institutes of Health (NINCDS) and grants from the Pauley Foundation and the 
Hope for Hearing Research Foundation. 
American Institute of Physics 1988 
458 
response properties defined by population averages from 
individual neurons. 2 
A new model of vestibular nerve organization is 
proposed to account for the observed variabilities in the 
primary vestibular afferent's anatomical and physiological 
characteristics. The model is an application of the concept 
of ""multilayered"" neural networks, 3,4 and it attempts to 
describe the behavior of the entire assembly of vestibular 
neurons based on new physiological and anatomical findings 
in the frog vestibular nerve. It was found that primary 
vestibular afferents show systematic differences in 
sensitivity and dynamics and that there is a correspondence 
between the individual neuron's physiological properties and 
the location of innervation in the area of the crista and also 
the sizes of the neuron's fibers and somas. This new view 
of topological organization of the receptor and vestibular 
nerve afferents is not included in previous models of 
vestibular nerve function. Detailed findings from this 
laboratory on the anatomical and physiological properties of 
the vestibular afferents in the bullfrog have been 
published. 5,6 
REVIEW OF THE ANATOMY AND PHYSIOLOGY 
OF THE VESTIBULAR NERVE 
The most pertinent anatomical and physiological data 
on the bullfrog vestibular afferents are summarized here. 
In the vestibular nerve from the anterior canal four major 
branches (bundles) innervate different parts of the crista 
(Figure 1). From serial histological sections it has been 
shown that fibers in the central bundle innervate hair cells 
at the center of the crista, and the lateral bundles project 
to the periphery of the crista. In each nerve there is an 
average of 1170 _+ 171 (n -- 5) fibers, of which the thick 
fibers (diameter > 7.0 microns, large dots) constitute 8% 
and the thin fibers (< 4.0 microns, small dots) 76%. The 
remaining fibers (16%) fall into the range between 4.0 and 
7.0 microns. We found that the thick fibers innervate only 
the center of the crista, and the thinner ones predominantly 
innervate the periphery. 
459 
400 
00 2 4 6 8 10 12 14 16 18 20 
DIAMETER (m i cron) 
Fig. 1. Number of fibers and their diameters in the anterior 
semicircular canal nerve in the bullfrog. 
There appears to be a physiological and anatomical 
correlation between fiber size and degree of regularity of 
spontaneous activity. By recording from individual neurons 
and subsequently labeling them with horseradish peroxidase 
intracellularly placed in the axon, it is possible to visualize 
and measure individual ganglion cells and axons and to 
determine the origin of the fiber in the crista as well as the 
projections in different parts of the vestibular nuclei. 
Figure 2 shows an example of three neurons of different 
sizes and degrees of regularity of spontaneous activity. In 
general, fibers with large diameters tend to be more 
irregular with large coefficients of variation (CV) of the 
interspike intervals, whereas thin fibers tend to be more 
regular. There is also a relationship for each neuron 
between CV and the magnitude of the response to 
physiological rotatory stimuli, that is, the response gain. 
(Gain is defined as the ratio of the response in spikes per 
second to the stimulus in degrees per second.) Figure 3 
shows a plot of gain as a function of CV as well as of fiber 
diameter. For the more regular fibers (CV < 0.5), the gain 
tends to increase as the diameter of the fiber increases. 
460 
,500um 
THIN MEDIUM THICK 
C.V. = 0.25 C V = 0 39 C V = 0 61 
,t . 
0 200 0 200 0 200 
MILLISECONDS 
Fig. 2. Examples of thin, medium and thick fibers and their 
spontaneous activity. CV - coefficient of variation. 
For the more irregular fibers (CV > 0.5), the gain tends to 
remain the same with increasing fiber diameter (4.9 _+ 1.9 
spik es/seco n d/d eg rees/seco nd). 
Figure 4 shows the location of projection of the 
afferent fibers at the vestibular nuclei from the anterior, 
posterior, and horizontal canals and saccule. There is an 
overall organization in the pattern of innervation from the 
afferents of each vestibular organ to the vestibular nuclei, 
with fibers from different receptors overlapping in various 
461 
0.1 
3.8 6.1 8.4 10.7 13.0 15.3 
FIBER DIAMETER 
I , ! . I I . I . 
0 0.2 0.4 0.6 0.8 1 1.2 
Coefficient of Variation 
Fig. 3. Gain versus fiber diameters and CV. Stimulus was a 
sinusoidal rotation of 0.05 Hz at 22 degrees/second peak 
velocity. 
parts of the vestibular nuclei. Fibers from the anterior 
semicircular canal tend to travel ventrally, from the 
horizontal canal dorsally, and from the posterior canal the 
most dorsally. 
For each canal nerve the thick fibers (indicated by 
large dots) tend to group together to travel lateral to the 
thin fibers (indicated by diffused shading); thus, the 
topographical segregation between thick and thin fibers at 
the periphery is preserved at the vestibular nuclei. 
In following the trajectories of individual neurons in 
the central nervous system, however, we found that each 
fiber innervates all parts of the vestibular nuclei, caudally 
to rostrally as well as transversely, and because of the 
spread of the large number of branches, as many as 200 
from each neuron, there is a great deal of overlap among the 
projections. 
DISTRIBUTED NEURAL INFORMATION-PROCESSING MODEL 
Figure 5 represents a conceptual organization, based 
on the above anatomical and physiological data, of Scarpa's 
462 
ANT. 
HORIZ. 
Fig. 4. 
POST. 
SAC. 
Three-dimensional reconstruction of the primary 
afferent fibers' location in the vestibular nuclei. 
ganglion cells of the vestibular nerve and their innervation 
of the hair cells and of the vestibular nuclei. The diagram 
depicts large Scarpa's ganglion cells with thick fibers 
innervating restricted areas of hair cells near the center of 
the crista (top) and smaller Scarpa's ganglion cells with 
thin fibers on the periphery of the crista innervating 
multiple hair cells with a great deal of overlap among 
fibers. At the vestibular nuclei, both thick and thin fibers 
innervate large areas with a certain gradient of overlapping 
among fibers of different diameters. 
The new distributed neural information-processing 
model for the vestibular system is based on this anatomical 
organization, as shown in Figure 6. The response 
463 
S, G, 
H.C. 
Fig. 5. Anatomical 
organization of the 
vestibular nerve. 
H.C. - hair ceils. 
S.G.- Scarpa's 
ganglion ceils. 
V.N. - vestibular 
nuclei. 
Fig. 6. Distributed neural 
the vestibular nerve. 
information-processing model of 
464 
characteristic of the primary afferent fiber is represented 
by the transfer function SGj(s). This transfer function 
serves as a description of the gain and phase response of 
individual neurons to angular rotation. The simplest model 
would be a first-order system with d.c. gain Kj (spikes/ 
second over head acceleration) and a time constant Tj 
(seconds) for the jth fiber as shown in equation (1): 
Kj 
SGj(s) = 1 + sT'j'""' (1) 
For the bullfrog, Kj can range from about 3 to 25 
spikes/second/degree/second 2, and Tj from about 10 to 0.5 
second. The large and high-gain neurons are more phasic 
than the small neurons and tend to have shorter time 
constants. As described above, Kj and Tj for the jth neuron 
are functions of location and fiber diameter. Bode plots 
(gain and phase versus frequency) of experimental data 
seem to indicate, however, that a better transfer function 
would consist of a higher-order system that includes 
fractional power. This is not surprising since the afferent 
fiber response characteristic must be the weighted sum of 
several electromechanical steps of transduction in the hair 
cells. A plausible description of these processes is given in 
equation (2): 
K k 
SGj(s) = '. Wjk 1 + sT k ' 
k 
(2) 
where gain K k and time constant T k are the electro- 
mechanical properties of the hair cell-cupula complex and 
are functions of location on the crista, and Wjk is the 
synaptic efficacy (strength) between the jth neuron and the 
kth hair cell. In this context, the transfer function given 
in equation (1) provides a measure of the ""weighted 
average"" response of the multiple synapses given in 
equation (2). 
465 
We also postulate that the responses of the vestibular 
nuclei neurons reflect the weighted sums of the responses 
of the primary vestibular afferents, as follows: 
VN i=f(y., Tij SGj), (3) 
J 
where f(.) is a sigmoid function describing the change in 
firing rates of individual neurons due to physiological 
stimulation. It is assumed to saturate between 100 to 300 
spikes/second, depending on the neuron. Tij is the synaptic 
efficacy (strength) between the ith vestibular neuron and 
the jth afferent fiber. 
CONCLUSIONS 
Based on anatomical and physiological data from the 
bullfrog we presented a description of the organization of 
the primary afferent vestibular fibers. The responses of 
the afferent fibers represent the result of summated 
excitatory processes. The information on head movement in 
the assemblage of neurons is codified as a continuum of 
varying physiological responses that reflect a sensoritopic 
organization of inputs from the receptor to the central 
nervous system. We postulated a new view of the 
organization in the peripheral vestibular organs and in the 
vestibular nuclei. This view does not require unnecessary 
simplification of the varying properties of the individual 
neurons. The model is capable of extracting the weighted 
average response from assemblies of large groups of 
neurons while the unitary contribution of individual neurons 
is preserved. The model offers the opportunity to 
incorporate further developments in the evaluation of the 
different roles of primary afferents in vestibular function. 
Large neurons with high sensitivity and high velocity of 
propagation are more effective in activating reflexes that 
require quick responses such as vestibulo-spinal and 
vestibulo-ocular reflexes. Small neurons with high 
thresholds for the generation of action potentials and lower 
sensitivity are more tuned to the maintenance of posture 
466 
and muscle tonus. We believe the physiological differences 
reflect the different physiological roles. 
In this emerging scheme of vestibular nerve 
organization it appears that information about head 
movement, topographically filtered in the crista, is 
distributed through multiple synapses in the vestibular 
centers. Consequently, there is also reason to believe that 
different neurons in the vestibular nuclei preserve the 
variability in response characteristics and the topological 
discrimination observed in the vestibular nerve. Whether 
this idea of the organization and function of the vestibular 
system is valid remains to be proven experimentally. 
References
1. W. Steinhausen, Arch. Ges. Physiol. 217, 747 (1927). 
2. J. M. Goldberg and C. Fernandez, in: Handbook of 
Physiology, Sect. 1, Vol. III, Part 2 (I. Darian-Smith, 
ed., Amer. Physiol. Soc., Bethesda, MD, 1984), p. 977. 
3. D. E. Rumelhart, G. E. Hinton and J. L. McClelland, in: 
Parallel Distributed Processing: Explorations in the 
Microstructure of Cognition, Vol. 1: Foundations 
(D. E. Rumelhart, J. L. McClelland and the PDP Research 
Group, eds., MIT Press, Cambridge, MA, 1986), p. 45. 
4. J. Hopfield, Proc. Natl. Acad. Sci. 7), 2554 (1982). 
5. V. Honrubia, S. Sitko, J. Kimm, W. Betts and I. Schwartz, 
Intern. J. Neurosci. 1,, 197 (1981). 
6. V. Honrubia, S. Sitko, R. Lee, A. Kuruvilla and I. Schwartz, 
Laryngoscope 94, 464 (1984). 
", neural inform process system lau naval research detach ca divis head neck surgeri ca new distribut neural propos explain respons characterist system reflect latest anatom neurophysiolog vestibular affer fiber vestibular head motion sens topograph hair semicircular hair cell signal multipl synaps primari affer exhibit continuum vari applic concept network descript find vestibular allow us formul behavior assembl neuron physiolog characterist vari accord physiolog properti vestibular affer neuron model linear system base cupular vestibular nerv input differ part central nervou system usual vestibular primari affer work support grant nation health grant pauley foundat hear research institut physic properti defin popul averag new model vestibular nerv organ account observ variabl vestibular anatom physiolog model applic concept neural attempt behavior entir assembl vestibular base new physiolog anatom find frog vestibular found primari affer show systemat differ dynam correspond individu physiolog properti locat innerv area crista also size fiber new view topolog organ receptor vestibular affer includ previou model nerv detail find anatom physiolog properti vestibular affer bullfrog anatomi physiolog vestibular nerv pertin anatom physiolog data bullfrog vestibular affer summar vestibular nerv anterior canal four major innerv differ part crista serial histolog section fiber central bundl innerv hair cell center later bundl project peripheri nerv thick larg constitut thin fiber small fiber fall rang found thick fiber innerv center thinner one predominantli number fiber diamet anterior canal nerv appear physiolog anatom fiber size degre regular record individu neuron subsequ label horseradish peroxidas place possibl visual measur individu ganglion cell axon origin fiber crista well differ part vestibular show exampl three neuron differ degre regular spontan fiber larg diamet tend larg coeffici variat wherea thin fiber tend also relationship neuron cv magnitud respons rotatori respons defin ratio respons spike per stimulu degre per figur plot gain function cv well fiber regular fiber gain increas diamet fiber medium thick exampl medium thick fiber cv coeffici irregular fiber gain tend increas fiber diamet eg show locat project fiber vestibular nuclei horizont canal organ pattern innerv vestibular organ vestibular fiber differ receptor overlap variou diamet variat gain versu fiber diamet stimulu rotat hz peak vestibular fiber anterior canal tend travel canal posterior canal canal nerv thick fiber tend group togeth travel later fiber diffus segreg thick thin fiber peripheri preserv vestibular follow trajectori individu neuron central nervou found innerv part vestibular caudal rostral well larg number mani great deal overlap among neural model repres conceptu base anatom physiolog reconstruct primari locat vestibular cell vestibular nerv innerv hair cell vestibular diagram larg ganglion cell thick fiber restrict area hair cell near center crista smaller ganglion cell fiber peripheri crista innerv hair cell great deal overlap among vestibular thick thin fiber larg area certain gradient overlap fiber differ new distribut neural vestibular system base anatom shown figur respons anatom hair vestibular distribut neural vestibular model primari affer fiber repres transfer function transfer function descript gain phase respons neuron angular simplest model system gain kj head time constant tj jth fiber shown equat kj rang tj larg neuron phasic small neuron tend shorter time describ kj tj jth neuron function locat fiber bode plot phase versu experiment data better transfer function consist system includ surpris sinc affer respons characterist must weight sum electromechan step transduct hair plausibl descript process given wjk gain time constant properti hair complex function locat wjk efficaci jth neuron hair transfer function given equat provid measur respons multipl synaps given also postul respons vestibular neuron reflect weight sum respons primari vestibular tij sigmoid function describ chang rate individu neuron due physiolog assum satur depend tij synapt ith vestibular neuron jth affer anatom physiolog data present descript organ primari affer vestibular respons affer fiber repres result summat inform head movement assemblag neuron codifi continuum physiolog respons reflect sensoritop input receptor central postul new view peripher vestibular organ view requir unnecessari vari properti individu model capabl extract weight respons assembl larg group unitari contribut individu neuron model offer opportun develop evalu role primari affer vestibular neuron high sensit high veloc effect activ reflex quick respons small neuron high gener action potenti lower tune mainten postur muscl believ physiolog differ differ physiolog emerg scheme vestibular nerv appear inform head topograph filter multipl synaps vestibular also reason believ neuron vestibular nuclei preserv respons characterist topolog observ vestibular whether idea organ function vestibular valid remain proven goldberg handbook part hinton distribut explor foundat clelland pdp research mit bett kuruvilla,0
49,49,"467 
SPONTEOUS D INFORPtATION-TRIGGERED SEOMENTS OF SERIES 
OF HUM BRAIN ELECTRIC FIELD P1APS 
D. Lehmann, D. Brandeis*, A. Horst, H. Ozaki* and I. Pal* 
Neurolosy Department, University Hospital, 8091ZOrich, Switzerland 
ABSTRACT 
The brain works in a state-dependent manner: processin 9 
stratesies and access to stored information depends on the momentary 
functional state which is continuously re-adjusted. The state is 
manifest as spatial confisuration of the brain electric field. 
Spontaneous and information-trissered brain electric activity is a 
series of momentary field maps. Adaptive sesnentation of spontaneous 
series into spatially stable epochs (states) exhibited 210 mse� mean 
sesments, discontinuous chanses. Different maps imply different 
active neural populations, hence expectedly different effects on 
information processins: Reaction time differred between map classes 
at stimulus arrival. Se9ments misht be units of brain information 
processins (content/mode/step), possibly operationalizin9 
consciousness time. Related units (e. 9. trissered by stimuli durin S 
fisure perception and voluntary attention) misht specify brain sub- 
mechanisms of information treatment. 
BRAIN FUNCTIL STATES D THEIR CHANGES 
The momentary functional state of the brain is reflected by the 
confisuration of the brain's electro-rnasnetic field. The state 
manifests the stratesy , mode, step and content of brain information 
processins, and the state constrains the choice of stratesies and 
modes and the access to memory material available for processin 9 of 
incomin 9 information (1). The constraints include the avaiIabIe 
ranse of chanses of state in PAVLOV's classical ""orientin9 reaction"" 
as response to new or important informations. Different states misht 
be viewed as different functional connectivities between the neural 
elements. 
The orientin9 reaction (see 1,2) is the result of the first 
(""pre-attentive"") stase of information processin 9. This stase 
operates automatically (no involvement of consciousness) and in a 
parallel mode, and quickly determines whether (a) the information is 
important or unknown and hence requires increased attention and 
alertness, i.e. an orientin S reaction which means a re-adjustment of 
functional state in order to deal adequately with the information 
invokin 9 consciousness for further processins, or whether (b) the 
information is known or unimportant and hence requires no re- 
adjustment of state, i.e. that it can be treated further with well- 
* Present addresses: D.B. at Psychiat. Dept., V.A. Med. Center, San 
Francisco CA 94121; H.O. at Lab. Physiol. for the Developmentally 
Handicapped, Ibaraki Univ., Mito, Japan 310; I.P. at BioLosic 
Systems Corp., Mundelein IL 60060. 
American Institute of Physics 1988 
468 
established (""automatic"") strategies. Conscious strategies are slow 
but flexible (offer wide choice), automatic strategies are fast but 
rigid. 
Examples for functional states on a gross scale are wakefulness, 
drowsiness and sleep in adults, or developmental stages as infancy, 
childhood and adolescence, or drug states induced by alcohol or 
other psychoactive agents. The different states are associated with 
distinctly different ways of information processing. For example, in 
normal adults, reality-close, abstracting strategies based on causal 
relationships predominate during wakefulness, whereas in drowsiness 
and sleep (dreams), reality-remote, visualizing, associative 
concatenations of contents are used. Other well-known examples are 
drug states. 
BRAIN ELECTRIC FIELD DATA D STATES 
While alive, the brain produces an ever-changing electromagnetic 
field, which very sensitively reflects global and local states as 
effected by spontaneous activity, incoming information, metabolism, 
drugs, and diseases. The electric component of the brain's electro- 
magnetic field as non-invasively measured from the intact human 
scalp shows voltages between O.l and 250 microVolts, temporal 
frequencies between O.1 and 30, 100 or 3000 Hz depending on the 
examined function, and spatial frequencies up to 0.2 cycles/cm. 
Brain electric field data are traditionally viewed as time series 
of potentia! differences between two scalp locations (the 
electroencephalogram or EEG). Time series analysis has offered an 
effective way to class different gross brain functional states, 
typically using EEG power spectral values. Differences between power 
spectra during different gross states typically are greater than 
between different locations. States of lesser functional complexity 
such as childhood vs adult states, sieep vs wakefulness, and many 
drug-states vs non-drug states tend to increased power in slower 
frequencies (e.g. ,4). 
Time series analyses of epochs of intermediate durations between 
30 and 0 seconds have demonstrated (e.g. ,5,6) that there are 
significant and reliable relations between spectra! power or 
coherency values of EEG and characteristics of human menration 
(reality-close thoughts vs free associations, visual vs non-visual 
thoughts, positive vs negative emotions). 
Viewing brain electric field data as series of momentary field 
maps (7,8) opens the possibility to investigate the temporal 
microstructure of brain functional states in the sub-second range. 
The rationale is that the momentary configuration of activated 
neural elements represents a given brain functional state, and that 
the spatial pattern of activation is reflected by the momentary 
brain electric field which is recordable on the scalp as a momentary 
field map. Different configurations of activation (different field 
maps) are expected to be associated with different modes, 
strategies, steps and contents of information processing. 
469 
SE{!E]TATION OF BRuIN ELECTRIC P:P SERIES INT0 STABLE SEGME]qTS 
When viewin 9 brain electric activity as series of maps of 
momentary potential distributions, chan9es of functional state are 
reco9nizable as chan9es of the ""electric landscapes"" of these maps. 
Typically, several successive maps show similar landscapes, then 
quickly chan9e to a new confi9uration which a9ain tends to persist 
for a number of successive maps, su99estive of stable states 
concatenated by non-linear transitions (9,10). Stable map landscapes 
mi9ht be hypothesized to indicate the basic buildin 9 blocks of 
information processin9 in the brain, the ""atoms of thou9hts"". Thus, 
the task at hand is the reco9nition of the landscape confi9urations; 
this leads to the adaptive se9rnentation of time series of momentary 
maps into se9ments of stable landscapes durin9 varyin9 durations. 
We have proposed and used a method which describes the 
confi9uration of a momentary map by the locations of its maximal and 
minimal potential values, thus invokin9 a dipole model. The 
here is the phenomenolo9ical reco9nition of different momentary 
functional states usin9 a very limited number of major map features 
as classifiers, and we su99est conservative interpretion of the data 
as to real brain locations of the 9eneratin9 processes which always 
involve millions of neural elements. 
We have studied (11) map series recorded from 16 scalp locations 
over posterior skull areas from normal subjects durin9 relaxation 
with closed eyes. For adaptive se9mentation, the maps at the times 
of maximal map relief were selected for optimal si9nal/noise 
conditions. The locations of the maximal and minimal (extrema) 
potentials were extracted in each map as descriptors of the 
landscape; takin 9 into account the basically periodic nature of 
spontaneous brain electric activity (Fi9. 1), extrema locations were 
treated disre9ardin9 polarity information. If over time an extreme 
left its pre-set spatial window (say, one electrode distance), the 
se9ment was terminated. The map series showed stable map 
confi9urations for varyin9 durations (Fi9. 2), and discontinuous, 
step-wise chan9es. Over 6 subjects, restin 9 alpha-type EEG showed 
210 msec mean se9rnent duration; se9ments 1on9er than 323 msec 
covered 50% of total time; the most prominent se9ment class (1.5% of 
all classes) covered 20% of total time (prominence varied stron91y 
over classes; not all possible classes occurred). Spectral power and 
phase of avera9es of adaptive and pre-detemined se9ments 
demonstrated the adequacy of the strate9y and the homo9eneity of 
adaptive se9ment classes by their reduced within-class variance. 
Se9mentation usin9 91obal map dissimilarity (sum of Euklidian 
difference vs avera9e reference at all measured points) emulates the 
results of the extracted-characteristics-strate9y. 
FUNCTIL SIGNIFIC:qCE OF MOME]TARY MICRO STATES 
Since different maps of momentary EEG fields imply activity of 
different neural populations, different se9ment classes must 
manifest different brain functional states with expectedly different 
470 
189 %o 189 117 %o 117 125 to 125 132 to 132 
148 to 148 
171 to 171 179 .o 179 
RECORD=I FILE=:UP3EC2 
148 156 to 156 164 o 164 
187 o 187 195 to 195 s 
qORML SUBJECT, EYES CLOSED 
Fi9. 1. Series of momentary potential distribution maps of the brain 
field recorded from the scalp of a normal human durin 9 relaxation 
with closed eyes. Recordin 9 with 21 electrodes (one 5-electrode row 
added to the 16-electrode array in Fi9. 2) usin9 128 samples/sac/ 
channel. Head seen from above left ear left; white positive dark 
ne9ative  8 levels from +32 to -32 microVolts. Note the periodic 
reversal of field polarity within the about 100 msec (one cycle of 
the 8-12Hz so-called ""EEG alpha"" activity) while the field confi- 
9uration remains lar9ely constant. - This recordin9 and display was 
done with a BIAIN ATLAS system (BioLo9ic Systems Hundelein, IL). 
effects on on9oin 9 information processin9. This was supported by 
measurements of selective reaction time to acoustic stimuli which 
were randomly presented to ei9ht subjects durin9 different classes 
of EEG se9ments (323 responses for each subject). We found 
si9nificant reaction time differences over se9ment classes (ANOUA p 
smaller than .02) but similar characteristics over subjects. This 
indicates that the momentary sub-second state as manifest in the 
potential distribution map si9nificantly influences the behavioral 
consequence of information reachin 9 the brain. 
Presentation of information is followed by a sequence of 
potential distribution maps (""event-related potentials"" or EEP's, 
avera9ed over say 100 presentations of the same stimulus see 
The different spatial confi9urations of these maps (12) are thou9ht 
to reflect the sequential sta9es of information processin9 
associated with ""components"" of event-related brain activity (see 
e.9. i3) which are traditionally defined as times of maximal 
volta9es after information input (maximal response stren9th). 
471 
o 
Fig. 2. Sequence of spatially stable segments durin 9 a spontaneous 
series of momentary EEG maps of 3.1 sec duration in a normal 
volunteer. Each map shows the occurrence of the extreme potential 
values during one adaptively determined segment: the momentary maps 
were searched for the locations of the two extreme potentials; these 
locations were accumulated, and linearly interpolated between 
electrodes to construct the present maps. (The number of iso- 
frequency-of-occurrence lines therefore is related to the number of 
searched maps). - Head seen from above, left ear left, electrode 
locations indicated by crosses, most forward electrode at vertex. 
Data FIR filtered to 8-12Hz (alpha EEG). The figure to the left 
below each map is a running segment number. The figure to the right 
above each map multiplied by 50 indicates the senent duration in 
msec. 
Application of the adaptive segnentation procedure described above 
for identification of functional components of event-related brain 
electric map sequences requires the inclusion of polarity 
information (14); such adaptive segmentation permits to separate 
different brain functional states without resorting to the strength 
concept of processing stages. 
An example (12) might illustrate the type of results obtained 
with this analysis: Given segments of brain activity which were 
triggered by visual information showed different map configurations 
when subjects paid attention vs when they paid no attention to the 
stimulus, and when they viewed figures vs meaningless shapes as 
472 
LVF RYF 
FIGUR 
Ss) 
AATTENTION 
Fi 9, 3. Four difference maps, computed as differences between maps 
obtained durin9 (upper row) perception of a visual ""illusionary"" 
triangle figure (left picture) minus a visual non-figure (ri9ht) 
shown to the left and right visual hemi-fields (LVF, RVF), and 
obtained durin9 (lower row) attendin9 minus durin inorin the 
presented display. The analysed se9ment covered the time from 168 to 
200 msec after stimulus presentations. - Hean of 12 subjects. Head 
seen fom above, left ear left, 16 electrodes as in Fi. 2, 
isopotential contour lines at O.i microVolt steps, dotted negative 
referred to mean of all values. The ""illusionary"" figure stimulus 
was studied by Kanisza (16); see also (12). - Note that the mirror 
symmetric configuration of the difference maps for LVF and RVF is 
found for the ""figure"" effect only, not for the ""attention"" effect, 
but that the anterior-posterior difference is similar for both cases. 
stimuli. Fi. 3 illustrates such differences in map configuration. 
The ""attention""-induced and ""fi9ure""-induced chan9es in map 
configuration showed certain similarities e.. in the illustrated 
se9ment 168-200 msec after information arrival, supporting the 
hypothesis that brain mechanisms for figure perception draw on brain 
resources which in other circumstances are utilized in volontary 
attention. 
The spatially homogeneous temporal se9ments might be basic 
buildin blocks of brain information processin9, possibly 
operationalizin consciousness time (15), and offerin9 a common 
concept for analysis of brain spontaneous activity and event related 
brain potentials. The functional significance of the se9ments mi9ht 
be types/ modes/ steps of brain information processin or 
performance. Identification of related buildin9 blocks durin 
different brain functions accordingly could specify brain sub- 
mechanisms of information treatment. 
473 
Acknowledqement: Financial support by the Swiss National Science 
Foundation (including Fellowships to H.O. and I.P.) and by the EMDO, 
the Hartmann Muller and the SANDOZ Foundation is 9ratefully 
acknowledged. 
REFERENCES 
1. M. Koukkou and D. Lehmann, Brit. J. Psychiat. 142, 221-231 
(1983). 
2. A. Ohman, In: H.D. Kimmel, E.H. yon 01st and J.F. Orlebeke 
(Eds.), Dru9-Discrimination and State Dependent Learnin 9 
(Academic Press, New York, 1979), pp. 283-318. 
3. A. Katada, H. Ozaki, H. Suzuki and K. Suhara, Electroenceph. 
Clin. Neurophysiol. 52, 192-201 (1981). 
4. M. Koukkou and D. Lehmann, Biol. Psychiat. 11, 663-677 (1976). 
5. J. Berkhout, D.O. Walter and W.R. Adey, Electroenceph. olin. 
Neurophysiol. 27, 457-469 (1969). 
6. P. Grass, D. Lehmann, B. Meier, C.A. Meier and I. Pal, Sleep 
Res. 16, 231 (1987). 
7. D. Lehmann, Electroenceph. Clin. Neurophysiol. 31, 439-449 
8. D. Lehmann, In: H.H. Petsthe and M.A.B. Brazier (eds.), 
Synchronization of EEG Activity in Epilepsies (Springer, Wien, 
1972), pp. 307-326. 
9. H. Haken, Advanced Synergetics (Springer, Heidelberg, 1983). 
10. J.J. Nright, R.R. Kydd and G.L. Lees, Biol. Cybern., 1985, 53, 
11-17. 
11. D. Lehmann, H. Ozaki and I. Pal, Electroenceph. Clin. 
Neurophysiol. 67, 271-288 (1987). 
12. D. Brandeis and D. Lehmann, Neuropsychologia 24, 151-168 (1986). 
13. A.S. Gevins, N.H. Morgan, S.L. Bressler, B.A. Cutillo, R.M. 
White, J. Illes, D.S. Greet, J.C.Doyle and M. Zeitlin, Science 
235, 580-585 (1987). 
14. D. Lehmann and W. Skrandies, Progr. Neurobiol. 23, 227-250 
(1984). 
15. B. Libet, Human Neurobiol. 1, 235-242 (1982). 
16. G. Kanisza, Organization of Vision (Praeger, New York, 1979). 
", seoment seri brain electr field univers switzerland brain work processin access store inform depend momentari state continu state spatial confisur brain electr brain electr activ momentari field adapt sesnent spontan spatial stabl epoch exhibit mean discontinu differ map impli differ neural henc expectedli differ effect reaction time differ map class stimulu misht unit brain inform possibl relat unit trisser stimuli durin percept voluntari misht specifi brain inform state chang momentari function state brain reflect state stratesi step content brain inform state constrain choic stratesi access memori materi avail processin inform constraint includ ie chans state classic respons new import differ state misht view differ function connect neural reaction result first stase inform processin stase automat involv quickli determin whether inform unknown henc requir increas attent orientin reaction mean state order deal adequ inform conscious whether known unimport henc requir treat present san ca development ibaraki japan losic mundelein il institut physic consciou strategi slow flexibl wide automat strategi fast function state gross scale sleep development stage drug state induc alcohol psychoact differ state associ differ way inform abstract strategi base causal predomin wherea drowsi sleep associ content exampl electr field data state brain produc electromagnet sensit reflect global local state spontan incom electr compon field measur intact human show voltag tempor hz depend spatial frequenc electr field data tradit view time seri differ two scalp locat time seri analysi offer way class differ gross brain function use eeg power spectral differ power differ gross state typic greater differ state lesser function complex childhood vs adult sieep vs mani vs state tend increas power slower seri analys epoch intermedi durat second demonstr reliabl relat power valu eeg characterist human menrat thought vs free visual vs posit vs neg brain electr field data seri momentari field open possibl investig tempor brain function state rational momentari configur activ element repres given brain function spatial pattern activ reflect momentari electr field record scalp momentari differ configur activ field expect associ differ step content inform electr seri stabl ts viewin brain electr activ seri map potenti function state sever success map show similar new tend persist number success stabl state transit stabl map landscap hypothes indic basic buildin block task hand landscap lead adapt time seri momentari stabl landscap propos use method describ momentari map locat maxim potenti thu dipol differ momentari state limit number major map featur conserv interpret data real brain locat process alway million neural studi map seri record scalp locat posterior skull area normal subject relax close adapt map time maxim map relief select optim locat maxim minim extract map descriptor takin account basic period natur brain electr activ extrema locat polar time extrem spatial window one electrod map seri show stabl map durat restin eeg show msec mean msec total promin class cover total time vari possibl class spectral power adapt adequaci class reduc map dissimilar euklidian vs refer measur emul ce micro state differ map momentari eeg field impli activ neural differ class must differ brain function state expectedli differ eye close seri momentari potenti distribut map brain record scalp normal human durin relax close recordin electrod row array head seen left ear white dark level note period field polar within msec cycl field remain display atla system inform support select reaction time acoust stimuli randomli present subject differ class eeg respons found reaction time differ class similar characterist momentari state manifest distribut map influenc behavior inform reachin inform follow sequenc distribut map present see differ spatial map reflect sequenti inform brain activ tradit defin time maxim inform input respons sequenc spatial stabl segment durin spontan momentari eeg map sec durat normal map show occurr extrem potenti one adapt determin momentari map search locat two extrem linearli interpol construct present number line therefor relat number head seen left ear electrod indic forward electrod fir filter figur left map run segment figur right map multipli indic durat adapt segnent procedur describ identif function compon brain map sequenc requir inclus polar adapt segment permit separ brain function state without resort strength process exampl might illustr type result obtain given segment brain activ visual inform show differ map configur subject paid attent vs paid attent view figur vs meaningless shape ryf four differ comput differ map percept visual figur minu visual left right visual minu analys cover time msec stimulu hean head left ear electrod contour line volt dot neg mean figur stimulu studi kanisza see also note mirror configur differ map lvf rvf effect differ similar illustr differ map map show certain similar illustr msec inform support brain mechan figur percept draw brain circumst util volontari spatial homogen tempor might basic block brain inform possibl conscious time common analysi brain spontan activ event relat function signific step brain inform identif relat block brain function accordingli could specifi brain inform financi support swiss nation scienc fellowship hartmann muller sandoz foundat koukkou yon orlebek state depend learnin new suzuki koukkou walter meier sleep petsth brazier eeg activ epilepsi advanc synerget kydd ozaki brandei neuropsychologia scienc lehmann human organ vision new,0
50,50,"474 
OPTIMIZATION WITH ARTIFICIAL NEURAL NETWORK SYSTEMS: 
A MAPPING PRINCIPLE 
AND 
A COMPARISON TO GRADIENT BASED METHODS * 
Harrison MonFook Leong 
Research Institute for Advanced Computer Science 
NASA Ames Research Center 230-5 
Moffett Field, CA, 94035 
ABSTRACT 
General formulae for mapping optimization problems into systems of ordinary differential 
equations associated with artificial neural networks are presented. A comparison is made to optim- 
ization using gradient-search methods. The performance measure is the settling time from an initial 
state to a target state. A simple analytical example illustrates a situation where dynamical systems 
representing artificial neural network methods would settle faster than those representing gradient- 
search. Settling time was investigated for a more complicated optimization problem using com- 
puter simulations. The problem was a simplified version of a problem in medical imaging: deter- 
mining loci of cerebral activity from electromagnetic measurements at the scalp. The simulations 
showed that gradient based systems typically setfled 50 to 100 times faster than systems based on 
current neural network optimization methods. 
INTRODUCTION 
Solving optimization problems with systems of equations based on neurobiological principles 
has recently received a great deal of attention. Much of this interest began when an artificial 
neural network was devised to find near-optimal solutions to an np-complete problem t3. Since 
then, a number of problems have been mapped into the same acdficial neural network and varia- 
tions of it to.3.,.7.8.9.2L23.2, In this paper, a unifying principle underlying these mappings is 
derived for systems of first to n th-order ordinary differential equations. This mapping principle 
bears similarity to the mathematical tools used to generate optimization methods based on the gra- 
dient. In view of this, it seemed important to compare the optimization efficiency of dynamical 
systems constructed by the neural network mapping principle with dynamical systems constructed 
from the gradient. 
THE PRINCIPLE 
This paper concerns itself with networks of computational units having a state variable v, a 
function f that describes how a unit is driven by inputs, a linear ordinary differential operator with 
constant coefficients D (v) that describes the dynamical response of each unit, and a function g that 
describes how the output of a computational unit is determined from its state v. In particular, the 
paper explores how outputs of the computational units evolve with time in terms of a scalar func- 
tion E, a single state variable for the whole network. Fig. 1 summarizes the relationships between 
variables, functions, and operators associated with each computational unit. Eq. (1) summarizes the 
equations of motion for a network composed of such units: 
tY()(v ) = j'(g (vO ..... gN(vN ) ) 
where the i th element of/(t) is D(t)(v;) ' superscript (M) denotes that operator D is M tn order, 
the i tn element of f is fi(gt(vt) ..... gv(vv)), and the network is comprised of N computa- 
tional units. The network of Hopfield t2 has M=I, functions f are weighted linear sums, and func- 
tions  (where the i  element of  is gi(vi) ) are all the same sigmoJd function. We will exam- 
ine two ways of defining functions  given a function F. Along with these definitions will be 
Work supported by NASA Cooperative Agreement No. NCC 2408 
American Institute of Physics 1988 
475 
deftned corresponding functions E that will be used to describe the dynamics of Eq. (1). 
The first method corresponds to optimization methods introduced by artificial neural network 
research. It will be referred to as method V (""dell g""): 
�-- 
with associated E function 
Here, 
dr,, (s) 
dt (2b) 
denotes the gradient of H, where partials are taken with respect to variables of 2?, and 
Ee denotes the E function associated with gradient operator Ve. With appropriate operator D and 
functions f and , EF is simply the ""energy function"" of Hopfield 2. Note that F_,q. (2a) makes 
explicit that we will only be concerned with f'"" that can be derived from scalar potential functions. 
For example, this restriction excludes artificial neural networks that have connections between exci- 
tatory and inhibitory units such as that of Freeman 8. The second method corresponds to optimiza- 
tion methods based on the gradient. It will be referred to as method V v, (""dell v""): 
f = V-,F (3a) 
with associated E function 
t N 
= F() - ,. 9(U)(v:(s)) 
to that for Eqs. (2). 
dvi(s) ] dvi(s) 
dt J dt ds 
(3b) 
 computational unit i: 
transform that determines unit i's 
g;(, output from state variable vi 
/t D (v:)  differential operator specifying the 
\ - v(] function governing how inputs to 
 //'- unit i are combined to drive it 
Figure 1: Schematic of a computational unit i from which net- 
where notation is analogous 
The critical result 
that allows us to map 
optimization problems into 
networks described by Eq. 
(1) is that conditions on the 
constituents of the equation 
can be chosen so that along 
any solution trajectory, the 
E function corresponding 
to the system will be a 
monotonic function of time. 
For method Vxv, here are 
the conditions: all func- 
tions  axe 1) differentiable 
and 2) monotonic in the 
same sense. Only the first 
works considered in this paper are constructed. Trianes suggest 
condition is needed to 
make a similar assertion for connections between computational units. 
method V�. When these conditions are met and when solutions of Eq. (1) exist, the dynamical sys- 
tems can he used for optimization. The appendix contains proofs for the monotonicity of function 
E along solution trajectories and references necessary existence theorems. In conclusion, mapping 
optimization problems onto dynamical systems summarized by Eq. (1) can he reduced to a matter 
of differentiation if a scalar function representation of the problem can be found and the integrals 
of Eqs. (2b) and (3b) are ignorable. This last assumption is certainly upheld for the case where 
operator D has no derivatives less than M t"" order. In simulations below, it will be observed to 
hold for the case M=I with a nonzero 0 t"" order derivative in D. (Also see Lapedes and Farber 9.) 
PERSPECTIVES OF RECENT WORK 
476 
The formulations above can be used to classify the neural network optimization techniques 
used in several recent studies. In these studies, the functions  were all identical. For the most 
part, following Hopfield's formulation, researchers o.3.1,.7,23. z have used method Vi to derive 
forms of Eq. (1) that exhibit the ability to find extrema of Ei with Ei quadratic in functions  and 
all functions  describable by sigrnoid functions such as tanh (x). However, several researchers 
have written about artificial neural networks associated with non-quadratic E functions. Method 
Vi has been used to derive systems capable of finding extrema of non-quadratic Ei 19. Method 
V� has been used to derive systems capable of optimizing E- e where E- e were not necessarily qua- 
dratic in variables  2. A sort of hybrid of the two methods was used by leffery and Rosner a to 
find extrema of functions that were not quadratic. The important distinction is that their functions f 
were derived from a given function F using Eq. (3a) where, in addition, a sign definite diagonal 
matrix was introduced; the left side of Eq. (3a) was left multiplied by this matrix. A perspective 
on the relationship between all three methods to construct dynamical systems for optimization is 
summarized by Eq. (4) which describes the relationship between methods Vi and VN 
[as(v,) ]-, 
vf, = a,g [. (4) 
where diag [ xl ] is a diagonal matrix with xi as the diagonal element of row i. (A similar equation 
has been derived for quadratic F .) The relationship between the method of Jeffery and Rosner 
and V is simply F.q. (4) with the time dependent diagonal matrix replaced by a constant diagonal 
matrix of free parameters. It is noted that Jeffery and Rosner presented timing results that compared 
simulated annealing, conjugate-gradient, and artificial neural network methods for optimization. 
Their results axe not comparable to the results reported below since they used computation time as 
a performance measure, not settling times of analog systems. The perspective provided by F.q. (4) 
will be useful for anticipating the relative performance of methods Vi and V in the analytical 
example below and will aid in understanding the results of computer simulations. 
COMPARISON OF METHODS V AND 
When M=I and operator D has no 0 th order derivatives, method V is the basis of gradient- 
search methods of optimization. Given the long history of of such methods, it is important to know 
what possible benefits could be achieved by the relatively new optimization scheme, method Vi. 
In the following, the optimization efficiency of methods Vi,, ad V v, is compared by comparing set- 
tling times, the time required for dynamical systems described by Eq. (1) to traverse a continuous 
path to local optima. To qualify this performance measure, this study anticipates application to the 
creation of analog devices that would instantlate F.q. (1); hence, we are not interested in estimating 
the number of discrete steps that would be required to find local optima, an appropriate perfor- 
mance measure if the point was to develop new numerical methods. An analytical example will 
serve to illustrate the possibility of improvements in settling time by using method Vi instead of 
method V,. Computer simulations will be reported for more complicated problems following this 
example. 
For the analytical example, we will examine the case where all functions  are identical and 
g (v) = tanhG (v - Th ) (5) 
where G > 0 is the gain and Th is the threshold. Transforms similar to this are widely used in 
artificial neural network research. Suppose we wish to use such computational units to search a 
multi-dimensional binary solution space. We note that 
dg= O sech :O (v - Th ) (6) 
dv 
is near 0 at valid solution states (comers of a hypercube for the case of binary solution spaces). We 
see from Eq. O) that near a valid solution state, a network based on method Vi will allow compu- 
tational units to recede from incorrect states and approach correct states comparatively faster. Does 
477 
thin imply faster settling time for method V,? 
To obtain an analytical comparison of settling times, consider the case where M=I and 
operator D has no 0 tn order derivatives and 
1 Sij (tanhGvl XtanhGvj) (7) 
where matrix S is symmetric. Method V, gives network equations 
 = S tanhG (8) 
dt 
and method V, gives network equations 
d""V = diag [G sech 2Gvl ] S tanhG-v  (9) 
dt 
where tanhG-V denotes a vector with i's component tanhGv. For method V there is one stable 
point, i.e. where  = 0, at  = 0. For method V, the stable points are V' = 0 and V'� V where 
V is the set of vectors with component values that are either +oo or --. Further trivialization 
allows for comparing estimates of settling times: Suppose S is diagonal. For this case, if v; = 0 is 
on the trajectory of any computational unit i for one method, v,. = 0 is on the trajectory of that unit 
for the other method; hence, a comparison of settling times can be obtained by comparing time 
estimates for a computational unit to evolve from near 0 to near an extremum or, equivalently, the 
converse. Specifically, let the interval be [o, 1-4] where 0<o<l-b and 0<b<l. For method Vv,, 
integrating velocity over time gives the estimate 
re = 
and for method V, the estimate is 
1- +in 'f2-b)--' 
(10) 
(11) 
From these estimates, method Vv will always take longer to satisfy the criterion for convergence: 
Note that only with the largest value for o, o = 1-4, is the first term of Eq. (10) zero; for any 
smaller o, this term is positive. Unfortunately, this simple analysis cannot be generalized to non- 
diagonal S. With diagonal S, all computational units operate independently. Hence, the derivation 
of -- is irrelevant with respect to convergence rates; convergence rate depends only on the diago- 
nal element of S having the smallest magnitude. In this sense, the problem is one dimensional. 
But for non-diagonal S, the problem would be, in general, multi-dimensional and, hence, the direc- 
tion of -- becomes relevant To compare settling times for non-diagonal S, computer simulations 
were done. These are described below. 
COMPUTER SIMULATIONS 
Methods 
The problem chosen for study was a much simplified version of a problem in medical imag- 
ing: Given electromagnetic field measurements taken from the human scalp, identify the location 
and magnitude of cerebral activity giving rise to the fields. This problem has received much atten- 
tion in the last 20 years 3,6.7. The problem, sufficient for our purposes here, was reduced to the 
following problem: given a few samples of the electric potential field at the surface of a spherical 
conductor wit_hin which reside several static electric dipoles, identify the dipole locations and 
moments. For this situation, there is a closed form solution for electric potential fields at the 
478 
spherical surface: 
(12) 
where  is the electric potential at the spherical conductor surface, ,,,,vt, is the location of the 
sample point ( :e denotes a vector,  the corresponding unit vector, and x the corresponding vector 
magnitude), ,. is the dipole moment of dipole i, and  is the vector from dipole i to :eja,,,, (This 
equafon can be derived from one derived by Brody, Terry, and Ideker a ). Fig. 2 facilitates pictur- 
ing these relationships. 
Figure 2: Vectors of Eq. (12). 
With this analytical solution, the problem was for- 
mulated as a least squares minimization problem where 
the variables were dipole moments. In short, the fol- 
lowing process was used: A dipole model was chosen. 
This model was used with Eq. (12) to calculate poten- 
6als at points on a sphere which covered about 60% of 
the surface. A cluster of internal locations that encom- 
passed the locations of the model was specified. The 
two optimization techniques were then required to deter- 
mine dipole moment values at cluster locations such 
that the collection of dipoles at cluster locations accu- 
rately reflected the dipole distribution specified by the 
model. 
This was to be done given only the potential values at the sample points and an initial guess of 
dipole moments at cluster locations. The optimization systems were to accomplish the task by 
m'mimizing the sum of squared differences between potentials calculated using the dipole model 
and potentials calculated using a guess of dipole moments at cluster locatious where the sum is 
taken over all sample points. Further simplifications of the problem included 
1) choosing the dipole model locations to correspond exactly to various locations of the cluster, 
2) requiring dipole model moments to .be 1, 0, or -1, and 
3) representing dipole moments at cluster locations with two bit binary numbers. 
To describe the dynamical systems used, it suffices to specify operator D and functions  of 
Eq. (1) and function F used in Eqs. (2a) and (3a). Operator D was 
d 
D = -- + 1. (13) 
dt 
Eq. (5) with a multiplicative factor of ,4 was used for all functions . Hence, regarding 
simplification 3) above, each cluster location was associated with two computational units. Consid- 
ering simplification 2) above, dipole moment magnitude 1 would be represented by both computa- 
tional units being in the high state, for -1, both in the low state, and for 0, one in the high state and 
one in the low state. Regarding function F, 
F = , mea,ured()--�tt,r() -- C , g(v) 2 (14) 
all jampie all computational 
pointj j unJ'tJ j 
where ,,aJrd is calculated from the dipole model and Eq. (12) (The subscript measured is used 
because the role of the dipole model is to simulate electric potentials that would be measured in a 
real world situation. In real world situations, we do not know the source distribution underlying 
,,asr,a.), c is an experimentally determined constant (.002 was used), and ctt is Eq. (12) 
where the sum of Eq. (12) is taken over all cluster locations and the ktn coordinate of the i tn clus- 
ter location dipole moment is 
,p,.,= Y, g(v:,,). (15) 
all bitJ b 
479 
Index j of Eq. (14) corresponds to one combination of indices ikb. 
Sample points, 100 of them, were scattered semi-uniformly over the spherical surface 
emphasized by horizontal shading in Fig. 3. Cluster locations, 11, and model dipoles, 5, were scat- 
tered within the subset of the sphere emphasized by vertical shading. For the dipole model used, 
10 dipole moment components were non-zero; hence, optimization techniques needed to hold 56 
dipole moment components at zero and set 10 components to correct non-zero values in order to 
correctly identify the dipole model underlying 
0.8 
Figure 3: 111ustration of the distribution of 
sample points on the surface of the spheri- 
cal conductor (horizontal shading) and the 
distribution of model dipole locations and 
cluster locations within the conductor 
(vertical shading). 
The dynamical systems corresponding to 
methods V and V were integrated using the 
forward Euler method (e.g. Press, Flannery, 
Teukolsky, and Vettefiing 22). Numerical 
methods were observed to be convergent exper- 
imentally: settling time and path length were 
observed to asymtotically approach stable 
values as step size of the numerical integrator 
was decreased over two orders of magnitude. 
Settling times, path lengths, and relative 
directions of travel were calculated for the two 
optimization methods using several different 
initial bit patterns at the cluster locations. In 
other words, the search was staxted at different 
comers of the hypercube comprising the space 
of acceptable solutions. One comer of the 
hypercube was chosen to be the target solution. 
(Note that a zero dipole moment has a degen- 
erate two bit representation in the dynamical 
systems explored; the target comer was arbitrarily chosen to he one of the degenerate solutions.) 
Note from Eq. (5) that for the network to reach a hypercube comer, all elements of  would have 
to be singular. For this reason, setfling time and other measures 
proximity of the computational units to their extremum states. 
Computations were done on a Sequent Balance. 
5 
Results 
Graph 1 shows results for exploring settling 
time as a function of extrernum depth, the minimum of 
the deviations of variables 5* from the threshold of 
functions . Extremum depth is reported in multiples 3 I 
of the width of functions . The term transition, used 
in the caption of Graph 1 and below, refers to the  2 
movement of a computational unit from one extremum 
state to the other. The calculations were done for two 
initial states, one where the output of 1 computational 
unit was set to zero and one where outputs of 13 com- 
putational units were set to zero; hence, 1 and 13, 0 
respectively, half transitions were required to reach 
the target hypercube comer. It can be observed that 
settling time increases faster for method Vv than that 
for method V, just as we would expect from consid- 
ering Eqs. (4) and (5). However, it can be observed 
that method Vw is still an order of magnitude faster 
even when extremum depth is 3 widths of functions 
. For the purpose of unambiguously identifying 
what hypercube comer the dynamical system settles 
were studied as a function of the 
0 I 2 3 
exi.emum depth 
Graph 1: settling time as a function of 
extremum depth. #: method V,, 1 half 
transition requited. *: method V, 13 
half transitions requixed. +: method 
Vv,, 1 half transition requixed. -: 
13 half transitions required. 
48O 
to, this extremum depth is more than adequate. 
Table 1 displays results for various initial conditions. Angles are reported in degrees. These 
measures refer to the angle between directions of travel in -space as specified by the two optimi- 
zation methods. The average angle reported is taken over all trajectory points visited by the numer- 
ical integrator. Irdfal angle is the angle at the beginning of the path. Parasite cost percentage is a 
measure that compares parasite cost, the integral in F. qs. (2b) and (3b), to the range of function F 
over the path: 
parasite cost % = 100x parasite cost 
I F. tit - Fiiti,,t I (16) 
transitions time relative path inifal Mean angle extremum parasite 
required time length angle (std dev) depth cost % 
I 0.16 100 6.1 68 76 (3.8) 2.3 0.22 
0.0016 1.9 76 (3.5) 2.3 0.039 
2 0.14 78 4.7 75 72 (4.3) 2.5 0.055 
0.0018 1.9 73 (4.1) 2.5 0.016 
3 0.15 71 4.7 74 71 (3.7) 2.3 0.051 
0.0021 2.1 72 (3.0) 2.5 0.0093 
7 0.19 59 4.6 63 69 (4.1) 2.4 0.058 
0.0032 2.4 71 (7.0) 2.7 0.0033 
10 0.17 49 3.8 60 63 (2.8) 2.5 0.030 
0.0035 2.5 64 (4.7) 2.8 0.00060 
13 0.80 110 9.2 39 77 (11) 2.3 0.076 
0.0074 3.2 71 (8.9) 2.7 0.0028 
Table 1: Settling time and other measurements for various required transitions. For 
each transition case, the upper row is for V and the lower row is for V�. Std der 
denotes standard deviation. See text for definition of measurement terms and units. 
Noting the differences in path length and angles reported, it is clear that the path taken to the target 
hypercube comer was quite different for the two methods. Method Vv settles from 1 to 2 orders of 
magnitude faster than method V, and usually takes a path less than half as long. These relation- 
ships did not change significantly for different values for c of Eq. (14) and coefficients of Eq. (13) 
(both unity in Eq. (13)). Values used favored method Vi. Parasite cost is consistently less 
significant for method V,, and is quite small for both methods. 
To further compare the ability of the optimization methods to solve the brain imaging prob- 
lem, a large variety of initial hypercube comers were tested. Table 2 displays results that suggest 
the ability of each method to locate the target comer or to converge to a solution that was con- 
sistent with the dipole model. Initial comers were chosen by randomly selecting a number of com- 
putational units and setting them to extremum states opposite to that required by the target solution. 
Five cases were run for each case of required transitions. It can be observed that the system based 
on method V v, is better at finding the target comer and is much better at finding a solution that is 
consistent with the dipole model. 
DISCUSSION 
The simulation results seem to contradict settling time predictions of the second analytical 
example. It is intuitively clear that there is no contradiction when considering the analytical exam- 
ple as a one dimensional search and the simulations as multi-dimensional searches. Consider Fig. 4 
which ilhstmtes one dimensional search starting at point I. Since both optimizafon methods must 
decrease function E monotonically, both must head along the same path to the minimum point A. 
Now consider Fig. 5 which illustrates a two dimensional search starting at point I: Here, the two 
methods needn't follow the same paths. The two dashed paths suggest that method V 1, can still be 
481 
transitions I V, 
required ferent dipole !different target different dipole different target 
solution comer comer,. solution comer comer 
3 I 0 4 0 0 5 
4 1 ! 3 0 1 4 
6 2 1 2 0 1 [ 4 
13 5 0 0 I 3 J 1 
20 5 0 0 0 5 I 0 
-' 26 5 0 0 2 3 I 0 
33 5 I 0 0 3 2t0 
40 5 0 0 3 { 2 i 0 
i o o I 2 !3t.o 
I o o I I L,o t 
Table 2: Solutions found starting from various initial conditions, five cases for each 
transition case. Different dipole solution indicates that the system assigned non-zero 
dipole moments at cluster locations that did not correspond to locations of the dipole 
model sources. Different corner indicates the solution was consistent with the dipole 
model but was not the target hypercube comer. Target corner indicates that the solu- 
tion was the target solution. 
monotonically decreasing E while traversing a more circui- 
tous route to minimum B or traversing a path to minimum 
A. The longer path lengths reported in Table 1 for method 
V, suggest the occurrence of the former. The data of Table 
2 verifies the occurrence of the latter: Note that for many 
cases where the system based on method Ve settled to the 
target comer, the system based on method V, settled to some 
other minimum. 
Would we observe similar differences in optimization 
efficiency for other optimization problems that also have 
binary solution spaces.'? A view that supports the plausibility 
of the affirmative is the following: Consider Eq. (4) and Eq. 
(5). We have already made the observation that method V,, 
would slow convergence into extrema of functions . We 
have observed this experimentally via Graph 1. These obser- 
vations suggest that computational units of V systems 
tend to stay closer to the transition regions of functions  
compared to computational units of Vi systems. It seems 
plausible that this property may allow Vv systems to avoid 
advancing too deeply toward ineffective solutions and, hence, 
allow the systems to approach effective solutions more 
efficiently. This behavior might also be the explanation for 
the comparative success of method Vv revealed in Table 2. 
E 
v 
Figure 4: One dimensional search 
for minima. 
v x t -- 
Ytgure 5: Two dimensional search 
for re'raima. 
Regarding the construction of electronic circuitry to instantiate .Eq. (1), systems based on 
method V v, would require the introduction of a component implementing multiplication by the 
derivative of functions . This additional complexity may hinder the use of method V v, for the 
482 
(a) 
Input 
? 
Ourput 
Input 
Ourput 
Figure 6: Schematized circuits for a com- 
putational unit. Notation is consistent 
with Horowitz and Hill . Shading of 
amplifiers is to earmark components 
referred to in the text. a) Computational 
unit for method Vr. b) Computational 
unit for method V v. 
construction of analog circuits for optimization. To 
illustrate the extent of this additional complexity, Fig. 
6a shows a schematized circuit for a computational 
unit of method V and Fig. 6b shows a schematized 
circuit for a computational unit of method Vv The 
simulations reported above suggest that there may be 
problems for which improvements in settling time 
may offset complications that might come with added 
circuit complexity. 
On the problem of imaging cerebral activity, the 
restfits above suggest the possibility of constructing 
analog devices to do the job. Consider the problem of 
analyzing electric potentials from the scalp of one per- 
son: It is noted that the measured electric potentials, 
measured, appear as linear coefficients in F of Eq. 
(lz0; hence, they would appear as constant terms in  
of Eq. (1). Thus, ,a,,r,d would be implemented as 
amplifier biases in the circuits of Figs. 6. This is a 
significant benefit. To understand this, note that func- 
tion f,. of Fig. 1 corresponding to the optimization of 
function F of Eq. (14) would involve a weighted 
linear sum of inputs gi(vi) ..... gtv(vtv). The weights 
would be the nonlinear coefficients of Eq. (lz0 and correspond to the strengths of the connections 
shown in Fig. 1. These connection strengths need only be calculated once for the person and can 
then be set in hardware using, for example, a resistor network. Electric potential measurements 
could then be analyzed by simply using the measurements to bias the input to shaded amplifiers of 
Figs. 6. For initialization, the system can be initialized with all dipole moments at zero (the 10 
transition case in Table 1). This is a reasonable first guess if it is assumed that cluster locations are 
far denser than the loci of cerebral activity to be observed. For subsequent measurements, the solu- 
tion for immediately preceding measurements would be a reasonable initial state if it is assumed 
that cerebral activity of interest waxes and wanes continuously. 
Might non-invasive real time imaging of cerebral activity be possible using such optimization 
devices? Results of this study are far from adequate for answering this question. Many complexi- 
ties that have been avoided may nullify the practicality of the idea. Among these problems are: 
1) The experiment avoided the possibility of dipole sources actually occurring at locations other 
than cluster locations. The minimization of function F of Eq. (lZ) may circumvent this 
problem by employing the superposition of dipole moments at neighboring cluster locations 
to give a sufficient model in the mean. 
2) The experiment assumed a very restricted range of dipole strengths. This might be dealt 
with by increasing the number of bits used to represent dipole moments. 
3) The conductor model, a homogeneously conducting sphere, may not be sufficient to model 
the human head 6. Non-sphericity and major inhomogeneities in conductivity can be dealt 
with, to a certain extent, by replacing Eq. (12) with a generalized equation based on a 
numerical approximation of a boundary integral equation 20 
z) The cerebral activity of interest may not be observable at the scalp. 
5) Not all forms of cerebral activity give rise to dipolar sources. (For example, this is well 
known in olfactory cortex s.) 
6) Activity of interest may be overwhelmed by irrelevant activity. Many methods have been 
devised to contend with this problem (For example, Gevins and Morgan 9.) 
Clearly, much theoretical work is left to be done. 
CONCLUDING REMARKS 
483 
In this study, the mapping principle underlying the application of artificial neural networks to 
the optimization of multi-dimensional scalar functions has been stated explicitly. Hopfield 2 has 
shown that for some scalar functions, i.e. functions F quadratic in functions , this mapping can 
lead to dynamical systems that can be easily implemented in hardware, notably, hardware that 
requires electronic components common to semiconductor technology. Here, mapping principles 
that have been known for a considerably longer period of time, those underlying gradient based 
optimization, have been shown capable of leading to dynamical systems that can also be imple- 
mented using semiconductor hardware. A problem in medical imaging which requires the search of 
a multi-dimensional surface full of local extrema has suggested the superiority of the latter mapping 
principle with respect to settling time of the corresponding dynamical system. This advantage may 
be quite significant when searching for global extrema using techniques such as iterated descent 2 
or iterated genetic hill climbing  where many searches for local extrema are required. This advan- 
tage is further emphasized by the brain imaging problem: volumes of measurements can be 
analyzed without reconfiguring the interconnections between computational units; hence, the cost of 
developing problem specific hardware for finding local extrema may be justifiable. Finally, simula- 
tions have contributed plausibility to a possible scheme for non-invasively imaging cerebral 
activity. 
APPENDIX 
To show that for a dynamical system based on method Vi, E is a monotonic function of 
time given that all functions  are differentiable and monotonic in the same sense, we need to 
show that the derivative of E, with respect to time is semi-definite: 
dE_,,i)F,dgi  D(t)(v,. dvildg , 
� 3gi dt ,. )- dt 
dt 
Substituting Eq. (2a), 
dE, -D (st)(vi) + 
dt  
Using Eq. (1), 
(^la) 
(Alb) 
(Ale) 
as needed. The appropriate inequality depends on the sense in which functions  are monotonic. 
In a similar manner, the result can be obtained for method V With the condition that functions  
axe differentiable, we can show that the derivative of E-- e is semi-definite: 
dE e t� 3Fv, dvi (t)(vg)_ -- dt 
dt � Ovl dt i 
Using Eqs. (3a) and (1), 
dE . ['dvi12> 
(A2b) 
as needed. 
In order to use the results derived above to conclude that Eq. (1) can be used for optimiza- 
6on of functions E- e and E, in the vicinity of some point o, we need to show that there exists a 
neighborhood of o in which there exist solution trajectories to Eq. (1). The necessary existence 
theorems and transformations of Eq. (1) needed in order to apply the theorems can be found in 
many texts on ordinary differential equations; e.g. Guckenheimer and Hoimes u. Here, it is mainly 
important to state that the theorems require that functions .eC �), functions  are differentiab", artifici neural network map principl comparison gradient base fook leong institut advanc comput scienc ame research center formula map optim problem system ordinari differenti associ artifici neural network comparison made use perform measur settl time initi target simpl analyt exampl illustr situat dynam system artifici neural network method would settl faster repres settl time investig complic optim problem use problem simplifi version problem medic loci cerebr activ electromagnet measur simul gradient base system typic setfl time faster system base neural network optim optim problem system equat base neurobiolog principl recent receiv great deal much interest began artifici network devis find solut problem sinc number problem map acdfici neural network unifi principl underli map system first ordinari differenti map principl similar mathemat tool use gener optim method base view seem import compar optim effici dynam construct neural network map principl dynam system construct principl paper concern network comput unit state variabl describ unit driven linear ordinari differenti oper coeffici describ dynam respons function output comput unit determin state explor output comput unit evolv time term scalar singl state variabl whole summar relationship oper associ comput summar motion network compos th element superscript denot oper tn tn element network compris network hopfield function weight linear element jd two way defin function given function along definit support nasa cooper agreement ncc institut physic correspond function use describ dynam first method correspond optim method introduc artifici neural network refer method associ function gradient partial taken respect variabl denot function associ gradient oper appropri oper ef simpli hopfield note make concern deriv scalar potenti restrict exclud artifici neural network connect inhibitori unit freeman second method correspond method base refer method associ function dt ds comput unit determin unit output state variabl vi differenti oper specifi function govern input unit combin drive schemat comput unit notat analog critic result allow us map problem describ condit equat chosen along solut function correspond system function method axe differenti monoton first consid paper suggest need similar assert connect comput condit met solut dynam use appendix contain proof monoton function along solut trajectori refer necessari exist map problem onto dynam system summar reduc matter differenti scalar function represent problem found integr last assumpt certainli upheld case deriv less simul observ case nonzero order deriv see laped farber recent work formul use classifi neural network optim techniqu sever recent function follow research use method deriv exhibit abil find extrema quadrat function function describ sigrnoid function tanh sever research written artifici neural network associ method use deriv system capabl find extrema method use deriv system capabl optim necessarili variabl sort hybrid two method use lefferi rosner extrema function import distinct function deriv given function use sign definit diagon left side left multipli perspect relationship three method construct dynam system optim describ relationship method vn diag xl diagon matrix xi diagon element row similar equat deriv quadrat relationship method jefferi rosner simpli time depend diagon matrix replac constant diagon free note jefferi rosner present time result compar artifici neural network method result axe compar result report sinc use comput time perform settl time analog perspect provid use anticip rel perform method analyt aid understand result comput method oper th order method basi method given long histori import know possibl benefit could achiev rel new optim method optim effici method compar compar time requir dynam system describ travers continu local qualifi perform studi anticip applic analog devic would instantl interest estim number discret step would requir find local appropri measur point develop new numer analyt exampl illustr possibl improv settl time use method instead comput simul report complic problem follow analyt examin case function ident th gain th transform similar wide use neural network suppos wish use comput unit search binari solut note sech th near valid solut state hypercub case binari solut near valid solut network base method allow unit reced incorrect state approach correct state compar impli faster settl time method obtain analyt comparison settl consid case tn order deriv gvl matrix method give network equat method give network equat diag sech denot vector compon method one stabl method stabl point set vector compon valu either trivial compar estim settl suppos trajectori comput unit one trajectori unit comparison settl time obtain compar time comput unit evolv near near extremum let interv method veloc time give estim method estim method vv alway take longer satisfi criterion largest valu first term term simpl analysi can not gener diagon comput unit oper deriv irrelev respect converg converg rate depend element smallest problem one problem would becom relev compar settl time comput simul describ simul problem chosen studi much simplifi version problem medic given electromagnet field measur taken human identifi locat magnitud cerebr activ give rise problem receiv much last year suffici purpos reduc given sampl electr potenti field surfac spheric resid sever static electr identifi dipol locat close form solut electr potenti field electr potenti spheric conductor locat point denot correspond unit correspond vector dipol moment dipol vector dipol deriv one deriv idek facilit vector analyt problem least squar minim problem variabl dipol process dipol model model use calcul point sphere cover cluster intern locat locat model optim techniqu requir dipol moment valu cluster locat collect dipol cluster locat reflect dipol distribut specifi done given potenti valu sampl point initi guess moment cluster optim system accomplish task sum squar differ potenti calcul use dipol model potenti calcul use guess dipol moment cluster locati sum sampl simplif problem includ choos dipol model locat correspond exactli variou locat requir dipol model moment repres dipol moment cluster locat two bit binari describ dynam system suffic specifi oper function function use oper multipl factor use function regard cluster locat associ two comput simplif dipol moment magnitud would repres unit high low one high state low regard function jampi comput calcul dipol model subscript measur use role dipol model simul electr potenti would measur world real world know sourc distribut underli experiment determin constant sum taken cluster locat ktn coordin tn locat dipol moment correspond one combin indic scatter spheric surfac horizont shade cluster model within subset sphere emphas vertic dipol model dipol moment compon optim techniqu need hold moment compon zero set compon correct valu order identifi dipol model underli distribut point surfac conductor model dipol locat locat within conductor dynam system correspond integr use euler method vettefi numer observ converg settl time path length asymtot approach stabl step size numer integr decreas two order path rel travel calcul two method use sever differ bit pattern cluster search staxt differ hypercub compris space accept one comer chosen target zero dipol moment two bit represent dynam target comer arbitrarili chosen one degener network reach hypercub element would setfl time measur comput unit extremum done sequent show result explor settl function extrernum minimum deviat variabl threshold extremum depth report multipl width function term use caption graph refer comput unit one extremum calcul done two one output comput set zero one output unit set half transit requir reach target hypercub observ time increas faster method vv method would expect observ method vw still order magnitud faster extremum depth width function purpos unambigu identifi hypercub comer dynam system settl studi function depth settl time function method half method transit method half transit half transit extremum depth display result variou initi angl report refer angl direct travel specifi two averag angl report taken trajectori point visit irdfal angl angl begin parasit cost percentag compar parasit integr rang function cost parasit cost time rel path inif mean angl extremum parasit time length angl depth cost settl time measur variou requir transit upper row lower row std der standard see text definit measur term differ path length angl clear path taken target comer quit differ two method vv settl order faster method usual take path less half chang significantli differ valu coeffici uniti valu use favor method parasit cost consist less method quit small compar abil optim method solv brain imag larg varieti initi hypercub comer tabl display result suggest abil method locat target comer converg solut dipol initi comer chosen randomli select number unit set extremum state opposit requir target case run case requir observ system base method better find target comer much better find solut dipol simul result seem contradict settl time predict second analyt intuit clear contradict consid analyt one dimension search simul consid ilhstmt one dimension search start point sinc optimizafon method must function must head along path minimum point consid illustr two dimension search start point two follow two dash path suggest method still dipol target differ dipol differ target comer solut comer comer solut found start variou initi five case differ dipol solut indic system assign moment cluster locat correspond locat dipol differ corner indic solut consist dipol target hypercub target corner indic target decreas travers rout minimum travers path minimum longer path length report tabl method suggest occurr data tabl verifi occurr note mani system base method settl system base method settl observ similar differ optim optim problem also solut view support plausibl affirm consid alreadi made observ method slow converg extrema function observ experiment via graph suggest comput unit system stay closer transit region function comput unit vi seem properti may allow vv system avoid deepli toward ineffect solut system approach effect solut behavior might also explan compar success method vv reveal tabl one dimension search two dimension search construct electron circuitri instanti system base would requir introduct compon implement multipl function addit complex may hinder use method schemat circuit notat consist horowitz hill shade earmark compon comput method comput method analog circuit extent addit show schemat circuit comput method show schemat comput unit method report suggest may improv settl time offset complic might come ad problem imag cerebr suggest possibl construct devic consid problem electr potenti scalp one note measur electr appear linear coeffici would appear constant term would implement bias circuit understand note correspond optim would involv weight sum input weight nonlinear coeffici correspond strength connect connect strength need calcul person set hardwar resistor electr potenti measur analyz simpli use measur bia input shade amplifi system initi dipol moment zero case tabl reason first guess assum cluster locat denser loci cerebr activ subsequ immedi preced measur would reason initi state assum cerebr activ interest wax wane real time imag cerebr activ possibl use optim result studi far adequ answer mani avoid may nullifi practic among problem experi avoid possibl dipol sourc actual occur locat cluster minim function may circumv employ superposit dipol moment neighbor cluster locat give suffici model experi assum restrict rang dipol might dealt increas number bit use repres dipol conductor homogen conduct may suffici model human head major inhomogen conduct dealt certain replac gener equat base approxim boundari integr equat cerebr activ interest may observ form cerebr activ give rise dipolar well olfactori cortex activ interest may overwhelm irrelev mani method contend problem gevin morgan much theoret work left remark map principl underli applic artifici neural network optim scalar function state hopfield scalar function quadrat function map dynam system easili implement hardwar electron compon common semiconductor map principl known consider longer period underli gradient base shown capabl lead dynam system also use semiconductor problem medic imag requir search surfac full local extrema suggest superior latter map respect settl time correspond dynam advantag may quit signific search global extrema use techniqu iter descent iter genet hill climb mani search local extrema emphas brain imag volum measur without reconfigur interconnect comput cost problem specif hardwar find local extrema may contribut plausibl possibl scheme imag cerebr show dynam system base method monoton function given function differenti monoton need deriv respect time dvildg dt dt appropri inequ depend sens function similar result obtain method condit function show deriv dvi dt ovl dt order use result deriv conclud use function vicin point need show exist exist solut trajectori necessari exist transform need order appli theorem found text ordinari differenti guckenheim hoim mainli state theorem requir function function differentiab,2
51,51,"485 
TOWARDS AN ORGANIZING PRINCIPLE FOR 
A LAYERED PERCEPTUAL NETWORK 
Ralph Linsker 
IBM Thomas J. Watson Research Center, Yorktown Heights, NY 10598 
Abstract 
An information-theoretic optimization principle is proposed for the development 
of each processing stage of a multilayered perceptual network. This principle of 
""maximum information preservation"" states that the signal transformation that is to be 
realized at each stage is one that maximizes the information that the output signal values 
(from that stage) convey about the input signals values (to that stage), subject to certain 
constraints and in the presence of processing noise. The quantity being maximized is a 
Shannon information rate. I provide motivation for this principle and -- for some simple 
model cases -- derive some of its consequences, discuss an algorithmic implementation, 
and show how the principle may lead to biologically relevant neural architectural 
features such as topographic maps, map distortions, orientation selectivity, and 
extraction of spatial and temporal signal correlations. A possible connection between 
this information-theoretic principle and a principle of minimum entropy production in 
nonequilibrium thermodynamics is suggested. 
Introduction 
This paper describes some properties of a proposed information-theoretic 
organizing principle for the development of a layered perceptual network. The purpose 
of this paper is to provide an intuitive and qualitative understanding of how the principle 
leads to specific feature-analyzing properties and signal transformations in some simple 
model cases. More detailed analysis is required in order to apply the principle to cases 
involving more realistic patterns of signaling activity as well as specific constraints on 
network connectivity. 
This section gives a brief summary of the results that motivated the formulation 
of the organizing principle, which I call the principle of ""maximum information 
preservation."" In later sections the principle is stated and its consequences studied. 
In previous work  I analyzed the development of a layered network of model cells 
with feedforward connections whose strengths change in accordance with a Hebb-type 
synaptic modification rule. I found that this development process can produce cells that 
are selectively responsive to certain input features, and that these feature-analyzing 
properties become progressively more sophisticated as one proceeds to deeper cell 
layers. These properties include the analysis of contrast and of edge orientation, and 
are qualitatively similar to properties observed in the first several layers of the 
mammalian visual pathway. 2 
Why does this happen? Does a Hebb-type algorithm (which adjusts synaptic 
strengths depending upon correlations among signaling activities 3) cause a developing 
perceptual network to optimize some property that is deeply connected with the mature 
network's functioning as an information processing system? 
American Institute of Physics 1988 
486 
Further analysis 4.s has shown that a suitable Hebb-type rule causes a 
linear-response cell in a layered feedforward network (without lateral connections) to 
develop so that the statistical variance of its output activity (in response to an ensemble 
of inputs from the previous layer) is maximized, subject to certain constraints. The 
mature cell thus performs an operation similar to principal component analysis (PCA), 
an approach used in statistics to expose regularities (e.g., clustering) present in 
high-dimensional input data. (Oja 6 had earlier demonstrated a particular form of 
Hebb-type rule that produces a model cell that implements PCA exactly.) 
Furthermore, given a linear device that transforms inputs into an output, and given 
any particular output value, one can use optimal estimation theory to make a ""best 
estimate"" of the input values that gave rise to that output. Of all such devices, I have 
found that an appropriate Hebb-type rule generates that device for which this ""best 
estimate"" comes closest to matching the input values. 4.5 Under certain conditions, such 
a cell has the property that its output preserves the maximum amount of information 
about its input values? 
Maximum Information Preservation 
The above results have suggested a possible organizing principle for the 
development of each layer of a multilayered perceptual network? The principle can be 
applied even if the cells of the network respond to their inputs in a nonlinear fashion, 
and even if lateral as well as feedforward connections are present. (Feedback from later 
to earlier layers, however, is absent from this formulation.) This principle of ""maximum 
information preservation"" states that for a layer of cells L that is connected to and 
provides input to another layer M, the connections should develop so that the 
transformation of signals from L to M (in the presence of processing noise) has the 
property that the set of output values M conveys the maximum amount of information 
about the input values L, subject to various constraints on, e.g., the range of lateral 
connections and the processing power of each cell. The statistical properties of the 
ensemble of inputs L are assumed stationary, and the particular L-to-M transformation 
that achieves this maximization depends on those statistical properties. The quantity 
being maximized is a Shannon information rate. 7 
An equivalent statement of this principle is: The L-to-M transformation is chosen 
so as to minimize the amount of information that would be conveyed by the input values 
L to someone who already knows the output values M. 
We shall regard the set of input signal values L (at a given time) as an input 
""message""; the message is processed to give an output message M. Each message is in 
general a set of real-valued signal activities. Because noise is introduced during the 
processing, a given input message may generate any of a range of different output 
messages when processed by the same set of connections. 
The Shannon information rate (i.e., the average information transmitted from L 
to M per message) is 7 
R = E� E m P(L,M) log [P(L,M)/P(L)P(M)]. 
(1) 
For a discrete message space, P(L) [resp. P(M)] is the probability of the input (resp. 
output) message being L (resp. M), and P(L,M) is the joint probability of the input 
being L and the output being M. [For a continuous message space, probabilities are 
487 
replaced by probability densities, and sums (over states) by integrals.] This rate can be 
written as 
(2) 
where 
I� -- - Y� P(L) log P(L) 
(3) 
is the average information conveyed by message L and 
ItiM-- ZMP(M) YtP(LlM) logP(LlM) 
(4) 
is the average information conveyed by message L to someone who already knows M. 
Since It. is fixed by the properties of the input ensemble, maximizing R means 
minimizing ILi M, as stated above. 
The information rate R can also be written as 
L (5) 
where IM and I1L are defined by interchanging L and M in Eqns. 3 and 4. This form is 
heuristically useful, since it suggests that one can attempt to make R large by (if 
possible) simultaneously making I large and/ul  small. The term I is largest when 
each message M occurs with equal probability. The term !tl . is smallest when each L 
is transformed into a unique M, and more generally is made small by ""sharpening"" the 
P(M[ L) distribution, so that for each L, P(M [ L) is near zero except for a small set of 
messages M. 
How can one gain insight into biologically relevant properties of the L  M 
transformation that may follow from the principle of maximum information preservation 
(which we also call the ""infomax"" principle)? In a network, this L  M transformation 
may be a function of the values of one or a few variables (such as a connection strength) 
for each of the allowed connections between and within layers, and for each cell. The 
search space is quite large, particularly from the standpoint of gaining an intuitive or 
qualitative understanding of network behavior. We shall therefore consider a simple 
model in which the dimensionalities of the L and M signal spaces are greatly reduced, 
yet one for which the infomax analysis exhibits features that may also be important 
under more general conditions relevant to biological and synthetic network 
development. 
The next four sections are organized as follows. (i) A model is introduced in 
which the L and M messages, and the L-to-M transformation, have simple forms. The 
infomax principle is found to be satisfied when some simple geometric conditions (on 
the transformation) are met. (ii) I relate this model to the analysis of signal processing 
and noise in an interconnection network. The formation of topographic maps is 
discussed. (iii) The model is applied to simplified versions of biologically relevant 
problems, such as the emergence of orientation selectivity. (iv) I show that the main 
properties of the infomax principle for this model can be realized by certain local 
algorithms that have been proposed to generate topographic maps using lateral 
interactions. 
488 
A Simple Geometric Model 
In this model, each input message L is described by a point in a low-dimensional 
vector space, and the output message M is one of a number of discrete states. For 
definiteness, we will take the L space to be two-dimensional (the extension to higher 
dimensionality is straightforward). The L  M transformation consists of two steps. 
(i) A noise process alters L to a message L  lying within a neighborhood of radius v 
centered on L. (ii) The altered message L  is mapped deterministically onto one of the 
output messages M. 
A given L   M mapping corresponds to a partitioning of the L space into regions 
labeled by the output states M. (We do not exclude a priori the possibility that multiple 
disjoint regions may be labeled by the same M.) Let A denote the total area of the L 
state space. For each M, let A (M) denote the area of L space that is labeled by M. Let 
s(M) denote the total border length that the region(s) labeled M share with regions of 
unlike M-label. A point L lying within distance v of a border can be mapped onto either 
M-value (because of the noise process L  L  ). Call this a ""borderline"" L. A point L 
that is more than a distance v from every border can only be mapped onto the M-value 
of the region containing it. 
Suppose v is sufficiently small that (for the partitionings of interest) the area 
occupied by borderline L states is small compared to the total area of the L space. 
Consider first the case in which P(L) is uniform over L. Then the information rate R 
(using Eqn. 5) is given approximately (through terms of order v) by 
R = - E M [A(M)/A] 1og[A(M)/A] - (�v/A) E M s(M). (6) 
To see this, note that P(M) = A(M)/A and that P(M[ L) log P(MI L) is zero except for 
borderline L (since 0 log 0 = 1 log 1 = 0). Here 'r is a positive number whose value 
depends upon the details of the noise process, which determines P(M[ L) for borderline 
L as a function of distance from the border. 
For small v (low noise) the first term (I,) on the RHS of Eqn. 6 dominates. It is 
maximized when the A(M) [and hence the P(M)] values are equal for all M. The second 
term (with its minus sign), which equals (-IIL), is maximized when the sum of the 
border lengths of all M regions is minimized. This corresponds to ""sharpening"" the 
P(MIL) distribution in our earlier, more general, discussion. This suggests that the 
infomax solution is obtained by partitioning the L space into M-regions (one for each 
M value) that are of substantially equal area, with each M-region tending to have 
near-minimum border length. 
Although this simple analysis applies to the low-noise case, it is plausible that even 
when v is comparable to the spatial scale of the M regions, infomax will favor making 
the M regions have approximately the same extent in all directions (rather than be 
elongated), in order to ""sharpen"" P(M[ L) and reduce the probability of the noise 
process mapping L onto many different M states. 
What if P(L) is nonuniform.'? Then the same result (equal areas, minimum border) 
is obtained except that both the area and border-length elements must now be weighted 
by the local value of P(L). Therefore the infomax principle tends to produce maps in 
which greater representation in the output space is given to regions of the input signal 
space that are activated more frequently. 
To see how lateral interactions within the M layer can affect these results, let us 
suppose that the L-* M mapping has three, not two, process steps: L--,-L t 
489 
- M  - M, where the first two steps are as above, and the third step changes the output 
M' into any of a number of states M (which by definition comprise the 
""M-neighborhood"" of M'). We consider the case in which this M-neighborhood relation 
is symmetric. 
This type of ""lateral interaction"" between M states causes the infomax principle 
to favor solutions for which M regions sharing a border in L space are M-neighbors in 
the sense defined. For a simple example in which each state M' has n M-neighbors 
(including itself), and each M-neighbor has an equal chance of being the final state 
(given M'), infomax tends to favor each M-neighborhood having similar extent in all 
directions (in L space). 
Relation Between the Geometric Model and Network Properties 
The previous section dealt with certain classes of transformations from one 
message space to another, and made no specific reference to the implementation of these 
transformations by an interconnected network of processor cells. Here we show how 
some of the features discussed in the previous section are related to network properties. 
For simplicity suppose that we have a two-dimensional layer of uniformly 
distributed cells, and that the signal activity of each cell at any given time is either 1 
(active) or 0 (quiet). We need to specify the ensemble of input patterns. Let us first 
consider a simple case in which each pattern consists of a disk of activity of fixed radius, 
but arbitrary center position, against a quiet background. In this case the pattern is fully 
defined by specifying the coordinates of the disk center. In a two-dimensional L state 
space (previous section), each pattern would be represented by a point having those 
coordinates. 
Now suppose that each input pattern consists not of a sharply defined disk of 
activity, but of a ""fuzzy"" disk whose boundary (and center position) are not sharply 
defined. [Such a pattern could be generated by choosing (from a specified distribution) 
a position xc as the nominal disk center, then setting the activity of the cell at position 
x to 1 with a probability that decreases with distance I x - xc I � ] Any such pattern can 
be described by giving the coordinates of the ""center of activity"" along with many other 
values describing (for example) various moments of the activity pattern relative to the 
center. 
For the noise process L - L  we suppose that the activity of an L cell can be 
""misread"" (by the cells of the M layer) with some probability. This set of distorted 
activity values is the ""message"" L . We then suppose that the set of output activities M 
is a deterministic function of L . 
We have constructed a situation in which (for an appropriate choice of noise level) 
two of the dimensions of the L state space -- namely, those defined by the disk center 
coordinates -- have large variance compared to the variance induced by the noise 
process, while the other dimensions have variance comparable to that induced by noise. 
In other words, the center position of a pattern is changed only a small amount by the 
noise process (compared to the typical difference between the center positions of two 
patterns), whereas the values of the other attributes of an input pattern differ as much 
from their noise-altered values as two typical input patterns differ from each other. 
(Those attributes are ""lost in the noise."") 
Since the distance between L states in our geometric model (previous section) 
corresponds to the likelihood of one L state being changed into the other by the noise 
490 
process, we can heuristically regard the L state space (for the present example) as a 
""slab"" that is elongated in two dimensions and very thin in all other dimensions. (In 
general this space could have a much more complicated topology, and the noise process 
which we here treat as defining a simple metric structure on the L state space need not 
do so. These complications are beyond the scope of the present discussion.) 
This example, while simple, illustrates a feature that is key to understanding the 
operation of the infomax principle: The character of the ensemble statistics and of the 
noise process jointly determine which attributes of the input pattern are statistically 
most significant; that is, have largest variance relative to the variance induced by noise. 
We shall see that the infomax principle selects a number of these most significant 
attributes to be encoded by the L -- M transformation. 
We turn now to a description of the output state space M. We shall assume that 
this space is also of low dimensionality. For example, each M pattern may also be a disk 
of activity having a center defined within some tolerance. A discrete set of discriminable 
center-coordinate values can then be used as the M-region ""labels"" in our geometric 
model. 
Restricting the form of the output activity in this particular way restricts us to 
considering positional encodings L -* M, rather than encodings that make use of the 
shape of the output pattern, its detailed activity values, etc. However, this restriction 
on the form of the output does not determine which features of the input patterns are 
to be encoded, nor whether or not a topographic (neighbor-preserving) mapping is to 
be used. These properties will be seen to emerge from the operation of the infomax 
principle. 
In the previous section we saw that the infomax principle will tend to lead to a 
partitioning of the L space into M regions having equal areas [if P(L) is uniform in the 
coordinates of the L disk center] and minimum border length. For the present case this 
means that the M regions will tend to ""tile"" the two long dimensions of the L state space 
""slab,"" and that a single M value will represent all points h L space that differ only in 
their low-variance coordinates. If P(L) is nonuniform, then the area of the M region 
at L will tend to be inversely proportional to P(L). Furthermore, if there are local lateral 
connections between M cells, then (depending upon the particular form of such 
interaction) M states corresponding to nearby localized regions of layer-M activity can 
be M-neighbors in the sense of the previous section. In this case the mapping from the 
two high-variance coordinates of L space to M space will tend to be topographic. 
Examples: Orientation Selectivity and Temporal Feature Maps 
The simple example in the previous section illustrates how infomax can lead to 
topographic maps, and to map distortions [which provide greater M-space 
representation for regions of L having large P(L)]. Let us now consider a case in which 
information about input features is positionally encoded in the output layer as a result 
of the infomax principle. 
Consider a model case in which an ensemble of patterns is presented to the input 
layer L. Each pattern consists of a rectangular bar of activity (of fixed length and width) 
against a quiet background. The bar's center position and orientation are chosen for 
each pattern from uniform distributions over some spatial interval for the position, and 
over all orientation angles (i.e., from 0 � to 180�). The bar need not be sharply defined, 
but can be ""fuzzy"" in the sense described above. We assume, however, that all 
491 
properties that distinguish different patterns of the ensemble -- except for center 
position and orientation -- are ""lost in the noise"" in the sense we discussed. 
To simplify the representation of the solution, we further assume that only one 
coordinate is needed to describe the center position of the bar for the given ensemble. 
For example, the ensemble could consist of bar patterns all of which have the same y 
coordinate of center position, but differ in their x coordinate and in orientation 0. 
We can then represent each input state by a point in a rectangle (the L state space 
defined in a previous section) whose abscissa is the center-position coordinate x and 
whose ordinate is the angle 0. The horizontal sides of this rectangle are identified with 
each other, since orientations of 0 � and 180 � are identical. (The interior of the 
rectangle can thus be thought of as the surface of a horizontal cylinder.) 
The number Nx of different x positions that are discriminable is given by the range 
of x values in the input ensemble divided by the tolerance with which x can be measured 
(given the noise process L  L); similarly for No. The relative lengths Ax and A0 of the 
sides of the L state space rectangle are given by Ax/AO = Nx/No. We discuss below the 
case in which Nx   No; if No were > > Nx the roles of x and 0 in the resulting mappings 
would be reversed. 
There is one complicating feature that should be noted, although in the interest 
of clarity we will not include it in the present analysis. Two horizontal bar patterns that 
are displaced by a horizontal distance that is small compared with the bar length, are 
more likely to be rendered indiscriminable by the noise process than are two vertical bar 
patterns that are displaced by the same horizontal distance (which may be large 
compared with the bar's width). The Hamming distance, or number of binary activity 
values that need to be altered to change one such pattern into the other, is greater in the 
latter case than in the former. Therefore, the distance in L state space between the two 
180 
120 
6O 
0 
x 
UNORIENTED RECEPTIVE FIELDS 
180 
120 
60 
0 
Figure 1. 
Orientation Selectivity in a Simple Model: As the input domain size 
(see text) is reduced [from (a) upper left, to (b) upper right, to (c) 
lower left figure], infomax favors the emergence of an 
orientation-selective L -+ M mapping. (d) Lower right figure shows 
a solution obtained by applying Kohonen's relaxation algorithm with 
50 M-points (shown as dots) to this mapping problem. 
492 
states should be greater in the latter case. This leads to a ""warped"" rather than simple 
rectangular state space. We ignore this effect here, but it must be taken into account in 
a fuller treatment of the emergence of orientation selectivity. 
Consider now an L - M transformation that consists of the three-step process 
(discussed above) (i) noise-induced L  L  ; (ii) deterministic L Mr; (iii) 
lateral-interaction-induced M t  M. Step (ii) maps the two-dimensional L state space 
of points (x, 0) onto a one-dimensional M state space. For the present discussion, we 
consider L   M t maps satisfying the following Ansatz: Points corresponding to the 
M states are spaced uniformly, and in topographic order, along a helical line in L state 
space (which we recall is represented by the surface of a horizontal cylinder). The pitch 
of the helix (or the slope dO/dx) remains to be determined by the infomax principle. 
Each M-neighborhood of M states (previous section) then corresponds to an interval 
on such a helix. A state L  is mapped onto a state in a particular M-neighborhood if L  
is closer (in L space) to the corresponding interval of the helix than to any other portion 
of the helix. We call this set of L states (for an M-neighborhood centered on M ) the 
""input domain"" of M. It has rectangular shape and lies on the cylindrical surface of the 
L space. 
We have seen (previous sections) that infomax tends to produce maps having (i) 
equal M-region areas, (ii) topographic organization, and (iii) an input domain (for each 
M-neighborhood) that has similar extent in all directions (in L space). Our choice of 
Ansatz enforces (i) and (ii) explicitly. Criterion (iii) is satisfied by choosing dO/dx such 
that the input domain is square (for a given M-neighborhood size). 
Figure la (having dO/dx = 0) shows a map in which the output M encodes only 
information about bar center position x, and is independent of bar orientation 0. The 
size of the M-neighborhood is relatively large in this case. The input domain of the state 
M denoted by the 'x' is shown enclosed by dotted lines. (The particular 0 value at which 
we chose to draw the M line in Fig. la is irrelevant.) For this M-neighborhood size, the 
length of the border of the input domain is as small as it can be. 
As the M-neighborhood size is reduced, the dotted lines move closer together. A 
vertically oblong input domain (which would result if we kept dO/dx = 0 ) would not 
satisfy the infomax criterion. The helix for which the input domain is square (for this 
smaller choice of M-neighborhood size) is shown in Fig. lb. The M states for this 
solution encode information about bar orientation as well as center position. If each M 
state corresponds to a localized output activity pattern centered at some position in a 
one-dimensional array of M cells, then this solution corresponds to orientation-selective 
cells organized in ""orientation columns"" (really ""orientation intervals"" in this 
one-dimensional model). A ""labeling"" of the linear array of cells according to whether 
their orientation preferences lie between 0 and 60, 60 and 120, or 120 and 180 degrees 
is indicated by the bold, light, and dotted line segments beneath the rectangle in Fig. 1 b 
(and lc). 
As the M-neighborhood size is decreased still further, the mapping shown in Fig. 
lc becomes favored over that of either Fig. la or lb. The ""orientation columns"" shown 
in the lower portion of Fig. lc are narrower than in Fig. 1 b. 
A more detailed analysis of the information rate function for various mappings 
confirms the main features we have here obtained by a simple geometric argument. 
The same type of analysis can be applied to different types of input pattern 
ensembles. To give just one other example, consider a network that receives an 
ensemble of simple patterns of acoustic input. Each such pattern consists of a tone of 
493 
some frequency that is sensed by two ""ears"" with some interaural time delay. Suppose 
that the initial network layers organize the information from each ear (separately) into 
tonotopic maps, and that (by means of connections having a range of different time 
delays) the signals received by both ears over some time interval appear as patterns of 
cell activity at some intermediate layer L. We can then apply the infomax principle to 
the signal transformation from layer L to the next layer M. The L state space can (as 
before) be represented as a rectangle, whose axes are now frequency and interaural 
delay (rather than spatial position and bar orientation). Apart from certain differences 
(the density of L states may be nonuniform, and states at the top and bottom of the 
rectangle are no longer identical), the infomax analysis can be carried out as it was for 
the simplified case of orientation selectivity. 
Local Algorithms 
The information rate (Eqn. 1), which the infomax principle states is to be 
maximized subject to constraints (and possibly as part of an optimization function 
containing other cost terms not discussed here), has a very complicated mathematical 
form. How might this optimization process, or an approximation to it, be implemented 
by a network of cells and connections each of which has limited computational power? 
The geometric form in which we have cast the infomax principle for some very simple 
model cases, suggests how this might be accomplished. 
An algorithm due to Kohonen 8 demonstrates how topographic maps can emerge 
as a result of lateral interactions within the output layer. I applied this algorithm to a 
one-dimensional M layer and a two-dimensional L layer, using a Euclidean metric and 
imposing periodic boundary conditions on the short dimension of the L layer. A 
resulting map is shown in Fig. 1 d. This map is very similar to those of Figs. 1 b and 1 c, 
except for one reversal of direction. The reversal is not surprising, since the algorithm 
involves only local moves (of the M-points) while the infomax principle calls for a 
globally optimal solution. 
More generally, Kohonen's algorithm tends empirically 8 to produce maps having 
the property that if one constructs the Voronoi diagram corresponding to the positions 
of the M-points (that is, assigns each point L to an M region based on which M-point 
L is closest to), one obtains a set of M regions that tend to have areas inversely 
proportional to P(L) , and neighborhoods (corresponding to our input domains) that 
tend to have similar extent in all directions rather than being elongated. 
The Kohonen algorithm makes no reference to noise, to information content, or 
even to an optimization principle. Nevertheless, it appears to implement, at least in a 
qualitative way, the geometric conditions that infomax imposes in some simple cases. 
This suggests that local algorithms along similar lines may be capable of implementing 
the infomax principle in more general situations. 
Our geometric formulation of the infomax principle also suggests a connection 
with an algorithm proposed by von der Malsburg and Willshaw 9 to generate topographic 
maps. In their ""tea trade"" model, neighborhood relationships are postulated within the 
source and the target spaces, and the algorithm's operation leads to the establishment 
of a neighborhood-preserving mapping from source to target space. Such neighborhood 
relationships arise naturally in our analysis when the infomax principle is applied to our 
three-step L -* L  -* M' -* M transformation. The noise process induces a 
494 
neighborhood relation on the L space, and lateral connections in the M cell layer can 
induce a neighborhood relation on the M space. 
More recently, Durbin and Willshaw '� have devised an approach to solving certain 
geometric optimization problems (such as the traveling salesman problem) by a gradient 
descent method bearing some similarity to Kohonen's algorithm. 
There is a complementary relationship between the infomax principle and a local 
algorithm that may be found to implement it. On the one hand, the principle may 
explain what the algorithm is ""for"" -- that is, how the algorithm may contribute to the 
generation of a useful perceptual system. This in turn can shed light on the system-level 
role of lateral connections and synaptic modification mechanisms in biological networks. 
On the other hand, the existence of such a local algorithm is important for demonstrating 
that a network of relatively simple processors -- biological or synthetic -- can in fact find 
global near-maxima of the Shannon information rate. 
A Possible Connection Between Infomax and a Thermodynamic Principle 
The principle of ""maximum preservation of information"" can be viewed 
equivalently as a principle of ""minimum dissipation of information."" When the principle 
is satisfied, the loss of information from layer to layer is minimized, and the flow of 
information is in this sense as ""nearly reversible"" as the constraints allow. There is a 
resemblance between this principle and the principle of ""minimum entropy production"" 
""in nonequilibrium thermodynamics. It has been suggested by Prigogine and others 
that the latter principle is important for understanding self-organization in complex 
systems. There is also a resemblance, at the algorithmic level, between a Hebb-type 
modification rule and the autocatalytic processes '2 considered in certain models of 
evolution and natural selection. This raises the possibility that the connection I have 
drawn between synaptic modification rules and an information-theoretic optimization 
principle may be an example of a more general relationship that is important for the 
emergence of complex and apparently ""goal-oriented"" structures and behaviors from 
relatively simple local interactions, in both neural and non-neural systems. 
References 
[5] 
[6] 
[7] 
[8] 
[9] 
[10] 
[11] 
[1] R. Linsker, Proc. Natl. ,,Icad. Sci. USA 83,7508, 8390, 8779 (1986). 
[2] D.H. Hubel and T. N. Wiesel, Proc. Roy. Soc. London B198 , I (1977). 
[3] D.O. Hebb, The Organization of Behavior (Wiley, N.Y., 1949). 
[4] R. Linsker, in: R. Cotterill (ed.), Computer Simulation in Brain Science (Copenhagen, 
20-22 August 1986; Ca", organ principl layer perceptu network linsker thoma watson research yorktown ny optim principl propos develop process stage multilay perceptu principl inform state signal transform stage one maxim inform output signal valu convey input signal valu subject certain presenc process quantiti maxim inform provid motiv principl simpl case deriv discuss algorithm show principl may lead biolog relev neural architectur topograph map orient spatial tempor signal possibl connect principl principl minimum entropi product thermodynam paper describ properti propos principl develop layer perceptu purpos paper provid intuit qualit understand principl specif properti signal transform simpl detail analysi requir order appli principl case realist pattern signal activ well specif constraint section give brief summari result motiv formul organ call principl inform later section principl state consequ previou work analyz develop layer network model cell feedforward connect whose strength chang accord modif found develop process produc cell select respons certain input becom progress sophist one proce deeper cell properti includ analysi contrast edg qualit similar properti observ first sever layer visual algorithm adjust synapt depend upon correl among signal activ caus develop network optim properti deepli connect matur function inform process institut physic analysi shown suitabl rule caus cell layer feedforward network later statist varianc output activ respons ensembl input previou subject certain cell thu perform oper similar princip compon analysi approach use statist expos regular present input earlier demonstr particular form rule produc model cell implement pca given linear devic transform input given particular output one use optim estim theori make input valu gave rise appropri rule gener devic come closest match input certain cell properti output preserv maximum amount inform input inform preserv result suggest possibl organ principl layer multilay perceptu principl even cell network respond input nonlinear even later well feedforward connect later earlier absent principl state layer cell connect input anoth layer connect develop signal presenc process set output valu convey maximum amount inform input valu subject variou constraint rang later process power statist properti input assum particular transform achiev maxim depend statist quantiti maxim shannon inform equival statement principl transform chosen minim amount inform would convey input valu someon alreadi know output valu shall regard set input signal valu given input messag process give output messag messag set signal nois introduc given input messag may gener rang differ output process set shannon inform rate averag inform transmit per log discret messag probabl input messag joint probabl input output continu messag probabl probabl sum rate log averag inform convey messag averag inform convey messag someon alreadi know fix properti input maxim mean ili state inform rate also written im defin interchang form sinc suggest one attempt make larg simultan make larg term largest messag occur equal term smallest transform uniqu gener made small near zero except small set one gain insight biolog relev properti may follow principl maximum inform preserv also call transform function valu one variabl connect allow connect within space quit particularli standpoint gain intuit understand network shall therefor consid simpl dimension signal space greatli one infomax analysi exhibit featur may also import gener condit relev biolog synthet network next four section organ model introduc simpl principl found satisfi simpl geometr condit relat model analysi signal process nois interconnect format topograph map model appli simplifi version biolog relev emerg orient show main infomax principl model realiz certain local propos gener topograph map use later simpl geometr model input messag describ point output messag one number discret take space extens higher transform consist two nois process alter messag lie within neighborhood radiu alter messag map determinist onto one messag given map correspond partit space region output state exclud priori possibl multipl region may label let denot total area let denot area space label let denot total border length label share region point lie within distanc border map onto either nois process call point distanc everi border map onto region contain suffici small partit area borderlin state small compar total area first case uniform inform rate given approxim term order see note log zero except log log posit number whose valu upon detail nois determin borderlin function distanc small first term rh henc valu equal second minu equal maxim sum length region correspond distribut suggest solut obtain partit space substanti equal tend border simpl analysi appli plausibl even compar spatial scale infomax favor make region approxim extent direct order reduc probabl nois map onto mani differ result minimum obtain except area element must weight local valu therefor infomax principl tend produc map greater represent output space given region input signal activ see later interact within layer affect let us map process first two step third step chang output number state definit compris consid case relat type state caus infomax principl favor solut region share border space sens simpl exampl state equal chanc final state infomax tend favor similar extent geometr model network properti previou section dealt certain class transform one space made specif refer implement interconnect network processor show featur discuss previou section relat network simplic suppos layer uniformli signal activ cell given time either need specifi ensembl input let us first simpl case pattern consist disk activ fix arbitrari center quiet case pattern fulli specifi coordin disk state pattern would repres point suppos input pattern consist sharpli defin disk disk whose boundari center sharpli pattern could gener choos specifi posit xc nomin disk set activ cell posit probabl decreas distanc xc pattern describ give coordin along mani describ variou moment activ pattern rel nois process suppos activ cell cell set distort valu suppos set output activ determinist function construct situat appropri choic nois dimens state space defin disk center larg varianc compar varianc induc nois dimens varianc compar induc center posit pattern chang small amount process typic differ center posit two wherea valu attribut input pattern differ much valu two typic input pattern differ attribut distanc state geometr model likelihood one state chang nois heurist regard state space present elong two dimens thin space could much complic nois process treat defin simpl metric structur state space need complic beyond scope present illustr featur key understand infomax charact ensembl statist process jointli determin attribut input pattern statist largest varianc rel varianc induc shall see infomax principl select number signific encod turn descript output state space shall assum space also low pattern may also disk activ center defin within discret set discrimin valu use geometr form output activ particular way restrict us posit encod rather encod make use output detail activ restrict form output determin featur input pattern whether topograph map properti seen emerg oper infomax previou section saw infomax principl tend lead space region equal area uniform disk minimum border present case region tend two long dimens state space singl valu repres point space differ area region tend invers proport local later upon particular form state correspond nearbi local region activ sens previou case map coordin space space tend orient select tempor featur map simpl exampl previou section illustr infomax lead map distort provid greater region larg let us consid case input featur posit encod output layer result infomax model case ensembl pattern present input pattern consist rectangular bar activ fix length quiet center posit orient chosen pattern uniform distribut spatial interv orient angl bar need sharpli sens describ distinguish differ pattern ensembl except center orient sens simplifi represent assum one need describ center posit bar given ensembl could consist bar pattern center differ coordin orient repres input state point rectangl state space previou whose abscissa coordin ordin angl horizont side rectangl identifi sinc orient interior thu thought surfac horizont number nx differ posit discrimin given rang valu input ensembl divid toler measur nois process similarli rel length ax state space rectangl given discuss nx nx role result map one complic featur although interest clariti includ present two horizont bar pattern displac horizont distanc small compar bar like render indiscrimin nois process two vertic bar displac horizont distanc may larg ham number binari activ need alter chang one pattern greater case distanc state space two recept field select simpl input domain size reduc upper upper left infomax favor emerg lower right figur show solut obtain appli relax algorithm map greater latter lead rather simpl state ignor effect must taken account fuller treatment emerg orient transform consist process determinist step map state space point onto state present map satisfi follow point correspond state space topograph along helic line state recal repres surfac horizont pitch helix slope remain determin infomax state correspond interv state map onto state particular closer correspond interv helix portion call set state center rectangular shape lie cylindr surfac seen infomax tend produc map topograph input domain similar extent direct choic enforc criterion satisfi choos input domain squar given la show map output encod bar center posit independ bar orient rel larg input domain state denot shown enclos dot particular valu chose draw line la border input domain small size dot line move closer oblong input domain would result kept would infomax helix input domain squar choic shown state encod inform bar orient well center correspond local output activ pattern center posit array solut correspond organ linear array cell accord whether orient prefer lie degre indic dot line segment beneath rectangl size decreas still map shown becom favor either la shown lower portion lc narrow detail analysi inform rate function variou map main featur obtain simpl geometr type analysi appli differ type input pattern give one consid network receiv simpl pattern acoust pattern consist tone frequenc sens two interaur time suppos initi network layer organ inform ear mean connect rang differ time signal receiv ear time interv appear pattern activ intermedi layer appli infomax principl signal transform layer next layer state space repres whose axe frequenc interaur spatial posit bar apart certain differ densiti state may state top bottom longer infomax analysi carri simplifi case orient algorithm inform rate infomax principl state subject constraint possibl part optim function cost term discuss complic mathemat might optim approxim implement network cell connect limit comput geometr form cast infomax principl simpl suggest might algorithm due kohonen demonstr topograph map emerg result later interact within output appli algorithm layer use euclidean metric period boundari condit short dimens map shown map similar one revers revers sinc algorithm local move infomax principl call optim algorithm tend empir produc map properti one construct voronoi diagram correspond posit assign point region base closest one obtain set region tend area invers neighborhood input similar extent direct rather kohonen algorithm make refer inform optim appear least geometr condit infomax impos simpl suggest local algorithm along similar line may capabl implement infomax principl gener geometr formul infomax principl also suggest connect algorithm propos von der malsburg willshaw gener topograph neighborhood relationship postul within target oper lead establish map sourc target neighborhood aris natur analysi infomax principl appli nois process induc relat later connect cell layer neighborhood relat durbin willshaw devis approach solv certain optim problem travel salesman gradient method bear similar complementari relationship infomax principl local may found implement one principl may algorithm algorithm may contribut use perceptu turn shed light later connect synapt modif mechan biolog exist local algorithm import demonstr network rel simpl processor biolog synthet fact find shannon inform possibl connect infomax thermodynam principl principl preserv view principl dissip principl loss inform layer layer flow sens constraint principl principl entropi nonequilibrium suggest prigogin other latter principl import understand complex also algorithm rule autocatalyt process consid certain model natur rais possibl connect synapt modif rule optim may exampl gener relationship import complex appar structur behavior simpl local neural usa hubel london organ behavior cotteril comput simul brain scienc august ca,0
52,52,"495 
REFLEX! VE ASSOCIATI VE MEMORIES 
Hendricus G. Loos 
Laguna Research Laboratory, Fallbrook, CA 92028-9765 
ABSTRACT 
In the synchronous discrete model, the average memory capacity of 
bidirectional associative memories (BAMs) is compared with that of 
Hopfield memories, by means of a calculation of the percentage of good 
recall for 100 random BAMs of dimension 64x64, for different numbers 
of stored vectors. The memory capacity is found to be much smaller than 
the Kosko upper bound, which is the lesser of the two dimensions of the 
BAM. On the average, a 64x64 BAM has about 68 % of the capacity of the 
corresponding Hopfield memory with the same number of neurons. Ortho- 
normal coding of the BAM increases the effective storage capacity by 
only 25 %. The memory capacity limitations are due to spurious stable 
states, which arise in BAMs in much the same way as in Hopfield 
memories. Occurrence of spurious stable states can be avoided by 
replacing the thresholding in the backlayer of the BAM by another 
nonlinear process, here called ""Dominant Label Selection"" (DLS). The 
simplest DLS is the winner-take-all net, which gives a fault-sensitive 
memory. Fault tolerance can be improved by the use of an orthogonal or 
unitary transformation. An optical application of the latter is a Fourier 
transform, which is implemented simply by a lens. 
INTRODUCTION 
A reflexive associative memory, also called bidirectional associa- 
tive memory, is a two-layer neural net with bidirectional connections 
between the layers. This architecture is implied by Dana Anderson's 
optical resonator 1 , and by similar configurations 2,3. Bart Kosko 4 coined 
the name ""Bidirectional Associative Memory"" (BAM), and investigated 
several basic properties 4-6. We are here concerned with the memory 
capacity of the BAM, with the relation between BAMs and Hopfield 
memories 7, and with certain variations on the BAM. 
American Institute of Physics 1988 
496 
BAMSTRUCTURE 
We will use the discrete model in which the state of a layer of 
neurons Is described by a bipolar vector. The Dirac notation 8 will be 
used, in which I> and <l denote respectively column and row vectors. <al 
and la> are each other transposes, <alb> is a scalar product, and !a><bl is 
an outer product. As depicted in Fig. 1, the BAM has two layers of 
neurons, a front layer of N neurons with state vector If>, and a back layer 
backlayer, P neurons 
state vector b 
frontlayer, N neurons 
state vector f 
back 
stroke 
forward 
stroke 
Fig. 1. BAM structure 
of P neurons with state vector 
lb>. The bidirectional connec- 
tions between the layers allow 
slgnal flow in two directions. 
The front stroke gives lb> = 
s(B!f>), where B is the connec- 
tion matrix, and s( ) is a thres- 
hold function, operating at 
zero. The back stroke results In an ugraded front state <f'l=s(<b!B), 
which also may be written as !f'>=s(B'!b>), where the superscript T 
denotes transposition. We consider the synchronous model, where all 
neurons of a layer are updated simultaneously, but the front and bacl( 
layers are updated at different times. The BAM action ls shown In Fig. 2. 
The forward stroke entails taking scalar products between a front 
state vector If> and the rows of B, and entering the thresholded results 
as elements of the back state vector lb>. !n the bacl< stroke we take 
f 
thresholding 
& reflection 
NxP 
Flg. 2. BAM action 
thresholding 
& reflection 
b 
V f ( 
, 
NxN 
j thresholding 
& 
feedback 
Fig. 3. Autoassociative 
memory action 
scalar products of lb> with column vectors of B, and enter the 
thresholded results as elements of an upgraded state vector If'>. !n 
contrast, the action of an autoassociative memory is shown in Figure 3. 
The BAM may also be described as an autoassociative memory 5 by 
497 
concatenating the front and back vectors into a slngle state vector 
Iv>=!f,b>,and by taking the (N+ P)x(N+ P) connection matrlx as shown in Flg. 
4. This autoassociative memory has the same number of neurons as our 
 zro 
b 
Fig. 4. BAM as autoasso- 
ciative memory 
memory 7 the connection 
BAM, viz. N+P. The BAM operation where 
initially only the front state is speci- 
fied may be obtained with the corres- 
ponding autoassociative memory by 
initially specifying lb> as zero, and by 
arranging the thresholding operation 
such that s(O) does not alter the state 
vector component. For a Hopfield 
matrix is 
M 
H=(lm><ml) -MI , (1) 
m=l 
where Im>, m=l to M, are stored vectors, and I is the identity matrix. 
Writing the N+P dimensional vectors Im> as concatenations Idm,Cm>, (1) 
takes the form 
M 
H-(  (!dm><dml+lcm><cml+ldm><cml+lcm><dml))-Ml, (2) 
m=l 
with proper block placing of submatrices understood. Writing 
M 
Hd=(  
m=l 
M 
K= ElCm><dml , (3) 
m=l M 
Idm> <dml)-Ml, Hc=( - Icm> <cml)-Ml, (4) 
m--1 
where the I are identities in appropriate subspaces, the Hopfield matrix 
be as 
H may partitioned shown in Fig. 5. K is just the BAM matrix given 
by Kosko 5, and previously used by Kohonen 9 for linear heteroassociative 
memories. Comparison of Figs. 4 and ,% shows that in the synchronous 
discrete model the BAM with connection matrix (3) is equivalent to a 
Hopfield memory in which the diagona! blocks H d and H c have been 
498 
deleted. Since the Hopfield memory is robust, this ""pruning"" may not 
affect much the associative recall of stored vectors, if M is small; 
however, on the average, pruning will not improve the memory capacity. 
It follows that, on the average, a discrete synchronous BAM with matrix 
(3) can at best have the capacity of a Hopfield memory with the same 
number of neurons. 
We have performed computations of the average memory capacity 
for 64x64 BAMs and for corresponding 128x128 Hopfield memories. 
Monte Carlo calculations were done for I O0 memories, each of which 
stores M random bipolar vectors. The straight recall of all these vectors 
was checked, allowing for 24 iterations. For the BAMs, the iterations 
were started with a forward stroke in which one of the stored vectors 
Idm> was used as input. The percentage of good recall and its standard 
deviation were calculated. The results plotted in Fig. 6 show that the 
square BAM has about 68% of the capacity of the corresponding Hopfield 
memory. Although the total number of neurons is the same, the BAM only 
needs 1/4 of the number of connections of the Hopfield memory. The 
storage capacity found is much smaller than the Kosko 6 upper bound, 
which is rain (N,P). oo- 
d T 
Fig. 5. Partitioned 
Hopfield matrix 
601 
4oi 
201 
10 20 30 40 50 60 
M, number of stored vectors 
Fig. 6. % of good recall versus M 
CODED BAM 
So far, we have considered both front and back states to be used for 
data. There is another use of the BAM in which only front states are used 
as data, and the back states are seen as providing a code, label, or 
pointer for the front state. Such use was anticipated in our expression 
(3) for the BAM matrix which stores data vectors Idm> and their labels or 
codes Icm>. For a square BAM, such an arrangement cuts the information 
contained in a single stored data vector in half. However, the freedom of 
499 
choosing the labels Icm> may perhaps be put to good use. Part of the 
problem of spurious stable states, whlch plagues BAMs as well as 
Hopfield memories as they are loaded up, is due to the lack of 
orthogonality of the stored vectors. In the coded BAM we have the 
opportunity to remove part of thls problem by choosing the labels as 
orthonormal. Such labels have been used previously by Kohonen 9 in linear 
heteroassociative memories. The question whether memory capacity can 
be improved In this manner was explored by taking 64x64 BAMs in which 
the labels are chosen as Hadamard vectors. The latter are bipolar vectors 
with Euclidean norm FP, which form an orthonormal set. These vectors 
are rows of a PxP Hadamard matrix; for a discussion see Hatwit and 
Sloane 10. The storage capacity of such Hadamard-coded BAHs was 
calculated as function of the number M of stored vectors for 100 cases 
for each value of M, in the manner discussed before. The percentage of 
good recall and its standard deviation are shown in Fig. 6. It is seen that 
the Hadamard coding gives about a factor 2.5 in M, compared to the 
ordinary 64x64 BAM. However, the coded BAM has only half the stored 
data vector dimension. Accounting for this factor 2 reduction of data 
vector dimension, the effective storage capacity advantage obtained by 
Hadamard coding comes to only 25 %. 
HALF BAH WITH HADAMARD CODING 
For the coded BAH there is the option of deleting the threshold 
operation in the front layer. The resulting architecture may be called 
""half BAH"". In the half BAM, thresholding is only done on the labels, and 
consequently, the data may be taken as analog vectors. Although such an 
arrangement diminishes the robustness of the memory somewhat, there 
are applications of interest. We have calculated the percentage of good 
recall for 100 cases, and found that giving up the data thresholding cuts 
the storage capacity of the Hadamard-coded BAH by about 60 %. 
SELECTIVE REFLEXIVE MEMORY 
The memory capacity limitations shown in Fig. 6 are due to the 
occurence of spurious states when the memories are loaded up. 
Consider a discrete BAM with stored data vectors Ira>, m = 1 to M, 
orthonormal labels Icm>, and the connection matrix 
500 
M 
K=. Icm><ml 
m=l 
(5) 
For an input data vector Iv> which is closest to the stored data vector 
II>, one has in the forward stroke 
M 
Ib>=s(clc 1 >+ Z amlcm>) ' (6) 
m=2 
where 
c=<11v>, and am=<mlv> (7) 
Although for m  1 
M 
am<C, for some vector component the sum 7 amlcm> 
m=2 
may accumulate to such a large value as to affect the thresholded result 
lb>. The problem would be avoided if the thresholding operation s( ) in the 
back layer of the BAM were to be replaced by another nonlinear operation 
which selects, from the linear combination 
M 
ClCl >+ - amlcm> (8) 
m=2 
the dominant label ICl>. The hypothetical device which performs this 
operation is here called the ""Dominant Label Selector"" (DLS) 11, and we 
call the resulting memory architecture ""Selective Reflexive Memory"" 
(SRM). With the back state selected as the dominant label ICl>, the back 
stroke gives <f'l=s(<clIK)=s(P<ll)=<ll, by the orthogonality of the labels 
ICm>. !t follows TM that the SRM gives perfect associative recall of the 
nearest stored data vector, for any number of vectors stored. Of course, 
the linear independence of the P-dimensional label vectors ICm>, m= 1 to 
M, requires P>=M. 
The DLS must select, from a linear combination of orthonormal 
labels, the dominant label. A trivial case is obtained by choosing the 
501 
labels Icm> as basis vectors lUm>, which have all components zero except 
for the ml:h component, which is unity. With this choice of labels, the 
f DLS may be taken as a winner- 
zinner- 
: bl [ take-all 
net 
Fig.7. Simplest reflexive 
memory with DLS 
take-all net W, as shown in Fig. 7. 
This case appears to be Included in 
Adaptive Iesonance Theory 
(ART) 12 as a special simplified 
case. A relationship between 
the ordinary BAM and ART was 
pointed out by Kosko 5. As in ART, 
.,  /orthogonal 
trans[or- 
! ! I 'lg I m,,,o- I F lilt I .winner- 
 I /take-all 
U ! I net 
Fig. 8..Selective reflexive 
memory 
there is considerable fault sensitivity in this memory, because the 
stored data vectors appear in the connection matrix as rows. 
A memory with better fault tolerance may be obtained by using 
orthogonal labels other than basis vectors. The DLS can then be taken as 
an orthogonal transformation G followed by a winner-take-all net, as 
shown in Fig. 8. G is to be chosen such that it transforms the labels Icm> 
into vectors proportional to the 
basis vectors lum>. This can always 
be done by taking 
P 
G= Llup><cpl , (9) 
p--1 
where the ICp>, p= 1 to P, form a 
complete orthonormal set which 
contains the labels Icm>, m=l to M. The neurons in the DLS serve as 
grandmother cells. Once a single winning cell has been activated, i.e., 
the state of the layer Is a single basis vector, say lUl>, this vector 
must be passed back, after application of the transformation 6-1, such 
as to produce the label Ic1> at the back of the BAM. Since 6 is 
orthogonal, we have 6-1=6 T, so that the required lnverse 
transformation may be accomplished simply by sending the basis vector 
back through the transformer; this gives 
P 
<Ul!G=  <UllUp><cpl=<c 1 I 
p=i 
(lO) 
502 
as required. 
HALF SRM 
The SRM may be modified by deleting the thresholding operation in 
the front layer. The front neurons then have a linear output, which is 
reflected back through the SRM, as shown in Fig. g. !n this case, the 
stored data vectors and the 
linear neurons 
,, T I /orthogonal 
, i transf�r- 
I ! g mation 
!  J liT I winner- 
 / /take-all 
LI I i net 
Fig. g. Half SRM with linear 
neurons in front layer 
input data vectors may be taken 
as analog vectors, but we re- 
quire all the stored vectors to 
have the same norm. The action 
of the SRM proceeds in the same 
way as described above, except 
that we now require the ortho- 
normal labels to have unit 
norm. It follows that, just like 
the full SRM, the half SRM gives 
perfect associative recall to the nearest stored vector, for any number 
of stored vectors up to the dimension P of the labels. The latter 
condition is due to the fact that a P-dimensional vector space can at 
most contain P orthonormal vectors. 
In the SRM the output transform G is introduced in order to improve 
the fault tolerance of the connection matrix K. This is accomplished at 
the cost of some fault sensitivity of G, the extent of which needs to be 
investigated. In this regard it is noted that in certain optical implemen- 
tations of reflexive memories, such as Dana Anderson's resonator I and 
similar configurations2, 3, the transformation G is a Fourier transform, 
which Is implemented simply as a lens. Such an implementation is quite 
lnsentive to the common semiconductor damage mechanisms. 
EQUIVALENT AUTOASSOCI AT IVE I""'IEI'RIES 
Concatenation of the front and back state vectors allows descrip- 
tion of the SRHs in terms of autoassociative memories. For the SRM 
which uses basis vectors as labels the corresponding autoassociative 
memory is shown in Fig. 10. This connection matrix structure was also 
proposed by 6uest et. al. 13. The winner-take-all net W needs to be 
503 
Fig. 10. Equivalent auto- 
associative memory 
given time to settle on a basis 
vector state before the state lb> 
can influence the front state If>. 
This may perhaps be achieved by 
arranging the W network to have a 
thresholding and feedback which 
are fast compared with that of the 
K network. An alternate method 
may be to equip the W network 
with an output gate which is 
opened only after the W net has 
settled. These arrangements 
present a complication and cause a delay, which in some applications 
may be inappropriate, and In others may be acceptable in a trade 
between speed and memory denslty. 
For the SRM with output transformer and orthonormal labels other 
f b W /eedback 
f thresholded 
b linear 
W thresholded 
+ output gate 
Fig. 11. Autoassociative memory 
equivalent to SRM with transform 
output gate 
winner-take-al 
""i"" w output 1 
?:"" b back layer, 
linear 
'' ,""' f front Iayer 
BAM connections 
$ =orthogonal transformation 
winner-take-all net 
Fig. 12. Structure of SRM 
than basis vectors, a correspon- 
ding autoassociative memory may 
be composed as shown in Fig. 11. 
An output gate in the w layer is 
chosen as the device which 
prevents the backstroke through 
the BAM to take place before the 
winner-take-al net has settled. 
The same effect may perhaps be 
achieved by choosing different 
response times for the neuron 
layers f and w. These matters 
require investigation. Unless 
the output transform G is already 
required for other reasons, as in 
some optical resonators, the DLS 
with output transform is clumsy. 
it would far better to combine 
the transformer G and the net W 
into a single network. To find 
such a DLS should be considered 
a challenge. 
5O4 
The work was partly supported by the Defense Advanced Research 
Projects Agency, ARPA order 5916, through Contract DAAHO 1-86-C 
-0968 with the U.S. Army Missile Command. 
REFERENCES 
1. D. Z. Anderson, ""Coherent optical eigenstate memory"", Opt. Lett. 11, 
56 (1986). 
2. B. H. Sollet, 6. d. Dunning, Y. Owechko, and E. Margin, ""Associative 
holographic memory with feedback using phase-conjugate mirrors"", Opt. 
Lett. 1 I, 118 (1986). 
3. A. Yamiv and S. K. Wong, ""Associative memories based on message- 
bearing optical modes In phase-conjugate resonators"", Opt. Lett. 11, 
186 (1986). 
4. B. Kosko, ""Adaptive Cognitive Processing"", NSF Workshop for Neural 
Networks and Neuromorphic Systems, Boston, Mass., Oct. &-8, 1986. 
5. B. Kosko, ""Bidirectional Associative Memories"", IEEE Trans. SMC, In 
press, 1987. 
6. B. Kosko, ""Adaptive Bidirectional Associative Memories"", Appl. Opt., 
In press, 1987. 
7. J.J. Hopfield, ""Neural networks and physical systems with emergent 
collective computational abilities"", Proc. Natl. Acad. Scl. USA 79, 2554 
(1982). 
8. P. A.M. Dirac, THE PRINCIPLES OF QUANTUM MECHANICS, Oxford, 1958. 
9. T. Kohonen, ""Correlation Matrix Memories"", Helsinski University of 
Technology Report TKK-F-A 130, 1970. 
10. M. Harwit and N.J. A, 51oane, HADAMARD TRANSFORM OPTICS, 
Academic Press, New York, 1979. 
11. H. G. Logs, ""Adaptive Stochastic Content-Addressable Memory"", Final 
Report, ARPA Order 5916, Contract DAAHO 1-86-C-0968, March 1987. 
12. G. A. Carpenter and S. Grossberg, ""A Massively Parallel Architecture 
for a Self-Organizing Neural Pattern Recognition Machine"", Computer 
Vision, Graphics, and Image Processing, 37, 54 (1987). 
13. R. D. TeKolste and C. C. Guest, ""Optical Cohen-Grossberg System 
with All-Optical Feedback"", IEEE First Annual International Conference 
on Neural Networks, San Diego, June 21-24, 1987. 
", associati memori loo research ca synchron discret averag memori capac associ memori compar mean calcul percentag good random bam dimens differ number store memori capac found much smaller kosko upper lesser two dimens bam capac hopfield memori number code bam increas effect storag capac memori capac limit due spuriou stabl aris bam much way hopfield occurr spuriou stabl state avoid threshold backlay bam anoth call label dl give fault toler improv use orthogon optic applic latter fourier implement simpli reflex associ also call bidirect neural net bidirect connect architectur impli dana reson similar configur bart kosko coin name associ investig basic properti concern memori relat bam hopfield certain variat institut physic use discret model state layer describ bipolar dirac notat denot respect column row scalar outer depict bam two layer front layer neuron state vector back layer neuron vector neuron vector bam structur neuron state vector bidirect layer allow flow two front stroke give oper back stroke result front state also may written superscript consid synchron layer updat front updat differ bam action ls shown forward stroke entail take scalar product front vector row enter threshold result element back state vector stroke take reflect bam action reflect threshold autoassoci action product column vector enter result element upgrad state vector action autoassoci memori shown figur bam may also describ autoassoci memori front back vector slngle state vector take connect matrlx shown autoassoci memori number neuron bam memori connect bam oper front state may obtain autoassoci memori specifi threshold oper alter state hopfield store ident dimension vector concaten form proper block place submatric write ident appropri hopfield matrix may partit shown bam matrix given kosko previous use kohonen linear heteroassoci comparison show synchron model bam connect matrix equival memori block sinc hopfield memori may much associ recal store prune improv memori follow discret synchron bam matrix best capac hopfield memori perform comput averag memori capac bam correspond hopfield carlo calcul done random bipolar straight recal vector allow iter start forward stroke one store vector use percentag good recal standard result plot show bam capac correspond hopfield although total number neuron bam number connect hopfield capac found much smaller kosko upper rain partit matrix number store vector good recal versu bam consid front back state use anoth use bam front state use back state seen provid front use anticip express bam matrix store data vector label squar arrang cut inform singl store data vector freedom label may perhap put good part spuriou stabl whlch plagu bam well memori load due lack store code bam remov part thl problem choos label label use previous kohonen linear question whether memori capac improv manner explor take bam label chosen hadamard latter bipolar vector euclidean norm form orthonorm vector row hadamard discuss see hatwit storag capac bah function number store vector case valu manner discuss percentag recal standard deviat shown seen hadamard code give factor compar code bam half store vector account factor reduct data effect storag capac advantag obtain code come bah hadamard code code bah option delet threshold front result architectur may call half threshold done data may taken analog although diminish robust memori applic calcul percentag good found give data threshold cut storag capac bah reflex memori memori capac limit shown due spuriou state memori load discret bam store data vector label connect matrix input data vector closest store data vector one forward stroke vector compon sum accumul larg valu affect threshold result problem would avoid threshold oper layer bam replac anoth nonlinear oper linear combin cl domin label hypothet devic perform call label result memori architectur reflex back state select domin label back give orthogon label follow tm srm give perfect associ recal store data number vector linear independ label vector requir dl must linear combin orthonorm domin trivial case obtain choos basi vector compon zero except choic dl may taken bl simplest reflex dl net shown case appear includ theori special simplifi relationship ordinari bam art kosko lilt net reflex consider fault sensit data vector appear connect matrix memori better fault toler may obtain use label basi dl taken orthogon transform follow chosen transform label vector proport vector alway done take form orthonorm set label neuron dl serv singl win cell state layer singl basi say vector pass applic transform produc label back sinc requir lnvers may accomplish simpli send basi vector give srm srm may modifi delet threshold oper front front neuron linear back shown data vector neuron mation net half srm linear front layer data vector may taken analog store vector action srm proce describ except requir label unit follow like full half srm give associ recal nearest store number store vector dimens latter due fact vector space contain orthonorm srm output transform introduc order improv fault toler connect matrix accomplish cost fault sensit extent need regard note certain optic reflex dana reson transform fourier implement simpli implement quit common semiconductor damag autoassoci ive front back state vector allow srh term autoassoci srm use basi vector label correspond autoassoci shown connect matrix structur also net need equival memori time settl basi state state influenc front state may perhap achiev network feedback fast compar altern method equip network output gate net arrang complic caus applic other may accept trade speed memori srm output transform orthonorm label threshold linear threshold output gate autoassoci memori srm transform gate output back front iayer connect transform net structur srm basi autoassoci memori may compos shown output gate layer devic backstrok bam take place net effect may perhap choos differ time neuron matter unless output transform alreadi optic dl output transform would far better combin transform net singl find dl consid work partli support defens advanc research arpa order contract daaho armi missil optic eigenst memori feedback use yamiv memori base optic mode cognit nsf workshop neural neuromorph associ ie bidirect associ network physic system emerg comput usa principl quantum matrix helsinski univers report harwit hadamard transform new stochast final arpa order contract daaho march carpent massiv parallel architectur neural pattern recognit comput imag kolst system ie first annual intern confer neural san june,1
53,53,"5O5 
CONNECTING TO THE PAST 
Bruce A. MacDonald, Assistant Professor 
Knowledge Sciences Laboratory, Computer Science Department 
The University of Calgary, 2500 University Drive NW 
Calgary, Alberta T2N 1N4 
ABSTRACT 
lecently there has been renewed interest in neural-like processing systems, evidenced for ex- 
ample in the two volumes Parallel Distributed Processing edited by Pumelhart and McClelland, 
and discussed as parallel distributed systems, connectionist models, neural nets, value passing 
systems and multiple context systems. Dissatisfaction with symbolic manipulation paradigms 
for artificial intelligence seems partly responsible for this attention, encouraged by the promise 
of massively parallel systems implemented in hardware. This paper relates simple neural-like 
systems based on multiple context to some other well-known formalisms--namely production 
systems, k-length sequence prediction, finite-state machines and Turing machines--and presents 
earlier sequence prediction results in a new light. 
1 INTRODUCTION 
The revival of neural net research has been very strong, exemplified recently by Pumelhart 
and McClelland , new journals and a number of meetings �. The nets are also described as 
parallel distributed systems  , connectionist models 2, value passing systems 3 and multiple context 
learning systems 4,5,6,7,8.9. The symbolic manipulation paradigm for artificial intelligence does 
not seem to have been as successful as some hoped , and there seems at last to be real promise 
of massively parallel systems implemented in hardware. However, in the flurry of new work it 
is important to consolidate new ideas and place them solidly alongside established ones. This 
paper relates simple neural-like systems to some other well-known notions--namely production 
systems, k-length sequence prediction, finite-state machines and Turing machines--and presents 
earlier results on the abilities of such networks in a new light. 
The general form of a connectionist system � is simplified to a three layer net with binary 
fixed weights in the hidden layer, thereby avoiding many of the difficulties--and challenges-- 
of the recent work on neural nets. The hidden unit weights are regularly patterned using a 
template. Sophisticated, expensive learning algorithms are avoided, and a simple method is 
used for determining output unit weights. In this way we gain some of the advantages of multi- 
layered nets, while retaining some of the simplicity of two layer net training methods. Certainly 
nothing is lost in computational power--as I will explain--and the limitations of two layer 
nets are not carried over to the simplified three layer one. Biological systems may similarly 
avoid the need for learning algorithms such as the ""simulated annealing"" method commonly 
used in connectionist models u. For one thing, biological systems do not have the same clearly 
distinguished training phase. 
Briefly, the simplified net b is a production system implemented as three layers of neuron-like 
units; an output layer, an input layer, and a hidden layer for the productions themselves. Each 
hidden production unit potentially connects a predetermined set of inputs to any output. A 
k-length sequence predictor is formed once k levels of delay unit are introduced into the input 
layer. k-length predictors are unable to distinguish simple sequences such as ha... a and aa... a 
since after k or more characters the system has forgotten whether an a or b appeared first. If 
the k-length predictor is augmented with ""auxiliary"" actions, it is able to learn this and other 
regular languages, since the auxiliary actions can be equivalent to states, and can be inputs to 
aAmong them the 1st International Conference on Neural Nets, San Diego,CA, June 21-24, 1987, and this 
conference. 
bRoughly equivalent to a single context system in Andreae's multiple context system 4'5'6'7'$'9. See also 
MacDonald 12. 
@ American Institute of Physics 1988 
506 
Figure 1: The general form of a connectionist system �. 
(a) Form of a unit 
o 1 
0 2 
o i 
Oo 
(a) Operations within a unit 
inputs -. excitation 
weighm '"" 
sum 
-- activation J- output 
Typical F Typical f 
the production units enabling predictions to depend on previous states 7. By combining several 
augmented sequence predictors a Turing machine tape can be simulated along with a finite-state 
controller 9, giving the net the computational power of a Universal Turing machine. Relatively 
simple neural-like systems do not lack computational ability. Previous implementations 7,9 of 
this ability are production system equivalents to the simplified nets. 
1.1 Organization of the paper 
The next section briefly reviews the general form of connectionist systems. Section 2 simplifies 
this, then section 3 explains that the result is equivalent to a production system dealing only 
with inputs and outputs of the net. Section 4 extends the simplified version, enabling it to learn 
to predict sequences. Section 5 explains how the computational power of the sequence predictor 
can be increased to that of a Turing machine if some input units receive auxiliary actions; in fact 
the system can learn to be a Turing machine. Section 6 discusses the possibility of a number of 
nets combining their outputs, forming an overall net with ""association areas"". 
1.2 General form of a connectionist system 
Figure 1 shows the general form of a connectionist system unit, neuron or cell �. In the figure 
unit i has inputs, which are the outputs oj of possibly all units in the network, and an output of 
its own, oi. The net input excitation, neti, is the weighted sum of inputs, where wij is the weight 
connecting the output from unit j as an input to unit i. The activation, ai of the unit is some 
function Fi of the net input excitation. Typically Fi is semilinear, that is non~decreasing and 
differentiable a, and is the same function for all, or at least large groups of units. The output is 
a function fi of the activation; typically some kind of threshold function. I will assume that the 
quantities vary over discrete time steps, so for example the activation at time t + 1 is ai(t q- 1) 
and is given by Fi((neti(t)). 
In general there is no restriction on the connections that may be made between units. 
Units not connected directly to inputs or outputs are hidden units. In more complex nets 
than those described in this paper, there may be more than one type of connection. Figure 2 
shows a common connection topology, where there are three layers of units--input, hidden and 
output--with no cycles of connection. 
The net is trained by presenting it with input combinations, each along with the desired 
output combination. Once trained the system should produce the desired outputs given just 
507 
Figure 2: The basic structure of a three layer connectionist system. 
input units hidden output units 
units 
inputs. During training the weights are adjusted in some fashion that reduces the discrepancy 
between desired and actual output. The general method ism�: 
Awij = g(ai, ti) h(oj, Wij), 
where ti is the desired, ""training"" activation. Equation 1 is a general form of Hebb's classic 
rule for adjusting the weight between two units with high activations �. The weight adjustment 
is the product of two functions, one that depends on the desired and actual activations--often 
just the difference--and another that depends on the input to that weight and the weight itself. 
As a simple example suppose g is the difference and h as just the output o i. Then the weight 
change is the product of the output error and the input excitation to that weight: 
Aw 0 = rloj(ti - ai) 
where the constant r/determines the learning rate. This is the Widrow-Hoff or Delta rule which 
may be used in nets without hidden units. � 
The important contribution of recent work on connectionist systems is how to implement 
equation 1 in hidden units; for which there are no training signals ti directly available. The 
Boltzmann learning method iteratively varies both weights and hidden unit training activations 
using the controlled, gradually decreasing randomizing method ""simulated annealing""4 Back- 
propagation 3 is also iterative, performing gradient descent by propagating training signal errors 
back through the net to hidden units. I will avoid the need to determine training signals for 
hidden units, by fixing the weights of hidden units in section 2 below. 
2 SIMPLIFIED SYSTEM 
Assume these simplifications are made to the general connectionist system of section 1.2: 
1. The system has three layers, with the topology shown in Figure 2 (ie no cycles) 
2. All hidden layer unit weights are fixed, say at unity or zero 
3. Each unit is a linear threshold unit �, which means the activation function for all units 
is the identity function, giving just neti, a weighted sum of the inputs, and the output 
function is a simple binary threshold of the form: 
T ouut 
threshol a  
activation 
508 
so that the output is binary; on or off. Hidden units will have thresholds requiring all 
inputs to be active for the output to be active (like an ,ND gate) while output units will 
have thresholds requiring only I or two active highly weighted inputs for an output to be 
generated (like an OR gate). This is in keeping with the production system view of the 
net, explained in section 3. 
4. Learning--which now occurs only at the output unit weights--gives weight adjustments 
according to: 
wlj -- 1 if a i '- oj -- 1 
Wij '-- 0 otherwise 
so that weights are turned on if their input and the unit output are on, and off otherwise. 
That is, Wij -- ai A oj. A simple example is given in Figure 3 in section 3 below. 
This simple form of net can be made probabilistic by replacing 4 with 4' below: 
4'. Adjust weights so that wij estimates the conditional probability of the unit i output being 
on when output j is on. That is, 
Wij -- estimate of P(oi[oj). 
Then, assuming independence of the inputs to a unit, an output unit is turned on when the 
conditional probability of occurrence of that output exceeds the threshold of the output 
function. 
Once these simplifications are made, there is no need for learning in the hidden units. Also no 
iterative learning is required; weights are either assigned binary values, or estimate conditional 
probabilities. This paper presents some of the characteristics of the simplified net. Section 6 
discusses the motivation for simplifying neural nets in this way. 
3 PRODUCTION SYSTEMS 
The simplified net is a kind of simple production system. A production system comprises a 
global database, a set of production rules and a control system s. The database for the net is 
the system it interacts with, providing inputs as reactions to outputs from the net. The hidden 
units of the network are the production rules, which have the form 
IF precondition THEN action 
The precondition is satisfied when the input excitation exceeds the threshold of a hidden unit. 
The actions are represented by the output units which the hidden production units activate. 
The control system of a production system chooses the rule whose action to perform, from the 
set of rules whose preconditions have been met. In a neural net the control system is distributed 
throughout the net in the output units. For example, the output units might form a winner-take- 
all net. In production systems more complex control involves forward and backward chaining to 
choose actions that seek goals. This is discussed elsewhere �. Figure 3 illustrates a simple 
production implemented as a neural net. As the figure shows, the inputs to hidden units are 
just the elements of the precondition. When the appropriate input combination is present the 
associated hidden (production) unit is fired. Once weights have been learned connecting hidden 
units to output units, firing a production results in output. The simplified neural net is directly 
equivalent to a production system whose elements are inputs and outputs c . 
Some production systems have symbolic elements, such as variables, which can be given 
values by production actions. The neural net cannot directly implement this, since it can 
have outputs only from a predetermined set. However, we will see later that extensions to the 
framework enable this and other abilities. 
CThis might be referred to as a ""sensory-motor"" production system, since when implemented in a real system 
such as a robot, it deals only with sensed inputs and executable motor actions, which may include the auxiliary 
actions of section 4.3. 
509 
Figure 3: A production implemented in a simplified neural net. 
(a) A production rule 
] IF I c!oudy I AND I pressure falling ] THEN lit will rain ]1 
(b) The rule implemented as a hidden unit. The threshold of the hidden unit is 2 so it is. 
an AND gate. The threshold of the output unit is I so it is an oR gate. The learned 
weight will be 0 or 1 if the net is not probabilistic, otherwise it will be an estimate of 
P 'it will rainlclouds AND pressure falling) 
It will 
rain 
weight 
Figure 4: A net that predicts the next character in a sequence, based on only the last character. 
(a) The net. Production units (hidden units) have been combined with input units. 
For example this net could predict the sequence abcabcabc .... Productions have the 
form: IF last character is ...THEN next character will be .... The learning rule is 
wij -- i if (inputj AND output/). Output is ai -' OR 
j Wij Oj 
neural net 
input 
� 
output 
(b) Learning procedure. 
1. Clamp inputs and outputs to desired values 
2. System calculates weight values 
3. Repeat 4 and 4 for all required input/output combinations 
4 SEQUENCE PREDICTION 
A production system or neural net can predict sequences. Given examples of a repeating se- 
quence, productions are learned which predict future events on the basis of recent ones. Figure 4 
shows a trivially simple sequence predictor. It predicts the next character of a sequence based 
on the previous one. The figure also gives the details of the ]earning procedure for the simplified 
net. The net need be trained only once on each input combination, then it will ""predict"" as 
an output every character seen after the current one. The probabilistic form of the net would 
estimate conditional probabilities for the next character, conditional on the current one. Many 
510 
Figure 5: Using delayed inputs, a neural net can implement a k-length sequence predictor. 
(a) A net with the last three characters as input. 
input hidden output 
a 
2nd last 
weights 
fixed at 1 
weights 
learned 
(b) An example production. 
[iF last three characters were a-THEN -]] 
presentations of each possible character pair would be needed to properly estimate the probabil- 
ities. The net would be learning the probability distribution of character pairs. A predictor like 
the one in Figure 4 can be extended to a general k-length l? predictor so long as inputs delayed 
by 1, 2,..., k steps are available. Then, as illustrated in Figure 5 for 3-length prediction, hidden 
production units represent all possible combinations of k symbols. Again output weights are 
trained to respond to previously seen input combinations, here of three characters. These delays 
can be provided by dedicated neural nets d, such as that shown in Figure 6. Note that the net 
is assumed to be synchronously updated, so that the input from feedback around units is not 
changed until one step after the output changes. There are various ways of implementing delay 
in neurons, and Andreae 4 investigates some of them for the same purpose--delaying inputs--in 
a more detailed simulation of a sirrdlar net. 
d.1 Other work on sequence prediction in neural nets 
Feldman and BMlard 2 find connectionist systems initially not suited to representing changes 
with time. One form of change is sequence, and they suggest two methods for representing 
sequence in nets. The first is by units connected to each other in sequence so that sequential 
tasks are represented by firing these units in succession. The second method is to buffer the 
inputs in time so that inputs from the recent past are available as well as current inputs; that 
is, delayed inputs are available as suggested above. An important difference is the necessary 
length of the buffer; Feldman and Ballard suggest the buffer be long enough to hold a phrase of 
natural language, but I expect to use buffers no longer than about 7, after Andreae 4. Symbolic 
inputs can represent more complex information effectively giving the length seven buffers more 
information than the most recent seven simple inputs, as discussed in section 5. 
The method of back-propagation la enables recurrent networks to learn sequential tasks in a 
dFeldman and Ballard 2 give some dedicated neural net connections for a variety of functions 
511 
Figure 6: Inputs can be delayed by dedicated neural subnets. A two stage delay is shown. 
(a) Delay network. 
o = 1, input >= 0.75 
""o = 0, input < 0.75 % 
or+ 1 = 0.5 ( Or+ input) 
(b) Timing diagram for (a). 
A I 1.0--  time 
B ! 0.5 ' 0.75  0.375 
c 1 
D 1 ....... 
original signal 
delay of one step 
delay of two steps 
manner similar to the first suggestion in the last paragraph, where sequences of connected units 
represent sequenced events. In one example a net learns to complete a sequence of characters; 
when given the first two characters of a six character sequence the next four are output. Errors 
must be propagated around cycles in a recurrent net a number of times. 
Seriality may also be achieved by a sequence of states of distributed activation s. An example 
is a net playing both sides of a tic-tac-toe game xs. The sequential nature of the net's behavior is 
derived from the sequential nature of the responses to the net's actions; tic-tac-toe moves. A net 
can model sequence internally by modeling a sequential part of its environment. For example, 
a tic-tac-toe playing net can have a model of its opponent. 
k-length sequence predictors are unable to learn sequences which do not repeat more fre- 
quently that every k characters. Their k-length context includes only information about the last 
k events. However, there are two ways in which information from before the kth last input can 
be retained in the net. The first method latches some inputs, while the second involves auxiliary 
actions. 
4.2 Latch units 
Inputs can be latched and held indefinitely using the combination shown in Figure 7. Not all 
inputs would normally be latched. Andreae 4 discusses this technique of ""threading"" latched 
events among non-latched events, giving the net both information arbitrarily far back in its 
input-output history and information from the immediate past. Briefly, the sequence ba...a 
can be distinguished from aa... a if the first character is latched. However, this is an ad hoc 
solution to this problem *. 
.3 Auxiliary actions 
When an output is fed back into the net as an input signal, this enables the system to choose the 
next output at least partly based on the previous one, as indicated in Figure 8. If a particular 
fed back output is also one without external manifestation, or whose external manifestation 
is independent of the task being performed, then that output is an auxiliary action. It Las 
eThe interested reader should refer to Andreae 4 where more extensive analysis is given. 
512 
Figure 7: Threading. A latch circuit remembers an event until another comes along. This is a 
two input latch, e.g. for two letters a and b, but any number of units may be similarly connected. 
It is formed from a mutual inhibition layer, or winner-take-all connection, along with positive 
feedback to keep the selected output activated when the input disappears. 
Figure 8: Auxiliary actions--the S outputs--are fed back to the inputs of a net, enabling the 
net to remember a state. Here both part of a net and an example of a production are shown. 
There are two types of action, characters and S actions. 
S inputs 0 S outputs 
character ' 
 cter outputs 
input is [ and character input is [ THEN output character [] and S [1 
no direct effect on the task the system is performing since it evokes no relevant inputs, and 
so can be used by the net as a symbolic action. If an auxiliary action is latched at the input 
then the symbolic information can be remembered indefinitely, being lost only when another 
auxiliary action-of that kind is input and takes over the latch. Thus auxiliary actions can act 
like remembered states; the system performs an action to ""remind"" itself to be in a particular 
state. The figure illustrates this for a system that predicts characters and state changes given 
the previous character and state. An obvious candidate for auxiliary actions is speech. So 
the blank oval in the figure would represent the net's environment, through which its own 
speech actions are heard. Although it is externally manifested, speech has no direct effect on 
our physical interactions with the world. Its symbolic ability not only provides the power of 
auxiliary actions, but also includes other speakers in the interaction. 
5 SIMULATING ABSTRACT AUTOMATA 
The example in Figure 8 gives the essence of simulating a finite state automaton with a produc- 
tion system or its neural net equivalent. It illustrates the transition function of an automaton; 
the new state and output are a function of the previous state and input. Thus a neural net can 
simulate a finite state automaton, so long as it has additional, auxiliary actions. 
A Turing machine is a finite state automaton controller plus an unbounded memory. A 
neural net could simulate a Turing machine in two ways, and both ways have been demonstrated 
with production system implementations---equivalent to neural nets---called ""multiple context 
learning systems ""f, briefly explained in section 6. The first Turing machine simulation 7 has the 
system simulate only the finite state controller, but is able to use an unbounded external memory 
fSee John Andreae's and his colleagues' work 4,5,6,7,8,9,12,16 
513 
Figure 9: Multiple context learning system implementation as multiple neural nets. Each 3 
layer net has the simplified form presented above, with a number of elaborations such as extra 
connections for goal-seeking by forward and backward chaining. 
Input 
channels 
Output 
channels 
from the real world, much like the paper of Turing's original work x9. The second sinrelation }. 
embeds the memory in the multiple context learning system, along with a counter for accessing 
this simulated memory. Both learn all the productions--equivalent to learning output unit 
weights--required for the simulations. The second is able to add internal memory as required, 
up to a limit dependent on the size of the network (which can easily be large enough to allow 70 
years of computation!). The second could also employ external memory as the first did. Briefly, 
the second simulation comprised multiple sequence predictors which predicted auxiliary actions 
for remembering the state of the controller, and the current memory position. The memory 
element is updated by relearning the production representing that element; the precondition is 
the address and the production action the stored item. 
MULTIPLE SYSTEMS FORM ASSOCIATION AREAS 
A multiple context learning system is production system version of a multiple neural net, al- 
though a simple version has been implemented as a simulated net 4.2�. It effectively comprises 
several nets-or ""association"" areas--which may have outputs and inputs in common, as indi- 
cated in Figure 9. Hidden unit weights are specified by templates; one for each net. A template 
gives the inputs to have a zero weight for the hidden units of a net and the inputs to have a 
weight of unity. Delayed and latched inputs are also available. The actual outputs are selected 
from the combined predictions of the nets in a winner-take-all fashion. 
I see the design for real neural nets, say as controllers for real robots, requiring a large 
degree of predetermined connectivity. A robot controller could not be one three layer net with 
every input connected to every hidden unit in turn connected to every output. There will 
need to be some connectivity constraints so the net reflects the functional specialization in the 
control requirements a . The multiple context learning system has all the hidden layer connections 
predetermined, but allows output connections to be learned. This avoids the ""credit assignment"" 
problem and therefore also the need for learning algorithms such as Boltzmann learning and 
back-propagation. However, as the multiple context learning system has auxiliary actions, and 
delayed and latched inputs, it does not lack computational power. Future work in this area 
should investigate, for example, the ability of different kinds of nets to learn auxiliary actions. 
This may be difficult as symbolic actions may not be provided in training inputs a.nd outputs. 
gFor example a controller for a robot body would have to deal with vision, nlalipttlation, nxotiolb etc. 
514 
7 CONCLUSION 
This paper has presented a simplified three layer connectionist model, with fixed weights for 
hidden units, delays and latches for inputs, sequence prediction ability, auxiliary ""state"" actions, 
and the ability to use internal and external memory. The result is able to learn to simulate a 
Turing machine. Simple neural-like systems do not lack computational power. 
ACKNOWLEDGEMENTS 
This work is supported by the Natural Sciences and Engineering Council of Canada. 
REFERENCES 
1. Rumelhart,D.E. and McClelland,J.L. Parallel distributed processing. Volumes 1 and 2. MIT 
Press. (1986) 
2. Feldman,J.A. and Ballard,D.H. Connectionist models and their properties. Cognitive Science 
6, pp.205-254. (1982) 
3. Fahlman,S.E. Three Flavors of Parallelism. Proc.4th Nat.Conf. CSCSI/SCSEIO, Saskatoon. 
(1982) 
4. Andreae,J.H. Thinking with the teachable machine. Academic Press. (1977) 
5. Andreae,J.H. Man-Machine Studies Progress leports UC-DSE/1-28. Dept Electrical and 
Electronic Engineering, Univ. Canterbury, Christchurch, New Zealand. editor. (1972-87) 
(Also available from NTIS, 5285 Port Royal Rd, Springfield, VA 22161) 
6. Andreae,J.H. and Andreae,P.M. Machine learning with a multiple context. Proc.9th 
Int,Conf. on Cybernetics and Society. Denver. October. pp.734-9. (1979) 
7. Andreae,J.H. and Cleary,J.G. A new mechanism for a brain. Int. J. Man-Machine Studies 
8(1): pp.89-119. (1976) 
8. Andreae,P.M. and Andreae,J.H. A teachable machine in the real world. Int. J. Man-Machine 
Studies 10: pp.301-12. (1978) 
9. MacDonald,B.A. and Andreae,J.H. The competence of a multiple context learning system. 
Int. J. Gen. Systeras 7: pp.123-37. (1981) 
10. Rumelhart,D.E., Hinton,G.E. and McClelland,J.L. A general framework for parallel dis- 
tributed processing. chapter 2 in Rumelhart and McClelland , pp.45-76. (1986) 
11. Hinton,G.E. and Sejnowski,T.L. Learning and relearning in Boltzmann machines. chapter 7 
in lumelhart and McClelland l, pp.282-317. (1986) 
12. MacDonald,B.A. Designing teachable robots. PhD thesis, University of Canterbury, 
Christchurch, New Zealand. (1984) 
13. Rumelhart,D.E., Hinton,G.E. and Williams,R.J. Learning Internal Representations by Error 
Propagation. chapter 8 in Rumelhart and McClelland , pp.318-362. (1986) 
14. Ackley,D.H., Hinton,G.E. and Sejnowski,T.J. A Learning Algorithm for Boltzmann Ma- 
chines. Cognitive Science 9, pp.147-169. (1985) 
15. Nilsson,N.J. Principles of Artificial Intelligence. Tioga. (1980) 
16. Andreae,J.H. and MacDonald,B.A. Expert control for a robot body. lesearch Report 
87/286/34 Dept. of Computer Science, University of Calgary, Alberta, Canada, T2N-1N4. 
(1987) 
17. Witten,I.H. Approximate, non-deterministic modelling of behaviour sequences. Int. J. Gen- 
eral Systems, vol. 5 pp.1-12. (1979) 
18. Rumelhart,D.E.,Smolensky, P.,McClelland,J.L. and Hinton,G.E. Schemata and Sequential 
thought Processes in PDP Models. chapter 14, vol 2 in lumelhart and McClelland . pp.7- 
57. (1986) 
19. Turing,A.M. On computable numbers, with an application to the entscheidungsproblcm. 
Proc. London Math. Soc. vol J2(3). pp. 230-65. (1936) 
20. Dowd,R.B. A digital simulation of mew-brain. Report no. UC-DSE/105. pp.25-46. (1977) 
", past assist professor scienc comput scienc depart univers univers drive nw alberta renew interest process evidenc two volum parallel distribut process edit discuss parallel distribut connectionist neural valu pass multipl context dissatisfact symbol manipul paradigm artifici intellig seem partli respons encourag promis massiv parallel system implement paper relat simpl base multipl context product sequenc machin ture present sequenc predict result new introduct reviv neural net research exemplifi recent clelland new journal number meet net also describ distribut system connectionist model valu pass system multipl context system symbol manipul paradigm artifici intellig seem success hope seem last real promis massiv parallel system implement flurri new work import consolid new idea place solidli alongsid establish relat simpl system product sequenc machin ture present result abil network new gener form connectionist system simplifi three layer net binari weight hidden therebi avoid mani recent work neural hidden unit weight regularli pattern use expens learn algorithm simpl method determin output unit way gain advantag retain simplic two layer net train certainli lost comput limit two layer carri simplifi three layer biolog system may similarli need learn algorithm method commonli connectionist model one biolog system clearli train simplifi net product system implement three layer output input hidden layer product product unit potenti connect predetermin set input sequenc predictor form level delay unit introduc input predictor unabl distinguish simpl sequenc charact system forgotten whether appear predictor augment abl learn sinc auxiliari action equival input among intern confer neural san june roughli equival singl context system multipl context system see also donald american institut physic gener form connectionist system form unit oper within unit excit activ output typic product unit enabl predict depend previou state combin sever sequenc predictor ture machin tape simul along give net comput power univers ture rel system lack comput previou implement abil product system equival simplifi organ paper next section briefli review gener form connectionist section simplifi section explain result equival product system deal input output section extend simplifi enabl learn predict section explain comput power sequenc predictor increas ture machin input unit receiv auxiliari fact system learn ture section discuss possibl number combin form overal net gener form connectionist system show gener form connectionist system neuron cell figur output oj possibl unit output net input weight sum wij weight output unit input unit ai unit fi net input typic fi function least larg group output function fi typic kind threshold assum vari discret time exampl activ time given gener restrict connect may made connect directli input output hidden complex net describ may one type figur common connect three layer hidden cycl net train present input along desir train system produc desir output given basic structur three layer connectionist unit hidden output unit train weight adjust fashion reduc discrep desir actual gener method ti equat gener form classic adjust weight two unit high activ weight adjust product two one depend desir actual anoth depend input weight weight simpl exampl suppos differ output weight product output error input excit constant learn delta rule use net without hidden import contribut recent work connectionist system implement hidden train signal ti directli learn method iter vari weight hidden unit train activ gradual decreas random method also perform gradient descent propag train signal error net hidden avoid need determin train signal fix weight hidden unit section simplifi system simplif made gener connectionist system section system three topolog shown figur hidden layer unit weight say uniti zero unit linear threshold unit mean activ function unit ident give weight sum output simpl binari threshold output hidden unit threshold requir activ output activ output unit threshold requir two activ highli weight input output keep product system view explain section occur output unit weight adjust oj otherwis weight turn input unit output wij ai simpl exampl given figur section simpl form net made probabilist replac adjust weight wij estim condit probabl unit output output estim assum independ input output unit turn probabl occurr output exce threshold output simplif need learn hidden also learn weight either assign binari estim condit paper present characterist simplifi section motiv simplifi neural net product system simplifi net kind simpl product product system compris set product rule control system databas net system interact provid input reaction output hidden network product form precondit action precondit satisfi input excit exce threshold hidden action repres output unit hidden product unit control system product system choos rule whose action rule whose precondit neural net control system distribut net output output unit might form product system complex control involv forward backward chain action seek discuss elsewher figur illustr simpl implement neural figur input hidden unit element appropri input combin present hidden unit weight learn connect hidden output fire product result simplifi neural net directli product system whose element input output product system symbol given product neural net can not directli implement sinc output predetermin see later extens enabl might refer product sinc implement real system deal sens input execut motor may includ auxiliari section product implement simplifi neural product rule pressur fall lit rain rule implement hidden threshold hidden unit threshold output unit learn net otherwis estim rainlcloud pressur net predict next charact base last product unit combin input exampl net could predict sequenc abcabcabc product last charact next charact learn rule output ai wij oj net learn clamp input output desir valu system calcul weight valu repeat requir combin sequenc predict product system neural net predict given exampl repeat product learn predict futur event basi recent figur trivial simpl sequenc predict next charact sequenc base previou figur also give detail procedur simplifi net need train input output everi charact seen current probabilist form net would condit probabl next condit current mani use delay neural net implement sequenc net last three charact hidden output last exampl last three charact possibl charact pair would need properli estim net would learn probabl distribut charact predictor like one figur extend gener predictor long input delay step illustr figur hidden unit repres possibl combin output weight respond previous seen input three delay provid dedic neural net shown figur note net assum synchron input feedback around unit one step output variou way implement delay andrea investig detail simul sirrdlar work sequenc predict neural net bmlard find connectionist system initi suit repres chang one form chang suggest two method repres first unit connect sequenc sequenti repres fire unit second method buffer time input recent past avail well current delay input avail suggest import differ necessari feldman ballard suggest buffer long enough hold phrase expect use buffer longer andrea symbol repres complex inform effect give length seven buffer recent seven simpl discuss section method la enabl recurr network learn sequenti task feldman ballard give dedic neural net connect varieti function input delay dedic neural two stage delay delay input input time diagram time signal one step two step similar first suggest last sequenc connect unit sequenc one exampl net learn complet sequenc given first two charact six charact sequenc next four error propag around cycl recurr net number may also achiev sequenc state distribut activ exampl net play side game sequenti natur behavior sequenti natur respons net model sequenc intern model sequenti part play net model sequenc predictor unabl learn sequenc repeat everi context includ inform last two way inform kth last input retain first method latch second involv auxiliari latch unit latch held indefinit use combin shown figur would normal andrea discuss techniqu latch among give net inform arbitrarili far back histori inform immedi sequenc distinguish first charact ad hoc auxiliari action output fed back net input enabl system choos output least partli base previou indic figur particular back output also one without extern whose extern manifest independ task output auxiliari la interest reader refer andrea extens analysi latch circuit rememb event anoth come input two letter number unit may similarli form mutual inhibit along posit keep select output activ input auxiliari fed back input enabl rememb part net exampl product two type charact input output cter output charact input output charact direct effect task system perform sinc evok relev use net symbol auxiliari action latch input symbol inform rememb lost anoth kind input take thu auxiliari action act rememb system perform action particular figur illustr system predict charact state chang given previou charact obviou candid auxiliari action blank oval figur would repres action although extern speech direct effect physic interact symbol abil provid power also includ speaker simul abstract automata exampl figur give essenc simul finit state automaton system neural net illustr transit function new state output function previou state thu neural net finit state long auxiliari ture machin finit state automaton control plu unbound net could simul ture machin two way demonstr product system neural context system briefli explain section first ture machin simul simul finit state abl use unbound extern memori see john work multipl context learn system implement multipl neural net simplifi form present number elabor extra forward backward real much like paper origin work second sinrel memori multipl context learn along counter access simul learn learn output unit second abl add intern memori limit depend size network easili larg enough allow second could also employ extern memori first second simul compris multipl sequenc predictor predict auxiliari action rememb state current memori memori updat relearn product repres precondit address product action store system form associ area multipl context learn system product system version multipl neural simpl version implement simul net effect compris may output input figur hidden unit weight specifi one templat input zero weight hidden unit net input delay latch input also actual output select combin predict net see design real neural say control real requir larg predetermin robot control could one three layer net input connect everi hidden unit turn connect everi connect constraint net reflect function special requir multipl context learn system hidden layer connect allow output connect avoid therefor also need learn algorithm boltzmann learn multipl context learn system auxiliari latch lack comput futur work area abil differ kind net learn auxiliari may difficult symbol action may provid train input exampl control robot bodi would deal nxotiolb conclus paper present simplifi three layer connectionist fix weight delay latch sequenc predict auxiliari abil use intern extern result abl learn simul simpl system lack comput work support natur scienc engin council parallel distribut volum mit connectionist model cognit scienc three flavor think teachabl academ studi progress dept electr new avail port royal va machin learn multipl cybernet new mechan studi teachabl machin real compet multipl context learn systera gener framework parallel chapter rumelhart clelland learn relearn boltzmann chapter clelland design teachabl univers new learn intern represent error chapter rumelhart clelland learn algorithm boltzmann cognit scienc principl artifici expert control robot report comput univers model behaviour schemata sequenti process pdp chapter vol clelland comput applic london vol digit simul report,2
54,54,"515 
MICROELECTRONIC IMPLEMENTATIONS OF CONNECTIONIST 
NEURAL NETWORKS 
Stuart Mackie, Hans P. Graf, Daniel B. Schwartz, and John S. Denker 
AT&T Bell Labs, Holmdel, NJ 07733 
Abstract 
In this paper we discuss why special purpose chips are needed for useful 
implementations of connectionist neural networks in such applications as pattern 
recognition and classification. Three chip designs are described: a hybrid 
digital/analog programmable connection matrix, an analog connection matrix with 
adjustable connection strengths, and a digital pipelined best-match chip. The common 
feature of the designs is the distribution of arithmetic processing power amongst the 
data storage to minimize data movement. 
10 9 
106 
'103 
,,,/AMs 
',,, Distributed 
'-computation 
chip, s 
I �.jj/ '-, Conventional 
"",, CPUs 
10 3 10 6 10 9 
Node Complexity 
(No. of Transistors) 
Figure 1. A schematic graph of addressable node complexity and size for conventional 
computer chips. Memories can contain millions of very simple nodes each 
with a very few transistors but with no processing power. CPU chips are 
essentially one very complex node. Neural network chips are in the 
distributed computation region where chips contain many simple fixed 
instruction processors local to data storage. (After Reece and Treleaven 1 ) 
� American Institute of Physics 1988 
516 
Introduction 
It is clear that conventional computers lag far behind organic computers when it 
comes to dealing with very large data rates in problems such as computer vision and 
speech recognition. Why is this? The reason is that the brain performs a huge number 
of operations in parallel whereas in a conventional computer there is a very fast 
processor that can perform a variety of instructions very quickly, but operates on only 
two pieces of data at a time. 
The rest of the many megabytes of RAM is idle during any instruction cycle. The 
duty cycle of the processor is close to 100%, but that of the stored data is very close to 
zero. If we wish to make better use of the data, we have to distribute processing 
power amongst the stored data, in a similar fashion to the brain. Figure 1 illustrates 
where distributed computation chips lie in comparison to conventional computer chips 
as regard number and complexity of addressable nodes per chip. 
In order for a distributed strategy to work, each processing element must be small 
in order to accommodate many on a chip, and communication must be local and hard- 
wired. Whereas the processing element in a conventional computer may be able to 
execute many hundred different operations, in our scheme the processor is hard-wired 
to perform just one. This operation should be tailored to some particular application. 
In neural network and pattern recognition algorithms, the dot products of an input 
vector with a series of stored vectors (referred to as features or memories) is often 
required. The general calculation is: 
Sum of Products 
V. F(i)= v. f.. 
j j Ij 
where V is the input vector and F(i) is one of the stored feature vectors. Two 
variations of this are of particular interest. In feature extraction, we wish to find all the 
features for which the dot product with the input vector is greater than some threshold 
T, in which case we say that such features are present in the input vector. 
Feature Extraction 
V. F(i) = v. f.. 
j J IJ 
In pattern classification we wish to find the stored vector that has the largest dot 
product with the input vector, and we say that the the input is a member of the class 
represented by that feature, or simply that that stored vector is closest to input vector. 
Classification 
max(V. F(i) = v. f.. 
j j Ij 
The chips described here are each designed to perform one or more of the above 
functions with an input vector and a number of feature vectors in parallel. The overall 
strategy may be summed up as follows: we recognize that in typical pattern recognition 
applications, the feature vectors need to be changed infrequenfiy compared to the input 
517 
vectors, and the calculation that is performed is fixed and low-precision, we therefore 
distribute simple fixed-instruction processors throughout the data storage area, thus 
minimizing the data movement and optimizing the use of silicon. Our ideal is to have 
every transistor on the chip doing something useful during every instruction cycle. 
Analog Sum-of-Products 
Using an idea slightly reminiscent of synapses and neurons from the brain, in two 
of the chips we store elements of features as connections from input wires on which the 
elements of the input vectors appear as voltages to summing wires where a sum-of- 
products is performed. The voltage resulting from the current summing is applied to 
the input of an amplifier whose output is then read to determine the result of the 
calculation. A schematic arrangement is shown in Figure 2 with the vertical inputs 
connected to the horizontal summing wires through resistors chosen such that the 
conductance is proportional to the magnitude of the feature element. When both 
positive and negative values are required, inverted input lines are also necessary. 
Resistor matrices have been fabricated using amorphous silicon connections and metal 
linewidths. These were programmed during fabrication by electron beam lithography 
to store names using the distributed feedback method described by Hopfield 2,3. This 
work is described more fully elsewhere. n,s Hard-wired resistor matrices are very 
compact, but also very inflexible. In many applications it is deskable to be able to 
reprogram the matrix without having to fabricate a new chip. For this reason, a series 
of programmable chips has been designed. 
Feature 4 
Feature 3 
Feature 2 
Feature 1 
Input lines 
? 
/ ,? 
,/ ? 
- ? 
> 
> 
> 
Figure 2. 
A schematic arrangement for calculating parallel sum-of-products with a 
resistor matrix. Features are stored as connections along summing wires and 
the input elements are applied as voltages on the input wires. The voltage 
generated by the current summing is thresholded by the amplifer whose 
output is read out at the end of the calculation. Feedback connections may be 
518 
made to give mutual inhibition and allow only one feature amplifier to tum 
on, or allow the matrix to be used as a distributed feedbick memory. 
Programmable Connection Matrix 
Figure 3 is a schematic diagram of a programmable connection using the contents of 
two RAM cells to control current sinking or sourcing into the summing wire. The 
switches are pass transistors and the 'resistors' are transistors with gates connected to 
their drains. Current is sourced or sunk if the appropriate RAM cell contains a '1' and 
the input Vi is high thus closing both switches in the path. Feature elements can 
therefore take on values (a,0,-b) where the values of a and b are determined by the 
conductivities of the n- and p-transistors obtained during processing. A matrix with 
2916 such connections allowing full interconnection of the inputs and outputs of 54 
amplifiers was designed and fabricated in 2.5gm CMOS (Figure 4). Each connection 
is about 100x100gm, the chip is 7x7mm and contains about 75,000 transistors. When 
loaded with 49 49-bit features (7x7 kernel), and presented with a 49-bit input vector, 
the chip performs 49 dot products in parallel in under 1 gs. This is equivalent to 2.4 
billion bit operations/sec. The flexibility of the design allows the chip to be operated in 
several modes. The chip was programmed as a distributed feedback memory 
(associative memory), but this did not work well because the current sinking capability 
of the n-type transistors was 6 times that of the p-types. An associative memory was 
implemented by using a 'grandmother cell' representation, where the memories were 
stored along the input lines of amplifiers, as for feature extraction, but mutually 
inhibitory connections were also made that allowed only one output to turn on. With 
10 stored vectors each 40 bits long, the best match was found in 50-600ns, depending 
on the data. The circuit can also be programmed to recognize sequences of vectors and 
to do error correction when vectors were omitted or wrong vectors were inserted into 
the sequences. The details of operation of the chip are described more fully 
elsewhere 6. This chip has been interfaced to a UNIX minicomputer and is in everyday 
use as an accelerator for feature extraction in optical character recognition of hand- 
written numerals. The chip speeds up this time consuming calculation by a factor of 
more than 1000. The use of the chip enables experiments to be done which would be 
too time consuming to simulate. 
Experience with this device has led to the design of four new chips, which are 
currently being tested. These have no feedback capability and are intended exclusively 
for feature extraction. The designs each incorporate new features which are being 
tested separately, but all are based on a connection matrix which stores 46 vectors each 
96 bits long. The chip will perform a full parallel calculation in lOOns. 
519 
VDD 
Output(i) 
vj 
Excitatory 
Inhibitory 
VSS 
Figure 3. 
Schematic diagram of a programmable connection. A current sourcing or 
sinking connection is made if a RAM cell contains a '1' and the input Vi is 
high. The currents are summed on the input wire of the amplifier. 
111 
I I I I,t,1 I t t. 
Pads 
[:=] Row Decoders 
'_IL- Connections 
ITITI Amplifiers 
Figure 4. Programmable connection matrix chip. The chip contains 75,000 transistors 
in 7x7mm, and was fabricated using 2.5gm design rules. 
52O 
Adaptive Connection Matrix 
Many problems require analog depth in the connection strengths, and this is 
especially important if the chip is to be used for learning, where small adjustments are 
required during training. Typical approaches which use transistors sized in powers of 
two to give conductance variability take up an area equivalent to the same number of 
minimum sized transistors as the dynamic range, which is expensive in area and 
enables only a few connections to be put on a chip. We have designed a fully analog 
connection based on a DRAM structure that can be fabricated using conventional 
CMOS technology. A schematic of a connection and a connection matrix is shown in 
Figure 5. The connection strength is represented by the difference in voltages stored 
on two MOS capacitors. The capacitors are 33m on edge and lose about 1% of their 
charge in five minutes at room temperature. The leakage rate can be reduced by three 
orders of magnitude by cooling the the capacitors to -50�C and by five orders of 
magnitude by cooling to -100�C. The output is a current proportional to the product of 
the input voltage and the connection strength. The output currents are summed on a 
wire and are sent off chip to external amplifiers. The connection strengths can be 
adjusted using transferring charge between the capacitors through a chain of transistors. 
The connections strengths may be of either polarity and it is expected that the 
connections will have about 7 bits of analog depth. A chip has been designed in 
1.25gm CMOS containing 1104 connections in an array with 46 inputs and 24 outputs. 
Weight update and decay 
by shifting charge 
Q1 
Input 
I � � 02 
Output 
w ( (Q1-Q2) 
Output=w*lnput 
Input 
Output through external amplifiers 
Figure 5. Analog connection. The connection strength is represented by the difference 
in voltages stored on two capacitors. The output is a current proprtional to 
the product of the input voltage and the connection strength. 
Each connection is 70x240[tm. The design has been sent to foundry, and testing is 
expected to start in April 1988. The chip has been designed to perform a network 
calculation in <30ns, i.e., the chip will perform at a rate of 33 billion multiplies/sec. It 
can be used simply as a fast analog convolver for feature extraction, or as a learning 
521 
engine in a gradient descent algorithm using external logic for connection strength 
adjustment. Because the inputs and outputs are true analog, larger networks may be 
formed by tiling chips, and layered networks may be made by cascading through 
amplifiers acting as hidden units. 
Digital Classifier Chip 
The third design is a digital implementation of a classifier whose architecture is not 
a connectionist matrix. It is nearing completion of the design stage, and will be 
fabricated using 1.25gm CMOS. It calculates the largest five V.F(i) using an all- 
digital pipeline of identical processors, each attached to one stored word. Each 
processor is also intemally pipelined to the extent that no stage contains more than two 
gate delays. This is important, since the throughput of the processor is limited by the 
speed of the slowest stage. Each processor calculates the Hamming distance (number 
of difference bits) between an input word and its stored word, and then compares that 
distance with each of the smallest 5 values previously found for that input word. An 
updated list of 5 best matches is then passed to the next processor in the pipeline. At 
the end of the pipeline the best 5 matches overall are output. 
(1) Features stored in 
ring shift register 
Data Best match list 
pipeline pipeline 
Tag register 
(2) Input and feature 
are compared 
bit-serially 
(3) Accumulator 
dumps distance 
into comparison 
register at end 
of input word 
(4) Comparator inserts 
new match and tag into 
list when better than 
old match 
Fig. 6 
Schematic of one of the 50 processors in the digital classifier chip. The 
Hamming distance of the input vector to the feature vector is calculated, and 
if better than one of the five best matches found so far, is inserted into the 
match list together with the tag and passed onto the next processor. At the 
end of the pipeline the best five matches overall are output. 
522 
The data paths on chip are one bit wide and all calculations are bit serial. This 
means that the processing elements and the data paths are compact and maximizes the 
number of stored words per chip. The layout of a single processor is shown in 
Fig. 6. The features are stored as 128-bit words in 8 16-bit ring shift registers and 
associated with each feature is a 14~bit tag or name string that is stored in a static 
register. The input vector passes through the chip and is compared bit-by-bit to each 
stored vector, whose shift registers are cycled in turn. The total number of bits 
difference is summed in an accumulator. After a vector has passed through a processor, 
the total Hamming distance is loaded into the comparison register together with the tag. 
At this time, the match list for the input vector arrives at the comparator. It is an 
ordered list of the 5 lowest Hamming distances found in the pipeline so far, together 
with associated tag strings. The distance just calculated is compared bit-serially with 
each of the values in the list in turn. If the current distance is smaller than one of the 
ones in the list, the output streams of the comparator are switched, having the effect of 
inserting the current match and tag into the list and deleting the previous fifth best 
match. After the last processor in the pipeline, the list stream contains the best five 
distances overall, together with the tags of the stored vectors that generated them. The 
data stream and the list stream are loaded into 16-bit wide registers ready for output. 
The design enables chips to be connected together to extend the pipeline if more than 50 
stored vectors are required. The throughput is constant, irrespective of the number of 
chips connected together; only the latency increases as the number of chips increases. 
The chip has been designed to operate with an on-chip clock frequency of at least 
100MHz. This high speed is possible because stage sizes are very small and data paths 
have been kept short. The computational efficiency is not as high as in the analog chips 
because each processor only deals with one bit of stored data at a time. However, the 
overall throughput is high because of the high clock speed. Assuming a clock 
frequency of 100MHz, the chip will produce a list of 5 best distances with tag strings 
every 1.3Its, with a latency of about 2.5gs. Even if a thousand chips containing 
50,000 stored vectors were pipelined together, the latency would be 2.5ms, low 
enough for most real time applications. The chip is expected to perform 5 billion bit 
operation/sec. 
While it is important to have high clock frequencies on the chip, it is also important 
to have them much lower off the chip, since frequencies above 50MHz are hard to deal 
on circuit boards. The 16-bit wide communication paths onto and off the chip ensure 
that this is not a problem here. 
Conclusion 
The two approaches discussed here, analog and digital, represent opposites in 
computational approach. In one, a single global computation is performed for each 
match, in the other many local calculations are done. Both the approaches have their 
advantages and it remains to be seen which type of circuit will be more efficient in 
applications, and how closely an electronic implementation of a neural network should 
resemble the highly interconnected nature of a biological network. 
These designs represent some of the first distributed computation chips. They are 
characterized by having simple processors distributed amongst data storage. The 
operation performed by the processor is tailored to the application. It is interesting to 
note some of the reasons why these designs can now be made: minimum linewidths on 
523 
circuits are now small enough that enough processors can be put on one chip to make 
these designs of a useful size, sophisticated design tools are now available that enable a 
single person to design and simulate a complete circuit in a matter of months, and 
fabrication costs are low enough that highly speculative circuits can be made without 
requiring future volume production to offset prototype costs. 
We expect a flurry of similar designs in the coming years, with circuits becoming 
more and more optimized for particular applications. However, it should be noted that 
the impressive speed gain achieved by putting an algorithm into custom silicon can only 
be done once. Further gains in speed will be closely tied to mainstream technological 
advances in such areas as transistor size reduction and wafer-scale integration. It 
remains to be seen what influence these kinds of custom circuits will have in useful 
technology since at present their functions cannot even be simulated in reasonable time. 
What can be achieved with these circuits is very limited when compared with a three 
dimensional, highly complex biological system, but is a vast improvement over 
conventional computer architectures. 
The authors gratefully acknowledge the contributions made by L.D. Jackel, and 
R.E. Howard 
References 
M. Reece and P.C. Treleaven, ""Parallel Architectures for Neural Computers"", Neural 
Computers, R. Eckmiller and C. v.d. Malsburg, eds (Springer-Verlag, Heidelberg, 
1988) 
2 j.j. Hopfield, Proc. Nat. Acad. Sci. 79, 2554 (1982). 
3 J.S. Denker, Physica 22D, 216 (1986). 
R.E. Howard, D.B. Schwartz, J.S. Denker, R.W. Epworth, H.P. Graf, W.E. 
Hubbard, L.D. Jackel, B.L. Straughn, and D.M. Tennant, IEEE Trans. Electron 
Devices ED-34, 1553, (1987) 
H.P. Graf and P. deVegvar, ""A CMOS Implementation of a Neural Network 
Model"", in ""Advanced Research in VLSI"", Proceedings of the 1987 Stanford 
Conference, P. Losleben (ed.), (MIT Press 1987). 
6 H.P. Graf and P. deVegvar, ""A CMOS Associative Memory Chip Based on Neural 
Networks"", Tech. Digest, 1987 IEEE International Solid-State Circuits Conference. 
", implement connectionist network han daniel john denker bell nj paper discuss special purpos chip need use connectionist neural network applic pattern three chip design hybrid programm connect analog connect matrix connect digit pipelin common design distribut arithmet process power amongst storag minim data distribut convent cpu complex schemat graph address node complex size convent memori contain million simpl node transistor process cpu chip one complex neural network chip comput region chip contain mani simpl fix processor local data reec treleaven american institut physic clear convent comput lag far behind organ comput deal larg data rate problem comput vision reason brain perform huge number oper parallel wherea convent comput fast perform varieti instruct oper piec data rest mani megabyt ram idl instruct cycl processor close store data close wish make better use distribut process amongst store similar fashion figur illustr distribut comput chip lie comparison convent comput chip regard number complex address node per order distribut strategi process element must small order accommod mani commun must local wherea process element convent comput may abl mani hundr differ scheme processor perform oper tailor particular neural network pattern recognit dot product input seri store vector featur often gener calcul product ij input vector one store featur two particular featur wish find dot product input vector greater threshold case say featur present input extract ij pattern classif wish find store vector largest dot input say input member class simpli store vector closest input ij chip describ design perform one input vector number featur vector overal may sum recogn typic pattern recognit featur vector need chang infrequenfiy compar input calcul perform fix therefor simpl processor throughout data storag thu data movement optim use ideal transistor chip someth use everi instruct idea slightli reminisc synaps neuron two chip store element featur connect input wire input vector appear voltag sum wire voltag result current sum appli input amplifi whose output read determin result schemat arrang shown figur vertic input horizont sum wire resistor chosen proport magnitud featur neg valu invert input line also matric fabric use amorph silicon connect metal program fabric electron beam lithographi store name use distribut feedback method describ hopfield describ fulli resistor matric also mani applic deskabl abl matrix without fabric new seri programm chip line schemat arrang calcul parallel featur store connect along sum wire input element appli voltag input voltag current sum threshold amplif whose read end feedback connect may give mutual inhibit allow one featur amplifi tum allow matrix use distribut connect matrix schemat diagram programm connect use content ram cell control current sink sourc sum pass transistor transistor gate connect current sourc sunk appropri ram cell contain input vi high thu close switch featur element take valu valu determin obtain matrix connect allow full interconnect input output design fabric cmo connect chip contain featur present input chip perform dot product parallel equival bit flexibl design allow chip oper chip program distribut feedback memori work well current sink capabl transistor time associ memori use memori along input line featur mutual connect also made allow one output turn store vector bit best match found depend circuit also program recogn sequenc vector error correct vector omit wrong vector insert detail oper chip describ fulli chip interfac unix minicomput everyday acceler featur extract optic charact recognit chip speed time consum calcul factor use chip enabl experi done would time consum devic led design four new feedback capabl intend exclus featur design incorpor new featur base connect matrix store vector bit chip perform full parallel calcul diagram programm current sourc connect made ram cell contain input vi current sum input wire row decod connect amplifi programm connect matrix chip contain transistor fabric use design connect matrix problem requir analog depth connect import chip use small adjust typic approach use transistor size power give conduct variabl take area equival number size transistor dynam expens area connect put design fulli analog base dram structur fabric use convent schemat connect connect matrix shown connect strength repres differ voltag store two mo capacitor edg lose five minut room leakag rate reduc three magnitud cool capacitor five order cool output current proport product input voltag connect output current sum sent chip extern connect strength use transfer charg capacitor chain connect strength may either polar expect bit analog chip design cmo contain connect array input updat decay shift charg lnput extern amplifi analog connect strength repres differ voltag store two output current proprtion product input voltag connect connect design sent test start april chip design perform network chip perform rate billion use simpli fast analog convolv featur learn gradient descent algorithm use extern logic connect strength input output true larger network may tile layer network may made cascad act hidden classifi chip third design digit implement classifi whose architectur connectionist near complet design use calcul largest five use pipelin ident attach one store also intem pipelin extent stage contain two sinc throughput processor limit slowest processor calcul ham distanc differ input word store compar smallest valu previous found input list best match pass next processor end pipelin best match overal featur store shift regist best match list pipelin regist input featur compar accumul distanc comparison end input word compar insert match tag better match one processor digit classifi distanc input vector featur vector better one five best match found insert list togeth tag pass onto next pipelin best five match overal data path chip one bit wide calcul bit process element data path compact maxim store word per layout singl processor shown featur store word ring shift regist featur tag name string store static input vector pass chip compar whose shift regist cycl total number bit sum vector pass total ham distanc load comparison regist togeth match list input vector arriv list lowest ham distanc found pipelin togeth associ tag distanc calcul compar valu list current distanc smaller one output stream compar effect current match tag list delet previou fifth best last processor list stream contain best five togeth tag store vector gener stream list stream load wide regist readi design enabl chip connect togeth extend pipelin vector throughput irrespect number connect latenc increas number chip chip design oper clock frequenc least high speed possibl stage size small data path kept comput effici high analog chip processor deal one bit store data throughput high high clock assum clock chip produc list best distanc tag string latenc even thousand chip contain store vector pipelin latenc would low real time chip expect perform billion bit import high clock frequenc also import much lower sinc frequenc hard deal circuit wide commun path onto chip ensur problem two approach discuss analog repres opposit singl global comput perform mani local calcul approach remain seen type circuit effici close electron implement neural network highli interconnect natur biolog design repres first distribut comput simpl processor distribut amongst data perform processor tailor interest reason design minimum linewidth small enough enough processor put one chip make design use sophist design tool avail enabl person design simul complet circuit matter cost low enough highli specul circuit made without futur volum product offset prototyp expect flurri similar design come circuit becom optim particular note impress speed gain achiev put algorithm custom silicon done gain speed close tie mainstream technolog area transistor size reduct seen influenc kind custom circuit use sinc present function can not even simul reason achiev circuit limit compar three highli complex biolog vast improv comput author grate acknowledg contribut made howard reec architectur neural neural eckmil ed physica ie electron graf cmo implement neural network research proceed stanford losleben press graf cmo associ memori chip base neural ie intern circuit,2
55,55,"524 
BASINS OF ATTRACTION FOR 
ELECTRONIC NEURAL NETWORKS 
C. M. Marcus 
R. M. Westervelt 
Division of Applied Sciences and Department of Physics 
Harvard University, Cambridge, MA 02138 
ABSTRACT 
We have studied the basins of attraction for fixed point and 
oscillatory attractors in an electronic analog neural network. Basin 
measurement circuitry periodically opens the network feedback loop, 
loads raster-scanned initial conditions and examines the resulting 
attractor. Plotting the basins for fixed points (memories), we show 
that overloading an associative memory network leads to irregular 
basin shapes. The network also includes analog time delay circuitry, 
and we have shown that delay in symmetric networks can introduce 
basins for oscillatory attractors. Conditions leading to oscillation 
are related to the presence of frustration; reducing frustration by 
diluting the connections can stabilize a delay network. 
(1) - INTRODUCTION 
The dynamical system formed from an interconnected network of 
nonlinear neuron-like elements can perform useful parallel 
computation 1-5. Recent progress in controlling the dynamics has 
focussed on algorithms for encoding the location of fixed points 1,4 
and on the stability of the flow to fixed points 3,5-8 An equally 
important aspect of the dynamics is the structure.of the basins of 
attraction, which describe the location of all points in initial 
condition space which flow to a particular attractor 10,22 
In a useful associative memory, an initial state should lead 
reliably to the ""closest"" memory. This requirement suggests that a 
well-behaved basin of attraction should evenly surround its attractor 
and have a smooth and regular shape. One dimensional basin maps 
plotting ""pull in"" probability against Hamming distance from an 
attractor do not reveal the shape of the basin in the high 
dimensional space of initial states 9,19 Recently, a numerical study 
of a Hopfield network with discrete time and two-state neurons showed 
rough and irregular basin shapes in a two dimensional Hamming space, 
suggesting that the high dimensional basin has a complicated 
structure 10. It is not known how the basin shapes change with the 
size of the network and the connection rule. 
We have investigated the basins of attraction in a network with 
continuous state dynamics by building an electronic neural network 
with eight variable gain sigmoid neurons and a three level (+,0,-) 
interconnection matrix. We have also built circuitry that can map 
out the basins of attraction in two dimensional slices of initial 
state space (Fig.l). The network and the basin measurements are 
described in section 2. 
American Institute of Physics 1988 
525 
In section 3, we show that the network operates well as an 
associative memory and can retrieve up to four memories (eight fixed 
points) without developing spurious attractors, but that for storage 
of three or more memories, the basin shapes become irregular. 
In section 4, we consider the effects of time delay. Real network 
components cannot switch infinitely fast or propagate signals 
instantaneously, so that delay is an intrinsic part of any hardware 
implementation of a neural network. We have included a controllable 
CCD (charge coupled device) analog time delay in each neuron to 
investigate how time delay affects the dynamics of a neural network. 
We find that networks with symmetric interconnection matrices, which 
are guaranteed to converge to fixed points for no delay, show 
collective sustained oscillations when time delay is present. By 
discovering which configurations are maximally unstable to 
oscillation, and looking at how these configurations appear in 
networks, we are able to show that by diluting the interconnection 
matrix, one can reduce or eliminate the oscillations in neural 
networks with time delay. 
(2) - NETWORK AND BASIN MEASUREMENT 
A block diagram of the network and basin measurement circuit is 
shown in fig.1. 
sigmoid amplifiers 
with delay 
digital 
comparator 
and 
oscillation 
detector 
storage 
outputs 
t 
'[desired 
jmemory 
initial 
-- run/load switches 
Fiq.1 Block diagram 
of the network and 
basin measurement 
system. 
The main feedback loop consists of non-linear amplifiers 
(""neurons"", see fig.2) with capacitive inputs and a resistor matrix 
allowing interconnection strengths of -l/R, 0, +i/R (R = 100 k). In 
all basin measurements, the input capacitance was 10 nF, giving a 
time constant of 1 ms. A charge coupled device (CCD) analog time 
delay 11 was built into each neuron, providing an adjustable delay per 
neuron over a range 0.4 - 8 ms. 
526 
Fig.2 Electronic neuron. 
Non-linear gain provided 
by feedback diodes. 
Inset: Nonlinear 
behavior at several 
different values of 
gain. 
Analog switches allow the feedback path to be periodically 
disconnected and each neuron input charged to an initial voltage. The 
network is then reconnected and settles to the attractor associated 
with that set of initial conditions. Two of the initial voltages are 
raster scanned (on a time scale that is long compared to the load/run 
switching time) with function generators that are also connected to 
the X and Y axes of a storage scope. The beam of the scope is 
activated when the network settles into a desired attractor, 
producing an image of the basin for that attractor in a two- 
dimensional slice of initial condition space. The ""attractor of 
interest"" can be one of the 2 8 fixed points or an oscillatory 
attractor. 
A simple example of this technique is the case of three neurons 
with symmetric non-inverting connection shown in fig.3. 
..."" / ,,',,,',:{{,,SASlN HTrl F i g. $ Basin of 
'.i].'..' ..,--....,.BASINFOR attraction for three 
neurons with sym- 
metric non-inverting 
"" ,"", .,, ',,, ,, ,,, ., ;,,', ;""/ ,,',,__, ,,, ,,, ..,. ;,,iL.. -1.0V coupling. Slices are 
in the plane of 
initial voltages on 
""'/'/;;<', ,,',;"" ;[t ,,--0.1V neurons 1 and 2. The 
,, i',',,b..,',;',./""/', , 6'"";, *;..'.;< , v3 c, two fixed points are 
_ ''. 9%.':,%10V_ _/_ . . i7. ' all neurons saturated 
positive or all 
negative. The data 
-1V are photographs of 
 Vl __ I.UV I' ""-'-'"" the screen. 
-' V 1V scope 
(3) BASINS FOR FIXED POINTS - ASSOCIATIVE MEMORY 
Two dimensional slices of the eight dimensional initial condition 
space (for the full network) reveal important qualitative features 
about the high dimensional basins. Fig. 4 shows a typical slice for 
a network programmed with three memories according to a clipped Hebb 
rulel, 12. 
527 
Tij = 1/R Sqn(=l, m i  j); Tii = 0 (1) 
where  is an N-component memory vector of l's and -l's, and m is 
the number of memories. The memories were chosen to be orthogonal 
MEMORIES: 
1 , 1, 1, 1,-1 ,-1,-1,-1 
1 ,-1,1 ,-1,1 ,-1,1 ,-1 
1, 1 ,-1 ,-1,1 ,1 ,-1,-1 
Fig. 4 A slice of initial condition space shows the basins of 
attraction for five of the six fixed points for three memories 
in eight-neuron Hopfield net. Learning rule was clipped Hebb 
(Eq.1). Neuron gain = 15. 
Because the Hebb rule (eq.1) makes  and - stable attractors, a 
three-memory network will have six fixed point attractors. In fig.4, 
the basins for five of these attractors are visible, each produced 
with a different rastering pattern to make it distinctive. Several 
characteristic features should be noted: 
-- All initial conditions lead to one of the memories (or 
inverses), no spurious attractors were seen for three or four 
memories. This is interesting in light of the well documented 
emergence of spurious attractors at m/N -15% in larger networks with 
discrete time 2'18 
-- The basins have smooth and continuous edges. 
-- The shapes of the basins as seen in this slice are irregular. 
Ideally, a slice with attractors at each of the corners should have 
rectangular basins, one basin in each quadrant of the slice and the 
location of the lines dividing quadrants determined by the initial 
conditions on the other neurons (the ""unseen"" dimensions). With three 
or more memories the actual basins do not resemble this ideal form. 
(4) TIME DELAY, FRUSTRATION AND SUSTAINED OSCILLATION 
Arguments defining conditions which guarantee convergence to 
fixed points 3'$'6 (based, for example, on the construction of a 
Liapunov function) generally assume instantaneous communication 
between elements of the network. In any hardware implementation, 
these assumptions break down due to the finite switching speed of 
amplifiers and the charging time of long interconnect lines. 13 It is 
the ratio of delay/RC which is important for stability, so keeping 
this ratio small limits how fast a neural network chip can be 
designed to run. Time delay is also relevant to biological neural 
nets where propagation and response times are comparable. 14'15 
528 
Our particular interest in this section is how time delay can 
lead to sustained oscillation in networks which are known to be 
stable when there is no delay. We therefore restrict our attention 
to networks with symmetric interconnection matrices (Tij = Tji). 
An obvious ingredient in producing oscillations in a delay 
network is feedback, or stated another way, a graph representing the 
connections in a network must contain loops. 
The simplest oscillatory structure made of delay elements is the 
ring oscillator (fig.5a). Though not a symmetric configuration, the 
ring oscillator illustrates an important point: the ring will 
oscillate only when there is negative feedback at dc - that is, when 
the product of'interconnection around the loop is negative. Positive 
feedback at dc (loop product of connections > 0) will lead to 
saturation. 
Observing various symmetric configurations (e.g. fig.5b) in the 
delayed-neuron network, we find that a negative product of 
connections around a loop is also a necessary condition for sustained 
oscillation in symmetric circuits. An important difference between 
the ring (fig.5a) and the symmetric loop (fig.5b) is that the period 
of oscillation for the ring is the total accumulated delay around the 
ring - the larger the ring the longer the period. In contrast, for 
those symmetric configurations which have oscillatory attractors, the 
period of oscillation is roughly twice the delay, regardless of the 
size of the configuration or the value of delay. This indicates that 
for symmetric configurations the important feedback path is local, 
not around the loop. 
 ring 
%oscillator O =time delay 
 (NEGATIVE neuron 
O ,1 ...........  FEEDBAOK) /=non-inverting 
connection 
/%?) ,,;IP =inverting 
Y n]omoe; r ic ,"" connection 
(FRUSTRATED) 
Fig.5 (a) A ring oscillator: 
needs negative feedback at dc 
to oscillate. (b) Symmetrical- 
ly connected triangle. This 
configuration is ""frustrated"" 
(defined in text), and has 
both oscillatory and fixed 
point attractors when neurons 
have delay. 
Configurations with loop connection product < 0 are important in 
the theory of spin glasses 16, where such configurations are called 
""frustrated."" Frustration in magnetic (spin) systems, gives a measure 
of ""serious"" bond disorder (disorder that cannot be removed by a 
change of variables) which can lead to a spin glass state. 16,17 
Recent results based on the similarity between spin glasses and 
symmetric neural networks has shown that storage capacity limitations 
can be understood in terms of this bond disorder. 18,19 Restating our 
observation above: We only find stable oscillatory modes in symmetric 
networks with delay when there is frustration. A similar result for a 
sign-symmetric network (Tij , Tji both  0 or  0) with no delay is 
described by Hirsch. 6 
We can set up the basin measurement system (fig.l) to plot the 
basin of attraction for the oscillatory mode. Fig.6 shows a slice of 
the oscillatory basin for a frustrated triangle of delay neurons. 
529 
(a): delay/RC=0.48 
1,5V- 
(b): delay/RC--0.61 
i i I 
-1.5V 0 Vi 1.5V 
-1.5V- 
-1.5V 
I I 
0 Vi 1.5V 
Fig.6 Basin for oscillatory attractor (cross-hatched region) 
in frustrated triangle of delay-neurons. Connections were 
all symmetric and inverting; other frustrated configurations 
(e.g. two non-inverting, one inverting, all symmetric) were 
similar. (6a): delay = 0.48RC, inset shows trajectory to fixed 
point and oscillatory mode for two close-lying initial 
conditions. (6b): delay = 0.61RC, basin size increases. 
A fully connected feedback associative network with more that one 
memory will contain frustration. As more memories are added, the 
amount of frustration will increases until memory retrieval 
disappears. But before this point of memory saturation is reached, 
delay could cause an oscillatory basin to open. In order to design 
out this possibility, one must understand how frustration, delay and 
global stability are related. A first step in determining the 
stability of a delay network is to consider which small 
configurations are most prone to oscillation, and then see how these 
""dangerous"" configurations show up in the network. As described 
above, we only need to consider frustrated configurations. 
A frustrated configuration of neurons can be sparsely connected, 
as in a loop, or densely connected, with all neurons connected to all 
others, forming what is called in graph theory a ""clique."" 
Representing a network with inverting and non-inverting connections 
as a signed graph (edges carry + and -), we define a frustrated clique 
as a fully connected set of vertices (r vertices; r(r-1)/2 edges) 
with all sets of three vertices in the clique forming frustrated 
triangles. Some examples of frustrated loops and cliques are shown in 
fig.7. Notice that neurons connected with all inverting symmetric 
connections, a configuration that is useful as a ""winner-take-all"" 
circuit, is a frustrated clique. 
 FRUSTRATED Fic. Examples of frustrated 
\ ? 7 
 j....,,. LOOPS - 
, , I, =roverting /=non-inverting I 
// "", I symmetric connection symmetric connectionJ 
� ............... ll  .., ::... FRUSTRATED 
/iX .'i:::;.}:::i.1 --.. CLIQUES 
/  \ :..""..,, ,:::'.."" "",.:.'"".!9(fully connected; 
/\ \ /,,"": :',,\J ':""/,. }i'"" alltriangles 
� : ............... � : .......... :e ""=::it: ::' frustrated) 
loops and frustrated 
cliques. In the graph 
representation vertices 
(black dots) are neurons 
(with delay) and undirected 
edges are symmetric 
connections. 
530 
We find that delayed neurons connected in a frustrated loop 
longer than three neurons do not show sustained oscillation for any 
value of delay (tested up to delay = 8RC). In contrast, when delayed 
neurons are connected in any frustrated clique configuration, we do 
find basins of attraction for sustained oscillation as well as fixed 
point attractors, and that the larger the frustrated clique, the more 
easily it oscillates in the following ways: (1) For a given value of 
delay/RC, the size of the oscillatory basin increases with r, the 
size of the frustrated clique (fig.8). (2) The critical value of 
delay at which the volume of the oscillatory basin goes to zero 
decreases with increasing r (fig.9); For r=8 the critical delay is 
already less than 1/30 RC. 
1 
Fig. Size of basin 
for oscillatory mode 
increases with size of 
frustrated clique. The 
delay is 0.46RC per 
neuron in each picture. 
Slices are in the space 
of initial voltages on 
neurons 1 and 2, other 
initial voltages near 
zero. 
size of frustrated clique (r) 1 0 
Fig.9 The critical value of delay 
where the oscillatory mode vanishes. 
Measured by reducing delay until 
system leaves oscillatory attractor. 
Delay plotted in units of the 
characteristic time RlnC , where Rin 
=(j 1/Rij)-l=105/(r-1) and C=10nF, 
indicating that the critical delay 
decreases faster than 1/(r-l). 
Having identified frustrated cliques as the maximally unstable 
configuration of time delay neurons, we now ask how many cliques of a 
given size do we expect to find in a large network. 
A set of r vertices (neurons) can be fully connected by r(r-1)/2 
edges of two types (+ or -) to form 2 r(r-1)/2 different cliques. Of 
these, 2 (r-l) will be frustrated cliques. Fig.-10 shows all 2(4-1)=8 
cases for r=4. ' 
Fig.10 All graphs of size r=4 that are frustrated cliques 
(fully connected, every triangle frustrated.) Solid lines = 
positive edges, dashed lines = negative edges. 
531 
For a randomly connected network, this result combined with 
results from random graph theory 2� gives an expected number of 
frustrated cliques of size r in a network of size N, EN(r) : 
N 
EN(r) = (r) c(r,p) (2) 
c(r,p) = 2-(r-l)(r-2)/2 pr(r-1)/2 (3) 
where () is the binomial coefficient and c(r,p) is defined as the 
concentration of frustrated cliques. p is the connectance of the 
network, defined as the probability that any two neurons are 
connected. Eq.3 is the special case where + and - edges (non- 
inverting, inverting connections) are equally probable. We have also 
generalized this result to the case p(+)p(-). 
Fig.ll shows the dramatic reduction in the concentration of all 
frustrated configurations in a diluted random network. For the 
general case (p(+)p(-)) we find that the negative connections 
affect the concentrations of frustrated cliques more strongly than 
the positive connections, as expected (Frustration requires 
negatives, not positives, see fig.10). 
10 0 
 10' 
o 
o 
o 1 
.1 �0nnectance(p) 
When the interconnections in a network are specified by a 
learning rule rather than at random, the expected numbers of any 
configuration will differ from the above results. We have compared 
the number of frustrated triangles in large three-valued (+1,0,-1) 
Hebb interconnection matrices (N=100,300,600) to the expected number 
in a random matrix of the same size and connectance. The Hebb matrix 
was constructed according to the rule: 
Fig.ll Concentration of 
frustrated cliques of size 
r=3,4,5,6 in an unbiased 
random network, from eq.3. 
Concentrations decrease 
rapidly as the network is 
diluted, especially for 
large cliques note: log 
scale). 
Tij = Zk (CZ=l,m i cz jcz) ; Tii = 0 (4a) 
Zk(X) = +1 for x > k; 0 for -k _<x _<k; -1 for x < -k; (4b) 
m is the number of memories, ZkiS a threshold function with cutoff 
k, and e is a random string of l's and -l's. The matrix constructed 
by eq.4 is roughly unbiased (equal number of positive and negative 
connections) and has a connectance p(k) . Fig.12 shows the ratio of 
frustrated triangles in a diluted Hebb matrix to the expected number 
in a random graph with the same connectance for different numbers of 
532 
memories stored in the Hebb matrix. At all values of connectance, the 
Hebb matrix has fewer frustrated triangles than the random matrix by 
a ratio that is decreased by diluting the matrix or storing fewer 
memories. The curves do not seem to depend on the size of the matrix, 
N. This result suggests that diluting a Hebb matrix breaks up 
frustration even more efficiently than diluting a random matrix. 
B ratio m=15 N = 300 � � 
0,9 � ratiom=25  �[] 
[] ratlomb--40 ..,-/_. Fig.12 The number of frustrated 
� ratio re=55 ///// triangles in a (+ 0 -) Hebb rule 
0.7 � ' ' 
� ratiorrl=l matrix (300x300) divided by the 
expected number in a random 
0.5 signed graph with equal 
connectance. The different sets 
0.3 of points are for different 
numbers of random memories in the 
0.1 Hebb matrix. The lines are 
.1 connectance guides to the eye. 
The sensitive dependence of frustration on connectance suggests 
that oscillatory modes in a large neural network with delay can be 
eliminated by diluting the interconnection matrix. As an example, 
consider a unbiased random network with delay = RC/10. From fig.9, 
only frustrated cliques of size r=5 or larger have oscillatory basins 
for this value of delay; frustration in smaller configurations in the 
network cannot lead to sustained oscillation in the network. 
Diluting the connectance to 60% will reduce the concentration of 
frustrated cliques with r=5 by a factor of over 100 and r=6 by a 
factor of 2000. The reduction would be even greater for a clipped 
Hebb matrix. 
Results from spin glass theory 21 suggest that diluting a clipped 
Hebb matrix can actually improve the storage capacity for moderated 
dilution, with a maximum in the capacity at a connectance of 61%. To 
the extent this treatment applies to an analog continuous-time 
network, we should expect that by diluting connections, oscillatory 
modes can be killed before memory capacity is compromised. 
We have confirmed the stabilizing effect of dilution in our 
network: For a fully connected eight neuron network programmed with 
three orthogonal memories according to eq.1, adding a delay of 0.4RC 
opens large basins for sustained oscillation. By randomly diluting 
the interconnections to p~0.85, we were able to close the 
oscillatory basins and recover a useful associative memory. 
SUMMARY 
We have investigated the structure of fixed point and oscillatory 
basins of attraction in an electronic network of eight non-linear 
amplifiers with controllable time delay and a three value (+,0,-) 
interconnection matrix. 
For fixed point attractors, we find that the network performs 
well as an associative memory - no spurious attractors were seen for 
up to four stored memories - but for three or more memories, the 
shapes of the basins of attraction became irregular. 
533 
A network which is stable with no delay can have basins for 
oscillatory attractors when time delay is present. For symmetric 
networks with time delay, we only observe sustained oscillation when 
there is frustration. Frustrated cliques (fully connected 
configurations with all triangles frustrated), and not loops, are 
most prone to oscillation, and the larger the frustrated clique, the 
more easily it oscillates. The number of these ""dangerous"" 
configurations in a large network can be greatly reduced by diluting 
the connections. We have demonstrated that a network with a large 
basin for an oscillatory attractor can be stabilized by dilution. 
ACKNOWLEDGEMENTS 
We thank K.L.Babcock, S.W.Teitsworth, S.Strogatz and P.Horowitz for 
useful discussions. One of us (C.M.M) acknowledges support as an AT&T 
Bell Laboratories Scholar. This work was supported by JSEP contract 
no. N00014-84-K-0465. 
REFERENCES 
1) 
2) 
3) 
4) 
5) 
6) 
7) 
8) 
9) 
J.S.Denker, Physica 2D, 216 (1986). 
J.J. Hopfield, Proc. Nat.Acad. Sci. 79, 2554 (1982). 
J.J. Hopfield, Proc. Nat.Acad. Sci. 81, 3008 (1984). 
J.S. Denker, Ed. Neural Networks for Computing, AIP Conf. Proc. 
151 (1986). 
M.A. Cohen, S. Grossberg, IEEE Trans. SMC-13, 815 (1983). 
M.W.Hirsch, Convergence in Neural Nets, IEEE Conf.on Neural 
Networks, 1987. 
K.L. Babcock, R.M. Westervelt, Physica 23D,464 (1986). 
K.L. Babcock, R.M. Westervelt, Physica 28D,305 (1987). 
See, for example: D.B.Schwartz, et al, Appl. Phys.Lett.,50 (16), 
1110 (1987); or M.A.Silviotti,et al, in Ref.4, pg.408. 
10) J.D. Keeler in Ref.4, pg.259. 
11) CCD analog delay: EG&G Reticon RD5106A. 
12) D.O.Hebb, The Organization of Behavior, (J.Wiley, N.Y., 1949). 
13) Delay in VLSI discussed in: A. Muhkerjee, Introduction to nMOS 
and CMOS VLSI System Design, (Prentice Hall, N.J.,1985) . 
14) U. an der Heiden, J.Math.Biology, , 345 (1979). 
15) M.C. Mackey, U. an der Heiden, J.Math.Biology, 19, 221 (1984). 
16) Theory of spin glasses reviewed in: K. Binder, A.P. Young, 
Rev. Mod. Phys.,58 (4),801, (1986). 
17) E. Fradkin,B.A. Huberman, S.H. Shenker, Phys.Rev. B18 (9),4789 
(1978). 
18) D.J. Amit, H. Gutfreund, H. Sompolinski, Ann.Phys. 175, 30, 
(1987) and references therein. 
19) J.L. van Hemmen, I. Morgenstern, Editors, Heidelberg Colloquium 
on Glassy Dynamics, Lecture Notes in Physics 275, (Springer- 
Verlag, Heidelberg, 1987). 
20) P.Erdos, A.Renyi, Pub. Math. Inst. Hung.Acad. Sci., ,17, (1960). 
21) I.Morgenstern in Ref.19, pg.399;H.Sompolinski in Ref.19, pg.485. 
22) J. Guckenheimer, P.Holmes, Nonlinear Oscillations,Dynamical 
Systems and Bifurcations of Vector Fields (Springer, N.Y.1983). 
", attract neural network marcu westervelt appli scienc depart physic studi basin attract fix point attractor electron analog neural basin circuitri period open network feedback initi condit examin result plot basin fix point show overload associ memori network lead irregular network also includ analog time delay shown delay symmetr network introduc oscillatori condit lead oscil relat presenc reduc frustrat connect stabil delay introduct dynam system form interconnect network element perform use parallel recent progress control dynam algorithm encod locat fix point stabil flow fix point equal aspect dynam basin describ locat point initi space flow particular attractor use associ initi state lead requir suggest basin attract evenli surround attractor smooth regular one dimension basin map probabl ham distanc reveal shape basin high space initi state numer studi hopfield network discret time neuron show irregular basin shape two dimension ham high dimension basin complic known basin shape chang network connect investig basin attract network state dynam build electron neural network eight variabl gain sigmoid neuron three level also built circuitri map basin attract two dimension slice initi space network basin measur section institut physic section show network oper well memori retriev four memori fix without develop spuriou storag three basin shape becom section consid effect time real network can not switch infinit fast propag signal delay intrins part hardwar neural includ control coupl analog time delay neuron time delay affect dynam neural find network symmetr interconnect guarante converg fix point show sustain oscil time delay configur maxim unstabl look configur appear abl show dilut interconnect one reduc elimin oscil neural time network basin measur block diagram network basin measur circuit amplifi delay switch block diagram network measur main feedback loop consist amplifi see capacit input resistor matrix interconnect strength basin input capacit give constant charg coupl devic analog time built provid adjust delay per rang electron gain provid feedback nonlinear sever valu switch allow feedback path period neuron input charg initi reconnect settl attractor associ set initi two initi voltag scan time scale long compar function gener also connect axe storag beam scope network settl desir imag basin attractor slice initi condit one fix point oscillatori simpl exampl techniqu case three neuron symmetr connect shown htrl basin attract three slice plane voltag neuron two fix point neuron satur data photograph vl scope basin fix point associ memori dimension slice eight dimension initi condit full reveal import qualit featur high dimension show typic slice network program three memori accord clip hebb tii memori vector number memori chosen orthogon slice initi condit space show basin five six fix point three memori hopfield learn rule clip hebb neuron gain hebb rule make stabl network six fix point basin five attractor produc differ raster pattern make sever featur initi condit lead one memori spuriou attractor seen three four interest light well document spuriou attractor larger network time basin smooth continu shape basin seen slice slice attractor corner one basin quadrant slice line divid quadrant determin initi neuron three memori actual basin resembl ideal time frustrat sustain oscil defin condit guarante converg point construct gener assum instantan commun element hardwar assumpt break due finit switch speed charg time long interconnect ratio import keep ratio small limit fast neural network chip time delay also relev biolog neural propag respons time particular interest section time delay sustain oscil network known therefor restrict attent network symmetr interconnect matric obviou ingredi produc oscil delay state anoth graph repres network must contain simplest oscillatori structur made delay element oscil though symmetr oscil illustr import ring neg feedback dc product around loop posit dc product connect lead variou symmetr configur find neg product around loop also necessari condit sustain symmetr import differ ring symmetr loop period oscil ring total accumul delay around larger ring longer symmetr configur oscillatori oscil roughli twice regardless configur valu indic symmetr configur import feedback path around ring delay neuron ic connect ring neg feedback dc connect oscillatori fix attractor neuron loop connect product import theori spin glass configur call frustrat magnet give measur bond disord can not remov lead spin glass result base similar spin glass neural network shown storag capac limit understood term bond restat find stabl oscillatori mode symmetr delay similar result network tji delay set basin measur system plot attract oscillatori show slice oscillatori basin frustrat triangl delay vi vi basin oscillatori attractor frustrat triangl connect symmetr frustrat configur two one delay inset show trajectori fix oscillatori mode two initi delay basin size fulli connect feedback associ network one contain memori frustrat increas memori retriev point memori satur could caus oscillatori basin order design one must understand delay stabil first step determin delay network consid small prone see configur show describ need consid frustrat frustrat configur neuron spars dens neuron connect form call graph theori network invert connect sign graph carri defin frustrat cliqu fulli connect set vertic set three vertic cliqu form frustrat exampl frustrat loop cliqu shown notic neuron connect invert symmetr configur use frustrat exampl frustrat loop symmetr connect symmetr frustrat cliqu alltriangl frustrat graph vertic neuron undirect symmetr find delay neuron connect frustrat loop three neuron show sustain oscil delay delay delay connect frustrat cliqu basin attract sustain oscil well fix larger frustrat oscil follow given valu size oscillatori basin increas frustrat cliqu critic valu volum oscillatori basin goe zero increas critic delay less size basin oscillatori mode size per space initi voltag voltag near frustrat cliqu critic valu delay oscillatori mode reduc delay leav oscillatori plot unit time rin critic delay faster identifi frustrat cliqu maxim unstabl time delay ask mani cliqu size expect find larg set vertic fulli connect two type form differ frustrat show graph size frustrat cliqu everi triangl solid line dash line neg randomli connect result combin random graph theori give expect number cliqu size network size binomi coeffici defin frustrat connect defin probabl two neuron special case edg invert equal also result case show dramat reduct concentr configur dilut random case find neg connect concentr frustrat cliqu strongli posit expect requir see interconnect network specifi rule rather expect number differ compar number frustrat triangl larg interconnect matric expect number random matrix size hebb matrix construct accord concentr cliqu size unbias decreas network especi cliqu log zk cz tii number threshold function cutoff random string matrix construct roughli unbias number posit neg connect show ratio triangl dilut hebb matrix expect number random graph connect differ number store hebb valu matrix fewer frustrat triangl random matrix ratio decreas dilut matrix store fewer curv seem depend size result suggest dilut hebb matrix break even effici dilut random ratio number frustrat ratio triangl hebb rule matrix divid number random sign graph equal differ set point differ random memori hebb line connect guid sensit depend frustrat connect suggest oscillatori mode larg neural network delay dilut interconnect unbias random network delay frustrat cliqu size larger oscillatori basin valu frustrat smaller configur can not lead sustain oscil connect reduc concentr cliqu factor reduct would even greater clip spin glass theori suggest dilut clip matrix actual improv storag capac moder maximum capac connect extent treatment appli analog expect dilut oscillatori kill memori capac confirm stabil effect dilut fulli connect eight neuron network program orthogon memori accord ad delay larg basin sustain randomli dilut interconnect abl close basin recov use associ investig structur fix point oscillatori attract electron network eight control time delay three valu fix point find network perform associ memori spuriou attractor seen four store memori three basin attract becam network stabl delay basin attractor time delay symmetr time observ sustain oscil frustrat cliqu connect triangl prone larger frustrat easili number larg network greatli reduc dilut demonstr network larg oscillatori attractor stabil thank one us acknowledg support laboratori work support jsep contract physica neural network aip ie converg neural ie neural physica physica et keeler ccd analog reticon organ delay vlsi discuss introduct mo cmo vlsi system der der theori spin glass review refer van heidelberg colloquium glassi lectur note physic nonlinear bifurc vector field,2
56,56,"534 
The Performance of Convex Set Projection Based Neural Networks 
Robert J. Marks II, Les E. Atlas, Seho Oh and James A. Ritcey 
Interactive Systems Design Lab, FT-10 
University of Washington, Seattle, Wa 98195. 
ABSTRACT 
We donsider a class of neural networks whose performance can be 
analyzed and geometrically visualized in a signal space 
environment. Alternating projection neural networks (APNN's) 
perform by alternately projecting between two or more constraint 
sets. Criteria for desired and unique convergence are easily 
established. The network can be configured in either a homogeneous 
or layered form. The number of patterns that can be stored in the 
network is on the order of the number of input and hidden neurons. 
If the output neurons can take on only one of two states, then the 
trained layered APNN can be easily configured to converge in one 
iteration. More generally, convergence is at an exponential rate. 
Convergence can be improved by the use of sigmoid type 
nonlinearities, network relaxation and/or increasing the number of 
neurons in the hidden layer. The manner in which the network 
responds to data for which it was not specifically trained (i.e. 
how it generalizes) can be directly evaluated analytically. 
1. INTRODUCTION 
In this paper, we depart from the performance analysis 
techniques normally applied to neural networks. Instead, a signal 
space approach is used to gain new insights via ease of analysis 
and geometrical interpretation. Building on a foundation laid 
elsewhere 1-3 , we demonstrate that alternating projecting neural 
network's (APNN's) formulated from such a viewpoint can be 
configured in layered form or homogeneously. 
Significiantly, APNN's have advantages over other neural 
network architectures. For example, 
(a) APNN's perform by alternatingly projecting between two or more 
constraint sets. Criteria can be established for proper 
iterative convergence for both synchronous and asynchronous 
operation. This is in contrast to the more conventional 
technique of formulation of an energy metric for the neural 
networks, establishing a lower energy bound and showing that 
the energy reduces each iteration 4-7 Such procedures generally 
do not address the accuracy of the final solution. In order to 
assure that such networks arrive at the desired globally 
minimum energy, computationaly lengthly procedures such as 
simulated annealing are used s-l� For synchronous networks, 
steady state oscillation can occur between two states of the 
same energy ll 
(b) Homogeneous neural networks such as Hopfield's content 
addressable memory 4'12-4 do not scale well, i.e. the capacity 
@ American Institute of Physics 1988 
535 
of Hopfield's neural networks less than doubles when the number 
of neurons is doubled 15-6 Also, the capacity of previously 
proposed layered neural networks 17,18 is not well understood. 
The capacity of the layered APNN'S, on the other hand, is 
roughly equal to the number of input and hidden neurons 19 
(c) The speed of backward error propagation learning 17-1s can be 
painfully slow. Layered APNN's, on the other hand, can be 
trained on only one pass through the training data 2 . If the 
network memory does not saturate, new data can easily be 
learned without repeating previous data. Neither is the 
effectiveness of recall of previous data diminished. Unlike 
layered back propagation neural networks, the APNN recalls by 
iteration. Under certain important applications, however, the 
APNN will recall in one iteration. 
(d) The manner in which layered APNN's generalizes to data for 
which it was not trained can be analyzed straightforwardly. 
The outline of this paper is as follows. After establishing the 
dynamics of the APNN in the next section, sufficient criteria for 
proper convergence are given. The convergence dynamics of the APNN 
are explored. Wise use of nonlinearities, e.g. the sigmoidal type 
nonlinearities 2, improve the network's performance. Establishing a 
hidden layer of neurons whose states are a nonlinear function of 
the input neurons' states is shown to increase the network's 
capacity and the network's convergence rate as well. The manner in 
which the networks respond to data outside of the training set is 
also addressed. 
2. THE ALTERNATING PROJECTION NEURAL NETWORK 
In this section, we established the notation for the APNN. 
Nonlinear modificiations to the network made to impose certain 
performance attributes are considered later. 
Consider a set of N continuous level linearly independent 
library vectors (or patterns) of length L > N: { 3 n I 0nN }. We form 
the library matrix  = [31 I I.%13 N ] and the neural network 
interconnect matrix a T = F T F F T where the superscript T 
denotes transposition. We divide the L neurons into two sets: one 
in which the states are known and the remainder in which the states 
are unknown. This partition may change from application to 
application. Let Sk (M) be the state of the k th node at time M. If 
the k th node falls into the known catego, its state is clamped to 
the known value (i.e. Sk (M) = /k where f is some library vector). 
The states of the remaining floating neurons are equal to the sum 
of the inputs into the node. That is, s k (M) = ik, where 
L 
i k = Z tpk S (1) 
P =1 P 
a The interconnect matrix is better trained iteratively 2 . To include 
a new library vector 3, the interconnects are updated as 
T . T 
+ () / ( ) where 
536 
If all neurons change state simultaneously (i.e. sp = sp (M-l)), then 
the net is said to operate synchronously� If only one neuron changes 
state at a time, the network is operating asynchronously. 
Let P be the number of clamped neurons� We have proven 1 that the 
neural states converge strongly to the extrapolated library vector 
if the first P rows of  (denoted F_m) form a matrix of full column 
rank� That is, no column of F_m can be expressed as a linear 
combination of those remaining. By strong convergence b we mean 
lira II (M) -  [[ 0 where II [[Z   ' 
  X T X. 
M ) 
Lastly, note that subsumed in the criterion that F_m be full 
rank is the condition that the number of library vectors not exceed 
the number of known neural states (Pk N). Techniques to bypass this 
restriction by using hidden neurons are discussed in section 5. 
Partition Notation: Without loss of generality� we will assume 
that neurons 1 through P are clamped and the remaining neurons are 
floating. We adopt the vector partitioning notation 
where p is the P-tuple of the first P elements of ? and Q is a 
vector of the remaining Q=L-P. We can thus write� for example� F_m = 
[  I I...IN  ]. Using this partition notation� we can define 
the neural clamping operator by: 
Thus� the first P elements of  are clamped to P The remaining Q 
nodes ""float"" 
Partition notation for the interconnect matrix will also prove 
useful. Define 
where 2 is a P by P and 4 a Q by Q matrix. 
3. STEADY STATE CONVERGENCE PROOFS 
For purposes of later reference, we address convergence of the 
network for synchronous operation. Asynchronous operation is 
addressed in reference 2. For proper convergence, both cases 
require that F_m be full rank. For synchronous operation, the 
network iteration in (1) followed by clamping can be written as: 
s(M+l) =   s(M) (2) 
As is illustrated in 1-3 this operation can easily be visualized 
� 
in an L dimensional signal space� 
b The referenced convergence proofs prove strong convergence in an 
infinite dimensional Hilbert space. In a discrete finite 
dimensional space, both strong, and weak convergence imply 
uniform convergence 9'2�, i.e. s(M) ) as M--. 
537 
For a given partition with P clamped neurons, 
written in partitioned form as 
(2) can be 
=  (3) 
Q (M+I 3 4 iM 
The states of the P clamped neurons are not affected by their input 
sum. Thus, there is no contribution to the iteration by 1 and 2' 
We can equivalently write (3) as 
s Q (M+I) = T 3 P + T 4 s Q (M) (4) 
We show in that if F_m is full rank, then the spectral radius 
(magnitude of the maximum eigenvalue) of 4 is strictly less than 
one 19 It follows that the steady state solution of (4) is: 
= - T f 
-- --4 (5) 
where, since F_m is full rank, we have made use of our claim that 
s Q () = Q (6) 
4. CONVERGENCE DYNAMICS 
In this section, we explore different convergence dynamics of 
the APNN when F_m is full column rank. If the library matrix 
displays certain orthogonality characteristics, or if there is a 
single output (floating) neuron, convergence can be achieved in a 
single iteration. More generally, convergence is at an exponential 
rate. Two techniques are presented to improve convergence. The 
first is standard relaxation. Use of nonlinear convex constraint at 
each neuron is discussed elsewhere 2,19 
One Step Converqence: There are at least two important cases where 
the APNN converges other than uniformly in one iteration. Both 
require that the output be bipolar (�1). Convergence is in one 
step in the sense that 
Q 
7 0 = sign s (1) (7) 
where the vector operation sign takes the sign of each element of 
the vector on which it operates. 
CASE 1: If there is a single output neuron, then, from (4), (5) and 
(6), s�(1) = (1 - tLL ) /O Since the eigenvalue of the (scalar) 
matrix, 4 = tLL /ies between zero and one 19, we conclude that 1 - 
tLL> O. Thus, if is restricted to �1, (7) follows immediately. A 
technique to extend this result to an arbitrary number of output 
neurons in a layered network is discussed in section 7. 
CASE 2: For certain library matrices, the APNN can also display one 
step convergence. We showed that if the columns of  are orthogonal 
and the columns of F_m are also orthogonal, then one synchronous 
iteration results in floating states proportional to the steady 
538 
state values 19 Specifically, for the floating neurons, 
An important special case of (8) is when the elements of F are 
all +_1 and orthogonal. If each element were chosen by a 50-50 coin 
flip, for example, we would expect (in the statistical sense) that 
this would be the case. 
Exponential Convergence: More generally, the convergence rate of 
the APNN is exponential and is a function of the eigenstructure of 
-% < 
T Let {p I 1 r< Q } denote the eigenvectors of T. and {X r } the 
--4 ' .r -- -- -% -% --9 -% 
corresponding eigenvalues. Define P = [ Pl I P2 I... I Po ] and the 
diagonal matrix A 4 such that diag  = [1 2 . . .n ] T .Then we can 
. T -- -% T- -- . T . 
wrmte T.=P A 4 P . Define x(M)=P s(M). Since P P = I, it follows from 
..... . ----r -- T-% T P 
the difference equation in (4) that x(M+I)=P T 4 P P s(M) + P T 
=_A 4 x(M) + g where g = P T 37- The solution to this difference 
equation is 
M 
= r = -- -- gk (9) 
r = 0 
Since the spectral radius of T_ is less than one 19 _}M- 0 as M-- 
--4 r 
oo. Our steady state result is thus x k (oo) = (1 - k)M+lg k . Equation 
(9) can therefore be written as x k (M) = [ 1 - k ] Xk (oo). The 
euivalent f a ""time constant"" in this exponential convergence is 
1/Zn(1/lk I � The speed of convergence is thus dictated by the 
spectral radius of T 4. As we have shown 19 later, adding neurons in 
a hidden layer in an APNN can significiantly reduce this spectral 
radius and thus improve the convergence rate. 
Relaxation: Both the projection and clamping operations can be 
relaxed to alter the network's convergence without affecting its 
steady state 2�-21 For the interconnects, we choose an appropriate 
value of the relaxation parameter 8 in the interval (0,2) and 
o 
redefine the interconnect matrix as  = 0 + (1 - 0) or 
equivalently, 
O <0(tnn - 1)+ 1 ; n=m 
tnm = 
0 tnm ; n  m 
To see the effect of such relaxation on convergence, we need 
simply examine the resulting eigenvalues. If 4 has eigenvalues 
o 0 
{r}, then 4 has eigenvalues X r  1 + 0(X r - 1). A wise choice of 0 
reduces the spectral radius of 4 with respect to that of 4' and 
thus decreases the time constant of the network's convergence. 
Any of the operators projecting onto convex sets can be relaxed 
without affecting steady state convergence 9-2� These include the 
 operator 2 and the sigmoid-type neural operator that projects onto 
a box. Choice of stationary relaxation parameters without numerical 
and/or empirical study of each specific case, however, generally 
remains more of an art than a science. 
539 
5 . LAYERED APNN ' S 
The networks thus far considered are homogeneous in the sense 
that any neuron can be clamped or floating. If the partition is 
such that the same set of neurons always provides the network 
stimulus and the remainder respond, then the networks can be 
simplified. Clamped neurons, for example, ignore the states of the 
other neurons. The corresponding interconnects can then be deleted 
from the neural network architecture. When the neurons are so 
partitioned, we will refer the APNN as layered. 
In this section, we explore various aspects of the layered APNN 
and in particular, the use of a so called hidden layer of neurons 
to increase the storage capacity of the network. An alternate 
architecture for a homogeneous APNN that require only Q neurons has 
been reported by Marks 2 . 
Hidden Layers: In its generic form, the APNN cannot perform a 
simple exclusive or (XOR). Indeed, failure to perform this same 
operation was a nail in the coffin of the perceptron 22 Rumelhart 
et. al. 7-18 revived the perceptron by adding additional layers of 
neurons. Although doing so allowed nonlinear discrimination, the 
iterative training of such networks can be painfully slow. With the 
addition of a hidden layer, the APNN likewise generalizes. In 
contrast, the APNN can be trained by looking at each data vector 
only once 1 . 
Although neural networks will not likely be used for performing 
XOR's, their use in explaining the role of hidden neurons is quite 
instructive. The library matrix for the XOR is 
o o 
0 1 1 0 
The first two rows of F do not form a matrix of full column rank. 
Our approach is to augment F_m with two more rows such that the 
resulting matrix is full rank. Most any nonlinear combination of 
the first two rows will in general increase the matrix rank. Such 
a procedure, for example, is used in -classifiers 23 Possible 
nonlinear operations include multiplication, a logical ""AND"" and 
running a weighted sum of the clamped neural states through a 
memoryless nonlinearity such as a sigmoid. This latter alteration 
is particularly well suited to neural architectures. 
To illustrate with the exclusive or (XOR), a new hidden neural 
state is set equal to the exponentiation of the sum of the first 
two rows. A second hidden neurons will be assigned a value equal to 
the cosine of the sum of the first two neural states multiplied by 
K/2. (The choice of nonlinearities here is arbitrary. ) The 
augmented library matrix is 
0 0 1 1 
0 1 0 1 
F+= 1 e e e 2 
1 0 0 -1 
0 1 1 0 
54O 
In either the training or look-up mode, the states of the hidden 
neurons are clamped indirectly as a result of clamping the input 
neurons. 
The playback architecture for this network is shown in Fig.1. 
The interconnect values for the dashed lines are unity. The remain- 
ing interconnects are from the projection matrix formed from +. 
Geometrical Interpretation : In lower dimensions, the effects of 
hidden neurons can be nicely illustrated geometrically. Consider 
the library matrix 
_F = 1 1/2 
Clearly F_ = [1/2 1] . Let the neurons in the hidden layer be 
determined by the nonlineariy x 2 where x denotes the elements in 
the first row of F. Then 
1/2 1 
1 1/2 
The corresponding geometry is shown in Fig.2 for x the input 
neuron, y the output and h the hidden neuron. The augmented library 
vectors are shown and a portion of the generated subspace is shown 
lightly shaded. The surface of h=x 2 resembles a cylindrical lens in 
three dimensions. Note that the linear variety corresponding to! = 
1/2 intersects the cylindrical lens and subspace only at 
Similarly, the x= 1 plane intersects the lens and subspace at 
Thus, in both cases, clamping the input corresponding to the first 
element of one of the two library vectors uniquely determines the 
library vector. 
Convergence Improvement: Use of additional neurons in the hidden 
layer will improve the convergence rate of the APNN 19 Specifically, 
the spectral radius of the T_ matrix is decreased as additional 
--4 
neurons are added. The dominant time constant controlling 
convergence is thus decreased. 
Capacity: Under the assumption that nonlinearities are chosen such 
that the augmented F_ matrix is of full rank, the number of vectors 
which can be stored in the layered APNN is equal to the sum of the 
number of neurons in the input and hidden layers. Note, then, that 
interconnects between the input and output neurons are not needed 
if there are a sufficiently large number of neurons in the hidden 
layer. 
6. GENERALIZATION 
We are assured that the APNN will converge to the desired 
result if a portion of a training vector is used to stimulate the 
network. What, however, will be the response if an initialization 
is used that is not in the training set or, in other words, how 
does the network generalize from the training set ? 
To illustrate generalization, we return to the XOR problem. Let 
s5 (M) denote the state of the output neuron at the M th (synchronous) 
541 
/ 
/ 
Figure 1. Illustration of a 
layered APNN for, performing 
an XOR. 
I.O 
0.5 
h=x 2 
I 
x 
Figure 2. A geometrical 
illustration of the use of an 
x 2 nonlinearity to determine 
the states of hidden neurons. 
Ioyer: 
input 
- hidden 
(1,1) 
Figure 3. Response of the 
elementary XOR APNN using an 
exponential and trignometric 
nonlinearity in the hidden 
layer. Note that, at the 
corners, the function is 
equal to the XOR of the 
coordinates. 1 
Figure 4. The generalization 
of the XOR networks formed by 
thresholding the function in 
Fig.3 at 3/4. Different 
hidden layer nonlinearities 
result in different 
generalizations. 
542 
iteration. If s! and S 2 denote the input clamped value, then 
s 5 (m+l) =t 15 sl + t25 s2 + t35 s3 + t45 s4 + t55 s5 (m) where s 3 =exp (s 1 +s 2 ) 
and s4=cos[(s 1 + s2)/2] To reach steady state, we let m tend to 
infinity and solve for s 5 (): 
1 K 
[tlsS 1 + t25s2 + t35exp(sl+S2) + t45c0s  (S1+S2)] 
S5 () - 1 - t55 (10) 
A plot of S5 () versus (sl,s 2) is shown in Figure 3. The 
plot goes through 1 and zero according to the XOR of the corner 
coordinates. Thresholding Figure 3 at 3/4 results in the 
generalization perspective plot shown in Figure 4. 
To analyze the network's generalization when there are more 
than one output neuron, we use (5) of which (10) is a special case. 
If conditions are such that there is one step convergence, then 
generalization plots of the type in Figure 4 can be computed from 
one network iteration using (7). 
7. NOTES 
(a) There clearly exists a great amount of freedom in the choice of 
the nonlinearities in the hidden layer. Their effect on the 
network performance is currently not well understood. One can 
envision, however, choosing nonlinearities to enhance some 
network attribute such as interconnect reduction, classification 
region shaping (generalization) or convergence acceleration. 
(b) There is a possibility that for a given set of hidden neuron 
nonlinearities, augmentation of the F_m matrix coincidentally 
will result in a matrix of deficent column rank, proper 
convergence is then not assured. It may also result in a poorly 
conditioned matrix, convergence will then be quite slow. A 
practical solution to these problems is to pad the hidden layer 
with additional neurons. As we have noted, this will improve 
the convergence rate. 
(c) We have shown in section 4 that if an APNN has a single 
bipolar output neuron, the network converges in one step in 
the sense of (7). Visualize a layered APNN with a single 
output neuron. If there are a sufficiently large number of 
neurons in the hidden layer, then the input layer does not 
need to be connected to the output layer. Consider a second 
neural network identical to the first in the input and hidden 
layers except the hidden to output interconnects are 
different. Since the two networks are different only in the 
output interconnects, the two networks can be combined into a 
singlee network with two output neurons. The interconnects 
from the hidden layer to the output neurons are identical to 
those used in the single output neurons architectures. The new 
network will also converge in one step. This process can 
clearly be extended to an arbitrary number of output neurons. 
REFERENCES 
R.J. Marks II, ""A Class of Continuous Level Associative Memory 
Neural Nets,"" Appl. Opt., vol.26, no.10, p.2005, 1987. 
543 
2. K.F. Cheung et. al., ""Neural Net Associative Memories Based on 
Convex Set Projections,"" Proc. IEEE 1st International Conf. on 
Neural Networks, San Diego, 1987. 
3. R.J. Marks IIet. al., ""A Class of Continuous Level Neural 
Nets,"" Proc. 14th Conqress of International Commission for 
Optics Conf., Quebec, Canada, 1987. 
4. J.J. Hopfield, ""Neural Networks and Physical Systems with 
Emergent Collective Computational Abilities,"" Proceedings 
Nat. Acad. of Sciences, USA, vol.79, p.2554, 1982. 
5. J.J. Hopfield et. al., ""Neural Computation of Decisions in 
Optimization Problem,"" Biol. Cyber., vol.52, p.141, 1985. 
6. 'D.W. Tank et. al., ""Simple Neurel Optimization Networks: an A/D 
Converter, Signal Decision Circuit and a Linear Programming 
Circuit,"" IEEE Trans. Cir. Sy$., vol. CAS-33, p.533, 1986. 
7. M. Takeda et. al, ""Neural Networks for Computation: Number 
Representation and Programming Complexity,"" Appl. Opt., vol. 
25, no. 18, p.3033, 1986. 
8. S. Geman et. al., ""Stochastic Relaxation, Gibb's Distributions, 
and the Bayesian Restoration of Images,"" IEEE Trans. Pattern 
Recog. & Machine Intelligence., vol. PAMI-6, p.721, 1984. 
9. S. Kirkpatrick et. al. ,""Optimization by Simulated Annealing,"" 
Science, vol. 220, no. 4598, p.671, 1983. 
10 D.H. Ackley et. al., ""A Learning Algorithm for Boltzmann 
Machines,"" Cognitive Science, vol. 9, p.147, 1985. 
11 K.F. Cheung et. al., ""Synchronous vs. Asynchronous Behaviour 
of Hopfield's CAM Neural Net,"" to appear in Applied Optics. 
12 R.P. Lippmann, ""An Introduction to Computing With Neural nets,"" 
IEEE ASSP Magazine, p.7, Apr 1987. 
13 N. Farhat et. al.., ""Optical Implementation of the Hopfield 
Model,"" Appl. Opt., vol. 24, pp.1469, 1985. 
14 L.E. Atlas, ""Auditory Coding in Higher Centers of the CNS,"" 
IEEE Eng. in Medicine and Biology Magazine, p.29, Jun 1987. 
15 Y.S. Abu-Mostafa et. al., ""Information Capacity of the Hopfield 
Model, ""IEEE Trans. Inf. Theory, vol. IT-31, p.461, 1985. 
16 R.J. McEliece et. al.,""The Capacity of the Hopfield Associative 
Memory, ""IEEE Trans. Inf. Theory (submitted), 1986. 
17 D.E. Rumelhart et. al., Parallel Distributed Processing, vol. I 
& II, Bradford Books, Cambridge, MA, 1986. 
18 D.E. Rumelhart et. al., ""Learning Representations by Back-Pro- 
pagation Errors,"" Nature. vol. 323, no. 6088, p.533, 1986. 
19 R.J. Marks II et. al.,""Alternating Projection Neural Networks,"" 
ISDL report %11587, Nov. 1987 (Submitted for publication). 
20 D.C. Youla et. al, ""Image Restoration by the Method of Convex 
Projections: Part I-Theory,"" IEEE Trans. Med. Imaging, vol. 
MI-1, p.81, 1982. 
21. M.I. Sezan and H. Stark. ""Image Restoration by the Method of 
Convex Projections: Part II-Applications and Numerical Results,"" 
IEEE Trans. Med. Imaging, vol. MI-1, p.95, 1985. 
22. M. Minsky et. al., Percepttons, MIT Press, Cambridge, MA, 1969. 
23. J. Sklansky et. al., Pattern Classifiers and Trainable 
Machines, Springer-Verlag, New York, 1981. 
", perform convex set project base neural network mark le seho oh jame ritcey system design wa donsid class neural network whose perform geometr visual signal space altern project neural network altern project two constraint criteria desir uniqu converg easili network configur either homogen layer number pattern store order number input hidden output neuron take one two layer apnn easili configur converg one converg exponenti improv use sigmoid type network relax increas number hidden manner network data specif train directli evalu introduct depart perform analysi normal appli neural signal approach use gain new insight via eas analysi geometr build foundat laid demonstr altern project neural formul viewpoint layer form advantag neural perform alternatingli project two criteria establish proper converg synchron asynchron contrast convent formul energi metric neural establish lower energi bound show energi reduc iter procedur gener address accuraci final order network arriv desir global computationali lengthli procedur anneal use synchron state oscil occur two state energi homogen neural network content memori scale capac american institut physic neural network less doubl number neuron doubl capac previous layer neural network well capac layer equal number input hidden neuron speed backward error propag learn layer one pass train data memori new data easili without repeat previou neither recal previou data unlik back propag neural apnn recal certain import recal one manner layer gener data train analyz outlin paper establish apnn next suffici criteria converg converg dynam apnn wise use sigmoid type improv establish layer neuron whose state nonlinear function input state shown increas converg rate manner network respond data outsid train set altern project neural network establish notat modifici network made impos certain attribut consid set continu level linearli independ vector length form librari matrix neural network matrix superscript divid neuron two one state known remaind state partit may chang applic let sk state th node time th node fall known state clamp known valu sk librari state remain float neuron equal sum input tpk interconnect matrix better train iter includ new librari vector interconnect updat neuron chang state simultan sp sp net said oper one neuron chang network oper number clamp proven state converg strongli extrapol librari vector first row form matrix full column column express linear strong converg mean ii ii note subsum criterion full condit number librari vector exceed number known neural state techniqu bypass use hidden neuron discuss section without loss assum neuron clamp remain neuron adopt vector partit notat first element remain thu use partit defin neural clamp oper first element clamp remain notat interconnect matrix also prove defin steadi state converg proof purpos later address converg synchron asynchron oper refer proper case full synchron iter follow clamp written illustr oper easili visual dimension signal referenc converg proof prove strong converg dimension hilbert discret finit weak converg impli converg given partit clamp partit form state clamp neuron affect input contribut iter equival write show full spectral radiu maximum strictli less follow steadi state solut sinc full made use claim converg dynam explor differ converg dynam apnn full column librari matrix certain orthogon output converg achiev converg exponenti two techniqu present improv standard use nonlinear convex constraint neuron discuss elsewher step least two import case apnn converg uniformli one output bipolar converg one sens sign vector oper sign take sign element vector singl output sinc eigenvalu zero one conclud restrict follow extend result arbitrari number output layer network discuss section certain librari apnn also display one show column orthogon column also one synchron result float state proport steadi valu float import special case element element chosen coin would expect statist would converg rate apnn exponenti function eigenstructur let denot eigenvector defin pl po matrix diag defin sinc follow differ equat solut differ gk spectral radiu less one steadi state result thu equat therefor written xk exponenti converg speed converg thu dictat radiu shown ad neuron hidden layer apnn significiantli reduc spectral thu improv converg project clamp oper alter converg without affect state choos appropri relax paramet interv interconnect matrix tnm see effect relax need examin result eigenvalu eigenvalu wise choic spectral radiu respect decreas time constant oper project onto convex set relax affect steadi state converg includ oper neural oper project onto choic stationari relax paramet without numer empir studi specif gener art layer apnn network thu far consid homogen sens neuron clamp partit set neuron alway provid network remaind network clamp ignor state correspond interconnect delet neural network neuron refer apnn explor variou aspect layer apnn use call hidden layer neuron increas storag capac altern homogen apnn requir neuron report mark gener apnn can not perform exclus failur perform nail coffin perceptron rumelhart reviv perceptron ad addit layer although allow nonlinear train network pain hidden apnn likewis apnn train look data vector neural network like use perform use explain role hidden neuron quit librari matrix xor first two row form matrix full column approach augment two row matrix full nonlinear combin first two row gener increas matrix use possibl oper includ logic weight sum clamp neural state nonlinear latter alter particularli well suit neural illustr exclus new hidden neural set equal exponenti sum first second hidden neuron assign valu equal cosin sum first two neural state multipli choic nonlinear librari matrix either train state hidden clamp indirectli result clamp input playback architectur network shown interconnect valu dash line interconnect project matrix form interpret lower effect neuron nice illustr consid librari matrix let neuron hidden layer nonlineariy denot element first row correspond geometri shown input output hidden augment librari shown portion gener subspac shown surfac resembl cylindr len note linear varieti correspond intersect cylindr len subspac plane intersect len subspac clamp input correspond first one two librari vector uniqu determin use addit neuron hidden improv converg rate apnn spectral radiu matrix decreas addit domin time constant control thu assumpt nonlinear chosen augment matrix full number vector store layer apnn equal sum neuron input hidden input output neuron need suffici larg number neuron hidden gener assur apnn converg desir portion train vector use stimul respons initi use train set network gener train set illustr return xor let denot state output neuron th illustr apnn perform geometr use nonlinear determin state hidden hidden respons xor apnn use trignometr hidden note function xor gener xor network form function differ layer nonlinear differ denot input clamp sl reach steadi let tend solv plot versu shown figur goe zero accord xor corner threshold figur result perspect plot shown figur analyz gener one output use special condit one step plot type figur comput network iter use note clearli exist great amount freedom choic nonlinear hidden effect perform current well one choos nonlinear enhanc attribut interconnect classif shape converg possibl given set hidden neuron augment matrix coincident result matrix defic column proper may also result poorli converg quit solut problem pad hidden layer addit improv converg shown section apnn singl output network converg one step sens visual layer apnn singl suffici larg number hidden input layer connect output consid second network ident first input hidden except hidden output interconnect sinc two network differ two network combin network two output interconnect hidden layer output neuron ident use singl output neuron new also converg one process extend arbitrari number output mark class continu level associ memori cheung net associ memori base set ie intern san mark class continu level neural conqress intern commiss network physic system collect comput proceed hopfield comput decis tank neurel optim signal decis circuit linear program ie takeda network number program geman bayesian restor ie pattern machin kirkpatrick simul ackley learn algorithm boltzmann cognit cheung asynchron behaviour cam neural appear appli introduct comput neural assp apr farhat implement hopfield code higher center medicin biolog jun capac hopfield eliec capac hopfield associ theori rumelhart parallel distribut bradford rumelhart represent mark ii project neural report youla restor method convex part ie sezan restor method part numer minski mit sklanski pattern classifi trainabl new,2
57,57,"544 
MURPHY: A Pobot that Learns by Doing 
Bartlett W. Mel 
Center for Complex Systems Research 
University of Illinois 
508 South Sixth Street 
Champaign, IL 61820 
January 2, 1988 
Abstract 
MURPHY consists of a camera looking at a robot arm, with a connectionist network 
architecture situated in between. By moving its arm through a small, representative 
sample of the 1 billion possible joint configurations, MURPHY learns the relationships, 
backwards and forwards, between the positions of its joints and the state of its visual field. 
MURPHY can use its internal model in the forward direction to ""envision"" sequences 
of actions for planning purposes, such as in grabbing a visually presented object, or in 
the reverse direction to 'qmitate"", with its arm, autonomous activity in its visual field. 
Furthermore, by taking explicit advantage of continuity in the mappings between visual 
space and joint space, MURPHY is able to learn non-linear mappings with only a single 
layer of modifiable weights. 
Background 
Current Focus Of Learning Research 
Most connectionist learning algorithms may be grouped into three general catagories, 
commonly referred to as supervised, unsupervised, and reinforcement learning. Supervised 
learning requires the explicit participation of an intelligent teacher, usually to provide the 
learning system with task-relevant input-output pairs (for two recent examples, see [1,2]). 
Unsupervised learning, exemplified by ""clustering"" algorithms, are generally concerned 
with detecting structure in a stream of input patterns [3,4,5,6,7]. In its final state, an 
unsupervised learning system will typically represent the discovered structure as a set of 
categories representing regions of the input space, or, more generally, as a mapping from 
the input space into a space of lower dimension that is somehow better suited to the task at 
hand. In reinforcement learning, a ""critic"" rewards or penalizes the learning system, until 
the system ultimately produces the correct output in response to a given input pattern 
[8]. 
It has seemed an inevitable tradeoff that systems needing to rapidly learn specific, 
behaviorally useful input-output mappings must necessarily do so under the auspices of 
an intelligent teacher with a ready supply of task-relevant training examples. This state of 
affairs has seemed somewhat paradoxical, since the processes of gerceptual and cognitive 
development in human infants, for example, do not depend on the moment by moment 
intervention of a teacher of any sort. 
Learning by Doing 
The current work has been focused on a fourth type of learning algorithm, i.e. learning-b.y- 
doing, an approach that has been very little studied from either a connectionist perspective 
American Institute of Physics 1988 
545 
or in the context of more traditional work in machine learning. In its basic form, the 
learning agent 
begins with a repertoire of actions and some form of perceptual input, 
exercises its repertoire of actions, learning to predict i) the detailed sensory conse- 
quences of its actions, and, in the other direction, it) its actions that are associated 
with incoming sensory patterns, and 
runs its internal model (in one or both directions) in a variety of behaviorally-relevant 
tasks, e.g. to ""envision"" sequences of actions for planning purposes, or to internally 
""imitate"", via its internal action representation, an autonomously generated pattern 
of perceptual activity. 
In comparison to standard supervised learning algorithms, the crucial property of 
learning-by-doing is that no intelligent teacher is needed to provide inpl-otpt pairs 
for learning. Laws of physics simply translate actions into their resulting percepts, both 
of which are represented internally. The learning agent need only notice and record this 
relationship for later use. In contrast to traditional unsupervised learning approaches, 
learning-by-doing allows the acquisition of specific, task-relevant mappings, such as the 
relationship between a simultaneously represented visual and joint state. Learning-by- 
doing differs as well from reinforcement paradigms in that it can operate in the absence of 
a critic, i.e. in situations where reward or penalty for a particular training instance may 
be inappropriate. 
Learning by doing may therefore by described as an ansapervised associative algorithm, 
capable of acquiring rich, task-relevant associations, but without an intelligent teacher or 
critic. 
Abridged History of the Approach 
The general concept of leaning by doing may be attributed at least to Piaget from the 
1940's (see [9] for review). Piaget, the founder of the ""constructivist"" school of cognitive 
development, argued that knowledge is not given to a child as a passive observer, but 
is rather discovered and constructed by the child, through active manipulation of the 
environment. A handful of workers in artificial intelligence have addressed the issue of 
learning-by-doing, though only in highly schematized, simulated domains, where actions 
and sensory states are represented as logical predicates [10,11,12,13]. 
Barto & Sutton [14] discuss learning-by-doing in the context of system identification 
and motor control. They demonstrated how a simple simulated automaton with two ac- 
tions and three sensory states can build a model of its environment through exploration, 
and subsequently use it to choose among behavioral alternatives. In a similar vein, Rumel- 
hart [15] has suggested this same approach could be used to learn the behavior of a robot 
arm or a set of speech articulators. Furthermore, the forward-going ""mental model"", once 
learned, could be used internally to train an inverse model using back-propagation. 
In previous work, this author [16] described a connectionist model (VIPS) that learned 
to perform 3-D visual transformations on simulated wire-frame objects. Since in complex 
sensory-motor environments it is not possible, in general, to learn a direct relationship 
between an outgoing command state and an incoming sensory state, VIPS was designed 
to predict changes in the state of its visual field as a function of its outgoing motor com- 
mand. VIPS could then use its generic knowledge of motor-driven visual transformations 
to ""mentally rotate"" objects through a series of steps. 
546 
Rednomp/c Value-Coded 
Visua/Repmmtafi(m $oim Repre. senmi(m 
Figure 1: MURPHY's Connectionist Architecture. 4096 coarsely-tuned visual 
units are organized in a square, retinotopic grid. These units are bi-directionlly 
interconnected with a population of 273 joint units. The joint population is subdi- 
vided into 3 subpopulations, each one a vaJue-coded representation of joint angle 
for one of the three joints. During training, activity in the joint unit population 
determines the physica arm configuration. 
Inside MURPY 
The current work has sought to further explore the process of learning-by-doing in a 
complex sensory-motor domain, extending previous work in three ways. First, the learning 
of mappings between sensory and command (e.g. motor) representations should be allowed 
to proceed in both directions simultaneousll during exploratory behavior, where each 
mapping may ultimately subserve a very different behavioral goal. Secondly, MURPHY 
has been implemented with a real camera and robot arm in order to insure representational 
realism to the greatest degree possible. Third, while the specifics of MURPHY's internal 
structures are not intended as a model of a specific neural system, a serious attempt has 
been made to adhere to architectural components and operations that have either been 
directly suggested by nervous system structures, or are at least compatible with what is 
currently known. Detailed biological justification on this point awaits further work. 
MURPHY's Body 
MURPHY consists of a 512 x 512 JVC color video camera pointed at a Rhino XR-3 robotic 
arm. Only the shoulder, elbow, and wrist joints are used, such that the arm can move 
only in the image plane of the camera. (A fourth, waist joint is not used). White spots are 
stuck to the arm in convenient places; when the image is thresholded, only the white spots 
appear in the image. This arrangement allows continuous control over the complexity of 
the visual image of the arm, which in turn affects time spent both in computing visual 
features and processing weights during learning. A Datacube image processing system is 
used for the thresholding operation and to ""blur"" the image in real time with a gaussian 
mask. The degree of blur is variable and can be used to control the degree of coarse-coding 
(i.e. receptive field overlap) in the camera-topic array of visual units. The arm is software 
controllable, with a stepper motor for each joint. Arm dynamics are not considered in this 
work. 
547 
MURPHY's Mind 
MURPHY is currently based on two interconnected populations of neuron-like units. The 
first is organized as a rectangular, visuotopically-mapped 64 x 64 grid of coarsely-tuned 
visual units that each responds when a visual feature (such as a white spot on the arm) 
falls into its receptive field (fig. 1). Coarse coding insures that a single visual feature will 
activate a small population of units whose receptive fields overlap the center of stimulation. 
The upper trace in figure 2 shows the unprocessed camera view, and the center trace depicts 
the resulting pattern of activation over the grid of visual units. 
The second population of 273 units consists of three subpopulations, representing the 
angles of each of the three joints. The angle of each joint is value-coded in a line of 
units dedicated to that joint (fig. 1). Each unit in the population is ""centered"" at a 
some joint angle, and is maximally activated when the joint is to be sent to that angle. 
Neighboring joint units within a joint subpopulation have overlapping ""projective fields"" 
and progressively increasing joint-angle centers. 
It may be noticed that both populations of units are coarsely tuned, that is, the units 
have overlapping receptive fields whose centers vary in an orderly fashion from unit to 
neighboring unit. This style of representation is extremely common in biological sensory 
systems [17,18,19], and has been attributed a number of representational advantages (e.g. 
fewer units needed to encode range of stimuli, increased immunity to noise and unit mal- 
function, and finer stimulus discriminations). A number of additional advantages of this 
type of encoding scheme are discussed in section , in relation to ease of learning, speed of 
learning, and efficacy of generalization. 
MURPHY's Education 
By moving its arm through a small, representative sample (approximately 4000) of the 
I billion possible joint configurations, MURPHY learns the relationships, backwards and 
forwards, between the positions of its joints and the state of its visual field. During train- 
ing, the physical environment to which MURPHY's visual and joint representations are 
wired enforces a particular mapping between the states of these two representations. The 
mapping comprises both the kinematics of the arm as well as the optical parameters and 
global geometry of the camera/imaging system. It is incrementally learned as each unit in 
population B comes to ""recognize"", through a process of weight modification, the states of 
population A in which it has been strongly activated. After sufficient training experience 
therefore, the state of population A is sufficient to generate a ""mental image"" on popula- 
tion B, that is, to predictively activate the units in B via the weighted interconnections 
developed during training. 
In its current configuration, MURPHY steps through its entire joint space in around 
i hour, developing a total of approximately 500,000 weights between the two populations. 
The Learning Rule 
Tradeoffs in Learning and Representation 
It is well known in the folklore of connectionist network design that a tradeoff exists 
between the choice of representation (i.e. the ""semantics"") at the single unit level and the 
consequent ease or difficulty of learning within that representational scheme. 
At one extreme, the single-unit representation might be completely decoded, calling for 
a separate unit for each possible input pattern. While this scheme requires a combinato- 
rially explosive number of units, and the system must ""see"" every possible input pattern 
during training, the actual weight modification rule is rendered very simple. At another 
extreme, the single unit representation might be chosen in a highly encoded fashion with 
complex interactions among input units. In this case, the activation of an output unit 
548 
may be a highly non-linear or discontinuous function of the input pattern, and must be 
learned and represented in multiple layers of weights. 
Research in connectionism has often focused on Boolean functions [20,21,1,22,23], typ- 
ified by the encoder problem [20], the shifter problem [21] and n-bit parity [22]. Since 
Boolean functions are in general discontinuous, such that two input patterns that are close 
in the sense of Hamming distance do not in general result in similar outputs, much effort 
has been directed toward the development of sophisticated, multilayer weight-modification 
rules (e.g. back-propagation) capable of learning arbitrary discontinuous functions. The 
complexity of such learning procedures has raised troubling questions of scaling behavior 
and biological plausibility. 
The assumption of continuity in the mappings to be learned, however, can act to 
significationly simplify the learning problem while still allowing for full generalization to 
novel input patterns. Thus, by relying on the continuity assumption, MURPHY's is able 
to learn continuous non-linear functions using a weight modification procedure that is 
simple, locally computable, and confined to a single layer of modifiable weights. 
How MURPHY learns 
For sake of concrete illustration, MURPHY's representation and learning scheme will be 
described in terms of the mapping learned from joint units to visual units during training. 
The output activity of a given visual unit may be described as a function over the 3- 
dimensional joint space, whose shape is determined by the kinematics of the arm, the 
location of visual features (i.e. white spots) on the arm, the global properties of the 
camera/imaging system, and the location of the visual unit's receptive field. In order for 
the function to be learned, a visual unit must learn to ""recognize"" the regions of joint 
space in which it has been visually activated during training. In effect, each visual unit 
learns to recognize the global arm configurations that happen to put a white spot in its 
receptive field. 
It may be recalled that MURPHY's joint unit population is value-coded by dimension, 
such that each unit is centered on a range of joint angles (overlapping with neighboring 
units) for one of the 3 joints. In this representation, a global arm configuration can 
be represented as the conjunctive activity of the k (where k = 3) most active joint units. 
MURPHY's visual units can therefore learn to recognize the regions of joint space in which 
they are strongly activated by simply 'Tnemorizing"" the relevant global joint configurations 
as conjunctive clusters of input connections from the value-coded joint unit population. 
To realize this conjunctive learning scheme, MURPHY's uses sigma-pt units (see [24]), 
as described below. At training step S, the set of k most active joint units are first 
identified. Some subset of visual units is also strongly activated in state S, each one 
signalling the presence of a visual feature (such as a white spot) in its receptive fields. 
At the input to each active visual unit, connections from the k most highly active joint 
units are formed as a multiplicative k-tuple of synaptic weights. The weights wi on these 
connections are initially chosen to be of unit strength. The output cj of a given synaptic 
conjunction is computed by multiplying the k joint unit activation values xl together with 
their weights: 
Cj -- --I Wi2i. 
i 
The output y of the entire unit is computed as a weighted sum of the outputs of each 
conjunction and then applying a sigmoidal nonlinearity: 
Sigma-pt units of this kind may be thought of as a generalization of a logical disjunction of 
conjunctions (OR of AND's). The multiplicative nature of the conjunctive clusters insures 
549 
that every input to the conjunct is active in order for the conjunct to have an effect on 
the unit as a whole. If only a single input to a conjunct is inactive, the effect of the 
conjunction is nullified. 
Specific-Instance Learning in Continuous Domains 
MURPHY's learning scheme is directly reminiscent of specific-instance learning as dis- 
cussed by Hampson & Volper [23] in their excellent review of Boolean learning and repre- 
senrational schemes. Specific-instance learning requires that each unit simply 'nemorize"" 
all relevant input states, i.e. those states in which the unit is intended to fire. Unfor- 
tunately, simple specific-instance learning allows for no generalization to novel inputs, 
implying that each desired system responses will have to have been explicitly seen dur- 
ing training. Such a state of affairs is clearly impractical in natural learning contexts. 
Hampson & Volper [23] have further shown that random Boolean functions will require 
an exponential number of weights in this scheme. 
For continous functions on the other hand, two kinds of generalization are possible 
within this type of specific-instance learning scheme. We consider each in turn, once again 
from the perspective of MURPHY's visual units learning to recognize the regions in joint 
space in which they are activated. 
Generalization by Coarse-Coding 
When a visual unit is activated in a given joint configuration, and acquires an appropriate 
conjunct of weights from the set of highly active units in the joint population, by conti- 
nuity the unit may assume that it should be at least partially activated in nearby joint 
configurations as well. Since MURPHY's joint units are coarse-coded in joint angle, this 
will happen automatically: as the joints are moved a small distance away from the specific 
training configuration, the output of the conjunct encoding that training configuration 
will decay smoothly from its maximum. Thus, a visual unit can ""fire"" predictively in joint 
configurations that it has never specifically seen during training, by interpolating among 
conjuncts that encode nearby joint configurations. 
This scheme suggests that training must be sufficiently dense in joint space to have 
seen configurations 'Rearby"" to all points in the space by some criterion. In practice, the 
training step size is related to the degree of coarse-coding in the joint population, which is 
chosen in turn such that a joint pertubation equal to the radius of a joint unit's projective 
field (i.e. the range of joint angles over which the unit is active) should on average push 
a feature in the visual field a distance of about one visual receptive field radius. As a rule 
of thumb, the visual receptive field radius is chosen small enough so as to contain only a 
single feature on average. 
Generalization by Extrapolation 
The second type of generalization is based on a heuristic principle, again illustrated in 
terms of learning in the visual population. If a visual unit has during training been 
very often activated over a large, easy-to-specify region of joint space, such as a hyper- 
rectangular region, then it may be assumed that the unit is activated over the entire region 
of joint space, i.e. even at points not yet seen. At the synaptic level, ""large regions"" can be 
represented as conjuncts with fewer terms. In its simplest form, this kind of generalization 
amounts to simply throwing out one or more joints as irrelevant to the activation of a 
given visual unit. What synaptic mechanism can achieve this effect? Competition among 
joint unit afferents can be used to drive irrelevant variables from the sigma-pi conjuncts. 
Thus, if a visual unit is activated repeatedly during training, and the elbow and shoulder 
angle units are constantly active while the most active wrist unit varies from step to step, 
then the weighted connections from the repeatedly activated elbow and shoulder units 
55O 
Figure 2: Three Visual Traces. The top trace shows the unprocessed camera view 
of MURPHY's arm. White spots have been stuck to the arm at various places, such 
that a thresholded image contains only the white spots. This aJlows continuous 
control over the visual complexity of the image. The center trace represents the 
resulting pattern of activation over the 64 x 64 grid of coarsely-tuned visual units. 
The bottom trace depicts an internally-produced ""mental"" image of the arm in the 
same configuration as driven by weighted connections from the joint population. 
Note that the ""mentaJ"" trace is a sloppy, but highly recognizable approximation 
to the camera-driven trace. 
will become progressively and mutually reinforced at the expense of the set of wrist unit 
connections, each of which was only activated a single time. 
This form of generalization is similar in function to a number of ""covering"" algorithms 
designed to discover optimal hyper-rectangular decompositions (with possible overlap) of 
a set of points in a multi-dimensional space (e.g. [25,26]). The competitive feature has 
not yet been implemented explicitly at the synaptic level, rather, the full set of conjuncts 
acquired during training are currently collapsed en masse into a more compact set of con- 
juncts, according to the above heuristics. In a typical run, MURPHY is able to eliminate 
between 30% and 70% of its conjuncts in this way. 
What MURPHY Does 
Grabbing A Visually Presented Target 
Once MURPHY has learned to image its arm in an arbitrary joint configuration, it can 
use heuristic search to guide its arm ""mentally"" to a visually specified goal. Figure 3(a) 
depicts a hand trajectory from an initial position to the location of a visually presented 
target. Each step in the trajectory represents the position of the hand (large blob) at an 
intermediate joint configuration. MURPHY can visually evaluate the remaining distance 
to the goal at each position and use best-first search to reduce the distance. Once a 
complete trajectory has been found, MURPHY can move its arm to the goal in a single 
physical step, dispensing with all backtracking dead-ends, and other wasted operations (fig. 
3(b)). It would also be possible to use the inverse model, i.e. the map from a desired visual 
into an internal joint image, to send the arm directly to its final position. Unfortunately, 
MURPHY has no means in its current early state of development to generate a full-blown 
551 
l,qIY*5 4mta]. TraJ:tory 
Figure 3: Grabbing an Object. (a) Irregular trajectory represents sequence of 
""mental"" steps taken by MURPHY in attempting to ""grab"" a visually-presented 
target (shown in (b) as white cross). Mental image depicts MURPHY's arm in its 
final goM configuration, i.e. with hand on top of object. Coarse-coded joint activity 
is shown at right. (b) Having mentally searched and found the target through a 
series of steps, MURPHY moves its arm physically in a single step to the target, 
discarding the intermediate states of the trajectory that are not relevant in this 
simple problem. 
visual image of its arm in one of the final goal positions, of which there are many possible. 
Sending the tip of a robot arm to a given point in space is a classic task in robotics. 
The traditional approach involves first writing explicit kinematic equations for the arm 
based on the specific geometric details of the given arm. These equations take joint angles 
as inputs and produce manipulator coordinates as outputs. In general, however, it is 
most often useful to specify the coordinates of the manipulator tip (i.e. its desired final 
position), and compute the joint angles necessary to achieve this goal. This involves the 
solution of the kinematic equations to generate an inverse kinematic model. Deriving such 
expressions has been called ""the most difficult problem we will encounter"" in vision-based 
robotics [27]. For this reason, it is highly desirable for a mobile agent to learn a model 
of its sensory-motor environment from scratch, in a way that depends little or not at all 
on the specific parameters of the motor apparatus, the sensory apparatus, or their mutual 
interactions. It is interesting to note that in this reaching task, MURPHY appears from 
the outside to be driven by an inverse kinematic model of its arm, since its first official 
act after training is to reach directly for a visually-presented object. 
While it is clear that best-first search is a weak method whose utility is limited in com- 
plex problem solving domains, it may be speculated that given the ability to rapidly image 
arm configurations, combined with a set of simple visual heuristics and various mechanism 
for escaping local minima (e.g. send the arm home), a number of more interesting visual 
planning problems may be within MURPHY's grasp, such as grabbing an object in the 
presence of obstacles. Indeed, for problems that are either difficult to invert, or for which 
the goal state is not fully known a priori, the technique of iterating a forward-going model 
has a long history (e.g. Newton's Method). 
552 
Imitating Autonomous Arm Activity 
A particularly interesting feature of 'qearning-by-doing"" is that for every pair of unit 
populations present in the learning system, a mapping can be learned between them both 
backwards and forwards. Each such mapping may enable a unique and interesting kind of 
behavior. In MURPHY's case, we have seen that the mapping from a joint state to a visual 
image is useful for planning arm trajectories. The reverse mapping from a visual state to 
a joint image has an altogether different use, i.e. that of ""imitation"". Thus, if MURPHY's 
arm is moved passively, the model can be used to 'qollow"" the motion with an internal 
command (i.e. joint) trace. Or, ff a substitute arm is positioned in MURPHY's visual 
field, MURPHY can ""assume the position"", i.e. imitate the model arm configuration by 
mapping the afferent visual state into a joint image, and using the joint image to move the 
arm. As of this writing, the implementation of this behavior is still somewhat unreliable. 
Discussion and Future Work 
In short, this work has been concerned with learning-by-doing in the domain of vision- 
based robotics. A number of features differentiate MURPHY from most other learning 
systems, and from other approaches to vision-based robotics: 
No intelligent teacher is needed to provide input-ouput pairs. MURPHY learns by 
exercising its repertoire of actions and learning the relationship between these actions 
and the sensory images that result. 
Mappings between populations of units, regardless of modality, can be learned in 
both directions simultaneously during exploratory behavior. Each mapping learned 
can support a distinct class of behaviorally useful functions. 
� MURPHY uses its internal models to first solve problems ""mentally"". Plans can 
therefore be developed and refined before they are actually executed. 
By taking explicit advantage of continuity in the mappings between visual and joint 
spaces, and by using a variant of specific-instance learning in such a way as to allow 
generalization to novel inputs, MURHPY can learn ""difficult"" non-linear mappings 
with only a single layer of modifiable weights. 
Two future steps in this endeavor are as follows: 
Provide MURPHY with direction-selective visual and joint units both, so that it 
may learn to predict relationships between rates of change in the visual and joint 
domains. In this way, MURPHY can learn how to perturb its joints in order to send 
its hand in a particular direction, greatly reducing the current need to search for 
hand trajectories. 
Challenge MURPHY to grab actual objects, possibly in the presence of obstacles, 
where path of approach is crucial. The ability to readily envision intermediate arm 
configurations will become critical for such tasks. 
Acknowledgements 
Particular thanks are due to Stephen Omohundro for his unrelenting scientific and moral 
support, and for suggesting vision and robotic kinematics as ideal domains for experimen- 
tation. 
553 
References 
[1] T.J. Sejnowski & C.R. Rosenberg, Complex Systems, 1, 145, (1969). 
[2] G.J. Tesauro & T.J. Sejnowskl. A parallel network that learns to play backgammon. Submitted for 
publication. 
[3] S. Grossberg, Biol. Cybern., 3, 187, (1976). 
[4] T. Kohonen, Self organization and associative memory., (Springer-Verlag, Berlin 1984). 
[5] D.E. Rumelkart & D. Zlpser. In Parallel distrlbted processing: explorations in the mlcrostrctre 
of cognition, vol. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford: Cambridge, MA, 1986), p. 
151. 
[6] R. Linsker, Proc. Natl. Acad. Sci., 83, 8779, (1986). 
[7] G.E. Hinton & J.L. McClelland. Learning representations by recirculation. Oral presentation, IEEE 
conference on Neural Information Processing Systems, Denver, 1987. 
[8] A.G. Barto, R.S. Sutton, & C.W. Anderson, IEEE Trans. on Sys., Man, Cybern., smc-13, 834, (1983). 
[9] H. Ginsburg & S. Opper, Piaget's theory of intellectual development., (Prentice Hall, New Jersey, 
199). 
[10] J.D. Becker. In Computer models for thought and language., R. Schank & K.M. Colby, Eds., (Free- 
man, San Francisco, 1973). 
[11] R.L. RJvest & R.]. Schaplre. In Proc. of the 4th int. workshop on machine learning, 364-375, (1987). 
[12] J.G. Carbonell & Y. Gi1. In Proc. of the 4th int. workshop on machine learning, 256-266, (1987). 
[13] K. Chen, Tech Report, Dept. of Computer Sdence, University of Illinois, 1987. 
[14] A.G. Barto & R.S. Sutton, AFWAL-TR-81-1070, Avionics Laboratory, Air Force Wright Aeronautical 
Laboratories, Wright-Patterson AFB, Ohio 45433, 1981. 
[15] D.E. Rumelhart, ""On learning to do what you want"". Talk given at CMU Connectionist Summer 
School, 1986a. 
[16] B.W. Mel In Pmc. of 8th Ann. Conf. of the Cognitive Science Soc., 562-571, (1986). 
[17] D.H. B,!l,rd, G.E. Hinton, & T.J Sejnowskl, Nature, 306, 21, (1983). 
[18] R.P. Erikson, American Scientist, May-June 1984, p. 233. 
[19] G.E. Hinton, J.L. McClelland, & D.E. Rumelhart. In Parallel distributed processing: explorations 
in the mlcrostr*cture of cognition, vol. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford, Cam- 
bridge, 1986), p. 77. 
[20] D.H. Acldey, G.E. Hinton, & T.J. Sejnowskl, Cognitive Science, 9, 147, (1985). 
[21] G.E. Hinton & T.J. Sejnowski. In Parallel dlstrlbted processing: explorations in the microstrctrc 
of cognition, vol. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford, Cambridge, 1986), p. 282. 
[22] G.J. Tesauro, Complex Systems, 1,367, (1987). 
[23] S.E. Hampson & D.J. Volper, Biological Cybernetics, 56, 121, (1987). 
[24] D.E. Rumelhart, G.E. Hinton, & J.L. McClelland. In Parallel distrlbted processing: explorations 
in the microstrcture of cognition, vol. 1, D.E. Rumelhart, J.L. McClelland, Eds., (Bradford, Cam- 
bridge, 1986), p. 3. 
[25] R.S. Michalski, J.G. Carbonell, & T.M. Mitchell, Eds., Machine learning: an artificial intelligence 
approach, Vols. I and II, (Morgan Kaufman, Los Altos, 1986). 
[26] S. Omohundro, Complex Systems, 1,273, (1987). 
[27] Paul, R. Robot manipalators: mathematics, programming, and control., (MIT Press, Cambridge, 
19Sl). 
", pobot learn mel complex system research illinoi south sixth street il consist camera look robot connectionist network situat move arm repres billion possibl joint murphi learn posit joint state visual use intern model forward direct sequenc action plan grab visual present revers direct autonom activ visual take explicit advantag continu map visual joint murphi abl learn map singl modifi focu learn research connectionist learn algorithm may group three gener refer reinforc supervis requir explicit particip intellig usual provid system pair two recent see exemplifi gener concern detect structur stream input pattern final learn system typic repres discov structur set repres region input map input space space lower dimens somehow better suit task reinforc reward penal learn system ultim produc correct output respons given input pattern seem inevit tradeoff system need rapidli learn use map must necessarili auspic intellig teacher readi suppli train state seem somewhat sinc process gerceptu cognit human depend moment moment teacher current work focus fourth type learn approach littl studi either connectionist perspect institut physic context tradit work machin basic agent repertoir action form perceptu repertoir learn predict detail sensori action associ incom sensori intern model one varieti sequenc action plan intern via intern action autonom gener pattern perceptu comparison standard supervis learn crucial properti intellig teacher need provid pair law physic simpli translat action result repres learn agent need notic record later contrast tradit unsupervis learn allow acquisit simultan repres visual joint differ well reinforc paradigm oper absenc situat reward penalti particular train instanc may may therefor describ ansapervis associ acquir without intellig teacher histori approach gener concept lean may attribut least piaget founder school cognit argu knowledg given child passiv rather discov construct activ manipul hand worker artifici intellig address issu though highli simul action sensori state repres logic predic sutton discuss context system identif motor demonstr simpl simul automaton two three sensori state build model environ subsequ use choos among behavior similar suggest approach could use learn behavior robot set speech could use intern train invers model use previou author describ connectionist model learn perform visual transform simul sinc complex environ learn direct relationship outgo command state incom sensori vip design predict chang state visual field function outgo motor vip could use gener knowledg visual transform object seri connectionist visual organ retinotop unit popul joint joint popul one represent joint angl one three activ joint unit popul arm murpi current work sought explor process extend previou work three learn map sensori command represent allow proceed direct exploratori may ultim subserv differ behavior murphi implement real camera robot arm order insur represent greatest degre specif intern intend model specif neural seriou attempt made adher architectur compon oper either suggest nervou system least compat detail biolog justif point await bodi consist jvc color video camera point rhino robot wrist joint arm move imag plane waist joint white spot arm conveni imag white spot arrang allow continu control complex visual imag turn affect time spent comput visual process weight datacub imag process system threshold oper imag real time gaussian degre blur variabl use control degre recept field array visual arm softwar stepper motor arm dynam consid mind current base two interconnect popul organ grid unit respond visual featur white spot recept field coars code insur singl visual featur small popul unit whose recept field overlap center upper trace figur show unprocess camera center trace depict result pattern activ grid visual second popul unit consist three repres three angl joint line dedic joint unit popul joint maxim activ joint sent joint unit within joint subpopul overlap progress increas may notic popul unit coars unit overlap recept field whose center vari orderli fashion unit style represent extrem common biolog sensori attribut number represent advantag unit need encod rang increas immun nois unit finer stimulu number addit advantag encod scheme discuss section relat eas speed efficaci educ move arm repres sampl billion possibl joint murphi learn backward posit joint state visual physic environ visual joint represent enforc particular map state two compris kinemat arm well optic paramet geometri increment learn unit come process weight state strongli suffici train experi state popul suffici gener predict activ unit via weight interconnect current murphi step entir joint space around develop total approxim weight two learn rule learn represent well known folklor connectionist network design tradeoff exist choic represent singl unit level eas difficulti learn within represent one represent might complet call separ unit possibl input scheme requir explos number system must everi possibl input pattern actual weight modif rule render anoth singl unit represent might chosen highli encod fashion interact among input activ output unit highli discontinu function input must repres multipl layer connection often focus boolean function encod problem shifter problem pariti sinc function gener two input pattern close sens ham distanc gener result similar much effort direct toward develop multilay capabl learn arbitrari discontinu learn procedur rais troubl question scale behavior biolog assumpt continu map act simplifi learn problem still allow full gener input reli continu abl learn continu function use weight modif procedur local confin singl layer modifi murphi learn sake concret represent learn scheme term map learn joint unit visual unit output activ given visual unit may describ function joint whose shape determin kinemat visual featur white global properti locat visual recept order function visual unit must learn region joint visual activ visual unit recogn global arm configur happen put white spot may recal joint unit popul unit center rang joint angl neighbor one global arm configur repres conjunct activ activ joint visual unit therefor learn recogn region joint space strongli activ simpli relev global joint configur conjunct cluster input connect joint unit realiz conjunct learn use unit describ train step set activ joint unit first subset visual unit also strongli activ state one presenc visual featur white recept input activ visual connect highli activ joint form multipl synapt weight wi initi chosen unit output cj given synapt comput multipli joint unit activ valu xl togeth output entir unit comput weight sum output appli sigmoid unit kind may thought gener logic disjunct multipl natur conjunct cluster insur everi input conjunct activ order conjunct effect unit singl input conjunct effect learn continu domain learn scheme directli reminisc learn hampson volper excel review boolean learn learn requir unit simpli relev input state unit intend simpl learn allow gener novel desir system respons explicitli seen state affair clearli impract natur learn volper shown random boolean function requir exponenti number weight contin function two kind gener possibl type learn consid perspect visual unit learn recogn region joint visual unit activ given joint acquir appropri weight set highli activ unit joint unit may assum least partial activ nearbi joint sinc joint unit joint happen joint move small distanc away specif output conjunct encod train configur decay smoothli visual unit predict joint never specif seen interpol among encod nearbi joint scheme suggest train must suffici dens joint space configur point space step size relat degre joint turn joint pertub equal radiu joint project rang joint angl unit averag push featur visual field distanc one visual recept field rule visual recept field radiu chosen small enough contain featur extrapol second type gener base heurist illustr learn visual visual unit train often activ region joint may assum unit activ entir region joint even point yet synapt conjunct fewer simplest kind gener simpli throw one joint irrelev activ visual synapt mechan achiev competit among unit affer use drive irrelev variabl visual unit activ repeatedli elbow shoulder unit constantli activ activ wrist unit vari step weight connect repeatedli activ elbow shoulder unit three visual top trace show unprocess camera view white spot stuck arm variou threshold imag contain white jlow continu visual complex center trace repres pattern activ grid visual bottom trace depict imag arm configur driven weight connect joint trace highli recogniz approxim becom progress mutual reinforc expens set wrist unit activ singl form gener similar function number algorithm discov optim decomposit possibl set point space competit featur yet implement explicitli synapt full set conjunct train current collaps en mass compact set accord typic murphi abl elimin conjunct murphi visual present target murphi learn imag arm arbitrari joint heurist search guid arm visual specifi figur hand trajectori initi posit locat visual present step trajectori repres posit hand joint murphi visual evalu remain distanc goal posit use search reduc trajectori murphi move arm goal singl dispens backtrack wast oper would also possibl use invers map desir visual intern joint send arm directli final mean current earli state develop gener grab irregular trajectori repres sequenc step taken murphi attempt white mental imag depict arm hand top joint activ shown mental search found target murphi move arm physic singl step intermedi state trajectori relev imag arm one final goal mani tip robot arm given point space classic task tradit approach involv first write explicit kinemat equat arm specif geometr detail given equat take joint angl input produc manipul coordin often use specifi coordin manipul tip desir final comput joint angl necessari achiev involv kinemat equat gener invers kinemat deriv call difficult problem highli desir mobil agent learn model environ way depend littl specif paramet motor sensori mutual interest note reach murphi appear outsid driven invers kinemat model sinc first offici train reach directli clear search weak method whose util limit problem solv may specul given abil rapidli imag combin set simpl visual heurist variou mechan escap local minima send arm number interest visual problem may within grab object problem either difficult goal state fulli known techniqu iter model long histori autonom arm activ particularli interest featur everi pair unit present learn map learn map may enabl uniqu interest kind seen map joint state visual use plan arm revers map visual state joint imag altogeth differ move model use motion intern ff substitut arm posit visual murphi imit model arm configur affer visual state joint use joint imag move implement behavior still somewhat futur work work concern domain number featur differenti murphi learn approach intellig teacher need provid murphi learn repertoir action learn relationship action sensori imag popul regardless learn direct simultan exploratori map learn support distinct class behavior use murphi use intern model first solv problem plan develop refin actual take explicit advantag continu map visual joint use variant learn way allow novel murhpi learn map singl layer modifi futur step endeavor murphi visual joint unit learn predict relationship rate chang visual joint murphi learn perturb joint order send hand particular greatli reduc current need search murphi grab actual possibl presenc path approach abil readili envis intermedi arm becom critic thank due stephen omohundro unrel scientif moral suggest vision robot kinemat ideal domain sejnowski complex tesauro parallel network learn play submit self organ associ berlin rumelkart parallel explor hinton learn represent oral ie neural inform process ie ginsburg theori intellectu new comput model thought schank san rjvest workshop machin carbonel workshop machin tech comput univers barto avion air forc wright aeronaut ohio learn talk given cmu connectionist summer mel cognit scienc american parallel distribut explor cognit hinton parallel explor complex hampson biolog parallel explor machin artifici intellig lo complex robot,0
58,58,"554 
STABILITY RESULTS FOR NEURAL NETWORKS 
A. N. Michel  , J. A. Farrell  , and W. Porod 2 
Department of Electrical and Computer Engineering 
University of Notre Dame 
Notre Dame, IN 46556 
ABSTRACT 
In the present paper we survey mad utilize results from the qualitative theory of large 
scale interconnected dynamical systems in order to develop a qualitative theory for the 
Hop field model of neural networks. In our approach we view such networks as an inter- 
connection of many single neurons. Our results are phrased in terms of the qualitative 
properties of the individual neurons and in terms of the properties of the interconnecting 
structure of the neural networks. Aspects of neural networks which we address include 
asymptotic stability, exponential stability, and instability of an equilibrium; estimates 
of trajectory bounds; estimates of the domain of attraction of an asymptotically stable 
equilibrium; and stability of neural networks under structural perturbations. 
INTRODUCTION 
In recent years, neural networks have attracted considerable attention as candidates 
for novel computational systems -3. These types of large-scale dynamical systems, in 
analogy to biological structures, take advantage of distributed information processing 
and their inherent potential for parallel computation 4,5. Clearly, the design of such 
neural-network-based computational systems entails a detailed understanding of the 
dynamics of large-scale dynamical systems. In particular, the stability and instability 
properties of the various equilibrium points in such networks are of interest, as well 
as the extent of associated domains of attraction (basins of attraction) and trajectory 
bounds. 
In the present paper, we apply and survey results from the qualitative theory of large 
scale interconnected dynamical systems 6-9 in order to develop a qualitative theory for 
neural networks. We will concentrate here on the popular Hopfield model 3, however, 
this type of analysis may also be applied to other models. In particular, we will address 
the following problems: (i) determine the stability properties of a given equilibrium 
point; (ii) given that a specific equilibrium point of a neural network is asymptotically 
stable, establish an estimate for its domain of attraction; (iii) given a set of initial condi- 
tions and external inputs, establish estimates for corresponding trajectory bounds; (iv) 
give conditions for the instability of a given equilibrium point; (v) investigate stability 
properties under structural perturbations. The present paper contains local results. A 
more detailed treatment of local stability results can be found in Ref. 10, whereas global 
results are contained in Ref. 11. 
In arriving at the results of the present paper, we make use of the method of anal- 
ysis advanced in Ref. 6. Specifically, we view high dimensional neural network as an 
XThe work of A. N. Michel and J. A. Farrell was supported by NSF under grant ECS84-19918. 
2The work of W. Porod was supported by ONR under grant N00014-86-K-0506. 
American Institute of Physics 1988 
555 
interconnection of individual subsystems (neurons). This interconnected systems view- 
point makes our results distinct from others derived in the literature L2. Our results 
are phrased in terms of the qualitative properties of the free subsystems (individual 
neurons, disconnected from the network) and in terms of the properties of the intercon- 
necting structure of the neural network. As such, these results may constitute useful 
design tools. This approach makes possible the systematic analysis of high dimensional 
complex systems and it frequently enables one to circumvent difficulties encountered in 
the analysis of such systems by conventional methods. 
The structure of this paper is as follows. We start out by defining the Hop field 
model and we then introduce the interconnected systems viewpoint. We then present 
representative stability results, including estimates of trajectory bounds and of domains 
of attraction, results for instability, and conditions for stability under structural pertur- 
bations. Finally, we present concluding remarks. 
THE HOPFIELD MODEL FOR NEURAL NETWORKS 
In the present paper we consider neural networks of the Hopfield type 3. Such systems 
can be represented by equations of the form 
N 
= '--biu + &j Cj(uj) + lot i = ,:v, 
j=l 
where A,j T Ui(t) = (t) and bi =  As usual, Ci > O,Tij = 
= c,, c c,' Pdj ' RijeR = 
__1 ._ 1 
(-oc, oc),r,  + Z= Ijl, Ri > O,Ii : R + = [0,)  R,Ii is continuous, 
ai =  Gi : R  (-1, 1),Gi is continuously differentiable and strictly monotoni- 
dt  
t 
cMly increasing (i.e., Ci(uti) > Ci(uti t) if and only if u i > utf),uiCi(ui) > 0 for all ui  0, 
and Gi(O) = 0. In (1), Ci denotes capacitance, R 0 denotes resistance (possibly includ- 
ing a sign inversion due to an inverter), Gi(.) denotes an amplifier nonlinearity, and 
denotes an externM input. 
In the terature it is frequently assumed that Tij = Tji for M1 i,j = 1,... ,N and 
that i = 0 for M1 i = 1,..., N. We will me these sumptions only when explicitly 
stated. 
We are interested in the quMitative behavior of solutions of (1) near equibrium 
points (rest positions where ai  O, for i = 1,..., N). By setting the extemM inputs 
Ui(t), i = 1,... ,N, equM to zero, we define u* = [u,... ,u]TeR N to be an equilibrium 
* N 
for (1) provided that -biu i + j= Aij Gj(u) = O, for i = 1,...,N. The locations 
of such equibria in R N are determined by the interconnection pattern of the neural 
network (i.e., by the pameters Aij, i,j = 1,..., N)  well as by the parameters bi and 
the nature of the nonlinearities Gi('), i = 1,..., N. 
Throughout, we will sume that a given equibrium u* being anMyzed is an isolated 
equilibrium for (1), i.e., there ests an r > 0 such that in the neighborhood B(u*, r) = 
{(u - u*)eR N '1 u - u* I < r} no equilibrium for (1), other than u = u*, effists. 
When analyzing the stability properties of a given equilibrium point, we will be able 
to assume, without loss of generMity, that this equibrium is located at the origin u = 0 
of R N. If this is not the ce, a triviM trsformation can be employed which shifts the 
equilibrium point to the origin and which leaves the structure of (1) the same. 
556 
INTERCONNECTED SYSTEMS VIEWPOINT 
We will find it convenient to view system (1) as an interconnection of N free sub- 
systems (or isolated subsystems) described by equations of the form 
Pi = -bipi + Zii Gi(pi) + Ui(t). (2) 
Under this viewpoint, the interconnecting structure of the system (1) is given by 
N 
i#j 
AijGj(xj), i= 1,...,N. (3) 
Following the method of analysis advanced in 6, we will establish stability results 
which are phrased in terms of the quMitative properties of the free subsystems (2) and 
in terms of the properties of the interconnecting structure given in (3). This method 
of aaalysis makes it often possible to circumvent difficulties that arise in the analysis 
of complex high-dimensional systems. Furthermore, results obtained in this manner 
frequently yield insight into the dynamic behavior of systems in terms of system com- 
ponents and interconnections. 
GENERAL STABILITY CONDITIONS 
We demonstrate below an example of a result for exponential stability of an equi- 
librium point. The principal Lyapunov stability results for such systems are presented, 
e.g., in Chapter 5 of Ref. 7. 
We will utilize the following hypotheses in our first result. 
(A-l) For system (1), the external inputs are all zero, i.e., 
(A-2) 
Ui(t) = O, i=l,...,N. 
For system (1), the interconnections satisfy the estimate 
xiAij Gj(xj) < xi aijxj 
for all ]xi[ < ri, [xj[ < rj, i,j = 1,...,N, where the aij are real constants. 
(A-a) There exists an N-vector a > 0 (i.e., a T = (a,...,aN) and a > 0, for all i: 
1,..., N) such that the test matrix S = [sj] 
{ ai(-bi +aii), i = j 
Sij = (oti aij + otj aji)/2, i  j 
is negative definite, where the bi are defined in (1) and the aij are given in (A-2). 
557 
We are now in a position to state and prove the following result. 
Theorem 1 The equilibrium x = 0 of the neural network (1) is exponentially stable 
if hypotheses (A-l), (A-2) and (A-3) are satisfied. 
Proof. For (1) we choose the Lyanpunov function 
v(x)= . i 2 
i=1 ""igi 
where the ai are given in (A-3). This function is clearly positive definite. 
derivative of v along the solutions of (1) is given by 
N i N 
Dvo)(x ) =  .i(2xi)[-bixi +  Aij 
i=1 j=l 
where (A-l) has been invoked. In view of (A-2) we have 
(4) 
The time 
Dv()(x) 
N N 
<_ + 
i--1 j=l 
= TRx for U 112 < r 
2 /2 
where r - min(r), I1 - E=  J , and the matrix R = [ro] is given by 
""i(-bi + aii), i = j 
rij -- ""i aij, i  j. 
But it follows that 
= - , � = xrs < A4(s) Il (5) 
where S is the matrix given in (A-3) and AM(S) denotes the largest eigenvalue of 
the real symmetric matrix S. Since S is by assumption negative definite, we have 
AM(S) < 0. It follows from (4) and (5) that in some neighborhood of the origin x = 0, 
we have c1122 < v() < c21xl22 and Dvo)(x ) <_ -calxl, where c = -} mini-/ > 0, 
c2 = � maxi ""i > 0, and ca = --AM(S) > 0. Hence, the equilibrium x = 0 of the neural 
network (1) is exponentially stable (c.f. Theorem 9.10 in Ref. 7). 
Consistent with the philosophy of viewing the neural network (1) as an intercon- 
nection of N free subsystems (2), we think of the Lyapunov function (4) as consisting 
of a weighted sum of Lyapunov functions for eax:h free subsystem (2) (with Ui(t) -- 0). 
The weighting vector , > 0 provides flexibility to emphasize the relative importance 
of the qualitative properties of the various individual subsystems. Hypothesis (A - 2) 
provides a measure of interaction between the various subsystems (3). Furthermore, it 
is emphasized that Theorem 1 does not require that the parameters Aij in (1) form a 
symmetric matrix. 
558 
WEAK COUPLING CONDITIONS 
The test matrix S given in hypothesis (A - 3) has off-diagonal terms which may be 
positive or nonpositive. For the special case where the off-diagonal terms of the test 
matrix $ = [sij] are non-negative, equivalent stability results may be obtained which are 
much easier to apply than Theorem 1. Such results are called weak-coupling conditions 
in the literature 6,9. The conditions sij > 0 for all i  j may reflect properties of the 
system (1) or they may be the consequence of a majorization process. 
In the proof of the subsequent result, we will make use of some of the properties 
of M- matrices (see, for example, Chapter 2 in Ref. 6). In addition we will use the 
following assumptions. 
(A-4) For system (1), the nonlinearity Gi(xi) satisfies the sector condition 
O < eri _< Gi(xi) 5 ai:, for all ]xil < ri, i=l,...,N. 
xi 
(A-5) The successive principal minors of the N x N test matrix D = [dij] 
bi-Aii, i=j 
dij = hi2 
are all positive where, the bi and Aij are defined in (1) and eri2 is defined in (A-4). 
Theorem 2 The equilibrium x = 0 of the neural network (1) is asymptotically sta- 
ble if hypotheses (A-l), (A-d) and (A-5) are true. 
Proof. The proof proceeds � along lines similar to the one for Theorem 1, this time 
with the following Lyapunov function 
N 
v(x) = lxil. (6) 
i=1 
The above Lyapunov function again reflects the interconnected nature of the whole 
system. Note that this Lyapunov function may be viewed as a generalized Hamming 
distance of the state vector from the origin. 
ESTIMATES OF TRAJECTORY BOUNDS 
In general, one is not only interested in questions concerning the stability of an 
equilibrium of the system (1), but also in performance. One way of assessing the qual- 
itative properties of the neural system (1) is by investigating solution bounds near an 
equilibrium of interest. We present here such a result by assuming that the hypotheses 
of Theorem 2 are satisfied. 
In the following, we will not require that the external inputs Ui(t), i = 1,..., N be 
zero. However, we will need to make the additional assumptions enumerated below. 
559 
(A-6) Assume that there exist Ai > 0, for i = 1,... ,N, and a e > 0 such that 
b'-'Li -Aii -  IAjil _ e > O, i=l,...,N 
(i2 
j=l 
i#j 
where bi ad Aij axe defined in (1) and ai2 is defined in (A-4). 
(A-7) Assume that for system (1), 
N 
for all t>0 
for some constant k > 0 where the Ai, i -- 1,..., N are defined in (A-6). 
In the proof of our next theorem, we will make use of a comparison result. We 
consider a scalar comparison equation of the form  = G(y) where yeR, G: B(r) - R 
for some r > 0, and G is continuous on B(r) = {xeR: Ixl < r}. We can then prove the 
following auxiliary theorem: Let p(t) denote the maximal solution of the comparison 
equation with p(to) = yoeB(r), t _ to > O. If r(t), t _ to _ 0 is a continuous 
function such that r(to) _ Yo, and if r(t) satisfies the differential inequality Dr(t) = 
limk_,0+ - sup[r(t + k) - r(t)] _ G(r(t)) almost everywhere, then r(t) _ p(t) for t _ 
to _ 0, for as long as both r(t) emd p(t) exist. For the proof of this result, as well as 
other comparison theorems, see e.g., Refs. 6 ad 7. 
For the next theorem, we adopt the following notation. We let 5 = mini ail 
where aix is defined in (A- 4), we let c = e5 , where e is given in (A-6), and 
we let 6(t,to, xo) = [ql(t, to,Xo),...,qN(t, to,xo)] T denote the solution of (1) with 
()(tO, tO, XO) = X 0 = (X10,... , XNO) T for some tO >_ O. 
We are now in a position to prove the following result, which provides bounds for 
the solution of (1). 
Theorem 3 Assume that hypotheses (A-6) and (A-7) are satisfied. Then 
N k 
II(t, to, xo)11   ili(t, t0, x0)l _ (- k)e-(-�) + 
i=1 C C 
t>_to>_O 
provided that  > k/c and IIx011 = E Alxi01 <_ , where the hi, i= 1,...,N are 
given in (A-6) and k is given in (A-7). 
Proof. For (1) we choose the Lyapunov function 
N 
(7) 
i=1 
560 
Along the solutions of (1), we obtain 
N 
Dvo)(x) < xrz>w + xilu(t)l (s) 
i=1 
where w T = [G'-lx[,... Gr(xr)lXN[ ] A = (A,.. AN) T, and D = [dii] is the test 
matrix ven in (A-5). Note that when (A-6) is satisfied, as in the present theorem 
then (A-5) s automaticM]y satisfied. Note Mso that w  0 (i.e., w{  0 { = 1... N) 
and w = 0 if d only if  = 0. 
Using manipulations ivolviug (A-6), (A- 7) and (8), it is ey to show that D(,) () S 
-c() + }. This inequMity yields now the comparison equatiou  = -cy + } whose 
uique solution is given by 
p(t, to,Po) = (Po-- 
e -c(t-t�) + -, for all t > to. 
If we let r - v, then we obtain from the comparison result 
N 
p(t) > r(t) = v(qb(t,to, xo)) = y] xilr)dt, to,xo)l = II(t, to,xo)l[, 
i.-ml 
i.e., the desired estimate is true, provided that I(to)[ = = I1oll _< a and 
a > k/c. 
ESTIMATES OF DOMAINS OF ATTRACTION 
Neural networks of the type considered herein have many equilibrium points. If 
a given equilibrium is asymptotically stable, or exponentially stable, then the extent 
of this stability is of interest. As usual, we assume that x = 0 is the equilibrium of 
interest. If qb(t, to, x0) denotes a solution of the network (1) with qb(t0, to, x0) = x0, then 
we would like to know for which points x0 it is true that qb(t, to, x0) tends to the origin 
as t - o. The set of all such points x0 makes up the domain of attraction (the basin of 
attraction) of the equilibrium x = 0. In general, one cannot determine such a domain 
in its entirety. However, several techniques have been devised to estimate subsets of 
a domain of attraction. We apply one such method to neural networks, making use 
of Theorem 1. This technique is applicable to our other results as well, by making 
appropriate modifications. 
We assume that the hypotheses (A-i), (A-2) and (A-3) are satisfied and for the free 
subsystem (2) we choose the Lyapunov function 
i 2 
vi(pd = (0) 
Then Dvi(2)(pi) _< (-bi + aii)p, Ipil < ri for some ri > 0. If (A-3) is satisfied, we 
must have (-bi +ail) < 0 and Dvi(2)(pi) is negative definite over B(ri). 
Let Cvo, = {pieR: vi(pi) = �p < �r = v0/}. Then Cvo, is contained in the domain 
of attraction of the equilibrium Pl = 0 for the free subsystem (2). 
To obtain an estimate for the domain of attraction of x = 0 for the whole neural 
network (1), we use the Lyapunov function 
561 
It is now an easy matter to show that the set 
(10) 
N 
i-'l 
will be a subset of the domain of attraction of x = 0 for the neural network (1), where 
 = min,(aivoi)= min air i . 
1<i<3/ l_<i_<N 
In order to obtain the best estimate of the domain of attraction of x = 0 by the 
present method, we must choose the ai in an optimal fashion. The reader is referred to 
the literature 9,3,4 where several methods to accomplish this are discussed. 
INSTABILITY RESULTS 
Some of the equilibrium points in a neural network may be unstable. We present 
here a sample instability theorem which may be viewed as a counterpart to Theorem 
2. Instabihty results, formulated as counterparts to other stability results of the type 
considered herein may be obtained by making appropriate modifications. 
(A-S) For system (1), the interconnections satisfy the estimates 
where i = cri when Aii< 0 and i = cri2 when Aii > 0 for all Ixi] < ri, and for 
all I;rl < rj,i,j = 1,...,N. 
(A-9) The successive principal minors of the N x N test matrix D = [dij] given by 
di = { cri' i = j 
-IAijl, i g j 
are positive, where cri = bi _Aii when ieF, (i.e., stable subsystems) and ai = 
_bl q_ Aii when iF (i.e., unstable subsystems) with F = F, U F and F = 
{1,...,N} and F, g qb. 
We are now in a position to prove the following result. 
Theorem 4 The equilibrium x = 0 of the neural network (1) is unstable/f hypotheses 
(A-l), (A-8) and (A-9) are satisfied. If in addition, F, = q5 (q5 denotes the empty set), 
then the equilibrium x = 0 is completely unstable. 
562 
Proof. We choose the Lyapunov function 
= i(-Iil) + ilxil (11) 
where ai > 0, i: 1,... ,N. Along the solutions of (1) we have (following the proof of 
Theorem 2), Dv0)(m )  -a Dw for  mB(r), r: min r where a 
D is defined in (A-9), nd w  [' ()lml] We conclude that 
= [ � 
Dv(x)(x) is negative definite over B(r). Since every neighborhood of the origin m = 0 
contns t let one point x  where v(x ) < 0, it follows that the equilibrium x = 0 for 
(1) is unstable. Moreover, when F,: , then the function v(x) is negative definite d 
the equilibrium x: 0 of (1) is in fct completely unstable (c.f. Chapter 5 in Ref. 7). 
STABILITY UNDER STRUCTURAL PERTURBATIONS 
In specific applications involving adaptive schemes for learning algorithms in neural 
networks, the interconnection patterns (and external inputs) are changed to yield an 
evolution of different sets of desired asymptotically stable equilibrium points with 
propriate domains of attraction. The present diagonal dominance conditions (see, e.g., 
hypothesis (A-6)) can be used as constraints to guarantee that the desired equilibria 
always have the desired stability properties. 
To be more specific, we assume that a given neural network has been designed with 
set of interconnections whose strengths can be varied from zero to some specified values. 
We express this by writing in place of (1), 
N 
ki = -bixi +  Oij Aij Gj(xj) + Ui(t), for i = 1,...,N, (12) 
j=l 
where 0 _ tij _ 1. We also assume that in the given neural network things have been 
arranged in such a manner that for some given desired value A > O, it is true that 
A - mini (_k_ _ iiAii). From what has been said previously, it should now be clear 
that if Ui(t) -- O, i = 1,... ,N and if the diagonal dominance conditions 
A--  [OijAijl >0, for i: 1,...,N (13) 
j=l 
i#j 
are satisfied for some Ai > 0, i = 1,... ,N, then the equilibrium z = 0 for (12) will be 
asymptotically stable. It is important to recognize that condition (13) constitutes a sin- 
gle stability condition for the neural network under structural perturbations. Thus, the 
strengths of interconnections of the neural network may be rearranged in any manner 
to achieve some desired set of equilibrium points. If (13) is satisfied, then these equi- 
libria will be asymptotically stable. (Stability under structural perturbations is nicely 
surveyed in Ref. 15.) 
563 
CONCLUDING REMARKS 
In the present paper we surveyed and applied results from the qualitative theory 
of large scale interconnected dynamical systems in order to develop a qualitative the- 
ory for neural networks of the Hop field type. Our results are local and use as much 
information as possible in the analysis of a given equilibrium. In doing so, we estab- 
lished criteria for the exponential stability, asymptotic stability, and instability of an 
equilibrium in such networks. We also devised methods for estimating the domain of 
attraction of an asymptotically stable equilibrium and for estimating trajectory bounds 
for such networks. Furthermore, we showed that our stability results are applicable 
to systems under structural perturbations (e.g., as experienced in neural networks in 
adaptive learning schemes). 
In arriving at the above results, we viewed neural networks as an interconnection 
of many single neurons, and we phrased our results in terms of the qualitative proper- 
ties of the free single neurons and in terms of the network interconnecting structure. 
This viewpoint is particularly well suited for the study of hierarchical structures which 
naturally lend themselves to implementations 16 in VLSI. Furthermore, this type of 
proach makes it possible to circumvent difficulties which usually arise in the analysis 
and synthesis of complex high dimensional systems. 
REFERENCES 
[1] For a review, see, Neural Networks for Computing, J. S. Denker, Editor, American 
Institute of Physics Conference Proceedings 151, Snowbird, Utah, 1986. 
[2] J. J. Hopfield and D. W. Tank, Science 233, 625 (1986). 
[3] J. J. Hopfield, Proc. Natl. Acad. Sci. U.S.A. 79, 2554 (1982), and ibid. 81, 3088 
(1984). 
[4] G. E. Hinton and J. A. Anderson, Editors, Parallel Models of Associative Memory, 
Efibaum, 1981. 
[5] T. Kohonen, Self-Organization and Associative Memory, Springer-Verlag, 1984. 
[6] A. N. Michel and R. K. Miller, Qualitative Analysis of Large Scale Dynamical 
Systems, Academic Press, 1977. 
[7] R. K. Miller and A. N. Michel, Ordinary Differential Equations, Academic Press, 
1982. 
I.W. 
A.N. 
[8] Sandberg, Bell System Tech. J. 48, 35 (1969). 
[9] Michel, IEEE Trans. on Automatic Control 28,639 (1983). 
[10] A. N. Michel, J. A. Farrell, and W. Porod, submitted for publication. 
[11] J.-H. Li, A. N. Michel, and W. Porod, IEEE Trans. Cftc. and Syst., in press. 
[12] G. A. Carpenter, M. A. Cohen, and S. Grossberg, Science 235, 1226 (1987). 
[13] M. A. Pai, Power System Stability, Amsterdam, North Holland, 1981. 
[14] A. N. Michel, N. R. Sarabudla, and R. K. Miller, Circuits, Systems and Signal 
Processing 1,171 (1982). 
[15] Lj. T. Grujic, A. A. Martynyuk and M. Ribbens-Pavella, Stability of Large-Scale 
Systems Under Structural and Singular Perturbations, Nauka Dumka, Kiev, 1984. 
[16] D. K. Ferry and W. Porod, Superlattices and Microstructures 2, 41 (1986). 
", result neural network michel farrel porod electr comput engin notr dame present paper survey mad util result qualit theori larg interconnect dynam system order develop qualit theori field model neural approach view network mani singl result phrase term qualit individu neuron term properti interconnect neural aspect neural network address includ exponenti instabl estim trajectori estim domain attract asymptot stabl stabil neural network structur recent neural network attract consider attent candid novel comput system type dynam biolog take advantag distribut inform process inher potenti parallel comput design comput system entail detail understand dynam stabil instabl variou equilibrium point network well extent associ domain attract trajectori present appli survey result qualit theori larg interconnect dynam system order develop qualit theori concentr popular hopfield model type analysi may also appli address follow determin stabil properti given equilibrium given specif equilibrium point neural network asymptot establish estim domain given set initi extern establish estim correspond trajectori condit instabl given equilibrium investig stabil structur present paper contain local detail treatment local stabil result found wherea global contain arriv result present make use method advanc view high dimension neural network work michel farrel support nsf grant work porod support onr grant institut physic individu subsystem interconnect system make result distinct other deriv literatur result phrase term qualit properti free subsystem disconnect term properti structur neural result may constitut use approach make possibl systemat analysi high dimension system frequent enabl one circumv difficulti encount analysi system convent structur paper start defin hop field introduc interconnect system present stabil includ estim trajectori bound domain result condit stabil structur present conclud hopfield model neural network present paper consid neural network hopfield type system repres equat form lot bi ci pdj ri gi continu differenti strictli mli increas ui ci denot denot resist sign invers due denot amplifi frequent assum tij tji explicitli interest mit behavior solut near posit ai set input defin equilibrium provid aij locat determin interconnect pattern neural well paramet bi natur nonlinear given myze isol neighborhood equilibrium analyz stabil properti given equilibrium abl without loss locat origin employ shift point origin leav structur system viewpoint find conveni view system interconnect free isol describ equat form zii interconnect structur system given method analysi advanc establish stabil result phrase term mit properti free subsystem term properti interconnect structur given method alysi make often possibl circumv difficulti aris analysi complex result obtain manner yield insight dynam behavior system term system stabil condit demonstr exampl result exponenti stabil princip lyapunov stabil result system chapter util follow hypothes first system extern input system interconnect satisfi estim aij xi aijxj aij real exist test matrix aij otj neg bi defin aij given posit state prove follow equilibrium neural network exponenti stabl hypothes choos lyanpunov function ai given function clearli posit along solut given aij view time matrix given follow matrix given denot largest eigenvalu real symmetr matrix sinc assumpt neg follow neighborhood origin maxi ca equilibrium neural exponenti stabl theorem philosophi view neural network free subsystem think lyapunov function consist weight sum lyapunov function free subsystem weight vector provid flexibl emphas rel import qualit properti variou individu hypothesi measur interact variou subsystem emphas theorem requir paramet aij form coupl condit test matrix given hypothesi term may special case term test equival stabil result may obtain easier appli theorem result call condit literatur condit sij may reflect properti may consequ major proof subsequ make use properti matric chapter addit use system nonlinear satisfi sector condit success princip minor test matrix posit bi aij defin defin equilibrium neural network asymptot hypothes proof proce along line similar one theorem time follow lyapunov function lyapunov function reflect interconnect natur whole note lyapunov function may view gener ham state vector trajectori bound one interest question concern stabil system also one way assess properti neural system investig solut bound near present result assum hypothes theorem requir extern input need make addit assumpt enumer assum exist ai iajil bi aij axe defin defin assum system constant defin proof next make use comparison scalar comparison equat form continu ixl prove auxiliari let denot maxim solut comparison continu satisfi differenti inequ almost long emd proof well comparison see next adopt follow let mini ail aix defin let given let denot solut posit prove follow provid bound solut assum hypothes given choos lyapunov function solut obtain test note present note mso manipul show miti yield comparison equati whose solut given let obtain comparison result desir estim provid domain attract network type consid herein mani equilibrium given equilibrium asymptot exponenti extent stabil assum equilibrium denot solut network would like know point true tend origin set point make domain attract basin equilibrium one can not determin domain sever techniqu devis estim subset domain appli one method neural make use theorem techniqu applic result make assum hypothes satisfi free choos lyapunov function ipil ri ri neg definit contain domain attract equilibrium pl free subsystem obtain estim domain attract whole neural use lyapunov function easi matter show set subset domain attract neural network min air order obtain best estim domain attract must choos ai optim reader refer literatur sever method accomplish result equilibrium point neural network may present sampl instabl theorem may view counterpart theorem instabihti formul counterpart stabil result type herein may obtain make appropri system interconnect satisfi estim aii success princip minor test matrix given cri bi stabl ai aii unstabl posit prove follow equilibrium neural network hypothes denot empti equilibrium complet choos lyapunov function ilxil ai along solut proof defin conclud neg definit sinc everi neighborhood origin one point follow equilibrium function neg definit equilibrium complet unstabl chapter structur perturb specif applic involv adapt scheme learn algorithm neural interconnect pattern extern chang yield differ set desir asymptot stabl equilibrium point domain present diagon domin condit use constraint guarante desir equilibria desir stabil assum given neural network design interconnect whose strength vari zero specifi express write place oij aij also assum given neural network thing manner given desir valu true mini said clear diagon domin condit aijl satisfi ai equilibrium import recogn condit constitut stabil condit neural network structur interconnect neural network may rearrang manner achiev desir set equilibrium asymptot structur perturb nice remark present paper survey appli result qualit theori larg scale interconnect dynam system order develop qualit neural network hop field result local use much possibl analysi given criteria exponenti asymptot instabl also devis method estim domain asymptot stabl equilibrium estim trajectori bound show stabil result applic system structur perturb experienc neural network learn arriv view neural network interconnect mani singl phrase result term qualit free singl neuron term network interconnect viewpoint particularli well suit studi hierarch structur lend implement type make possibl circumv difficulti usual aris analysi synthesi complex high dimension neural network american physic confer proceed hopfield scienc hinton parallel model associ associ michel qualit analysi larg scale dynam academ miller ordinari differenti academ bell system ie automat control submit ie scienc power system north system signal martynyuk stabil structur singular nauka ferri superlattic microstructur,0
59,59,"564 
PROGRAMMABLE SYNAPTIC CHIP FOR 
ELECTRONIC NEURAL NETWORKS 
A. Moopenn, H. Langenbacher, A.P. Thakoor, and S.K. Khanna 
Jet Propulsion Laboratory 
California Institute of Technology 
Pasadena, CA 91009 
ABSTRACT 
A binary synaptic matrix chip has been developed for electronic 
neural networks. The matrix chip contains a programmable 32X32 
array of ""long channel"" NMOSFET binary connection elements imple- 
mented in a 3-um bulk CMOS process. Since the neurons are kept off- 
chip, the synaptic chip serves as a ""cascadable"" building block for 
a multi-chip synaptic network as large as 512X512 in size. As an 
alternative to the programmable NMOSFET {long channel) connection 
elements, tailored thin film resistors are deposited, in series with 
FET switches, on some CMOS test chips, to obtain the weak synaptic 
connections. Although deposition and patterning of the resistors 
require additional processing steps, they promise substantial 
savings in silcon area. The performance of a synaptic chip in a 32- 
neuron breadboard system in an associative memory test application 
is discussed. 
INTRODUCTION 
The highly parallel and distributive architecture of neural 
networks offers potential advantages in fault-tolerant and high 
speed associative information processing. For the past few years, 
there has been a growing interest in developing electronic hardware 
to investigate the computational capabilities and application 
potential of neural networks as well as their dynamics and 
collective properties -5 . In an electronic hardware implementation 
of neural networks s,? , the neurons (analog processing units) are 
represented by threshold amplifiers and the synapses linking the 
neurons by a resistive connection network. The synaptic strengths 
between neurons (the electrical resistance of the connections) 
represent the stored information or the computing function of the 
neural network. 
Because of the massive interconectivity of the neurons and the 
large number of the interconnects required with the increasing 
number of neurons, implementation of a synaptic network using 
current LSI/VLSI technology can become very difficult. A synaptic 
network based on a multi-chip architecture would lessen this 
difficulty. We have designed, fabricated, and successfully tested 
CMOS-based programmable synaptic chips which could serve as basic 
""cascadable"" building blocks for a multi-chip electronic neural 
network. The synaptic chips feature complete programmability of 
1024, (32X32) binary synapses. Since the neurons are kept off- 
chip, the synaptic chips can be connected in parallel, to obtain 
multiple grey levels of the connection strengths, as well as 
@ American Institute of Physics 1988 
565 
""cascaded"" to form larger synaptic arrays for an expansion to a 512- 
neuron system in a feedback or feed-forward architecture. As a 
research tool, such a system would offer a significant speed 
improvement over conventional software-based neural network 
simulations since convergence times for the parallel hardware system 
would be significantly smaller. 
In this paper, we describe the basic design and operation of 
synaptic CMOS chips incorporating MOSFET's as binary connection 
elements. The design and fabrication of synaptic test chips with 
tailored thin film resistors as ballast resistors for controlling 
power dissipation are also described. Finally, we describe a 
synaptic chip-based 32-neuron breadboard system in a feedback 
configuration and discuss its performance in an associative memory 
test application. 
BINARY SYNAPTIC CMOS CHIP WITH MOSFET CONNECTION ELEMENTS 
There are two important design requirements for a binary 
connection element in a high density synaptic chip. The first 
requirement is that the connection in the ON state should be ""weak"" 
to ensure low overall power dissipation. The required degree of 
""weakness"" of the ON connection largely depends on the synapse 
density of the chip. If, for example, a synapse density larger than 
1000 per chip is desired, a dynamic resistance of the ON connection 
should be greater than ~100 K-ohms. The second requirement is that 
to obtain grey scale synapses with up to four bits of precision from 
binary connections, the consistency of the ON state connection 
resistance must be better than +/-5 percent, to ensure proper 
threshold operation of the neurons. Both of the requirements are 
generally difficult to satisfy simultaneously in conventional VLSI 
CMOS technology. For example, doped-polysilicon resistors could be 
used to provide the weak connections, but they are difficult to 
fabricate with a resistance uniformity of better than 5 percent. 
We have used NMOSFET's as connection elements in a multi-chip 
synaptic network. By designing the NMOSFET's with long channel, 
both the required high uniformity and high ON state resistance have 
been obtained. A block diagram of a binary synaptic test chip 
incorporating NMOSFET's as programmable connection elements is shown 
in Fig. 1. A photomicrograph of the chip is shown in Fig. 2. The 
synaptic chip was fabricated through MOSIS (MOS Implementation 
Service) in a 3-micron, bulk CMOS, two-level metal, P-well 
technology. The chip contains 1024 synaptic cells arranged in a 
32X32 matrix configuration. Each cell consists of a long channel 
NMOSFET connected in series with another NMOSFET serving as a simple 
ON/OFF switch. The state of the FET switch is controlled by the 
output of a latch which can be externally addressed via the ROW/COL 
address decoders. The 32 analog input lines {from the neuron 
outputs) and 32 analog output lines {to the neuron inputs} allow a 
number of such chips to be connected together to form larger 
connection matrices with up to 4-bit planes. 
The long channel NMOSFET can function as either a purely 
resistive or a constant current source connection element, depending 
566 
 -A9 
VGC 
i : 
i � 
RSTa 
FROM NEURON OUTPUTS 
)NEURON 
v' INPUTS 
Figure 1. Block diagram of a 32X32 binary synnaptic chip with long 
channel NMOSFETs as connection elements. 
Figure 2. Photomicrographs of a 32X32 binary connection CMOS chip. 
The blowup on the right shows several synaptic cells; the ""S""-shape 
structures are the long-channel NMOSFETs. 
on whether analog or binary output neurons are used. As a resistive 
connection, the NMOSFET's must operate in the linear region of the 
transistor's drain I-V characteristics. In the linear region, the 
channel resistance is approximately given by 8 
Ro = (l/K) (L/W) (VG - 
567 
Here, K is a proportionality constant which depends on process 
parameters, L and W are the channel length and width respectively, 
Vc is the gate voltage, and VT, is the threshold voltage. The 
transistor acts as a linear resistor provided the voltage across the 
channel is much less than the difference of the gate and threshold 
voltages, and thus dictates the operating voltage range of the 
connection. The NMOSFET's presently used in our synaptic chip 
design have a channel length of 244 microns and width of 12 microns. 
At a gate voltage of 5 volts, a channel resistance of about 200 K- 
ohms was obtained over an operating voltage range of 1.5 volts. The 
consistency of the transistor I-V characteristics has been verified 
to be within +/-3 percent in a single chip and +/-5 percent for 
chips from different fabrication runs. In the latter case, the 
transistor characteristics in the linear region can be further 
matched to within +/-3% by the fine adjustment of their common gate 
bias. 
With two-state neurons, current source connections may be used 
by operating the transistor in the saturation mode. Provided the 
voltage across the channel is greater than (Vc - VT,], the 
transistor behaves almost as a constant current source with the 
saturation current given approximately by  
Io = K {W/L) {Vc - VT.)  
With the appropriate selection of L, W, and W, it is possible to 
obtain ON-state currents which vary by two orders of magnitude in 
values. Figure 3 shows a set of measured I-V curves for a NMOSFET 
with the channel dimensions, L= 244 microns and W=12 microns and 
applied gate voltages from 2 to 4.5 volts. To ensure constant 
current source operation, the neuron's ON-state output should be 
greater than 3.5 volts. A consistency of the ON-state currents to 
within +/-5 percent has similarly been observed in a set of chip 
samples. With current source connections therefore, quantized grey 
scale synapses with up to 16 grey levels (4 bits) can be realized 
using a network of binary weighted current sources. 
Figure 3. I-V characteristics of 
an NMOSFET connection element. 
Channel dimension: L=244 um, 
W=12um 
For proper operation of the NMOSFET connections, the analog 
output lines (to neuron inputs} should always be held close to 
ground potential. Moreover, the voltages at the analog input lines 
must be at or above ground potential. Since the current normally 
568 
flows from the analog input to the output, the NMOSFET's may be used 
as either all excitatory or inhibitory type connections. However, 
the complementary connection function can be realized using long 
channel PMOSFET's in series with PMOSFET switches. For a PMOSFET 
connection, the voltage of an analog input line would be at or below 
ground. Furthermore, due to the difference in the mobilires of 
electrons and holes in the channel, a PMOSFET used as a resistive 
connection has a channel resistance about twice as large as an 
NMOSFET with the same channel dimension. This fact results in a 
subtantial reduction in the size of PMOSFET needed. 
THIN FILM RESISTOR CONNECTIONS 
The use of MOSFET's as connection elements in a CMOS synaptic 
matrix chip has the major advantage that the complete device can be 
readily fabricated in a conventional CMOS production run. However, 
the main disadvantages are the large area (required for the long 
channel] for the MOSFET's connections and their non-symmetrical 
inhibitory/excitatory functional characteristics. The large overall 
gate area not only substantially limits the number of synapses that 
can be fabricated on a single chip, but the transistors are more 
susceptible to processing defects which can lead to excessive gate 
leakage and thus reduce chip yield considerably. An alternate 
approach is simply to use resistors in place of MOSFET's. We have 
investigated one such approach where thin film resistors are 
deposited on top of the passivation layer of CMOS-processed chips as 
an additional special processing step to the normal CMOS fabrication 
run. With an appropriate choice of resistive materials, a dense 
array of resistive connections with highly uniform resistance of up 
to 10 M-ohms appears feasible. 
Several candidate materials, including a cermet based on 
platinum/aluminum oxide, and amorphous semiconductor/metal alloys 
such as a-Ge:Cu and a-Ge:A1, have been examined for their applica- 
bility as thin film resistor connections. These materials are of 
particular interest since their resistivity can easily be tailored 
in the desired semiconducting range of 1-10 ohm-cm by controlling 
the metal content s . The a-Ge/metal films are deposited by thermal 
evaporation of presynthesized alloys of the desired composition in 
high vacuum, whereas platinum/aluminum oxide films are deposited by 
co-sputtering from platinum and aluminum oxide targets in a high 
purity argon and oxygen gas mixture. Room temperature resistivities 
in the 0.1 to 100 ohm-cm range have been obtained by varying the 
metal content in these materials. Other factors which would also 
determine their suitability include their device processing and 
material compatibilities and their stability with time, temperat- 
ure, and extended application of normal operating electric current. 
The temperature coefficient of resistance (TCR] of these materials 
at room temperature has been measured to be in the 2000 to 6000 ppm 
range. Because of their relatively high TCR's, the need for weak 
connections to reduce the effect of localized heating is especially 
important here. The a-Ge/metal alloy films are observed to be 
relatively stable with exposure to air for temperatures below 130oC. 
569 
The platinum/aluminum oxide film stabilize with time after annealing 
in air for several hours at 130�C. 
Sample test arrays of thin film resistors based on the 
described materials have been fabricated to test their consistency. 
The resistors, with a nominal resistance of 1 M-ohm, were deposited 
on a glass substrate in a 40X40 array over a 0.4cm by 0.4cm area. 
Variation in the measured resistance in these test arrays has been 
found to be from +/- 2-5 percent for all three materials. Smaller 
test arrays of a-Ge:Cu thin film resistors on CMOS test chips have 
also been fabricated. A photo-micrograph of a CMOS synaptic test 
chip containing a 4X4 array of a-Ge:Cu thin film resistors is shown 
in Fig. 4. Windows in the passivation layer of silicon nitride 
{SIN] were opened in the final processing step of a normal CMOS 
fabrication run to provide access to the aluminum metal for 
electrical contacts. A layer of resistive material was deposited 
and patterned by lift-off. A layer of buffer metal of platinum or 
nickel was then deposited by RF sputtering and also patterned by 
lift-off. The buffer metal pads serve as a conducting bridges for 
connecting the aluminum electrodes to the thin film resistors. In 
addition to providing a reliable ohmic contact to the aluminum and 
resistor, it also provides conformal step coverage over the silicon 
nitride window edge. The resistor elements on the test chip are 100 
micron long, 10 micron wide with a thickness of about 1500 angsttoms 
and a nominal resistance of 250 K-ohms. Resistance variations from 
10-20 percent have been observed in several such test arrays. The 
unusually large variation is largely due to the surface roughness of 
the chip passivation layer. As one possible solution, a thin spin- 
Figure 4. Photomicrographs of.a CMOS synaptic test chip with a 4X4 
array of a-Ge:Cu thin film resistors. The nominal resistance was 
250 K-ohms. 
57O 
on coating of an insulating material such as polyimide to smooth out 
the surface of the passivation layer prior to depositing the 
resistors is under investigation. 
SYNAPTIC CHIP-BASED 32-NEURON BREADBOARD SYSTEM 
A 32-neuron breadboard system utilizing an array of discrete 
neuron electronics has been fabricated to evaluate the operation of 
32X32 binary synaptic CMOS chips with NMOSFET connection elements. 
Each neuron consists of an operational amplifier configured as a 
current to voltage converter (with virtual ground input) followed by 
a fixed-gain voltage difference amplifier. The overall time 
constant of the neurons is approximately 10 microseconds. The 
neuron array is interfaced directly to the synaptic chip in a full 
feedback configuration. The system also contains prompt electronics 
consisting of a programmable array of RC discharging circuits with a 
relaxation time of approximately 5 microseconds. The prompt 
hardware allows the neuron states to be initialized by precharging 
the selected capacitors in the RC circuits. A microcomputer 
interfaced to the breadboard system is used for programming the 
synaptic matrix chip, controlling the prompt electronics, and 
reading the neuron outputs. 
The stability of the breadboard .system is tested in an 
associative memory feedback configuration e. A dozen random dilute- 
coded binary vectors are stored using the following simplified 
outer-product storage scheme: 
T =. $ 
0 otherwise. 
In this scheme, the feedback matrix consists of only inhibitory (- 
1)or open (0) connections. The neurons are set to be normally ON 
and are driven OFF when inhibited by another neuron via the feedback 
matrix. The system exhibits excellent stability and associative 
recall performance. Convergence to a nearest stored memory in 
Hamming distance is always observed for any given input cue. Figure 
5 shows some typical neuron output traces for a given test prompt 
and a set of stored memories. The top traces show the response of 
two neurons that are initially set ON; the bottom traces for two 
other neurons initially set OFF. Convergence times of 10-50 
microseconds have been observed, depending on the prompt 
conditions, but are primarily governed by the speed of the neurons. 
CONCLUSIONS 
Synaptic CMOS chips containing 1024 programmable binary 
synapses in a 32X32 array have been designed, fabricated, and 
tested. These synaptic chips are designed to serve as basic 
building blocks for large multi-chip synaptic networks. The use of 
long channel MOSFET's as either resistive or current source 
connection elements meets the ""weak"" connection and consistency 
571 
Figure 5. Typical neuron response curves for a test prompt input� 
(Horiz scale: 10 microseconds per div} 
requirements. Alternately, CMOS-based synaptic test chips with 
specially deposited thin film high-valued resistors, in series with 
FET switches, offer an attractive approach to high density 
programmable synaptic chips. A 32-neuron breadboard system 
incorporating a 32X32 NMOSFET synaptic chip and a feedback 
configuration exhibits excellent stability and associative recall 
performance as an associative memory� Using discrete neuron array, 
convergence times of 10-50 microseconds have been demonstrated. 
With optimization of the input/output wiring layout and the use of 
high speed neuron electronics, convergence times can certainly be 
reduced to less than a microsecond. 
ACKNOWLEDGEMENTS 
This work was performed by the Jet Propulsion Laboratory, 
California Institute of Technology, and was sponsored by the Joint 
Tactical Fusion Program Office, through an agreement with the 
National Aeronautics and Space Administration. The authors would 
like to thank John Lambe for his invaluable suggestions, T. Duong 
for his assistance in the breadboard hardware development, J. Lamb 
and S. Thakoor for their help in the thin film resistor deposition, 
and R. Nixon and S. Chang for their assistance in the chip layout 
design. 
REFERENCES 
J. Lambe, A. Moopenn, and A.P. Thakoor, Proc. AIAA/ACM/NASA/- 
IEEE Computers in Aerospace V, 160 (1985) 
A.P. Thakoor, J.L. Lamb, A. Moopenn, and S.K. Khanna, MRS 
Proc. 95, 627 {1987) 
W. Hubbard, D. Schwartz, J. Denker, 
Jackel, B. Straughn, and D. Termant, 
(1986} 
M.A. Sivilotti, M.R. Emerling, and 
151, 408 (1986} 
J.P. Sage, K. Thompson, and R.S. 
H.P. Graf, R. Howard, L. 
AIP Conf. Proc. 151, 227 
C. Mead, AIP Conf. Proc. 
Withers, AIP Conf. Proc. 151, 
572 
6. J.J. Hopfield, Proc. Nat. Acad. Sci., 81, 3088 (1984) 
7. $.$. Hopfield, Proc. Nat. Acad. Sci., 79, 2554 (1982) 
8, S.M. Sze, ""Semiconductor Devices-Physics and Technology,"" (Wi- 
ley, New York, 1985) p.205 
9, J.L. Lamb, A.P. Thakoor, A. Moopenn, and S.K. Khanna, J. Vac. 
' Sci. Tech., A 5(4), 1407 (1987) 
", synapt chip neural network khanna propuls laboratori institut technolog ca binari synapt matrix chip develop electron matrix chip contain programm nmosfet binari connect element bulk cmo sinc neuron kept synapt chip serv build block synapt network larg programm nmosfet connect tailor thin film resistor seri cmo test obtain weak synapt although deposit pattern resistor addit process promis substanti silcon perform synapt chip breadboard system associ memori test applic highli parallel distribut architectur neural offer potenti advantag high associ inform past grow interest develop electron hardwar investig comput capabl applic neural network well dynam properti electron hardwar implement neural network neuron process threshold amplifi synaps link resist connect synapt strength neuron electr resist store inform comput function massiv interconect neuron number interconnect requir increas implement synapt network use technolog becom synapt base architectur would lessen success test programm synapt chip could serv basic build block electron neural synapt chip featur complet programm binari sinc neuron kept synapt chip connect obtain grey level connect well american institut physic form larger synapt array expans system feedback system would offer signific speed convent neural network sinc converg time parallel hardwar system significantli describ basic design oper cmo chip incorpor binari connect design fabric synapt test chip thin film resistor ballast resistor control dissip also describ breadboard system feedback discuss perform associ memori synapt cmo chip mosfet connect element two import design requir binari element high densiti synapt first connect state ensur low overal power requir degre connect larg depend synaps synaps densiti larger per chip dynam resist connect greater second requir obtain grey scale synaps four bit precis consist state connect must better ensur proper oper requir difficult satisfi simultan convent vlsi resistor could provid weak difficult resist uniform better use connect element design long requir high uniform high state resist block diagram binari synapt test chip programm connect element shown photomicrograph chip shown chip fabric mosi implement bulk chip contain synapt cell arrang matrix cell consist long channel connect seri anoth nmosfet serv simpl state fet switch control latch extern address via analog input line neuron analog output line neuron allow chip connect togeth form larger matric long channel nmosfet function either pure constant current sourc connect depend neuron output input block diagram binari synnapt chip long nmosfet connect photomicrograph binari connect cmo blowup right show sever synapt whether analog binari output neuron resist must oper linear region drain linear resist approxim given proportion constant depend process channel length width gate threshold act linear resistor provid voltag across much less differ gate threshold thu dictat oper voltag rang present use synapt chip channel length micron width gate voltag channel resist obtain oper voltag rang transistor characterist verifi within percent singl chip percent differ fabric latter characterist linear region within fine adjust common gate current sourc connect may use oper transistor satur provid across channel greater behav almost constant current sourc current given approxim appropri select possibl current vari two order magnitud figur show set measur curv nmosfet channel micron micron gate voltag ensur constant sourc output consist current percent similarli observ set chip current sourc connect quantiz grey synaps grey level realiz network binari weight current characterist nmosfet connect proper oper nmosfet analog line neuron alway held close voltag analog input line ground sinc current normal analog input may use either excitatori inhibitori type complementari connect function realiz use long seri pmosfet pmosfet voltag analog input line would due differ mobilir hole pmosfet use resist channel resist twice larg channel fact result reduct size pmosfet film resistor connect use connect element cmo synapt chip major advantag complet devic fabric convent cmo product main disadvantag larg area long connect function larg overal area substanti limit number synaps fabric singl transistor process defect lead excess gate thu reduc chip yield altern simpli use resistor place one approach thin film resistor top passiv layer chip addit special process step normal cmo fabric appropri choic resist dens resist connect highli uniform resist appear candid includ cermet base amorph alloy examin thin film resistor materi interest sinc resist easili tailor desir semiconduct rang control metal content film deposit thermal presynthes alloy desir composit wherea oxid film deposit platinum aluminum oxid target high argon oxygen ga room temperatur resist rang obtain vari content factor would also suitabl includ devic process compat stabil extend applic normal oper electr temperatur coeffici resist materi room temperatur measur ppm rel high need weak reduc effect local heat especi alloy film observ stabl exposur air temperatur oxid film stabil time anneal air sever hour test array thin film resistor base materi fabric test nomin resist deposit glass substrat array measur resist test array percent three smaller array thin film resistor cmo test chip cmo synapt test contain array thin film resistor shown window passiv layer silicon nitrid open final process step normal cmo run provid access aluminum metal layer resist materi deposit pattern layer buffer metal platinum deposit rf sputter also pattern buffer metal pad serv conduct bridg aluminum electrod thin film provid reliabl ohmic contact aluminum also provid conform step coverag silicon window resistor element test chip micron wide thick angsttom nomin resist resist variat percent observ sever test larg variat larg due surfac rough chip passiv one possibl thin photomicrograph cmo synapt test chip thin film nomin resist coat insul materi polyimid smooth surfac passiv layer prior deposit breadboard system breadboard system util array discret electron fabric evalu oper binari synapt cmo chip nmosfet connect neuron consist oper amplifi configur voltag convert virtual ground follow voltag differ overal time neuron approxim array interfac directli synapt chip full system also contain prompt electron programm array rc discharg circuit time approxim prompt allow neuron state initi precharg select capacitor rc microcomput breadboard system use program matrix control prompt neuron stabil breadboard test memori feedback configur dozen random binari vector store use follow simplifi storag feedback matrix consist inhibitori open neuron set normal driven inhibit anoth neuron via feedback system exhibit excel stabil associ converg nearest store memori distanc alway observ given input figur show typic neuron output trace given test prompt set store top trace show respons neuron initi set bottom trace two neuron initi set converg time depend prompt primarili govern speed cmo chip contain programm binari array synapt chip design serv basic block larg synapt use channel either resist current sourc element meet connect consist typic neuron respons curv test prompt microsecond per synapt test chip deposit thin film seri offer attract approach high densiti synapt breadboard system nmosfet synapt chip feedback exhibit excel stabil associ recal associ use discret neuron time microsecond optim wire layout use speed neuron converg time certainli less work perform jet propuls institut sponsor joint fusion program agreement aeronaut space author would thank john lamb invalu duong assist breadboard hardwar lamb thakoor help thin film resistor nixon chang assist chip layout comput aerospac mr aip aip new,2
60,60,"573 
BIT - SERIAL NEURAL NETWORKS 
Alan F. Murray, Anthony V. W. Smith and Zoe F. Buffer. 
Department of Electrical Engineering, University of Edinburgh, 
The King's Buildings, Mayfield Road, Edinburgh, 
Scoff and, EH9 3JL. 
ABSTRACT 
A bit - serial VLSI neural network is described from an initial architecture for a 
synapse array through to silicon layout and board design. The issues surrounding bit 
- serial computation, and analog/digital arithmetic are discussed and the parallel 
development of a hybrid analog/digital neural network is outlined. Learning and 
recall capabilities are reported for the bit - serial network along with a projected 
specification for a 64 - neuron, bit - serial board operating at 20 MHz. This tech- 
nique is extended to a 256 (2562 synapses) network with an update time of 3ms, 
using a ""paging"" technique to time - multiplex calculations through the synapse 
array. 
1. INTRODUCTION 
The functions a synthetic neural network may aspire to mimic are the ability to con- 
sider many solutions simultaneously, an ability to work with corrupted data and a 
natural fault tolerance. This arises from the parallelism and distributed knowledge 
representation which gives rise to gentle degradation as faults appear. These func- 
tions are attractive to implementation in VLSI and WSI. For example, the natural 
fault - tolerance could be useful in silicon wafers with imperfect yield, where the 
network degradation is approximately proportional to the non-functioning silicon 
area. 
To cast neural networks in engineering language, a neuron is a state machine that is 
either ""on"" or ""off"", which in general assumes intermediate states as it switches 
smoothly between these extrema. The synapses weighting the signals from a 
transmitting neuron such that it is more or less excitatory or inhibitory to the receiv- 
ing neuron. The set of synaptic weights determines the stable states and represents 
the learned information in a system. 
The neural state, Vi, is related to the total neural activity stimulated by inputs to 
the neuron through an activation function, F. Neural activity is the level of excita- 
tion of the neuron and the activation is the way it reacts in a response to a change 
in activation. The neural output state at time t, V[, is related to x! by 
V[ = F(x/) (1) 
The activation function is a ""squashing"" function ensuring that (say) Vi is 1 when 
xi is large and -1 when xi is small. The neural update function is therefore straight- 
forward: 
j =n -1 
x: *f= x[ ..... +8  T o V.[ (2) 
where 8 represents the rate of change of neural activity, Tq is the synaptic weight 
and n is the number of terms giving an n - neuron array [1]. 
Although the neural function is simple enough, in a totally interconnected n - neu- 
ron network there are n 2 synapses requiring n 2 multiplications and summations and 
� American Institute of Physics 1988 
574 
a large number of interconnects. The challenge in VLSI is therefore to design a sim- 
ple, compact synapse that can be repeated to build a VLSI neural network with 
manageable interconnect. In a network with fixed functionality, this is relatively 
straightforward. If the network is to be able to learn, however, the synaptic weights 
must be programmable, and therefore more complicated. 
2. DESIGNING A NEURAL NETWORK IN VLSI 
There are fundamentally two approaches to implementing any function in silicon - 
digital and analog. Each technique has its advantages and disadvantages, and these 
are listed below, along with the merits and demerits of bit - serial architectures in 
digital (synchronous) systems. 
Digital rs. analog: The primary advantage of digital design for a synapse array is 
that digital memory is well understood, and can be incorporated easily. Learning 
networks are therefore possible without recourse to unusual techniques or technolo- 
gies. Other strengths of a digital approach are that design techniques are advanced, 
automated and well understood and noise immunity and computational speed can 
be high. Unattractive features are that digital circuits of this complexity need to be 
synchronous and all states and activities are quantised, while real neural networks 
are asynchronous and unquantised. Furthermore, digital multipliers occupy a large 
silicon area, giving a low synapse count on a single chip. 
The advantages of analog circuitry are that asynchronous behaviour and smooth 
neural activation are automatic. Circuit elements can be small, but noise immunity 
is relatively low and arbitrarily high precision is not possible. Most importantly, no 
reliable analog, non - volatile memory technology is as yet readily available. For 
this reason, learning networks lend themselves more naturally to digital design and 
implementation. 
Several groups are developing neural chips and boards, and the following listing 
does not pretend to be exhaustive. It is included, rather, to indicate the spread of 
activity in this field. Analog techniques have been used to build resistor / opera- 
tional amplifier networks [2, 3] similar to those proposed by Hopfield and Tank [4]. 
A large group at Caltech is developing networks implementing early vision and 
auditory processing functions using the intrinsic nonlinearities of MOS transistors in 
the subthreshold regime [5, 6]. The problem of implementing analog networks with 
electrically programmable synapses has been addressed using CCD/MNOS technol- 
ogy [7]. Finally, Garth [8] is developing a digital neural accelerator board ('let- 
sire"") that is effectively a fast SIMD processor with supporting memory and com- 
munications chips. 
Bit - serial rs. bit - parallel: Bit - serial arithmetic and communication is efficient 
for computational processes, allowing good communication within and between 
VLSI chips and tightly pipelined arithmetic structures. It is ideal for neural net- 
works as it minimises the interconnect requirement by eliminating multi - wire 
busses. Although a bit - parallel design would be free from computational latency 
(delay between input and output), pipelining makes optimal use of the high bit - 
rates possible in serial systernx, and makes for efficient circuit usage. 
2.1 An asynchronous pulse stream VLSI neural network: 
In addition to the digital system that forms the substance of this paper, we are 
developing a hybrid analog/digital network family. This work is outlined here, and 
has been reported in greater detail elsewhere [9, 10, 11]. The generic (logical and 
layout) architecture of a single network of n totally interconnected neurons is shown 
575 
schematically in figure 1. Neurons are represented by circles, which signal their 
states, Vi upward into a matrix of synaptic operators. The state signals are con- 
neeted to a n - bit horizontal bus running through the synaptic array, with a con- 
nection to each synaptic operator in every column. All columns have n operators 
(denoted by squares) and each operator adds its synaptic contribution, T 0 Vj, to the 
running total of activity for the neuron i at the foot of the column. The synaptic 
function is therefore to multiply the signalling neuron state, Vi, by the synaptic 
weight, T0, and to add this product to the running total. This architecture is com- 
mon to both the bit - serial and pulse - stream networks. 
I I _1 I 
Synapse 
States { Vj } 
Neurons 
Figure 1. Generic architecture for a network of n totally interconnected neurons. 
This type of architecture has many attractions for implementation in 2 - dimensional 
j =n -1 
silicon as the summation  To V  is distributed in space. The interconnect 
requirement (n inputs to each neuron) is therefore distributed through a column, 
reducing the need for long - range wiring. The architecture is modular, regular and 
can be easily expanded. 
In the hybrid analog/digital system, the circuitry uses a ""pulse stream"" signalling 
method similar to that in a natural neural system. Neurons indicate their state by 
the presence or absence of pulses on their outputs, and synapfic weighting is 
achieved by time - chopping the presynaptic pulse stream prior to adding it to the 
postsynaptic activity summation. It is therefore asynchronous and imposes no fun- 
damental limitations on the activation or neural state. Figure 2 shows the pulse 
stream mechanism in more detail. The synaptic weight is stored in digital memory 
local to the operator. Each synaptic operator has an excitatory and inhibitory pulse 
stream input and output. The resultant product of a synaptic operation, To V, is 
added to the running total propagating down either the excitatory or inhibitory 
channel. One binary bit (the MSBit) of the stored T 0 determines whether the con- 
tribution is excitatory or inhibitory. 
The incoming excitatory and inhibitory pulse stream inputs to a neuron are 
integrated to give a neural activation potential that varies smoothly from 0 to 5 V. 
This potential controls a feedback loop with an odd number of logic inversions and 
576 
EXe. Znh. EXe. 
.. ! ,.,,,, 
Yi 
Figure 2. Pulse stream arithmetic. Neurons are denoted by C) and synaptic operators 
byE. 
thus forms a switched ""ring - oscillator"". If the inhibitory input dominates, the feed- 
back loop is broken. If excitatory spikes subsequently dominate at the input, the 
neural activity rises to 5V and the feedback loop oscillates with a period determined 
by a delay around the loop. The resultant periodic waveform is then converted to a 
series of voltage spikes, whose pulse rate represents the neural state, Vi. Interest- 
ingly, a not dissimilar technique is reported elsewhere in this volume, although the 
synapse function is executed differently [12]. 
3. A 5 - STATE BIT - SERIAL NEURAL NETWORK 
The overall architecture of the 5 - state bit - serial neural network is identical to 
that of the pulse stream network. It is an array of n 2 interconnected synchronous 
synaptic operators, and whereas the pulse stream method allowed Vi to assume all 
values between ""off"" and ""on"", the 5 - state network Vj is constrained to 0, -0.5 or 
-1. The resultant activation function is shown in Figure 3. Full digital multiplica- 
tion is costly in silicon area, but multiplication of T by Vj = 0.5 merely requires 
the synaptic weight to be right - shifted by 1 bit. Similarly, multiplication by 0.25 
involves a further right - shift of T 0, and multiplication by 0.0 is trivially easy. Vj 
< 0 is not problematic, as a switchable adder/subtractor is not much more complex 
than an adder. Five neural states are therefore feasible with circuitry that is only 
slightly more complex than a simple serial adder. The neural state expands from a 1 
bit to a 3 bit (5 - state) representation, where the bits represent ""add/subtract?"", 
""shift?"" and ""multiply by 07"". 
Figure 4 shows part of the synaptic array. Each synaptic operator includes an 8 bit 
shift register memory block holding the synaptic weight, T 0. A 3 bit bus for the 5 
neural states runs horizontally above each synaptic row. Single phase dynamic 
CMOS has been used with a clock frequency in excess of 20 MHz [13]. Details of 
a synaptic operator are shown in figure 5. The synaptic weight T 0 cycles around the 
shift register and the neural state Vj is present on the state bus. During the first 
clock cycle, the synaptic weight is multiplied by the neural state and during the 
second, the most significant bit (MSBit) of the resultant T o Vj is sign - extended for 
577 
THRESHOLD 
Sme 
--- AclivRy x 
State Vj harper"" 
State V SIGM .)./..o' _ 
-'' ' - Activity xj 
x t 
Figure 3. ""Hard - threshold"", 5 - state and sigmoid activation functions. 
j = -ITsjV j 
j- 10 
Figure 4. Section of the synaptic array of the 5 - state activation function neural net- 
work. 
8 bits to allow for word growth in the running summation. A least significant bit 
(LSBit) signal running down the synaptic columns indicates the arrival of the LSBit 
of the xi running total. If the neural state is -+0.5 the synaptic weight is right 
shined by 1 bit and then added to or subtracted from the running total. A multipli- 
cation of -+ 1 adds or subtracts the weight from the total and multiplication by 0 
578 
o.o 
Add/Subtract 
Add/ 
Subtract 
J= ,-ITiiV j 
J:=p 
Figure 5. The synaptic operator with a 5 - state activation function. 
does not alter the running summation. 
The final summation at the foot of the column is thresholded externally according 
to the 5 - state activation function in figure 3. As the neuron activity xj, increases 
through a threshold value x,, ideal sigmoidal activation represents a smooth switch 
of neural state from -1 to 1. The 5 - state ""staircase"" function gives a superficially 
much better approximation to the sigrnoid 
ment) threshold function. The sharpness 
""tune"" the neural dynamics for learning and 
referred to as temperature by analogy with 
form. High ""temperature"" gives a smoother 
form than a (much simpler to imple- 
of the transition can be controlled to 
computation. The control parameter is 
statistical functions with this sigmoidal 
staircase and sigrnoid, while a tempera- 
ture of 0 reduces both to the 'Iopfield"" - like threshold function. The effects of 
temperature on both learning and recall for the threshold and 5 - state activation 
options are discussed in section 4. 
4. LEARNING AND RECALL WITH VLSI CONSTRAINTS 
Before implementing the reduced - arithmetic network in VLSI, simulation experi- 
ments were conducted to verify that the 5 - state model represented a worthwhile 
enhancement over simple threshold activation. The 'qaenchmark"" problem was 
chosen for its ubiquitousness, rather than for its intrinsic value. The implications 
for learning and recall of the 5 - state model, the threshold (2 - state) model and 
smooth sigrnoidal activation ( o _ state) were compared at varying temperatures 
with a restricted dynamic range for the weights T 0 . In each simulation a totally 
interconnected 64 node network attempted to learn 32 random patterns using the 
delta rule learning algorithm (see for example [14]). Each pattern was then cor- 
rupted with 25% noise and recall attempted to probe the content addressable 
memory properties under the three different activation options. 
During learning, individual weights can become large (positive or negative). When 
weights are ""driven"" beyond the maximum value in a hardware implementation, 
579 
which is determined by the size of the synaptic weight blocks, some limiting 
mechanism must be introduced. For example, with eight bit weight registers, the 
limitation is -128 <- Tii <-- 127. With integer weights, this can be seen to be a prob- 
lem of dynamic range, where it is the relafonship between the smallest possible 
weight (-1) and the largest (+ 127/-128) that is the issue. 
Results: Fig. 6 shows examples of the results obtained, studying learning using 5 - 
state activation at different temperatures, and recall using both 5 - state and thres- 
hold activation. At temperature T=0, the 5 - state and threshold models are 
degenerate, and the results identical. Increasing smoothness of activation (tempera- 
ture) during learning improves the quality of learning regardless of the activation 
function used in recall, as more patterns are recognised succeasfully. Using 5 - state 
activation in recall is more effective than simple threshold activation. The effect of 
dynamic range restrictions can be assessed from the horizontal axis, where T:? is 
shown. The results from these and many other experiments may be summarised as 
follows:- 
5 - Stste activation rs. threshold: 
1) Learning with 5 - state activation was protracted over the threshold activation, 
as binary patterns were being learnt, and the inclusion of intermediate values 
added extra degrees of freedom. 
2) Weight sets learnt using the 5 - state activation function were 'l>etter"" than 
those learnt via threshold activation, as the recall properties of both 5 - state 
and threshold networks using such a weight set were more robust against 
noise. 
3) Full sigmoidal activation was better than 5 - state, but the enhancement was 
less significant than that incurred by moving from threshold --, 5 - state. This 
suggests that the law of diminishing returns applies to addition of levels to the 
neural state Vj. This issue has been studied mathematically [15], with results 
that agree qualitatively with ours. 
Weight Saturation: 
Three methods were tried to deal with weight saturation. Firstly, inclusion of a 
decay, or ""forgetting"" term was included in the learning cycle [1]. It is our view 
that this technique can produce the desired weight limiting property, but in the time 
available for experiments, we were unable to ""tune"" the rate of decay sufficiently 
well to confirm it. Renormalisafion of the weights (division to bring large weights 
back into the dynamic range) was very unsuccessful, suggesting that information 
distributed throughout the numerically small weights was being destroyed. Finally, 
the weights were allowed to ""clip"" (ie any weight outside the dynamic range was set 
to the maximum allowed value). This method proved very successful, as the learn- 
ing algorithm adjusted the weights over which it still had control to compensate for 
the saturation effect. It is interesting to note that other experiments have indicated 
that Hopfield nets can ""forget"" in a different way, under different learning control, 
giving preference to recently acquired memories [16]. The results from the satura- 
tion experiments were:- 
I) For the 32 pattern/64 node problem, integer weights with a dynamic range 
greater than _ 30 were necessary to give enough storage capability. 
2) For weights with maximum values Ti? -- 50--70, ""clipping"" occurs, but net- 
work performance is not seriously degraded over that with an unrestricted 
weight set. 
580 
15 
0 
15 
0 20 30 40 50 60 70 
Limit 
5 - state activation function recall 
T-- 30 ....... 
T=20 
T=10 ............ 
T=O 
0 20 30 40 50 60 70 
Limit 
""Hopfield"" activation function recall 
Figure 6. Recall of patterns learned with the 5 - state activation function and subse- 
quently restored using the 5-state and the hard - threshold activation functions. 
T is the ""temperature"", or smoothness of the activation function, and ""limit"" the value 
off,?. 
These results showed that the 5 - state model was worthy of implementation as a 
VLSI neural board, and suggested that 8 - bit weights were sufficient. 
5. PROJECTED SPECIFICATION OF A HARDWARE NEURAL BOARD 
The specification of a 64 neuron board is given here, using a 5 - state bit - serial 64 
x 64 synapse array with a derated clock speed of 20 MHz. The synaptic weights are 
8 bit words and the word length of the running summation x, is 16 bits to allow for 
growth. A 64 synapse column has a computational latency of 80 clock cycles or 
bits, giving an update time of 4xs for the network. The time to load the weights 
into the array is limited to 60xs by the supporting RAM, with an access time of 
120ns. These load and update times mean that the network is executing I x 10 9 
operations/second, where one operation is --+ T,jVj. This is much faster than a 
natural neural network, and much faster than is necessary in a hardware accelera- 
tor. We have therefore developed a ""paging"" architecture, that effectively ""trades 
off' some of this excessive speed against increased network size. 
A ""moving - patch"" neural board: An array of the 5 - state synapses is currently 
being fabricated as a VLSI integrated circuit. The shift registers and the 
adder/subtractor for each synapse occupy a disappointingly large silicon area, allow- 
ing only a 3 x 9 synaptic array. To achieve a suitable size neural network from this 
array, several chips need to be included on a board with memory and control circu- 
itry. The ""moving patch"" concept is shown in figure 7, where a small array of 
synapses is passed over a much larger n x n synaptic array. 
Each time the array is ""moved"" to represent another set of synapses, new weights 
must be loaded into it. For example, the first set of weights will be Tu ... 
... T2j to Tj, the second set Tj+L to T, etc.. The final weight to be loaded will be 
581 
0000� 
oooo 
n neurons -. nxn synaptic array 
Small Patch"" 
moves over array 
Figure 7. The ""moving patch"" concept, passing a small synaptic 'oatch"" over a larger 
nxn synapse array. 
T,. Static, off - the - shelf RAM is used to store the weights and the whole opera- 
tion is pipelined for maximum efficiency. Figure 8 shows the board level design for 
the network. 
Synaptic Accelerator Chips 
HOST 
Figure 8. A ""moving patch"" neural network board. 
The small ""patch"" that moves around the array to give n neurons comprises 4 VLSI 
synaptic accelerator chips to give a 6 x 18 synaptic array. The number of neurons to 
be simulated is 256 and the weights for these are stored in 0.5 Mb of RAM with a 
load time of 8ms. For each ""patch"" movement, the partial runninz summatin-,  
582 
calculated for each column, is stored in a separate RAM until it is required to be 
added into the next appropriate summation. The update time for the board is 3ms 
giving 2 x 10 ? operations/second. This is slower than the 64 neuron specification, 
but the network is 16 times larger, as the arithmetic elements are being used more 
efficiently. To achieve a network of greater than 256 neurons, more RAM is 
required to store the weights. The network is then slower unless a larger number of 
accelerator chips is used to give a larger moving ""patch"". 
6. CONCLUSIONS 
A strategy and design method has been given for the construction of bit - serial 
VLSI neural network chips and circuit boards. Bit - serial arithmetic, coupled to a 
reduced arithmetic style, enhances the level of integration possible beyond more 
conventional digital, bit - parallel schemes. The restrictions imposed on both synal> 
tic weight size and arithmetic precision by VLSI constraints have been examined 
and shown to be tolerable, using the associative memory problem as a test. 
While we believe our digital approach to represent a good compromise between 
arithmetic accuracy and circuit complexity, we acknowledge that the level of 
integration is disappoinfingly low. It is our belief that, while digital approaches 
may be interesting and useful in the medium term, essentially as hardware accelera- 
tors for neural simulations, analog techniques represent the best ultimate option in 2 
- dimensional silicon. To this end, we are currently pursuing techniques for analog 
pseudo - static memory, using standard CMOS technology. In any event, the full 
development of a nonvolatile analog memory technology, such as the MNOS tech- 
nique [7], is key to the long - term future of VLSI neural nets that can learn. 
7. ACKNOWLEDGEMENTS 
The authors acknowledge the support of the Science and Engineering Research 
Council (UK) in the execution of this work. 
References 
o 
S. Grossberg, ""Some Physiological and Biochemical Consequences of Psycho- 
logical Postulates,"" Proc. Natl. Acad. Sci. USA, vol. 60, pp. 758 - 765, 1968. 
H. P. Graf, L. D. Jackel, R. E. Howard, B. Straughn, J. S. Denker, W. 
Hubbard, D. M. Tennant, and D. Schwartz, ""VLSI Implementation of a 
Neural Network Memory with Several Hundreds of Neurons,"" Proc. AlP 
Conference on Neural Networks for Computing, Snowbird, pp. 182 - 187, 1986. 
W. $. Mackie, H. P. Graf, and J. S. Denker, ""Microelectronic Implementa- 
tion of Connectionist Neural Network Models,"" IEEE Conference on Neural 
Information Processing Systems, Denver, 1987. 
J. J. Hopfield and D. W. Tank, ""Neural"" Computation of Decisions in Optim- 
isation Problems,"" Biol. Cybern., vol. 52, pp. 141 - 152, 1985. 
M. A. Sivilotti, M. A. Mahowald, and C. A. Mead, Real - Time Visual Com- 
putations Using Analog CMOS Processing Arrays, 1987. To be published 
C. A. Mead, ""Networks for Real o Time Sensory Processing,"" IEEE Confer- 
ence on Neural Information Processing Systems, Denver, 1987. 
583 
7. J.P. Sage, K. Thompson, and R. S. Withers, ""An Artificial Neural Network 
Integrated Circuit Based on MNOS/CCD Principles,"" Proc. AIP Conference on 
Neural Networks for Computing, Snowbird, pp. 381 - 385, 1986. 
8. S.C.J. Garth, ""A Chipset for High Speed Simulation of Neural Network Sys- 
tems,"" IEEE Conference on Neural Networks, San Diego, 1987. 
9. A.F. Murray and A. V. W. Smith, ""A Novel Computational and Signalling 
Method for VLSI Neural Networks,"" European Solid State Circuits Conference 
,1987. 
10. A. F. Murray and A. J. W. Smith, ""Asynchronous Arithmetic for VLSI 
Neural Systems,"" Electronics Letters, vol. 23, no. 12, p. 642, June, 1987. 
11. A. F. Murray and A. V. W. Smith, ""Asynchronous VLSI Neural Networks 
using Pulse Stream Arithmetic,"" IEEE Journal of Solid-State Circuits and Sys- 
tems, 1988. To be published 
12. M.E. Gaspar, ""Pulsed Neural Networks: Hardware, Software and the Hop- 
field AfD Converter Example,"" IEEE Conference on Neural Information Pro- 
cessing Systems, Denver, 1987. 
13. M. S. McGregor, P. B. Denyet, and A. F. Murray, ""A Single - Phase Clock- 
ing Scheme for CMOS VLSI,"" Advanced Research in VLSI: Proceedings of the 
1987 Stanford Conference, 1987. 
14. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning Internal 
Representations by Error Propagation,"" Parallel Distributed Processing : 
Explorations in the Microstructure of Cognition, vol. 1, pp. 318 - 362, 1986. 
15. M. Fleisher and E. Levin, ""The Hopfiled Model with Multilevel Neurons 
Models,"" IEEE Conference on Neural Information Processing Systems, Denver, 
1987. 
16. G. Parisi, ""A Memory that Forgets,"" J. Phys. A : Math. Gert., vol. 19, pp. 
L617 - L620, 1986. 
", serial neural network anthoni smith zoe electr univers mayfield bit serial vlsi neural network describ initi architectur array silicon layout board issu surround bit serial arithmet discuss parallel hybrid neural network learn capabl report bit serial network along project bit serial board oper extend network updat time techniqu time multiplex calcul synaps introduct function synthet neural network may aspir mimic abil mani solut abil work corrupt data fault aris parallel distribut knowledg give rise gentl degrad fault attract implement vlsi natur toler could use silicon wafer imperfect degrad approxim proport silicon cast neural network engin neuron state machin gener assum intermedi state switch synaps weight signal neuron less excitatori inhibitori set synapt weight determin stabl state repres learn inform neural relat total neural activ stimul input neuron activ neural activ level neuron activ way react respons chang neural output state time relat activ function function ensur vi larg xi neural updat function therefor repres rate chang neural tq synapt weight number term give neuron array neural function simpl total interconnect network synaps requir multipl summat american institut physic larg number challeng vlsi therefor design compact synaps repeat build vlsi neural network network fix rel network abl synapt weight therefor design neural network vlsi fundament two approach implement function silicon techniqu advantag list along merit demerit bit serial architectur primari advantag digit design synaps array digit memori well incorpor learn therefor possibl without recours unusu techniqu strength digit approach design techniqu well understood nois immun comput speed unattract featur digit circuit complex need state activ real neural network asynchron digit multipli occupi larg give low synaps count singl advantag analog circuitri asynchron behaviour smooth activ circuit element nois immun rel low arbitrarili high precis non volatil memori technolog yet readili learn network lend natur digit design group develop neural chip follow list pretend indic spread analog techniqu use build resistor amplifi network similar propos hopfield tank larg group caltech develop network implement earli vision process function use intrins nonlinear mo transistor subthreshold regim problem implement analog network programm synaps address use garth develop digit neural acceler board effect fast simd processor support memori serial bit bit serial arithmet commun effici comput allow good commun within chip tightli pipelin arithmet ideal neural minimis interconnect requir elimin multi wire although bit parallel design would free comput latenc input pipelin make optim use high bit possibl serial make effici circuit asynchron puls stream vlsi neural addit digit system form substanc hybrid network work outlin report greater detail elsewher gener architectur singl network total interconnect neuron shown figur neuron repres signal vi upward matrix synapt state signal bit horizont bu run synapt synapt oper everi column oper oper add synapt total activ neuron foot synapt therefor multipli signal neuron synapt add product run architectur bit serial puls stream vj gener architectur network total interconnect type architectur mani attract implement dimension summat distribut interconnect input therefor distribut need long rang architectur regular easili hybrid circuitri use signal similar natur neural neuron indic state presenc absenc puls synapf weight time chop presynapt puls stream prior ad activ therefor asynchron impos limit activ neural figur show puls mechan synapt weight store digit memori synapt oper excitatori inhibitori puls input result product synapt run total propag either excitatori inhibitori one binari bit store determin whether excitatori incom excitatori inhibitori puls stream input neuron give neural activ potenti vari smoothli potenti control feedback loop odd number logic invers puls stream neuron denot synapt oper form switch inhibitori input loop excitatori spike subsequ domin activ rise feedback loop oscil period determin delay around result period waveform convert voltag whose puls rate repres neural dissimilar techniqu report elsewher although function execut differ state bit serial neural network overal architectur state bit serial neural network ident puls stream array interconnect synchron wherea puls stream method allow vi assum state network vj constrain result activ function shown figur full digit costli silicon multipl vj mere requir synapt weight right shift multipl right shift multipl trivial vj switchabl much complex five neural state therefor feasibl circuitri complex simpl serial neural state expand bit bit repres show part synapt synapt oper includ bit regist memori block hold synapt bit bu state run horizont synapt singl phase dynam use clock frequenc excess mhz detail synapt oper shown figur synapt weight cycl around regist neural state vj present state first synapt weight multipli neural state signific bit result vj sign extend ry vj activ xj state sigmoid activ section synapt array state activ function neural bit allow word growth run least signific bit signal run synapt column indic arriv lsbit xi run neural state synapt weight right bit ad subtract run add subtract weight total multipl synapt oper state activ alter run final summat foot column threshold extern accord state activ function figur neuron activ increas threshold valu ideal sigmoid activ repres smooth switch neural state state function give superfici better approxim sigrnoid threshold sharp neural dynam learn temperatur analog high give smoother simpler transit control control paramet function sigmoid reduc like threshold effect learn recal threshold state activ discuss section learn recal vlsi constraint implement reduc arithmet network simul conduct verifi state model repres worthwhil simpl threshold problem rather intrins implic learn recal state threshold model sigrnoid activ compar vari temperatur restrict dynam rang weight simul total node network attempt learn random pattern use rule learn algorithm exampl pattern nois recal attempt probe content address properti three differ activ individu weight becom larg beyond maximum valu hardwar determin size synapt weight limit must eight bit weight tii integ seen dynam relafonship smallest possibl largest show exampl result studi learn use activ differ recal use state temperatur state threshold model result increas smooth activ learn improv qualiti learn regardless activ use pattern recognis use state recal effect simpl threshold effect rang restrict assess horizont result mani experi may summaris stste activ learn state activ protract threshold binari pattern inclus intermedi valu extra degre weight set learnt use state activ function learnt via threshold recal properti state threshold network use weight set robust full sigmoid activ better enhanc signific incur move threshold law diminish return appli addit level state issu studi mathemat result agre qualit method tri deal weight inclus term includ learn cycl view techniqu produc desir weight limit time unabl rate decay suffici confirm renormalisafion weight bring larg weight dynam suggest inform throughout numer small weight weight allow weight outsid dynam rang set maximum allow method prove algorithm adjust weight still control compens satur interest note experi indic hopfield net differ differ learn prefer recent acquir memori result experi node integ weight dynam rang necessari give enough storag weight maximum valu perform serious degrad unrestrict state activ function recal activ function recal recal pattern learn state activ function restor use hard threshold activ smooth activ valu result show state model worthi implement neural suggest bit weight project specif hardwar neural board specif neuron board given use state bit serial synaps array derat clock speed synapt weight bit word word length run summat bit allow synaps column comput latenc clock cycl give updat time time load weight array limit support access time load updat time mean network execut one oper much faster neural much faster necessari hardwar therefor develop effect excess speed increas network neural array state synaps current fabric vlsi integr shift regist synaps occupi disappointingli larg silicon synapt achiev suitabl size neural network sever chip need includ board memori control concept shown figur small array pass much larger synapt time array repres anoth set new weight load first set weight tu second set final weight load neuron nxn synapt array array pass small synapt larger synaps shelf ram use store weight whole pipelin maximum figur show board level design acceler chip neural network small move around array give neuron compris vlsi acceler chip give synapt number neuron simul weight store mb ram time partial runninz store separ ram requir next appropri updat time board slower neuron network time arithmet element use achiev network greater ram store network slower unless larger number chip use give larger move conclus strategi design method given construct bit serial neural network chip circuit bit serial coupl arithmet enhanc level integr possibl beyond bit parallel restrict impos weight size arithmet precis vlsi constraint examin shown use associ memori problem believ digit approach repres good compromis accuraci circuit acknowledg level disappoinfingli belief digit approach interest use medium essenti hardwar neural analog techniqu repres best ultim option dimension current pursu techniqu analog static use standard cmo full nonvolatil analog memori mno key long term futur vlsi neural net acknowledg author acknowledg support scienc engin research execut physiolog biochem consequ implement network memori sever hundr neural network connectionist neural network ie confer neural process hopfield comput decis real time visual use analog cmo process publish real time sensori ie neural inform process artifici neural network circuit base aip confer network chipset high speed simul neural network ie confer neural san murray novel comput signal vlsi neural european solid state circuit confer murray arithmet vlsi electron murray vlsi neural network puls stream ie journal circuit publish neural softwar convert ie confer neural inform singl phase scheme cmo advanc research proceed stanford intern error parallel distribut process microstructur fleisher hopfil model multilevel neuron ie confer neural inform process memori,0
61,61,"584 
PHASOR NEURAL NETWORKS 
Andr J. Noest, N.I.B.R., NL-1105 AZ Amsterdam, The Netherlands. 
ABSTRACT 
A novel network type is introduced which uses unit-length 2-vectors 
for local variables. As an example of its applications, associative 
memory nets are defined and their performance analyzed. Real systems 
corresponding to such 'phasor' models can be e.g. (neuro)biological 
networks of limit-cycle oscillators or optical resonators that have 
a hologram in their feedback path. 
INTRODUCTION 
Most neural network models use either binary local variables or 
scalars combined with sigmoidal nonlinearities. Rather awkward coding 
schemes have to be invoked if one wants to maintain linear relations 
between the local signals being processed in e.g. associative memory 
networks, since the nonlinearities necessary for any nontrivial 
computation act directly on the range of values assumed by the local 
variables. In addition, there is the problem of representing signals 
that take values from a space with a different topology, e.g. that 
of the circle, sphere, torus, etc. Practical examples of such a 
signal are the orientations of edges or the directions of local optic 
flow in images, or the phase of a set of (sound or EM) waves as they 
arrive on an array of detectors. Apart from the fact that 'circular' 
signals occur in technical as well as biological systems, there are 
indications that some parts of the brain (e.g. olfactory bulb, cf. 
Dr.B.Baird's contribution to these proceedings) can use limit-cycle 
oscillators formed by local feedback circuits as functional building 
blocks, even for signals without circular symmetry. With respect to 
technical implementations, I had speculated before the conference 
whether it could be useful to code information in the phase of the 
beams of optical neurocomputers, avoiding slow optical switching 
elements and using only (saturating) optical amplification and a 
� American Institute of Physics 1988 
585 
hologram encoding the (complex) 'synaptic' weight factors. At the 
conference, I learnt that Prof. Dana Anderson had independently 
developed an optical device (cf. these proceedings) that basically 
works this way, at least in the slow-evolution limit of the dynamic 
hologram. Hopefully, some of the theory that I present here can be 
applied to his experiment. In turn, such implementations call for 
interesting extensions of the present models. 
BASIC ELEMENTS OF GENERAL PHASOR NETWORKS 
Here I study the perhaps simplest non-scalar network by using unit- 
length 2-vectors (phasors) as continuous local variables. The signals 
processed by the network are represented in the relative phaseangles. 
Thus, the nonlinearities (unit-length 'clipping') act orthogonally to 
the range of the variables coding the information. The behavior of 
the network is invariant under any rigid rotation of the complete set 
of phasors, representing an arbitrary choice of a global reference 
phase. Statistical physicists will recognize the phasor model as a 
generalization of 02-spin models to include vector-valued couplings. 
All 2-vectors are treated algebraically as complex numbers, writing 
Ixl for the length, /x/ for the phase-angle, and  for the complex 
conjugate of a 2-vector x. 
A phasor network then consists of N>>I phasors s. , with Isil=!, 
interacting via couplings cij , with cii = 0. The clj are allowed 
to be complex-valued quantities. For optical implementations this 
is clearly a natural choice, but it may seem less so for biological 
systems. However, if the coupling between two limitcycle oscillators 
with frequency f is mediated via a path having propagationdelay d, 
then that coupling in fact acquires a phaseshift of f.d.2radians. 
Thus, complex couplings can represent such systems more faithfully 
than the usual models which neglect propagationdelays altogether. 
Only 2-point couplings are treated here, but multi-point couplings 
Cijk, etc., can be treated similarly. 
The dynamics of each phasor depends only on its local field 
1 .. sj + n. where z is the number of inputs 
hi=  cij  ' 
586 
c..0 per cell and n. is a local noise term (complex and Gaussian). 
Various dynamics are possible, and yield largely similar results: 
Continuous-time, parallel evolution: (""type A"") 
d (/si/) = Ihil.sin(/h./ - /s./) 
Discrete-time updating: si(t+t)= h./ Ihil either serially in 
1 ' 
random i-sequence (""type B""), or in parallel for all i (""type C""). 
The natural time scale for type-B dynamics is obtained by scaling 
the discrete time-interval t as,,,1/N ; type-C dynamics has t=l. 
LYAPUNOV FUNCTION (alias ""ENERGY"", or ""HAMILTONIAN"" ) 
If one limits the attention temporarily to purely deterministic 
(ni=0) models, then the question suggests itself whether a class of 
couplings exists for which one can easily find a Lyapunov function 
i.e. a function of the network variables that is monotonic under the 
dynamics. A well-known example 1 is the 'energy' of the binary and 
scalar Hopfield models with symmetric interactions. It turns out that 
a very similar function exists for phasor networks with type-A or B 
dynamics and a Hermitian matrix of couplings. 
= hi = cij sj 
x i,j 
Hermiticity (clj=jl) makes H real-valued and non-increasing in time. 
This can be shown as follows, e.g. for the serial dynamics (type B). 
Suppose, without loss of generality, that phasor i=l is updated. 
Then -z H = z ! h 1 + Zi cil S 1 + EE i cij sj 
x>l i,j>l 
= z 1 hl + Sl'ZCil i + constant. 
i>1 
With Hermitian couplings, H becomes real-valued, and one also has 
..Cil ' = i>lli ' = z  1 . 
x>l x x 
Thus, - H - constant = 1 hl + Sl 1 = 2 Re(s 1 1) . 
Clearly, H is minimized with respect to s 1 by Sl(t+l) = hl/Ihll - 
Type-A dynamics has the same Lyapunovian, but type C is more complex. 
The existence of Hermitian interactions and the corresponding energy 
function simplifies greatly the understanding and design of phasor 
networks, although non-Hermitian networks can still have a Lyapunov- 
587 
function, and even networks for which such a function is not readily 
found can be useful, as will be illustrated later. 
AN APPLICATION : ASSOCIATIVE MEMORY. 
A large class of collective computations, such as optimisations 
and content-addressable memory, can be realised with networks having 
an energy function. The basic idea is to define the relevant penalty 
function over the solution-space in the form of the generic 'energy' 
of the net, and simply let the network relax to minima of this energy. 
As a simple example, consider an associative memory built within the 
framework of Hermitian phasor networks. 
In order to store a set of patterns in the network, i.e. to make 
a set of special states (at least approximatively) into attractive 
fixed points of the dynamics, one needs to choose an appropriate 
set of couplings. One particularly simple way of doing this is via 
the phasor-analog of ""Hebb's rule"" (note the Hermiticity) 
c.. =  s(k) (k! where s(k)is phasor i in learned pattern k. 
3 k  3 
The rule is understood to apply only to the input-sets i of each i. 
Such couplings should be realisable as holograms in optical networks, 
but they may seem unrealistic in the context of biological networks 
of oscillators since the phase-shift (e.g. corresponding to a delay) 
of a connection may not be changeable at will. However, the required 
coupling can still be implemented naturally if e.g. a few paths with 
different fixed delays exist between pairs of cells. The synaps in 
each path then simply becomes the projection of the complex coupling 
on the direction given by the phase of its path, i.e. it is just a 
classical Hebb-synapse that computes the correlation of its pre- and 
post-synaptic (imposed) signals, which now are phase-shifted versions 
of the phasors s!.k)The required complex c.. are then realised as the 
1 13 
vector sum over at least two signals arriving via distinct paths with 
corresponding phase-shift and real-valued synaps. Two paths suffice 
if they have orthogonal phase-shifts, but random phases will do as 
well if there are a reasonable number of paths. 
We need to have a concise way of expressing how 'near' any state 
of the net is to one or more of the stored patterns. A natural way 
588 
of doing this is via a set of p order parameters called ""overlaps"" 
N 
1 (k){ ; 0 < M k < 1 ; 1 < k < p . 
Mk= Isi. i .... 
i , 
P 2 
Note the constraint on the p overlaps M k 5 1 if all the patterns 
k 
are orthogonal, or merely random in the limit N-OO. This will be 
assumed from now on. Also, one sees at once that the whole behaviour 
of the network does not depend on aSy rigid rotation of all phasors 
over some angle since H, Mk, cij and the dynamics are invariant under 
multiplication of all s. by a fixed phasor : s = S.s. with ISI=i. 
1 1 1 
Let us find the performance at low loading: N,p,z-oo, with p/z-0 
and zero local noise. Also assume an initial overlap m>0 with only 
one pattern, say with k=l. Then the local field is 
1 j  s(k)(k) h!l)+ h* 
= s.. i ' j = 1 i , where 
hi  i 3 k 
h(1) 1 s(l! - !l!s j = ml s(l!s + 0(1//) with sf(i);Isl=l 
i =  i j-i 3 ' i ' ' 
* Z : o< 
and h = s . . 
i  ji 3 3 
Thus, perfect recall (Mi=I) occurs in one 'pass' at loadings p/zO. 
EXACTLY SOLVABLE CASE: SPARSE and ASYMMETRIC couplings 
Although it would be interesting to develop the full thermodynamics 
of Hermitian phasor networks with p and z of order N (analogous to the 
analysis of the finite-T Hopfield model by the teams of Amir 2 and van 
Hemmen3), I will analyse here instead a model with sparse, asymmetric 
connectivity, which has the great advantages of being exactly solvable 
with relative ease, and of being arguably more realistic biologically 
and more easily scalable technologically. In neurobiological networks 
a cell has up to zg104 asymmetric connections, whereas Ng101 This 
probably has the same reason as applies to most VLSI chips, namely to 
alleviate wiring problems. For my present purposes, the theoretical 
advantage of getting some exact results is of primary interest 4. 
Suppose each cell has z incoming connections from randomly selected 
t 
other cells. The state of each cell at time t depends on at most z 
cells at time t=0. Thus, if zt<< N1/2and N large, then the respective 
589 
4 
trees of 'ancestors' of any pair cells have no cells in common . In 
particular, if z~ (logN) x, for any finite x, then there are no common 
ancestors for any finite time t in the limit N-O. For fundamental 
information-theoretic reasons, one can hope to be able to store p 
patterns with p at most of order z for any sort of 2-point couplings. 
Important questions to be settled are: What are the accuracy and 
speed of the recall process, and how large are the basins of the 
attractors representing recalled patterns? 
Take again initial conditions (t=0) with, say, m(t)= M 1 > M>i = 0. 
Allowing again local random Gaussian (complex) noise n., the local 
fields become, in now familiar notation, h.= h!l)+ h  n.. 
1 1 1 1 
As in the previous section, the h(1)term consists of the 'signal' 
1 
m(t).s i (modulo the rigid rotation S) and a random term of variance 
, 
at most 1/z. For p ~ z, the h. term becomes important. Being sums of 
1 , 
z(p-1) phasors oriented randomly relative to the signal, the h. are 
independent Gaussian zero-mean 2-vectors with variance (p-1)/z , as 
2 
p,z and N- . Finally, let the local noises n. have variance r . 
Then the distribution of the si(t+l ) phasors can be found in terms of 
the signal m(t) and the total variance a=(p/z)+r2of the random h+n.. 
1 1 
After somewhat tedious algebraic manipulations (to be reorted in 
detail elsewhere) one obtains the dynamic behaviour of m(t) : 
m(t+l) = F(m(t),a) for discrete parallel (type-C) dynamics, 
and 
d m(t) = F(m(t),a) - m(t) for type-A or type-B dynamics , 
where the function F(m,a) = 
m , fdx. (l+cos2x).exp[-(m.sinx)2/a]. (l+erf[ (m.cosx)/4) 
* * 
The attractive fixed points M (a)= F(M ,a) represent the retrieval 
accuracy when the loading-plus-noise factor equals a. See figure 1. 
* a 3 ) 
For a<<l one obtains the expansion 1-M (a) = a/4 + 3a2/32 + O( � 
* 1/2at 
The recall solutions vanish continuously as M ~(ac-a) a =/4. 
c 
One also obtains (at any t) the distribution of the phase scatter of 
the phasors around the ideal values occurring in the stored pattern. 
59O 
where 
P(/ui/) = (1/2R).exp(-m2/a).(l+/.L.exp(L2).(l+erf(L)) 
cos(/ui/ s. !k)(modulo S). 
L = (m//). ) , and ui= 
Useful approximations for the high, respectively low M regimes are: 
� /)2/a] 
 >>,J': P(/ui/) = (M/,/ exp[-(M./ui 
; I/ui/I 
M <<t': p(/ui/) = (1/2).(l+L.v') 
Figure 1. 
RETRIEVAL-ERROR and BASIN OF ATTRACTION versus LOADING + NOISE. 
�o'. oo 
0.10 
0.20 
0.30 
0. qo o. ;o o. 60 
a = p/z + 
0 . 0 0 . 80 0 . 90 1 . 00 
591 
DISCUSSION 
It has been shown that the usual binary or scalar neural networks 
can be generalized to phasor networks, and that the general structure 
of the theoretical analysis for their use as associative memories can 
be extended accordingly. This suggests that many of the other useful 
applications of neural nets (back-prop, etcO can also be generalized 
to a phasor setting. This may be of interest both from the point of 
view of solving problems naturally posed in such a setting, as well 
as from that of enabling a wider range of physical implementations, 
such as networks of limit-cycle oscillators, phase-encoded optics, 
or maybe even Josephson-junctions. 
The performance of phasor networks turns out to be roughly similar 
to that of the scalar systems; the maximum capacity p/z=/4 for 
phasor nets is slightly larger than its value 2/ for binary nets, 
but there is a seemingly faster growth of the recall error 1-M at 
small a (linear for phasors, against exp(-1/(2a)) for binary nets). 
However, the latter measures cannot be compared directly since they 
stem from quite different order parameters. If one reduces recalled 
phasor patterns to binary information, performance is again similar. 
Finally, the present methods and results suggest several roads to 
further generalizations, some of which may be relevant with respect 
to natural or technical implementations. The first class of these 
involves local variables ranging over the k-sphere with k>l. The 
other generalizations involve breaking the O(n) (here n=2) symmetry 
of the system, either by forcing the variables to discrete positions 
on the circle (k-sphere), and/or by taking the interactions between 
two variables to be a more general function of the angular distance 
between them. Such models are now under development. 
REFERENCES 
1. J.J.Hopfield, Proc. Nat.Acad. Sci.USA 79, 2554 (1982) and 
idem, Proc.Nat.Acad. Sci.USA 81, 3088 (1984). 
2. D.J.Amit, H.Gutfreund and H.Sompolinski, Ann. Phys. 173, 30 (1987). 
3. D.Grensing, R.Kuhn and J.L. van Hemmen, J.Phys.A 20, 2935 (1987). 
4. B.Derrida, E.Gardner and A.Zippelius, Europhys.Lett. 4, 167 (1987) 
", neural network az novel network type introduc use local exampl associ net defin perform real system model oscil optic reson hologram feedback neural network model use either binari local variabl combin sigmoid rather awkward code invok one want maintain linear relat local signal process associ memori sinc nonlinear necessari nontrivi act directli rang valu assum local problem repres signal take valu space differ practic exampl orient edg direct local optic phase set wave array apart fact occur technic well biolog part brain olfactori contribut use form local feedback circuit function build even signal without circular respect specul confer could use code inform phase optic avoid slow optic switch use optic amplif american institut physic encod weight learnt dana anderson independ optic devic basic least limit dynam theori present implement call extens present element gener phasor network studi perhap simplest network use continu local signal network repres rel nonlinear act orthogon rang variabl code behavior network invari rigid rotat complet set repres arbitrari choic global refer statist physicist recogn phasor model model includ treat algebra complex write complex phasor network consist phasor via coupl cij cii clj allow optic implement clearli natur may seem less biolog coupl two limitcycl oscil frequenc mediat via path propagationdelay coupl fact acquir phaseshift complex coupl repres system faith usual model neglect propagationdelay coupl treat coupl treat dynam phasor depend local field sj number input cij per cell local nois term dynam yield larg similar parallel ihil either serial parallel natur time scale dynam obtain scale discret dynam function one limit attent temporarili pure determinist question suggest whether class exist one easili find lyapunov function function network variabl monoton exampl binari hopfield model symmetr turn similar function exist phasor network hermitian matrix hi cij sj make shown serial dynam without loss phasor cil ee cij sj hl hermitian becom one also constant hl sl minim respect dynam type exist hermitian interact correspond energi simplifi greatli understand design phasor although network still even network function readili illustr applic associ larg class collect optimis realis network energi basic idea defin relev penalti form gener simpli let network relax minima simpl consid associ memori built within hermitian phasor order store set pattern make set special state least attract point one need choos appropri one particularli simpl way via phasor learn pattern rule understood appli coupl realis hologram optic may seem unrealist context biolog network oscil sinc correspond connect may changeabl requir still implement natur path fix delay exist pair synap path simpli becom project complex coupl direct given phase comput correl version phasor requir complex realis sum least two signal arriv via distinct path two path suffic orthogon random phase reason number need concis way express state net one store natur way via set order paramet call constraint overlap pattern mere random limit one see whole behaviour network depend sy rigid rotat phasor angl sinc cij dynam invari fix phasor us find perform low zero local also assum initi overlap say local field ml perfect recal occur one load solvabl spars asymmetr coupl would interest develop full thermodynam hermitian phasor network order hopfield model team amir van analys instead model asymmetr great advantag exactli solvabl rel arguabl realist biolog easili scalabl neurobiolog network cell asymmetr wherea reason appli vlsi name wire present theoret get exact result primari interest cell incom connect randomli select state cell time depend time respect pair cell cell common finit common finit time limit fundament one hope abl store order sort question settl accuraci recal larg basin repres recal initi condit local random gaussian nois local familiar previou consist rigid rotat random term varianc term becom sum phasor orient randomli rel gaussian varianc let local nois varianc distribut phasor found term signal total varianc random somewhat tediou algebra manipul one obtain dynam behaviour discret parallel dynam function attract fix point repres retriev factor equal see figur one obtain expans recal solut vanish continu also obtain distribut phase scatter phasor around ideal valu occur store approxim respect low regim basin attract versu load oo qo shown usual binari scalar neural network gener phasor gener structur theoret analysi use associ memori extend suggest mani use neural net also gener phasor may interest point solv problem natur pose well enabl wider rang physic network mayb even perform phasor network turn roughli similar scalar maximum capac net slightli larger valu binari seemingli faster growth recal error binari latter measur can not compar directli sinc quit differ order one reduc recal pattern binari perform present method result suggest sever road may relev respect natur technic first class local variabl rang gener involv break symmetri either forc variabl discret posit circl take interact variabl gener function angular distanc model van,0
62,62,"592 
A Trellis-Structured Neural Network* 
Thomas Petsche t and Bradley W. Dickinson 
Princeton University, Department of Electrical Engineering 
Princeton, NJ 08544 
Abstract 
We have developed a neural network which consists of cooperatively inter- 
connected Grossberg on-center off-surround subnets and which can be used to 
optimize a function related to the log likelihood function for decoding convolu- 
tional codes or more general FIR signal deconvolution problems. Connections in 
the network are confined to neighboring subnets, and it is representative of the 
types of networks which lend themselves to VLSI implementation. Analytical and 
experimental results for convergence and stability of the network have been found. 
The structure of the network can be used for distributed representation of data 
items while allowing for fault tolerance and replacement of faulty units. 
1 Introduction 
In order to study the behavior of locally interconnected networks, we have focused 
on a class of ""trellis-structured"" networks which are similar in structure to multilayer 
networks [5] but use symmetric connections and allow every neuron to be an output. 
We are studying such. locally interconnected neural networks because they have the 
potential to be of great practical interest. Globally interconnected networks, e.g., 
Hopfield networks [3], are difficult to implement in VLSI because they require many 
long wires. Locally connected networks, however, can be designed to use fewer and 
shorter wires. 
In this paper, we will describe a subclass of trellis-structured networks which op- 
timize a function that, near the global minimum, has the form of the log likelihood 
function for decoding convolutional codes or more general finite impulse response sig- 
nMs. Convolutional codes, defined in section 2, provide an alternative representation 
scheme which can avoid the need for global connections. Our network, described in 
section 3, can perform maximum likelihood sequence estimation of convolutional coded 
sequences in the presence of noise. The performance of the system is optimal for low 
error rates. 
The specific application for this network was inspired by a signal decomposition 
network described by Hopfield and Tank [6]. However, in our network, there is an 
emphasis on local interconnections and a more complex neural model, the Grossberg 
on-center off-surround network [2], is used. A modified form of the Gorssberg model 
is defined in section 4. Section 5 presents the main theoretical results of this paper. 
Although the deconvolution network is simply a set of cooperatively interconnected 
*Supported by the Office of Naval Research through grant N00014-83-K-0577 and by the National 
Science Foundation through grant ECS84-05460. 
tPermanent address: Siemens Corporate Research and Support, Inc., 105 College Road East, 
Princeton, NJ 08540. 
American Institute of Physics 1988 
593 
on-center off-surround subnetworks, and absolute stability for the individual subnet- 
works has been proven [1], the cooperative interconnections between these subnets 
make a similar proof difficult and unlikely. We have been able, however, to prove 
equiasymptotic stability in the Lyapunov sense for this network given that the gain 
of the nonlinearity in each neuron is large. Section 6 will describe simulations of the 
network that were done to confirm the stability results. 
2 Convolutional Codes and MLSE 
In an error correcting code, an input sequence is transformed from a b-dimensional 
input space to an M-dimensional output space, where M _ b for error correction 
and/or detection. In general, for the b-bit input vector U - (u,..., ub) and the M- 
bit output vector V - (v,..., VM), we can write V -- F(u,..., ub). A convolutional 
code, however, is designed so that relatively short subsequences of the input vector 
are used to determine subsequences of the output vector. For example, for a rate 1/3 
convolutional code (where M  3b), with input subsequences of length 3, we can write 
the output, V = (v,..., vb) for vi - (vi,, vi,2, vi,3), of the encoder as a convolution 
of the input vector U -- (u,..., ub, 0, 0) and three generator sequences 
go=(1 i 1) g=(1 10) g2 =(0 i 1). 
This convolution can be written, using modulo-2 addition, as 
i 
vi --  ukgi-k (1) 
k=max(1,i-2) 
In this example, each 3-bit output subsequence, vi, of V depends only on three 
bits of the input vector, i.e., vi - f(ui-2, ui_, ui). In general, for a rate 1/n code, the 
coastraiat leagth, K, is the number of bits of the input vector that uniquely determine 
each a-bit output subsequence. In the absence of noise, any subsequences in the 
input vector separated by more than K bits (i.e., that do not overlap) will produce 
subsequences in the output vector that are independent of each other. 
If we view a convolutional code as a special case of block coding, this rate 1/3, 
K - 3 code converts a b-bit input word into a codeword of length 3(b + 2) where 
the 2 is added by introducing two zeros at the end of every input to ""zero-out"" the 
code. Equivalently, the coder can be viewed as embedding 2  memories into a 2 3(+)- 
dimensional space. The minimum distance between valid memories or codewords in 
this space is the free distaace of the code, which in this example is 7. This implies 
that the code is able to correct a minimum of three errors in the received signal. 
For a convolutional code with constraint length K, the encoder can be viewed as 
a finite state machine whose state at time i is determined by the K - I input bits, 
ui-k,. �., ui_. The encoder can also be represented as a trellis graph such as the one 
shown in figure i for a K - 3, rate 1/3 code. In this example, since the constraint 
length is three, the two bits ui_ and ui- determine which of four possible states the 
encoder is in at time i. In the trellis graph, there is a set of four nodes arranged in a 
vertical column, which we call a stage, for each time step i. Each node is labeled with 
the associated values of ui_ and ui_l. In general, for a rate 1/n code, each stage of 
the trellis graph contains 2 K-1 nodes, representing an equal number of possible states. 
A trellis graph which contains S stages therefore fully describes the operation of the 
encoder for time steps i through S. The graph is read from left to right and the upper 
edge leaving the right side of a node in stage i is followed if ui is a zero; the lower edge 
594 
stage i-2 stage i-1 stage i stage i+1 stage i+2 
0-- 000'- 000 0,/( 000000 state 1 
111 4 111X 111 4 -- 11 4  
X,._. 0 k,./O k,...O  00/ state 2 
 001 x)lu, f  001 ,10) 0-.01 10)g (01 (, 10) state3 
1)  010' 010'-- 010 010- state4 
Figure 1: Part of the trellis-code representation for a rate 1/3, K = 3 convolutional 
code, 
if ui is a one. The label on the edge determined by ui is vi, the output of the encoder 
given by equation i for the subsequence ui-2, ui_, ui. 
Decoding a noisy sequence that is the output of a convolutional coder plus noise 
is typicaJly done using a maximum likelihood sequence estimation (MLSE) decoder 
which is designed to accept as input a possibly noisy convolutional coded sequence, P, 
and produce as output the maximum likelihood estimate, ', of the originM sequence, 
V. If the set of possible n(b+ 2)-bit encoder output vectors is {Xm : m = 1, ..., 2'(b+2)} 
and Xm, i is the ith n-bit subsequence of Xm and ri is the ith n-bit subsequence of P 
then 
b 
Z = argmax 1-I P(ri ] Xm,i) (2) 
Xm i-1 
That is, the decoder chooses the Xm that maximizes the conditional probability, given. 
Xm, of the received sequence. 
A binary symmetric channel (BSC) is an often used transmission channel model in 
which the decoder produces output sequences formed from an alphabet containing two 
symbols and it is assumed that the probability of either of the symbols being affected 
by noise so that the other symbol is received is the same for both symbols. In the 
case of a BSC, the log of the conditional probability, P(ri [ Xm,i) , is a linear function 
of the Hamming distance between ri and Xm, i SO that maximizing the right side of 
equation 2 is equivaJent to choosing the X, that has the most bits in common with 
P. Therefore, equation 2 can be rewritten as 
9 -- argm_.a3(   [r,j(g6m,i,l) (3) 
� ,K-m i----1 /----1 
where Xm,i, l is the /th bit of the ith subsequence of X m and �a(b) is the indicator 
function: I,(b) -- 1 if and only if a equals b. 
For the generaJ case, maximum likelihood sequence estimation is very expensive 
since the number of possible input sequences is exponential in b. The Viterbi algo- 
rithm [7], fortunately, is able to take advantage of the structure of convolutional codes 
and their trellis graph representations to reduce the complexity of the decoder so that 
595 
it is only exponential in K (in general K << b). An optimum version of the Viterbi al- 
gorithm examines all b stages in the trellis graph, but a more practical and very nearly 
optimum version typically examines approximately 5K stages, beginning at stage i, 
before making a decision about ui. 
3 A Network for MLSE Decoding 
The structure of the network that we have defined strongly reflects the structure of a 
trellis graph. The network usually consists of 5K subnetworks, each containing 2 K-1 
neurons. Each subnetwork corresponds to a stage in the trellis graph and each neuron 
to a state. Each stage is implemented as an ""on-center off-surround"" competitive 
network [2], described in more detail in the next section, which produces as output a 
contrast enhanced version of the input. This contrast enhancement creates a ""winner 
take all"" situation in which, under normal circumstances, only one neuron in each 
stage --the neuron receiving the input with greatest magnitude -- will be on. The 
activation pattern of the network after it reaches equihbrium indicates the decoded 
sequence as a sequence of ""on"" neurons in the network. If the j-th neuron in subnet i, 
N},j is on, then the node representing state j in stage i hes on the network's estimate 
of the most likely path. 
For a rate 1In code, there is a symmetric cooperative connection between neurons 
A,j and A+,k if there is an edge between the corresponding nodes in the trellis 
graph. If (xi,j&,...,xi,j,,,) are the encoder output bits for the transition between 
these two nodes and (%,..., ri,,) are the received bits, then the connection weight 
for the symmetric cooperative connection between A,j and A+, is 
(4) 
If there is no edge between the nodes, then mi,j, = O. 
Intuitively, it is easiest to understand the action of the entire network by exam- 
ining one stage. Consider the nodes in stage i of the trellis graph and assume that 
the conditional probabilities of the nodes in stages i - i and i + i are known. (All 
probabilities are conditional on the received sequence.) Then the conditional proba- 
bility of each node in stage i is simply the sum of the probabihties of each node in 
stages i - i and i + 1 weighted by the conditional transition probabihties. If we look 
at stage i in the network, and let the outputs of the neighboring stages i- i and 
i + 1 be fixed with the output of each neuron corresponding to the ""likelihood"" of 
the corresponding state at that stage, then the final outputs of the neurons A/},j will 
correspond to the ""likelihood"" of each of the corresponding states. At equilibrium, the 
neuron corresponding to the most likely state will have the largest output. 
4 The Neural Model 
The ""on-center off-surround"" network[2] is used to model each stage in our network. 
This model allows the output of each neuron to take on a range of values, in this 
case between zero and one, and is designed to support contrast enhancement and 
competition between neurons. The model also guarantees that the final output of 
each neuron is a function of the relative intensity of its input as a fraction of the total 
input provided to the network. 
596 
Using the ""on-center off-surround"" model for each stage and the interconnection 
weights, rni,j,k, defined in equation 4, the differential equation that governs the in- 
stantaneous activity of the neurons in our deconvolution network with S stages and 
N states in each stage can be written as 
N 
iti, j -- - Aui, j q- ( B - ui,j ) ( f ( ui,j ) q- [Tl2i_l,k,j f ( Ui_l,k ) q- mi,j,k f ( ui+ l, )]) 
k=l 
N N 
kj /=1 
(5) 
where f(x) = (1 + �-x)-l, } iS the gain of the nonlinearity, and A, B, and C are 
constants 
For the analysis to be presented in section 5, we note that equation 5 can be 
rewritten more compactly in a notation that is similar to the equation for additive 
analog neurons given in [4]: 
s N 
k=l /=1 
where, for 1 < I < N, 
(6) 
'i,j,i,l -- 1 
q 
Si,j,i+l,l =-  mi,q,l 
q 
Si,j,,t=O � k  {i- l,i,i+ l} 
Ti,.i,i,j = B 
Ti,,,I=-C � t g j 
Ti,j,i-l,t -- Bmi_l,l,j -- U  mi_l,t, q 
Ti,j,i+l,l = Brni,j,l - C  mi,q,l 
(7) 
To eliminate the need for global interconnections within a stage, we can add two 
summing elements to calculate 
N N N 
Xi =  f(zi,j) and 
j=l j=l k=l 
Using these two sums allows us to rewrite equation 5 as 
, = -Au, + ( + c)(f(u,) + fi,) - u,(x + s) (9) 
This form provides a more compact design for the network that is particularly suited 
to implementation as a digital filter or for use in simulations since it greatly reduces 
the calculations required. 
Ji -- E E [mi-l,k,jf(ui-1, k) q- mi,j,kf(Ui+l,k)] (8) 
5 Stability of the Network 
The end of section 3 described the desired operation of a single stage, given that the 
outputs of the neighboring stages are fixed. It is possible to show that in this situation 
a single stage is stable. To do this, fix f(u,t) for k  {i - 1, i + 1} so that equation 6 
can be written in the form originally proposed by Grossberg [2]: 
N N 
-- 
(0) 
597 
where Ii,j = '.kN-_l [7ti-l,k,j f(Ui-l,k ) q- mi,j,kf(ui+l,k )]. 
Equation 10 is a special case of the more general nonlinear system 
:i -- ai(xi)(bi(xi) -- . Ci,kdk(Xk)) 
k----1 
(11) 
where: (1) ai(xi) is continuous and ai(xi) > 0 for xi > 0; (2) bi(xi) is continuous 
for :ri >_ 0; (3) ci,k = ck,i; and (4) di(xi) _> 0 for all xi � (-ec, ec). Cohen and 
Grossberg [1] showed that such a system has a global Lyapunov function: 
V(x) -- - bi(i)dti(i)d(i) q-  j--lk:l 
(12) 
and that, therefore, such a system is equiasymptotically stable for all constants and 
functions satisfying the four constraints above. In our case, this means that a single 
stage has the desired behavior when the neighboring stages are fixed. If we take the 
output of each neuron to correspond to the likelihood of the corresponding state then, 
if the two neighboring stages are fixed, stage i will converge to an equilibrium point 
where the neuron receiving the largest input will be on and the others will be off, just 
as it should according to section 2. 
It does not seem possible to use the Cohen-Grossberg stability proof for the entire 
system in equation 5. In fact, Cohen and Grossberg note that networks which allow 
cooperative interactions define systems for which no stabihty proof exists [1]. 
Since an exact stabihty proof seems unlikely, we have instead shown that in the 
limit as the gain, A, of the nonlinearity gets large the system is asymptoticMly stable. 
Using the notation in [4], define Vi = f(ui) and a normalized nonlinearity /(.) such 
that f-(�) = Aui. Then we can define an energy function for the deconvolution 
network to be 
(13) 
The time derivative of E is 
=- i,j dt k,l 
1 /v.,?l ) 
k,l 
(14) 
It is difficult to prove that/ is nonpositive because of the last term in the parentheses. 
However, for large gain, this term can be shown to have a negligible effect on the 
derivative. 
It can be shown that for f(u) = (1 + e-'u) -, f' ]/-l(()d( is bounded above 
by log(2). In this deconvolution network, there are no connections between neurons 
unless they are in the same or neighboring stages, i.e., Si,j,,t = 0 for li - k[ > 1 and 
1 is restricted so that 0 < 1 < S, so there are no more than 3S non-zero terms in the 
problematical summation. Therefore, we can write that 
hm 1 v*,t 
.k--oo-- y Si'j'k'l f-l(�) d c - 0 
k,l 
598 
Then, in the limit as A -+ oo, the terms in parentheses in equation 14 converge to/ti 
in equation 6, so that lim / =  � Using the chain rule, we can rewrite this 
-oo dt u,. 
i,j 
aS 
lira - - f-('J) 
It can Mso be shown that that, if f(.) is a monotocay increasing hnction then 
P 5 o, 
 ()) 0 for  . This impes that for a u = ,..., 
and, therefore, for large gns, E as defined in equation 13 is a Lyapunov hnction for 
the system described by equation 5 and the network is equiasymtoticay stable. 
If we apply a similar asymptotic argument to the energy hnction, equation 13 
reduces to 
1 
E = - i.j,lTi,j,,l,jVk,l (15) 
which is the Lyapunov hnction for a network of discontinuous on-off neurons with 
interconnection matrix T. For the binary neuron case, it is hirly straight forward to 
show that the energy hnction has minima at the desired decoder outputs if we assume 
that only one neuron in each stage may be on and that B and C are appropriately 
chosen to hvor this. However, since there are O(SN) terms in the disturbance 
summation ih equation 15, convergence in this case is not as hst as for the derivative 
of the energy hnction in equation 13, which has only O(S) terms in the summation. 
6 Simulation Results 
The simulations presented in this section are for the rate 1/3, K = 3 convolutional code 
illustrated in figure 1. Since this code has a constraint length of 3, there are 4 possible 
states in each stage and an MLSE decoder would normally examine a minimum of 
5K subsequences before making a decision, we will use a total of 16 stages. In these 
simulations, the first and last stage are fixed since we assume that we have prior 
knowledge or a decision about the first stage and zero knowledge about the last stage. 
The transmitted codeword is assumed to be all zeros. 
The simulation program reads the received sequence from standard input and uses 
it to define the interconnection matrix W according to equation 4. A relaxation 
subroutine is then called to simulate the performance of the network according to an 
Euler discretization of equation 5. Unit time is then defined as one RC time constant of 
the unforced system. All variables were defined to be single precision (32 bit) floating 
point numbers. 
Figure 2a shows the evolution of the network over two unit time intervals with the 
sampling time T = 0.02 when the received codeword contains no noise. To interpret 
the figure, recall that there are 16 stages of 4 neurons each. The output of each stage 
is a vertical set of 4 curves. The upper-left set is the output of the first stage; the 
upper-most curve is the output of the first neuron in the stage. For the first stage, 
the first neuron has a fixed output of 1 and the other neurons have a fixed output of 
0. The outputs of the neurons in the last stages are fixed at an intermediate value to 
represent zero a priori knowledge about these states. Notice that the network reaches 
an equilibrium point in which only the top neurons in each state (representing the ""00"" 
node in figure 1) are on and all others are off. This case illustrates that the network 
can correctly decode an unerrored input and that it does so rapidly, i.e., in about one 
time constant. In this case, with no errors in the input, the network performs the 
599 
0 2 0 2 
5 6 
14 
f 15 
0 2 0 10 0 10 0 10 0 10 
(a) (b) 
Figure 2: Evolution of the trellis network for (a) unerrored input, (b) input with burst 
errors: l is 000 000 000 000 000 000 000 000 111 000 000 000 000 000 000. ,X = 10., 
A = 1.0, B = 1.0, C = 0.75, T = 0.02. The initial conditions are x, = 1., x,j = 0.0, 
x16,j = 0.2, all other xi,j = 0.0. 
same function as Hopfield and Tank's network and does so quite well. Although we 
have not been able to prove it analytically, all our simulations support the conjecture 
that if x4j(0) = � for all i and j then the network will always converge to the global 
minimum. 
One of the more difficult decoding problems for this network is the correction of 
a burst of errors in a transition subsequence. Figure 2b shows the evolution of the 
network when three errors occur in the transition between stages 9 and 10. Note that 
10 unit time intervals are shown since complete convergence takes much longer than 
in the first example. However, the network has correctly decoded many of the stages 
far from the burst error in a much shorter time. 
If the received codeword contains scattered errors, the convolutional decoder should 
be able to correct more than 3 errors. Such a case is shown in figure 3a in which the 
received codeword contains 7 errors. The system takes longest to converge around two 
transitions, 5-6 and 11-12. The first is in the midst of consecutive subsequences which 
each have one bit errors and the second transition contains two errors. 
To illustrate that the energy function shown in equation 13 is a good candidate 
for a Lyapunov function for this network, it is plotted in figure 3b for the three cases 
described above. The nonlinearity used in these simulations has a gain of ten, and, as 
predicted by the large gain limit, the energy decreases monotonically. 
To more thoroughly explore the behavior of the network, the simulation program 
was modified to test many possible error patterns. For one and two errors, the program 
exhaustively tested each possible error pattern. For three or more errors, the errors 
were generated randomly. For four or more errors, only those errored sequences for 
which the MLS estimate was the sequence of all zeros were tested. The results of 
this simulation are summarized in the column labeled ""two-nearest"" in figure 4. The 
performance of the network is optimum if no more than 3 errors are present in the 
received sequence, however for four or more errors, the network fails to correctly decode 
some sequences that the MLSE decoder can correctly decode. 
600 
80 
60 
4O 
2O 
_20/0 err�rs I   
0.0 0.5 1.0 
0 2 0 2 0 2 0 2 time 
(a) (b) 
1.5 2.0 
Figure 3: (a) Evolution of the trellis network for input with distributed errors. The 
input, P, is 000 010 010 010 100 001 000 000 000 000 110 000 000 000 000. The 
constants and initial conditions are the same as in figure 2. (b) The energy function 
defined in equation 13 evaulated for the three simulations discussed. 
errored number of number of errors 
bits test vectors wo-nearest four-nearest 
0 1 0 0 
I 39 0 0 
2 500 0 0 
3 500 0 0 
4 500 7 0 
5 500 33 20 
6 500 72 68 
7 500 132 103 
Total 2500 244 191 
Figure 4: Simulation results for a deconvolution network for a K = 3, rate 1/3 code. 
The network parameters were: A - 15, A = 6, B = 1, C = 0.45, and T - 0.025. 
For locally interconnected networks, the major concern is the flow of information 
through the network. In the simulations presented until now, the neurons in each stage 
are connected only to neurons in neighboring stages. A modified form of the network 
was also simulated in which the neurons in each stage are connected to the neurons 
in the four nearest neighboring stages. To implement this network, the subroutine to 
initialize the connection weights was modified to assign a non-zero value to Wi,j,i+2,k. 
This is straight-forward since, for a code with a constraint length of three, there is a 
single path connecting two nodes a distance two apart. 
The results of this simulation are shown in the column labeled ""four-nearest"" in 
figure 4. It is easy to see that the network with the extra connections performs better 
601 
than the previous network. Most of the errors made by the nearest neighbor network 
occur for inputs in which the received subsequences ri and ri+l or ri+2 contain a total 
of four or more errors. It appears that the network with the additional connections 
is, in effect, able to communicate around subsequences containing errors that block 
communications for the two-nearest neighbor network. 
7 Summary and Conclusions 
We have presented a locally interconnected network which minimizes a function that 
is analogous to the log likelihood function near the global minimum. The results of 
simulations demonstrate that the network can successfully decode input sequences 
containing no noise at least as well as the globally connected Hopfield-Tank [6] de- 
composition network. Simulations also strongly support the conjecture that in the 
noiseless case, the network can be guaranteed to converge to the global minimum. In 
addition, for low error rates, the network can also decode noisy received sequences. 
We have been able to apply the Cohen-Grossberg proof of the stability of ""on- 
center off-surround"" networks to show that each stage will maximize the desired local 
""likelihood"" for noisy received sequences. We have also shown that, in the large gain 
limit, the network as a whole is stable and that the equilibrium points correspond to 
the MLSE decoder output. Simulations have verified this proof of stability even for rel- 
atively small gains. Unfortunately, a proof of strict Lyapunov stability is very difficult, 
and may not be possible, because of the cooperative connections in the network. 
This network demonstrates that it is possible to perform interesting functions even 
if only localized connections are allowed, although there may be some loss of perfor- 
mance. If we view the network as an associative memory, a trellis structured network 
that contains NS neurons can correctly recall 2 $ memories. Simulations of trellis net- 
works strongly suggest that it is possible to guarantee a non-zero minimum radius of 
attraction for all memories. We are currently investigating the use of trellis structured 
layers in multilayer networks to explicitly provide the networks with the ability to 
tolerate errors and replace faulty neurons. 
References 
[1] M. Cohen and S. Grossberg, ""Absolute stability of global pattern formation and parallel 
memory storage by competitive neural networks,"" IEEE Trans. Sys., Man, and Cyber., 
vol. 13, pp. 815-826, Sep.-Oct. 1983. 
[2] S. Grossberg, ""How does a brain build a cognitive code,"" in Studies oj' Mind and Brain, 
pp. 1-52, D. Reidel Pub. Co., 1982. 
[3] J. Hopfield, ""Neural networks and physical systems with emergent collective computational 
abilities,"" Proceedings of the National Academy of Sciences USA, vol. 79, pp. 2554-2558, 
1982. 
[4] J. Hopfield, ""Neurons with graded response have collective computational properties like 
those of two-state neurons,"" Proceeedings of the National Academy of Science, USA, vol. 81, 
pp. 3088-3092, May 1984. 
[5] J. McClelland and D. Rumelhart, Parallel Distributed Processing, Vol. 1. The MIT Press, 
1986. 
[6] D. Tank and J. Hopfield, ""Simple 'neural' optimization networks: an A/D converter, signal 
decision circuit and a linear programming circuit,"" IEEE Trans. on Circuits and Systems, 
vol. 33, pp. 533-541, May 1986. 
[7] A. Viterbi and J. Omura, Principles of Digital Communications and Coding. McGraw-Hill, 
1979. 
", neural petsch bradley dickinson depart electr engin nj develop neural network consist cooper grossberg subnet use function relat log likelihood function decod code gener fir signal deconvolut connect network confin neighbor repres network lend vlsi analyt result converg stabil network structur network use distribut represent data allow fault toler replac faulti introduct order studi behavior local interconnect focus class network similar structur multilay use symmetr connect allow everi neuron studi local interconnect neural network great practic global interconnect network difficult implement vlsi requir mani local connect design use fewer describ subclass network function near global form log likelihood decod convolut code gener finit impuls respons convolut defin section provid altern represent avoid need global describ perform maximum likelihood sequenc estim convolut code presenc perform system optim low specif applic network inspir signal decomposit describ hopfield tank local interconnect complex neural grossberg network modifi form gorssberg model defin section section present main theoret result deconvolut network simpli set cooper interconnect support offic naval research grant nation foundat grant perman siemen corpor research colleg road nj institut physic absolut stabil individu proven cooper interconnect subnet similar proof difficult prove stabil lyapunov sens network given gain nonlinear neuron section describ simul done confirm stabil convolut code mlse error correct input sequenc transform space output error correct input vector output vector write convolut design rel short subsequ input vector use determin subsequ output rate code input subsequ length write vi encod convolut input vector three gener sequenc convolut use output depend three input vi rate number bit input vector uniqu determin output absenc subsequ vector separ bit produc output vector independ view convolut code special case block rate code convert input word codeword length ad introduc two zero end everi input coder view embed memori minimum distanc valid memori codeword space free distaac exampl impli code abl correct minimum three error receiv convolut code constraint length encod view finit state machin whose state time determin input encod also repres trelli graph one figur rate sinc constraint two bit determin four possibl state time trelli set four node arrang call time step node label associ valu rate stage trelli graph contain repres equal number possibl trelli graph contain stage therefor fulli describ oper time step graph read left right upper leav right side node stage follow ui lower edg stage stage stage stage state state part represent rate convolut ui label edg determin ui output encod equat subsequ noisi sequenc output convolut coder plu nois jli done use maximum likelihood sequenc estim decod design accept input possibl noisi convolut code produc output maximum likelihood set possibl encod output vector ith subsequ xm ri ith subsequ argmax decod choos xm maxim condit receiv binari symmetr channel often use transmiss channel model decod produc output sequenc form alphabet contain two assum probabl either symbol affect nois symbol receiv log condit linear function ham distanc ri maxim right side jent choos bit common equat rewritten bit ith subsequ indic equal maximum likelihood sequenc estim expens number possibl input sequenc exponenti viterbi abl take advantag structur convolut code trelli graph represent reduc complex decod exponenti gener optimum version viterbi examin stage trelli practic nearli version typic examin approxim begin stage make decis network mlse decod structur network defin strongli reflect structur network usual consist contain subnetwork correspond stage trelli graph neuron stage implement competit describ detail next produc output enhanc version contrast enhanc creat situat normal one neuron neuron receiv input greatest magnitud pattern network reach equihbrium indic decod sequenc neuron neuron subnet node repres state stage he estim like rate symmetr cooper connect neuron edg correspond node trelli encod output bit transit two node receiv connect weight symmetr cooper connect edg easiest understand action entir network one consid node stage trelli graph assum condit probabl node stage condit receiv condit node stage simpli sum probabihti node weight condit transit look stage let output neighbor stage fix output neuron correspond correspond state final output neuron correspond correspond like state largest neural model use model stage model allow output neuron take rang zero design support contrast enhanc model also guarante final output neuron function rel intens input fraction total provid model stage interconnect defin equat differenti equat govern activ neuron deconvolut network stage state stage written gain analysi present section note equat compactli notat similar equat addit neuron given elimin need global interconnect within add two element calcul two sum allow us rewrit equat form provid compact design network particularli suit implement digit filter use simul sinc greatli reduc calcul stabil network end section describ desir oper singl given neighbor stage possibl show situat singl stage fix equat written form origin propos grossberg special case gener nonlinear system continu xi continu xi cohen show system global lyapunov system equiasymptot stabl constant satisfi four constraint mean singl desir behavior neighbor stage take neuron correspond likelihood correspond state two neighbor stage stage converg equilibrium point neuron receiv largest input other accord section seem possibl use stabil proof entir equat cohen grossberg note network allow interact defin system stabihti proof exist exact stabihti proof seem instead shown nonlinear get larg system mli notat defin vi normal nonlinear defin energi function deconvolut time deriv dt difficult prove nonposit last term larg term shown neglig effect shown bound deconvolut connect neuron neighbor li restrict term write limit term parenthes equat converg equat lim use chain rewrit dt mso shown increas hnction larg defin equat lyapunov hnction system describ equat network appli similar asymptot argument energi equat lyapunov hnction network discontinu neuron matrix binari neuron hirli straight forward energi hnction minima desir decod output assum one neuron stage may appropri hvor sinc term disturb ih equat converg case hst deriv energi hnction equat term simul result simul present section rate convolut code figur sinc code constraint length possibl stage mlse decod would normal examin minimum subsequ make use total first last stage fix sinc assum prior decis first stage zero knowledg last transmit codeword assum simul program read receiv sequenc standard input use defin interconnect matrix accord equat relax call simul perform network accord discret equat unit time defin one rc time constant unforc variabl defin singl precis float show evolut network two unit time interv time receiv codeword contain interpret recal stage neuron output stage vertic set set output first curv output first neuron first first neuron fix output neuron fix output output neuron last stage fix intermedi valu zero priori knowledg notic network reach equilibrium point top neuron state figur other case illustr network correctli decod unerror input one error network perform evolut trelli network unerror input burst initi condit function hopfield network quit although abl prove simul support conjectur network alway converg global difficult decod problem network correct burst error transit figur show evolut three error occur transit stage note unit time interv shown sinc complet converg take much longer first network correctli decod mani stage burst error much shorter receiv codeword contain scatter convolut decod abl correct case shown figur codeword contain system take longest converg around two first midst consecut subsequ one bit error second transit contain two illustr energi function shown equat good candid lyapunov function plot figur three case nonlinear use simul gain larg gain energi decreas thoroughli explor behavior simul program modifi test mani possibl error one two program test possibl error three error gener four error sequenc ml estim sequenc zero result simul summar column label figur network optimum error present howev four network fail correctli decod sequenc mlse decod correctli time evolut trelli network input distribut initi condit figur energi function equat evaul three simul number number error test vector simul result deconvolut network rate network paramet local interconnect major concern flow inform simul present neuron stage connect neuron neighbor modifi form network also simul neuron stage connect neuron four nearest neighbor implement subroutin connect weight modifi assign valu code constraint length path connect two node distanc two result simul shown column label easi see network extra connect perform better previou error made nearest neighbor network input receiv subsequ ri contain total four appear network addit connect abl commun around subsequ contain error block neighbor summari conclus present local interconnect network minim function analog log likelihood function near global result demonstr network success decod input sequenc nois least well global connect simul also strongli support conjectur network guarante converg global low error network also decod noisi receiv abl appli proof stabil network show stage maxim desir local noisi receiv also shown larg gain network whole stabl equilibrium point correspond mlse decod simul verifi proof stabil even small proof strict lyapunov stabil may cooper connect network demonstr possibl perform interest function even local connect although may loss view network associ trelli structur network contain ns neuron correctli recal simul trelli strongli suggest possibl guarante minimum radiu current investig use trelli structur multilay network explicitli provid network abil error replac faulti cohen stabil global pattern format parallel storag competit neural ie brain build cognit studi mind reidel network physic system emerg collect comput proceed nation academi scienc grade respons collect comput properti like proced nation academi may clelland parallel distribut mit tank optim signal circuit linear program ie circuit may viterbi principl digit commun,2
63,63,"6O2 
GENERALIZATION OF BACKPROPAGATION 
TO 
RECURRENT AND HIGHER ORDER NEURAL NETWORKS 
Fernando J. Pineda 
Applied Physics Laboratory, Johns Hopkins University 
Johns Hopkins Rd., Laurel MD 20707 
Abstract 
A general method for deriving backpropagation algorithms for networks 
with recurrent and higher order networks is introduced. The propagation of activation 
in these networks is determined by dissipative differential equations. The error signal 
is backpropagated by integrating an associated differential equation. The method is 
introduced by applying it to the recurrent generalization of the feedforward 
backpropagation network. The method is extended to the case of higher order 
networks and to a constrained dynamical system for training a content addressable 
memory. The essential feature of the adaptive algorithms is that adaptive equation has 
a simple outer product form. 
Preliminary experiments suggest that learning can occur very rapidly in 
networks with recurrent connections. The continuous formalism makes the new 
approach more suitable for implementation in VLSI. 
Introduction 
One interesting class of neural networks, typified by the Hopfield neural 
networks (1,2) or the networks studied by Amari (3,4) are dynamical systems with three 
salient properties. First, they posses very many degrees of freedom, second their 
dynamics are nonlinear and third, their dynamics are dissipative. Systems with these 
properties can have complicated attractor structures and can exhibit computational 
abilities. 
The identification of attractors with computational objects, e.g. memories at d 
rules, is one of the foundations of the neural network paradigm. In this paradigm, 
programming becomes an excercise in manipulating attractors. A learning algorithm is 
a rule or dynamical equation which changes the locations of fixed points to encode 
information. One way of doing this is to minimize, by gradient descent, some 
function of the system parameters. This general approach is reviewed by Amari (4) 
and forms the basis of many learning algorithms. The formalism described here is a 
specific case of this general approach. 
The purpose of this paper is to introduce a formalism for obtaining adaptive 
dynamical systems which are based on backpropagation(5,6,?). These dynamical 
systems are expressed as systems of coupled first order differential equations. The 
formalism will be illustrated by deriving adaptive equations for a recurrent network 
with first order neurons, a recurrent network with higher order neurons and finally a 
recurrent first order associative memory. 
Example 1: Recurrent backpropagation with first order units 
Consider a dynamical system whose state vector x evolves according to the 
following set of coupled differential equations 
American Institute of Physics 1988 
603 
dxi/dt =-x i + gi(.wijxj) + I i (1) 
J 
where i=l,...,N. The functions gi are assumed to be differentiable and may have 
different forms for various populations of neurons. In this paper we shall make no 
other requirements on gi' In the neural network literature it is common to take these 
functions to be sigmoid shaped functions. A commonly used form is the logistic 
function, 
g() = (1 + e-)- 1. (2) 
This form is biologically motivated since it attempts to account for the refractory phase 
of real neurons. However, it is important to stress that there is nothing in the 
mathematical content of this paper which requires this form -- any differentiable 
function will suffice in the formalism presented in this paper. For example, a choice 
which may be of use in signal processing is sin(). 
A necessary condition for the learning algorithms discussed here to exist is that the 
system posesses stable isolated attractors, i.e. fixed points. The attractor structure of 
(1) is the same as the more commonly used equation 
dui/dt =-u i + .wijg(uj) + K i. (3) 
J 
Because (1) and (3) are related by a simple linear transformation. Therefore results 
concerning the stability of (3) are applicable to (1). Amari � studied the dynamics of 
equation (3) in networks with random conections. He found that collective variables 
corresponding to the mean activation and its second moment must exhibit either stable 
or bistable behaviour. More recently, Hopfield (2) has shown how to construct content 
addressable memories from symmetrically connected networks with this same 
dynamical equation. The symmetric connections in the network gaurantee global 
stability. The solution of equation (1) is also globally asymptotically stable if w can be 
transformed into a lower triangular matrix by row and column exchange operations. 
This is because in such a case the network is a simply a feedforward network and the 
output can be expressed as an explicit function of the input. No Liapunov function 
exists for arbitrary weights as can be demonstrated by constructing a set of weights 
which leads to oscillation. In practice, it is found that oscillations are not a problem 
and that the system converges to fixed points unless special weights are chosen. 
Therefore it shall be assumed, for the purposes of deriving the backpropagation 
equations, that the system ultimately settles down to a fixed point. 
Consider a system of N neurons, or units, whose dynamics is determined by 
equation (1). Of all the units in the network we will arbitrarily define some subset of 
them (A) as input units and some other subset of them (f2) as output units. Units 
which are neither members of A nor f2 are denoted hidden units. A unit may be 
simultaneously an input unit and an output unit. The external environment influences 
the system through the source term, I. If a unit is an input unit, the corresponding 
component of I is nonzero. To make this more precise it is useful to introduce a 
notational convention. Suppose that � represent some subset of units in the network 
then the function �i is defined by 
1 if i-th unit is a member of � 
�i = { (4) 
0 otherwise 
In terms of this function, the components of the I vector are given by 
I i = i�iA , (5) 
6O4 
where i is determined by the external environment. 
Ouroal will be to find a local algorithm which adjusts the weight matrix w so that 
a given initial state x � = X(to), and a given input I result in a fixed point, x ��= x(too), 
whose components have a desired set of values Ti along the output units. This will be 
accomplished by minimizing a function E which eneasures the distance between the 
desired fixed point and the actual fixed point i.e., 
N 
E = 1 I; Ji 2 (6) 
2 i=l 
where 
Ji = (Ti- x�� i ) Oil I . (7) 
E depends on the weight matrix w through the fixed point x��(w). A learning 
algorithm drives the fixed points towards the manifolds which satisfy xi �� = T i on the 
output units. One way of accomplishing this with dynamics is to let the system evolve 
in the weight space along trajectories which are antiparallel to the gradient of E. In 
other words, 
OE 
dwij/dt = - q i)w.. (8) 
where q is a numerical constant which def'mes the (slow) time scale on which w 
changes. q must be small so that x is always essentially at steady state, i.e. 
x(t) _= x ��. It is important to stress that the choice of gradient descent for the learning 
dynamics is by no means unique, nor is it necessarily the best choice. Other learning 
dynami,cs, which employ second order time derivatives (e.g. the momentum 
m  
ethod ) or which employ second order space derivatives (e.g. second order 
backpropagation(8)) may be more useful in particular applications. However, equation 
(8) does have the virtue of being the simplest dynamics which minimizes E. 
On performing the differentiations in equation (8), one immediately obtains 
)Xk 
dwrs/dt = q I; Jk � (9) 
k )w 
rs 
The derivative of x�� k with respect to w_ is obtained by f'u'st noting that the fixed 
pmnts of equauon (1J-sansfy the nonlinear algebrmc equanon 
x�� i = gi(Z. wijx��j) + I i , (10) 
J 
differentiating both sides of this equation with respect to Wrs and finally solving for 
aX��k/aWrs. The result is 
aX��k - (L- 1)kr gr'(Ur)X�� s (11) 
Wr s 
where gr' is the derivative of gr and where the matrix L is given by 
Lij = �ij - gi'(ui)wij � (12) 
�:: is the Kroneker � function ( �:: = 1 if i=j, otherwise �ij = 0). On substituting (11) 
iro (9) one obtains the remarkably simple form 
6O5 
dwrs/dt = q yrX�� s 
where 
Yr = gr (Ur) (L- 1)kr 
Equations (13) and (14) specify a formal learning rule. 
(13) 
(14) 
Unfortunately, equation 
(14) requires a matrix inversion to calculate the error signals Yk. Direct matrix 
inversions are necessarily nonlocal calculations and therefore ttiis leaming algorithm is 
not suitable for implementation as a neural network. Fortunately, a local method for 
calculating Yr can be obtained by the introduction of an associated dynamical system. 
To obtain this dynamical system first rewrite equation (14) as 
ZLrk(Yr / gr'(Ur )} = Jk (15) 
r 
Then multiply both sides by fk'(Uk), substitute the explicit form for L and finally sum 
over r. The result is 
0=-Yk + gk'(Uk){ ZWrkYr + Jk ] (16) 
r 
One now makes the observation that the solutions of this linear equation are the fixed 
points of the dynamical system given by 
dYk/dt = - Yk +gk'(Uk ){ ZWrkYr + Jk ) (17) 
r 
This last step is not unique, equation (16) could be transformed in various ways 
leading to related differential equations, cf. Pineda (9). It is not difficult to show that 
the fu'st order finite difference approximation (with a time step At = 1) of equations 
(1), (13) and (17) has the same form as the conventional backpropagation algorithm. 
Equations (1), (13) and (17) completely specify the dynamics for an adaptive 
neural network, provided that (1) and (17) converge to stable fixed points and 
provided that both quantities on the fight hand side of equation (13) are the steady 
state solutions of (1) and (17). 
It was pointed out by Almeida (10) that the local stability of (1) is a sufficient 
condition for the local stability of (17). To prove this it suffices to linearize equation 
(1) about a stable fixed point. The resulting linearized equation depends on the same 
matrix L whose transpose appears in the derivation of equation (17), cf. equation 
(15). But L and L T have the same eigenvalues, hence it follows that the fixed points 
of (17) must also be locally stable if the fixed points of (1) are locally stable. 
Learning multiple associations 
It is important to stress that up to this point the entire discussionhas assumed that I 
and T are constant in time, thus no mechanism has been obtained for leaming multiple 
input/output associations. Two methods for training the network to learn multiple 
associations are now discussed. These methods lead to qualitatively different leaming 
behaviour. 
Suppose that each input/output pair is labeled by a pattern label c, i.e. {IC,T c }. 
Then the energy function which is minimized in the above discussion must also 
depend on this label since it is an implicit function of the Ia,T c pairs. In order to 
learn multiple input/output associations it is necessary to minimize all the E[cz] 
simultaniously. In otherwords the function to minimize is 
Etota 1 = Z E[c] (18) 
606 
where the sum is over all input/output associations. From (18) it follows that the 
gradient fo Etota I is simply the sum of the gradients for each association, hence the 
corresponoang gradient descent equation has the form, 
dwij/dt = q E y��i[a] x��j[a] (19) 
In numerical simulations, each time step of (19) requires relaxing (1) and (17) for each 
pattern and accumulating the gradient over all the paRems. This form of the algorithm 
is deterministic and is guaranteed to converge because, by construction, Etota l is a 
Liapunov function for equation (19). However, the system may get stuck-in a local 
minimum. This method is similar to the master/slave approach of Lapedes and 
Farber(11). Their adaptive equation, which plays the same role as equation (19), also 
has a gradient form, although it is not strictly descent along the gradient. For a 
randomly or fully connected network it can be shown that the number of opergtions 
required per weight update in the master/slave formalisrll is'proportional to N:' where 
N is the number of units. This is because there are O(N z) update equations and each 
equation requires O(N) operations (assuming some precomputation). On the other 
hand, in the backpropagation formalism each update equation req,uires only O(1) 
operations because of their trivial outer product form. Also O(N 'c) operations are 
required tt� precompute x �� and yOO. The result is that each weight update requires 
only O(N ') operations. It is not possible to conclude from this argument that one or 
the other approach will be more efficient in a particular application because there are 
other factors to consider such as the number of patterns and the number of time steps 
required for x and y to converge. A detailed comparison of the two methods is in 
preparation. 
A second approach to learning multiple patterns is to use (13) and to change the 
paRems randomly on each time step. The system therefore receives a sequence of 
random impulses each of which attempts to minimize E[{x] for a single pattern. One 
can then def'me L(w) to be the mean E[c] (averaged over the distribution of patterns). 
L(w) = <E [w, IC,T c ]> 
(20) 
Amari � has pointed out that if the sequence of random patterns is stationary and if 
L(w) has a unique minimum then the theory of stochastic approximation guarantees 
that the solution of (13) w(t) will converge to the minimum point Wmi a of L(w) to 
within a small fluctuating term which vanishes as I tends to zero. Eqi/:lently rl is 
analogous to the temperature parameter in simulated annealing. This second approach 
generally converges more slowly than the fu'st, but it will ultimately converge (in a 
statistical sense) to the global minimum. 
In principle the fixed points, to which the solutions of (1) and (17) eventually 
converge, depend on the initial states. Indeed, Amari's (3) results imply that equation 
(1) is bistable for certain choices of weights. Therefore the presentation of multiple 
patterns might seem problematical since in both approaches the final state of the 
previous pattern becomes the initial state of the new pattern. The safest approach is to 
reinitialize the network to the same initial state each time a new pattern is presented, 
e.g...xi(to) = 0.5 for all i. In practice the system learns robustly even if the initial 
conamons are chosen randomly. 
Example 2: Recurrent higher order networks 
It is straightforward to apply the technique of the previous section to a dynamical 
system with higher order units. Higher order systems have been studied by 
Sejnowski (12) and Lee et al.(13). Higher order networks may have definite advantages 
6O7 
over networks with first order'units alone A detailed discussion of the 
backpropagation formalism applied to higher order networks is beyond the scope of 
this paper. Instead, the adaptive equations for a network with purely n-th order units 
will be presented as an example of the formalism. To this end consider a dynamical 
system of the form 
dxi/dt = -x i + gi(ui) + I i 
(21) 
where 
>ij..,tj(xj)'""tk< k) 
ui = n x . 
(22) 
and where there are n+l indices and the summations are over all indices except i. The 
superscript on the weight tensor indicates the order of the correlation. Note that an 
additional nonlinear function f has been added to illustrate a further generalization. 
Both f and g must be differentiable and may be chosen to be sigmoids. It is not 
difficult, although somewhat tedious, to repeat the steps of the previous example to 
derive the adaptive equations for this system. The objective function in this case is the 
same as was used in the first example, i.e. equation (6). The n-th order gradient 
descent equation has the form 
dw (n)ij...k/dt = qy (n)��if(x��j)'""f(x��k) . 
(23) 
Equation (23) illustrates the major feature of backpropagation which distinguishes it 
from other gradient descent algorithms or similar algorithms which make use of a 
gradient. Namely, that the gradient of the objective function has a very trivial outer 
product form. y (n)oo is the steady state solution of 
dy(n)k/dt =- Y(n)k + gk'(Uk ) { fk'(Xk)EV(n)rkY (n)r + Jk } ' (24) 
r 
The matrix V � plays the role of w in the previous example, however V � now 
depends on the state of the network according to 
v(n)ij  E'-- 5; s(n)ijk...1 { f(xk) "". f(xl) ) (25) 
1 
where is S � a tensor which is symmetric with respect to the exchange of the second 
index and all the indices to the right, i.e. 
s(n)ijk'""l = w(n)ijk'""l + w(n)ikj'""l + '"" + w(n)ijl""'k � 
(26) 
Finally, it should be noted that: 1) If the polynomial u i is not homogenous, the 
adaptive equations are more complicated and involve cross terms between the various 
orders and that: 2) The local stability of the n-th order backpropagation equations now 
depends on the eigenvalues of the matrix 
Lij = �ij - gi'(ui) fi'(xi) v(n)ij (27) 
As before, if the forward propagation converges so will the backward propagation. 
Example 3: Adaptive content addressable memory 
In this section the adaptive equations for a content addressable memory 
(CAM) are derived as a f'mal illustration of the generality of the formalism. Perhaps 
6O8 
the best known (and best studied) examples of dy[A,a,mical systems which exhibit CAM 
behaviour are the systems discussed by HopfieldU,Z. Hopfield used a nonadaptive 
method for programming the symmetric weight matrix. More recently Lapedes and 
Farber(11) have demonstrated how to contruct a master dynamical system which can be 
used to train the weights of a slave system which has the Hopfield form. This slave 
system then performs the CAM operation. The resulting weights are not symmetric. 
The learning proceedure presented in this section is most closely related to the 
method of Lapedes and Farber in that a master network is used to adjust the weights of 
a slave network. In constrast to the afforementioned formalism, which requires a 
very large associated weight matrix for the master network, both the master and slave 
networks of the following approach make use of the same weight matrix. The CAM 
under consideration is based on equation (1). However, the interpretation of the 
dynamics will be somewhat different from the first section. The main difference is that 
the dynamics in the learning phase is constrained. The constrained dynamical system 
is denoted the master network. The unconstrained system is denoted the slave 
network. The units in the network are divided into only two sets: the set of visible 
units (V) and the set of internal or hidden units (H). There will be no distinction made 
between input and output units. Thus, I will generally be zero unless an input bias is 
needed in some application. 
The dynamical system will be used as an autoassociative memory, thus the 
memory recall is performed by starting the network at a particular initial state which 
represents partial information about a stored memory. More precisely, suppose that 
there exists a subset K of the visible units whose states are known to have values T i. 
Then the initial state of the network is 
xi(t o) = T i OiK + b i (1-OiK), 
(28) 
where the b i are arbitrary. The CAM relaxes to the previously stored memory whose 
basin of attraction contains this partial state. 
Memories are stored by a master network whose topology is exactly the same 
as the slave network, but whose dynamics is somewhat modified. The state vector z 
of the master network evolves according to the equation 
N 
dzi/dt = -z i + gi(ZwikZk ) + I i (29) 
k=l 
where Z is def'med by 
Z i=T iOiV +z iOiH. 
(30) 
The components of Z along the visible units are just the target value specified by T. 
This equation is useful as a master equation because if the weights can be chosen so 
that the z i of the visible units relax to the target values T i, then a fixed point of (29) is 
also a fixed point of (1). It can be concluded therefore, that by training the weights of 
the master network one is also training the weights of the slave network. Note that the 
form of Z implies that equation (29) can be rewritten as 
where 
dzi/dt = -z i + gi(;WikZk - 0i) + I i 
ke_H 
(31) 
0 i =- ZWikT k (32) 
keV 
From equations (31) and (32) it is clear that the dynamics of the master system is 
driven by the thresholds which depend on the targets. 
609 
where 
To derive the adaptive equations consider the objective ihnction 
I N 
Emaster =-  Ji2 
i=l 
Ji = Z��i - z��i � 
(33) 
(34) 
It is straightforward to apply the steps discussed in previous sections to E - This 
....... ster' . 
results in adapuve equauons for the weights. The mathemaucal detmls wl ormtted 
since they are essentially the same as before, the gradient descent equation is 
dwij/dt: 11Y��iZ*� j 
where yOO is the steady state solution of 
(35) 
dYk/dt = - Yk +g'k(Vk){OiHgwrkYr + Jk} (36) 
r 
where v i  rI. iWikZ�� k (37) 
Equations (31), and (35)-37) define the dynamics of the master network. To train the 
slave network to be an autoassociative memory it is necessary to use the stored 
memories as the initial states of the master network, i.e. 
zi(to) = T i {9iV + b i OiH 
(39) 
where b; is an arbitrary value as before. The previous discussions concerning the 
stability'of the three equations (1), (13) and (17) apply to equations (31) (35) and (36) 
as well. It is also possible to derive the adaptive equations for a higher order 
associative network, but this will not be done here. 
Only preliminary computer simulations have been performed with this 
algorithm to verify their validity, but more extensive experiments are in progress. The 
first simulation was with a fully connected network with 10 visible units and 5 hidden 
units. The training set consisted of four random binary vectors with the magnitudes of 
the vectors adjusted so that 0.1  Ti -< 0.9. The equations were approximated by first 
order f'mite difference equations wiih At = I and 1 = 1. The training was performed 
with the deterministic method for learning multiple associations. Figure 1. shows 
E ,, as a function of the number of updates for both the master and slave networks. 
E tv"" for the slave exhibits discontinous behaviour because the trajectory through the 
we'gtgt space causes X(to) to cut across the basins of attraction for the fixed points of 
equation (1). 
The number of updates required for the network to learn the patterns is 
relatively modest and can be reduced further by increasing tl. This suggests that 
learning can occur very rapidly in this type of network. 
Discussion 
The algorithms presented here by no means exhaust the class of possible 
adaptive algorithms which can be obtained with this formalism. Nor is the choice of 
gradient descent a crucial feature in this formalism. The key idea is that it is possible 
to express the gradient of an objective function as the outer product of vectors which 
can be calculated by dynamical systems. This outer produc,form is also responsible 
for the fact that the gradient can be calculated with only O(N ) operations in a fully 
connected or randomly connected network. In fact the number of operations per 
610 
weight update is proportional to the number of connections in the network. The 
methods used here will generalize to calculate higher order derivatives of the objective 
function as well. 
The fact that the algorithms are expressed as differential equations suggests 
that they may be implemented in analog electronic or optical hardware. 
-- Master 
""*' Slave 
0 20 40 60 80 100 
Updates 
figure 1. Etota 1 as a function of the the number of updates. 
References 
(1) 
(9) 
(10) 
J. J. Hopfield, Neural Networks as Physical Systems with Emergent Collective 
Computational Abilities, Proc. Nat. Acad. Sci. USA, Bio.79, 2554-2558, 
(1982) 
(2) J.J. Hopfield, Neurons with graded response have collective computational 
properties like those of two-state neurons, Proc. Nat. Acad. Sci. USA, Bio. 81, 
3088-3092, (1984) 
(3) Shun-Ichi Amari, IEEE Trans. on Systems Man and Cybernetics, 2, 643-657, 
(1972) 
(4) Shun-Ichi Amari, in Systems Neuroscience, ed. Jacqueline Metzler, 
Academic press, (1977) 
(5) D.E. Rumelhart, G. E. Hinton and R.J. Williams, in Parallel Distributed 
Processing, edited by D. E. Rumelhart and J. L. McClelland, 
M.I.T. press, (1986) 
(6) David B. Parker, Learning-Logic, Invention Report, S81-64, File 1, 
Office of Technology Licensing, Stanford University, October, 1982 
(7) Y. LeChun, Proceedings of Cognitiva, 85, p. 599, (1985) 
(8) David B. Parker, Second Order Backpropagation: Implementing an Optimal 
O(n) Approximation to Newton's Method as an Artificial Neural Network, 
submitted to Computer, (1987) 
Fernando J. Pineda, Generalization of backpropagation to recurrent neural 
networks, Phys. Rev. Lett., .18, 2229-2232, (1987) 
Luis B. Almeida, in the Proceedings of the IEEE First Annual International 
Conference on Neural Networks, San Diego, California, June 1987, edited by 
611 
(11) 
(12) 
(13) 
M. Caudil and C. Butler (to be published This is a discrete version of the 
algorithm presented as the farst example 
Alan Lapedes and Robert Farber, A self-optimizing, nonsymmetrical neural net 
for content addressable memory and pattern recognition, Physica, D22, 
247-259, (1986), see also, Programming a Massively Parallel, Computation 
Universal System: Static Behaviour, in Neural Networks for Computing 
Snowbird, UT 1986, AIP Conference Proceedings, 151, (1986), 
edited by John S. Denker 
Terrence J. Sejnowski, Higher-order Boltzmann Machines, Draft preprint 
obtained from author 
Y.C. Lee, Gary Doolen, H.H. Chen, G.Z. Sun, Tom Maxwell, H.Y. Lee and 
C. Lee Giles, Machine Learning using a higher order correlation network, 
Physica D22, 276-306, (1986) 
", backpropag higher order neural network pineda physic john hopkin univers hopkin laurel md gener method deriv backpropag algorithm network recurr higher order network propag activ network determin dissip differenti error signal backpropag integr associ differenti method appli recurr gener feedforward method extend case higher order constrain dynam system train content address essenti featur adapt algorithm adapt equat simpl outer product experi suggest learn occur rapidli recurr continu formal make new suitabl implement interest class neural typifi hopfield neural network studi amari dynam system three poss mani degre second nonlinear dynam system complic attractor structur exhibit comput identif attractor comput memori one foundat neural network becom excercis manipul learn algorithm rule dynam equat chang locat fix point encod one way gradient system gener approach review amari form basi mani learn formal describ case gener purpos paper introduc formal obtain adapt system base dynam express system coupl first order differenti illustr deriv adapt equat recurr network first order recurr network higher order neuron final first order associ recurr backpropag first order unit dynam system whose state vector evolv accord set coupl differenti equat institut physic function gi assum differenti may form variou popul paper shall make requir neural network literatur common take sigmoid shape commonli use form logist form biolog motiv sinc attempt account refractori phase real import stress noth content paper requir form differenti suffic formal present choic may use signal process necessari condit learn algorithm discuss exist posess stabl isol fix attractor structur commonli use equat relat simpl linear therefor result stabil applic amari studi dynam network random found collect variabl mean activ second moment must exhibit either stabl bistabl hopfield shown construct content memori symmetr connect network symmetr connect network gaurante global solut equat also global asymptot stabl lower triangular matrix row column exchang case network simpli feedforward network express explicit function liapunov function arbitrari weight demonstr construct set weight lead found oscil problem system converg fix point unless special weight shall purpos deriv backpropag system ultim settl fix system whose dynam determin unit network arbitrarili defin subset input unit subset output unit neither member denot hidden unit may input unit output extern environ influenc system sourc unit input correspond make precis use introduc suppos repres subset unit network function defin unit member otherwis term compon vector given determin extern find local algorithm adjust weight matrix given initi state given input result fix compon desir set valu ti along output minim function eneasur distanc fix point actual fix point ji oil depend weight matrix fix point learn drive fix point toward manifold satisfi xi one way accomplish dynam let system evolv weight space along trajectori antiparallel gradient numer constant time scale must small alway essenti steadi import stress choic gradient descent learn mean necessarili best learn employ second order time deriv momentum employ second order space deriv second order may use particular equat virtu simplest dynam minim perform differenti equat one immedi obtain jk deriv respect obtain note fix equauon nonlinear algebrmc equanon side equat respect wr final solv result deriv gr matrix given kronek function otherwis substitut one obtain remark simpl form gr specifi formal learn equat requir matrix invers calcul error signal direct matrix necessarili nonloc calcul therefor ttii leam algorithm suitabl implement neural local method yr obtain introduct associ dynam obtain dynam system first rewrit equat jk multipli side substitut explicit form final sum result yr jk make observ solut linear equat fix dynam system given yk yr jk last step equat could transform variou way relat differenti pineda difficult show order finit differ approxim time step equat form convent backpropag complet specifi dynam adapt provid converg stabl fix point quantiti fight hand side equat steadi solut point almeida local stabil suffici local stabil prove suffic linear equat stabl fix result linear equat depend whose transpos appear deriv equat equat henc follow fix point must also local stabl fix point local multipl associ import stress point entir discussionha assum constant thu mechan obtain leam multipl two method train network learn multipl method lead qualit differ leam pair label pattern label energi function minim discuss must also label sinc implicit function order multipl associ necessari minim otherword function minim sum follow etota simpli sum gradient henc gradient descent equat numer time step requir relax accumul gradient form algorithm determinist guarante converg etota function equat system may get local method similar approach laped adapt play role equat also gradient although strictli descent along fulli connect network shown number per weight updat formalisrl number updat equat requir oper backpropag formal updat equat trivial outer product also oper precomput result weight updat requir possibl conclud argument one approach effici particular applic factor consid number pattern number time step detail comparison two method second approach learn multipl pattern use chang rem randomli time system therefor receiv sequenc impuls attempt minim singl one mean distribut point sequenc random pattern stationari uniqu minimum theori stochast approxim guarante solut converg minimum point wmi small fluctuat term vanish tend rl temperatur paramet simul second approach converg slowli ultim converg global principl fix solut eventu depend initi result impli equat bistabl certain choic therefor present multipl might seem problemat sinc approach final state pattern becom initi state new safest approach network initi state time new pattern practic system learn robustli even initi chosen recurr higher order network straightforward appli techniqu previou section dynam higher order higher order system studi lee et higher order network may definit advantag network first alon detail discuss formal appli higher order network beyond scope adapt equat network pure order unit present exampl end consid dynam form indic summat indic except weight tensor indic order note nonlinear function ad illustr must differenti may chosen although somewhat repeat step previou exampl adapt equat object function case use first equat order gradient equat form qy illustr major featur backpropag distinguish gradient descent algorithm similar algorithm make use gradient object function trivial outer steadi state solut jk matrix play role previou howev state network accord tensor symmetr respect exchang second indic note polynomi equat complic involv cross term variou local stabil order backpropag equat eigenvalu matrix forward propag converg backward adapt content address memori section adapt equat content address memori deriv illustr gener perhap best known best exampl system exhibit cam system discuss hopfield use nonadapt program symmetr weight recent laped demonstr contruct master dynam system train weight slave system hopfield slave perform cam result weight learn proceedur present section close relat laped farber master network use adjust weight slave constrast afforement requir larg associ weight matrix master master slave follow approach make use weight cam consider base equat interpret somewhat differ first main differ dynam learn phase constrain dynam system denot master unconstrain system denot slave unit network divid two set visibl set intern hidden unit distinct made input output gener zero unless input bia dynam system use autoassoci thu recal perform start network particular initi state partial inform store suppos exist subset visibl unit whose state known valu initi state network cam relax previous store memori whose attract contain partial store master network whose topolog exactli slave whose dynam somewhat state vector master network evolv accord equat zk compon along visibl unit target valu specifi equat use master equat weight chosen visibl unit relax target valu fix point fix point conclud train weight master network one also train weight slave note impli equat rewritten zk equat clear dynam master system threshold depend deriv adapt equat consid object ihnction straightforward appli step discuss previou section adapuv equauon mathemauc detml ormt essenti gradient descent equat oo steadi state solut yk yr defin dynam master train network autoassoci memori necessari use store initi state master arbitrari valu previou discuss concern three equat appli equat also possibl deriv adapt equat higher order done preliminari comput simul perform verifi extens experi simul fulli connect network visibl unit hidden train set consist four random binari vector magnitud vector adjust ti equat approxim first differ equat wiih train perform determinist method learn multipl figur show function number updat master slave slave exhibit discontin behaviour trajectori space caus cut across basin attract fix point number updat requir network learn pattern modest reduc increas suggest occur rapidli type algorithm present mean exhaust class possibl algorithm obtain choic descent crucial featur key idea possibl express gradient object function outer product vector calcul dynam outer also respons fact gradient calcul oper fulli randomli connect fact number oper per updat proport number connect use gener calcul higher order deriv object fact algorithm express differenti equat suggest may implement analog electron optic master slave etota function number neural network physic system emerg collect neuron grade respons collect comput like ie system man system jacquelin hinton parallel distribut edit rumelhart david invent file technolog stanford proceed david second order implement optim approxim method artifici neural gener backpropag recurr neural proceed ie first annual intern neural san june edit caudil butler publish discret version present farst exampl laped robert nonsymmetr neural net content address memori pattern see program massiv comput static neural network comput ut aip confer john denker boltzmann draft preprint author gari tom lee lee machin learn use higher order correl,2
64,64,"612 
Constrained Differential Optimization 
John C. Platt 
Alan H. Ban' 
California Institute of Technology, Pasadena, CA 91125 
Abstract 
Many optimization models of neural networks need constraints to restrict the space of outputs to 
a subspace which satisfies external criteria. Optimizations using energy methods yield ""forces"" which 
act upon the state of the neural network. The penalty method, in which quadratic energy constraints 
are added to an existing optimization energy, has become popular recently, but is not guaranteed 
to satisfy the constraint conditions when there are other forces on the neural model or when there 
are multiple constraints. In this paper, we present the basic differential multiplier method (BDMM), 
which satisfies constraints exactly; we create forces which gradually apply the constraints over time, 
using ""neurons"" that estimate Lagrange multipliers. 
The basic differential multiplier method is a differential version of the method of multipliers 
from Numerical Analysis. We prove that the differential equations locally converge to a constrained 
minimum. 
Examples of applications of the differential method of multipliers include enforcing permutation 
codewords in the analog decoding problem and enforcing valid tours in the traveling salesman problem. 
1. Introduction 
Optimization is ubiquitous in the field of neural networks. Many learning algorithms, such as 
back-propagation, xs optimize by minimizing the difference between expected solutions and observed 
solutions. Other neural algorithms use differential equations which minimize an energy to solve 
a specified computational problem, such as associative memory, � differential solution of the trav- 
eling salesman problem, &� analog decoding? and linear programming? Furthermore, Lyapunov 
methods show that various models of neural behavior find minima of particular functions. a,� 
Solutions to a constrained optimization problem are restricted to a subset of the solutions of the 
corresponding unconswained optimization problem. For example, a mutual inhibition circuit e requires 
one neuron to be ""on"" and the rest to be ""off"". Another example is the waveling salesman problem? 
where a salesman tries to minimize his travel distance, subject to the constraint that he must visit 
every city exactly once. A third example is the curve fitting problem, where elastic splines are as 
smooth as possible, while still going through data pointsfi Finally, when digital decisions are being 
made on analog data, the answer is constrained to be bits, either 0 or 1. xa 
A constrained optimization problem can be stated as 
minimi.e f(_.x), (1) 
subject to g(/) ----- 0, 
where _.x is the state of the neural network, a position vector in a high-dimensional space; f(x__) is a 
scalar energy, which can be imagined as the height of a landscape as a function of position _.x; g(_x) = 0 
is a scalar equation describing a subspace of the state space. During constrained optimization, the 
state should be attracted to the subspace g(l} = 0, then slide along the subspace until it reaches the 
locally smallest value of f(_x) on (x_) = 0. 
In section 2 of the paper, we describe classical methods of constrained optimization, such as the 
penalty method and Laglange multipliers. 
Section 3 introduces the basic differential multiplier method (BDMM) for constrained optimiza- 
tion, which calculates a good local minimum. If the constrained optimization problem is convex, then 
the local minimum is the global minimum; in general, finding the global minimum of non-convex 
problems is fairly difficult. 
In section 4, we show a Lyapunov function for the BDMM by drawing on an analogy from 
physics. 
@ American Institute of Physics 1988 
613 
In section 5, augmented Lagrangians, an idea from optimization theory, enhances the convergence 
properties of the BDMM. 
In section 6, we apply the differential algorithm to two neural problems, and discuss the insen- 
sitivity of BDMM to choice of parameters. Parameter sensitivity is a persistent problem in neural 
networks. 
2. Classical Methods of Constrained Optimization 
This section discusses two methods of constrained optimization, the penalty method and Lagrange 
multipliers. The penalty method has been previously used in differential optimization. The basic 
differential multiplier method developed in this paper applies Lagrange multipliers to differential 
optimization. 
2.1. The Penalty Method 
The penalty method is analogous to adding a rubber band which attracts the neural state to 
the subspace !/(_x) = 0. The penalty method adds a quadratic energy term which penalizes viola- 
tions of constraints. s Thus, the constrained minimization problem (1) is converted to the following 
unconstrained minimization problem: 
minimize �ven,qtv(_x} = f(_x) + �(!/(_x}) 2. 
(2) 
= o 
Figure 1. The penalty method makes a trough in state space 
The penalty method can be extended to fulfill multiple constraints by using more than one rubber 
band. Namely, the constrained optimization problem 
minimize f(_x), (3) 
subject to !7-.(_x) = O; a = 1, 2,..., n; 
is converted into unconstrained optimization problem 
minimize 6enalW(a:)= f(x) + Z ca(ga(a:))2' (4) 
The penalty method has several convenient features. First, it is easy to use. Second, it is globally 
convergent to the correct answer as c,,  oo. s Third, it allows compromises between constraints. For 
example, in the case of a spline curve fitting input data, there can be a compromise between fitting 
the data and making a smooth spline. 
614 
However, the penalty method has a number of disadvantages. First, for finite constraint strengths 
�,,, it doesn't fulfill the constraints exactly. Using multiple rubber band constraints is like building 
a machine out of rubber bands: the machine would not hold together perfectly. Second, as more 
constraints are added, the constraint strengths get harder to set, especially when the size of the 
network (the dimensionality of x_) gets large. 
In addition, there is a dilemma to the setting of the constraint strengths. If the strengths are small, 
then the system finds a deep local minimum, but does not fulfill all the constraints. If the strengths 
are large, then the system quickly fulfills the constraints, but gets stuck in a poor local minimum. 
2.2. Lagrange Multipliers 
Lagrange multiplier methods also convert constrained optimization problems into unconstrained 
extremization problems. Namely, a solution to the equation (1) is also a critical point of the energy 
CLagrange(_Z) = f(2:) q- g(). (5) 
A is called the Lagrange multiplier for the constraint g(z_) -- 0. s 
A direct consequence of equation (5) is that the gradient of f is collinear to the gradient of g at 
the constrained extrema (see Figure 2). The constant of proportionality between Vf and Vg is -A: 
veL.,,..,e = o= v! + XVg. (6) 
We use the collinearity of Vf and Vg in the design of the BDMM. 
contours of f 
Vg 
=0 
Figure 2. At the constrained minimum, Vf = -AVg 
A simple example shows that Lagrange multipliers provide the exlxa degrees of freedom necessary 
to solve constrained optimization problems. Consider the problem of finding a point (z, y) on the 
line x + y = 1 that is closest to the origin. Using Lagrange multipliers, 
�Lasranse = za + Ya + A(z + y - 1) 
(7) 
Now, take the derivative with respect to all variables, z, y, and A. 
8�Lag..g = 2y + A = 0 
(s) 
615 
With the extra variable A, there are now three equations in three unknowns. In addition, the last 
equation is precisely the constraint equation. 
3. The Basic Differential Multiplier Method for Constrained Optimization 
This section presents a new ""neural"" algorithm for constrained optimization, consisting of dif- 
ferential equations which estimate Lagrange multipliers. The neural algorithm is a variation of the 
method of multipliers, first presented by Hestenes  and PowelP 6. 
3.1. Gradient Descent does not work with Lagrange Multipliers 
The simplest differential optimization algorithm is gradient descent, where the state variables of 
the network slide downhill, opposite the gradient. Applying gradient descent to the energy in equation 
(5) yields 
:i = Lagrange = f  a/' 
ax ax (9) 
Note that there is a auxiliary differential equation for A, which is an additional ""neuron"" necessary 
to apply the constraint g(a:) = 0. Also, recall that when the system is at a constrained extremum, 
Vf = -AVg, hence, fi: = 0. 
Energies involving Lagrange multipliers, however, have critical points which tend to be saddle 
points. Consider the energy in equation (5). If  is frozen, the energy can be decreased by sending 
A to +oo or -oo. 
Gradient descent does not work with Lagrange multipliers, because a critical point of the energy 
in equation (5) need not be an attractor for (9). A stationary point must be a local minimum in order 
for gradient descent to converge. 
3.2. The New Algorithm: the Basic Differential Multiplier Method 
We present an alternative to differential gradient descent that estimates the Lagrange multipliers, 
so that the constrained minima are attractors of the differential equations, instead of ""repulsors."" The 
differential equations that solve (1) is 
i,= 
axl axi ' 
i = 
(o) 
Equation (10) is similar to equation (9). As in equation (9), constrained extrema of the ener .gy 
(5) are stationary points of equation (10). Notice, however, the sign inversion in the equation for A, 
as compared to equation (9). The equation (10) is performing gradient ascent on A. The sign flip 
makes the BDMM stable, as shown in section 4. 
Equation (10) corresponds to a neural network with anti-symmetric connections between the A 
neuron and all of the _x neurons. 
3.3. Extensions to the Algorithm 
One extension to equation (10) is an algorithm for constrained minimization with multiple con- 
straints. Adding an extra neuron for every equality constraint and summing all of the constraint forces 
creates the energy 
emu,tip, e = f(:z) '- Z )[t""a (---)' (11) 
which yields differential equations 
=  aga 
L, = 
616 
Another extension is constrained minimization with inequality constraints. As in traditional 
optimization theory, s one uses extra slack variables to convert inequality constraints into equality 
constraints. Namely, a constraint of the form h(x__) > 0 can be expressed as 
(13) 
Since z 2 must always be positive, then h(_x) is constrained to be positive. The slack variable z is 
treated like a component of _.x in equation (10). An inequality constraint requires two extra neurons, 
one for the slack variable a: and one for the Lagrange multiplier A. 
Alternatively, the inequality constraint can be represented as an equality constraint. For example, 
if h(_x} > 0, then the optimization can be constrained with g(_x) = h(_x}, when h(_z} _> 0; and 
() = o otherwise. 
4. Why the algorithm works 
The system of differential equations (10) (the BDMM) gradually fulfills the constraints. Notice 
that the function g(X) can be replaced by kg(x), without changing the location of the constrained 
minimum. As k is increased, the state begins to undergo damped oscillation about the constraint 
subspace g(_x) = 0. As k is increased further, the frequency of the oscillations increase, and the time 
to convergence increases. 
subspace  
 . path of algorithm 
_ 
N. g(_) < o 
force/' X-- 
(a) > o N,() = o 
constraint 
initial state 
Figure 3. The state is attracted to the constraint subspace 
The damped oscillations of equation (10) can be explained by combining both of the differential 
equations into one second-order differential equation. 
{ a/ a ' a =o. (14) 
Equation (14) is the equation for a damped mass system, with an inertia term it, a damping matrix 
A= a2f ag (15) 
and an internal force, gBg/Ox, which is the derivative of the internal energy 
1 
v= [ ((_)?. (1) 
617 
If the system is damped and the state remains bounded, the state falls inw a constrained minima. 
As in physics, we can construct a total energy of the system, which is the sum of the kinetic and 
potential energies. 
i 
If the total energy is decreasing with time and the state remains bounded, then the system will 
dissipate any extra energy, and will settle down into the state where 
[) = o, 
x +A :0. 
(18) 
which is a constrained extremum of the original problem in equation (1). 
The time derivative of the total energy in equation (17) is 
(19) 
If damping matrix Aj is positive definite, the system converges to fulfill the constraints. 
BDMM always converges for a special case of constrained optimization: quadratic programming. 
A quadratic programming problem has a quadratic function f(a:} and a piecewise linear continuous 
function 9{_) such that 
a=ax. i positive aefinite; a.,a=. = o. (20) 
Under these circumstances, the damping matrix Aij is positive definite for all a: and A, so that the 
system converges to the consxaints. 
4.1. Multiple constraints 
For the case of multiple constraints, the total energy for equation (12) is 
1.3 
:: v + v:  [(,) + Z g,.(_). 
i 
(21) 
and the time derivative is 
 = Z i,, + Z .(-) , 
i 
(22) 
Again, BDMM solves a quadratic programming problem, if a solution exists. However, it is 
possible to pose a problem that has contradictory constraints. For example, 
(23) 
In the case of conflicting constraints, the BDMM compromises, trying to make each constraint 9- as 
small as possible. However, the Lagrange multipliers A, goes to 4-00 as the conslxaints oppose each 
other. It is possible, however, to arbitrarily limit the A, at some large absolute value. 
618 
LaSalle's invariance theorem xa is used to prove that the BDMM eventually fulfills the consaints. 
Let O be an open subset of R"". Let F be a subset of O*, the closure of G, where the system of 
differential equations (12) is at an equilibrium. 
If the damping matrix 
Oaf aa9o, 
+ (25) 
is positive defiMte  G, if x(t) d A(t) e boundS, and mma  G for aH time, and f F 
is non-empty, en F is e gest int set in G*, hence, by LaSle's ce eorem, e 
system xi (t), A (t) apaches F  t  . 
5. The Modified Differential Method of Multipliers 
is fion psen e dified dereid tiplier thod , wch is a modifi- 
cation of e BD wi more robust convergen propes. For a given consn operation 
problem, it is ffuently n m mr e BDMM m have a region of positive mpg sound- 
ing e consnM mima. e non-differential meod of multipliers om Numefic lysis so 
h th ficulty.  Numefic ysis combes e multiprier meod with e pety method  
yield a modified mfiplier meod at is locally convergent ound consn mima.  
e BD is complemly compatible wi e penW meod. If one adds a penW force to 
equation (10) coespong to an quaafic energy 
= 
then the set of differential equations for MDMM is 
a/ a a9 
: = a=i A - cg-z , 
i = 
(27) 
The exxa force from the penalty does not change the position of the stationary points of the differential 
equations, because the penalty force is 0 when g(_x} = 0. The damping matrix is modified by the 
penalty force to be 
(28) 
There is a theorem  that states that there exists a c* > 0 such that if � > c*, the damping matrix 
in equation (28) is positive definite at conslxained minima. Using continuity, the damping matrix is 
positive definite in a region R surrounding each conslxained minimum. If the system starts in the 
region R and remains bounded and in R, then the convergence theorem at the end of section 4 is 
applicable, and MDMM will converge to a constrained minimum. 
The minimum necessary penalty strength � for the MDMM is usually much less than the strength 
needed by the penalty method alone? 
6. Examples 
This section contains two examples which illustrate the use of the BDMM and the MDMM. First, 
the BDMM is used to find a good solution to the planar traveling salesman problem. Second, the 
MDMM is used to enforcing mutual inhibition and digital results in the task of analog decoding. 
6.1. Planar Traveling Salesman 
The traveling salesman problem (TSP) is, given a set of cities lying in the plane, find the shortest 
closed path that goes through every city exactly once. Finding the shortest path is NP-complete. 
619 
Finding a nearly optimal path, however, is much easier than finding a globally optimal path. There 
exist many heuristic algorithms for approximately solving the traveling salesman problemfi ,x o, xx,xa 
The solution presented in this section is moderately effective and illustrates the independence of 
BDMM to changes in parameters. 
Following Durbin and Willshawfi we use an elastic snake to solve the TSP. A snake is a discretized 
curve which lies on the plane. The elements of the snake are points on the plane, ( x, Sty). A snake 
is a locally connected neural network, whose neural outputs are positions on the plane. 
The snake minimizes its length 
E(xi+x - i) 2 -(sti+x -i)2, (29) 
i 
subject to the constraint that the snake must lie on the cities: 
- = o, k(st' - stc) = o, (30) 
where (a:*, st*) are city coordinates, (:,, tt,) is the closest snake point to the city, and k is the constraint 
strength. 
The minimization in equation (29) is quadratic and the constraints in equation (30) are piecewise 
linear, corresponding to a C � continuous potential energy in equation (21). Thus, the damping is 
positive definite, and the system converges to a state where the constraints are fulfilled. 
In practice, the snake starts out as a circle. Groups of cities grab onto the snake, deforming 
it. As the snake gets close to groups of cities, it grabs onto a specific ordering of cities that locally 
minimize its length (see Figure 4). 
The system of differential equations that solve equations (29) and (30) are piecewise linear. The 
differential equations for : and st are solved with implicit Euler's method, using tridiagonal LU 
decomposition to solve the linear system. x* The points of the snake are sorted into bins that divide 
the plane, so that the computation of finding the nearest point is simplified. 
Figure 4. The snake eventually attaches to the cities 
The constrained minimization in equations (29) and (30) is a reasonable method for approximately 
solving the TSP. For 120 cities distributed in the unti square, and 600 snake points, a numerical step 
size of 100 time units, and a constraint strength of 5 x 10 -3, the tour lengths are 6% q- 2% longer 
than that yielded by simulated annealing xx. Empirically, for 30 to 240 cities, the time needed to 
compute the final city ordering scales as N x'6, as compared to the Kernighan-Lin method x3, which 
scales roughly as N 2-2. 
The constraint strength is usable for both a 30 city problem and a 240 city problem. Although 
changing the constraint strength affects the performance, the snake attaches to the cities for any non- 
zero constraint strength. Parameter adjustment does not seem to be an issue as the number of cities 
increases, unlike the penalty method. 
620 
6.2. Analog Decoding 
Analog decoding uses analog signals from a noisy channel to reconstruct codewords. Analog 
decoding has been performed neurally, x with a code space of permutation matrices, out of the 
possible space of binary matrices. 
To perform the decoding of permutation matrices, the nearest permutation matrix to the signal 
matrix must be found. In other words, find the nearest matrix to the signal matrix, subject to the 
constraint that the matrix has on/off binary elements, and has exactly one ""on"" per row and one ""on"" 
per column. If the signal matrix is lj and the result is Vj, then minimize 
subject to constraints 
V$(1 - V.) -- O; 
(32) 
In this example, the first constraint in equation (32) forces crisp digital decisions. The second 
and third constraints are mutual inhibition along the rows and columns of the matrix. 
The optimization in equation (3 l) is not quadratic, it is linear. In addition, the first constraint in 
equation (32) is non-linear. Using the BDMM results in undamped oscillations. In order to converge 
onto a constrained minimum, the MDMM must be used. For both a 5 x 5 and a 20 x 20 system, a 
c = 0.2 is adequate for damping the oscillations. The choice of c seems to be reasonably insensitive 
to the size of the system, and a wide range of c, from 0.02 to 2.0, damps the oscillations. 
....... � ......... 
........ � .... O. .O. ' - 
oo .... � ............. 
Figure 5. The decoder finds the nearest permutation matrix 
In a test of the MDMM, a signal matrix which is a permutation matrix plus some noise, with 
a signal-to-noise ratio of 4 is supplied to the network. In figure 5, the system has turned on the 
correct neurons but also many incorrect neurons. The constraints start to be applied, and eventually 
the system reaches a permutation matrix. The differential equations do not need to be reset. If a new 
signal matrix is applied to the network, the neural state will move towards the new solution. 
7. Conclusions 
In the field of neural networks, there are differential optimization algorithms which find local 
solutions to non-convex problems. The basic differential multiplier method is a modification of a 
standard constrained optimization algorithm, which improves the capability of neural networks to 
perform constrained optimization. 
The BDMM and the MDMM offer many advantages over the penalty method. First, the differ- 
ential equations (10) are much less stiff than those of the penalty method. Very large quadratic terms 
are not needed by the MDMM in order to strongly enforce the constraints. The energy terrain for the 
621 
penalty method looks like steep canyons, with gentle floors; finding minima of these types of energy 
surfaces is numerically difficult. In addition, the steepness of the penalty terms is usually sensitive 
to the dimensionality of the space. The differential multiplier methods are promising techniques for 
alleviating stiffness. 
The differential multiplier methods separate the speed of fulfilling the constraints from the ac- 
curacy of fulfilling the constraints. In the penalty method, as the strengths of a constraint goes to 
oo, the constraint is fulfilled, but the energy has many undesirable local minima. The differential 
multiplier methods allow one to choose how quickly to fulfill the constraints. 
The BDMM fulfills constraints exactly and is compatible with the penalty method. Addition of 
penalty terms in the MDMM does not change the stationary points of the algorithm, and sometimes 
helps to damp oscillations and improve convergence. 
Since the BDMM and the MDMM are in the form of first-order differential equations, they can 
be directly implemented in hardware. Performing constrained optimization at the raw speed of analog 
VLSI seems like a promising technique for solving difficult perception problems. TM 
There exist Lyapunov functions for the BDMM and the MDMM. The BDMM converges glob- 
ally for quadratic programming. The MDMM is provably convergent in a local region around the 
constrained minima. Other optimization algorithms, such as Newton's method, x 7 have similar lo- 
cal convergence properties. The global convergence properties of the BDMM and the MDMM are 
currently under investigation. 
In summary, the differential method of multipliers is a useful way of enforcing constraints on 
neural networks for enforcing syntax of solutions, encouraging desirable properties of solutions, and 
making crisp decisions. 
Acknowledgments 
This paper was supported by an AT&T Bell Laboratories Fellowship (JCP). 
References 
1. K. J. Arrow, L. Hurwicz, H. Uzawa, Studies in Linear and Nonlinear Programming, (Stanford 
University Press, Stanford, CA, 1958). 
2. D. P. Bertsekas, Automatica, 12, 133-145, (1976). 
3. C. de Boor, A Practical Guide to Splines, (Springer-Verlag, NY, 1978). 
4. M. A. Cohen, S. Grossberg, IEEE Trans. Systems, Man, and Cybernetics,, 815-826, (1983). 
5. R. Durbin, D. Willshaw, Nature, 326, 689-691, (1987). 
6. J. C. Eccles, The Physiology of Nerve Cells, (Johns Hopkins Press, Baltimore, 1957). 
7. M. R. Hestenes, J. Opt. Theory Appl., 4, 303-320, (1969). 
8. M. R. Hestenes, Optimization Theory, (Wiley & Sons, NY, 1975). 
9. J. J. Hopfield, PNAS, 81, 3088, (1984). 
10. J. J. Hopfield, D. W. Tank, Biological Cybernetics, 52, 141, (1985). 
11. S. Kirkpatrick, C. D. Gelatt, C. M. Vecchi, Science, 220, 671-680, (1983). 
12. J. LaSalle, The Stability of Dynamical Systems, (SIAM, Philadelphia, 1976). 
13. S. Lin, B. W. Kernighan, Oper. Res., 21, 498-516 (1973). 
14. C. A. Mead, Analog VLSI and Neural Systems, (Addison-Wesley, Reading, MA, TBA). 
15. J. C. Platt, J. J. Hopfield, in AIP Conf. Proc. 151: Neural Networks for Computing (J. Denker 
ed.) 364-369, (American Institute of Physics, NY, 1986). 
16. M. J. Powell, in Optimization, (R. Fletcher, ed.), 283-298, (Academic Press, NY, 1969). 
17. W. H. Press, B. P. Flannery, S. A. Teukolsky, W. T. Vetterling, Numerical Recipes, (Cam- 
bridge University Press, Cambridge, 1986). 
18. D. Rumelhart, G. Hinton, R. Williams, in Parallel Distributed Processing, (D. Rumelhart, 
ed.), 1, 318-362, (MIT Press, Cambridge, MA, 1986). 
19. D. W. Tank, J. J. Hopfield, IEEE Trans. Cir. & Sys., CAS-33, no. 5, 533-541 (1986). 
", differenti optim platt institut ca optim model neural network need constraint restrict space output subspac satisfi extern optim use energi method yield upon state neural penalti quadrat energi constraint ad exist optim becom popular guarante satisfi constraint condit forc neural model multipl present basic differenti multipli method satisfi constraint creat forc gradual appli constraint estim lagrang basic differenti multipli method differenti version method multipli numer prove differenti equat local converg constrain applic differenti method multipli includ enforc permut analog decod problem enforc valid tour travel salesman introduct ubiquit field neural mani learn xs optim minim differ expect solut observ neural algorithm use differenti equat minim energi solv specifi comput associ differenti solut salesman analog linear lyapunov show variou model neural behavior find minima particular constrain optim problem restrict subset solut unconswain optim mutual inhibit circuit requir neuron rest anoth exampl wavel salesman salesman tri minim travel subject constraint must visit citi exactli third exampl curv fit elast spline still go data pointsfi digit decis analog answer constrain either xa constrain optim problem state state neural posit vector imagin height landscap function posit scalar equat describ subspac state constrain attract subspac slide along subspac reach smallest valu section describ classic method constrain method laglang introduc basic differenti multipli method constrain calcul good local constrain optim problem local minimum global find global minimum fairli section show lyapunov function bdmm draw analog american institut physic section augment idea optim enhanc converg section appli differenti algorithm two neural discuss bdmm choic paramet sensit persist problem neural classic method constrain optim section discuss two method constrain penalti method lagrang penalti method previous use differenti basic multipli method develop paper appli lagrang multipli differenti penalti method penalti method analog ad rubber band attract neural state subspac penalti method add quadrat energi term penal constrain minim problem convert follow minim penalti method make trough state space penalti method extend fulfil multipl constraint use one rubber constrain optim problem convert unconstrain optim problem penalti method sever conveni easi global correct answer allow compromis case spline curv fit input compromis fit data make smooth penalti method number finit constraint strength fulfil constraint use multipl rubber band constraint like build machin rubber machin would hold togeth constraint strength get harder especi size dimension get dilemma set constraint strength system find deep local fulfil strength system quickli fulfil get stuck poor local lagrang multipli multipli method also convert constrain optim problem unconstrain solut equat also critic point energi call lagrang multipli constraint direct consequ equat gradient collinear gradient constrain extrema figur constant proportion vf vg use collinear vf vg design constrain vf simpl exampl show lagrang multipli provid exlxa degre freedom necessari solv constrain optim consid problem find point closest use lagrang za ya take deriv respect extra variabl three equat three last precis constraint basic differenti multipli method constrain optim section present new algorithm constrain consist equat estim lagrang neural algorithm variat first present hesten gradient descent work lagrang multipli simplest differenti optim algorithm gradient state variabl network slide opposit appli gradient descent energi equat yield auxiliari differenti equat addit necessari appli constraint recal system constrain involv lagrang critic point tend saddl consid energi equat energi decreas send descent work lagrang critic point energi equat need attractor stationari point must local minimum order gradient descent new basic differenti multipli method present altern differenti gradient descent estim lagrang constrain minima attractor differenti instead equat solv axi similar equat equat constrain extrema ener stationari point equat sign invers equat compar equat equat perform gradient ascent sign flip bdmm shown section correspond neural network connect extens algorithm extens equat algorithm constrain minim multipl ad extra neuron everi equal constraint sum constraint forc energi yield differenti equat aga extens constrain minim inequ tradit one use extra slack variabl convert inequ constraint equal constraint form express must alway constrain slack variabl like compon equat inequ constraint requir two extra slack variabl one lagrang multipli inequ constraint repres equal optim constrain algorithm work system differenti equat gradual fulfil notic function replac without chang locat constrain state begin undergo damp oscil constraint increas frequenc oscil time converg path algorithm state state attract constraint subspac damp oscil equat explain combin differenti one differenti equat damp mass inertia term damp matrix intern deriv intern energi system damp state remain state fall inw constrain construct total energi sum kinet total energi decreas time state remain system extra settl state constrain extremum origin problem equat time deriv total energi equat damp matrix posit system converg fulfil alway converg special case constrain quadrat quadrat program problem quadrat function piecewis linear continu posit damp matrix aij posit definit converg multipl constraint case multipl total energi equat time deriv bdmm solv quadrat program solut pose problem contradictori case conflict bdmm tri make constraint lagrang multipli goe conslxaint oppos arbitrarili limit larg absolut invari theorem xa use prove bdmm eventu fulfil open subset let subset closur system equat damp matrix posit mte set xi apach modifi differenti method multipli robust given oper bdmm region posit multipli multipri method modifi local converg complemli compat one add forc energi set differenti equat mdmm forc penalti chang posit stationari point differenti penalti forc damp matrix modifi forc theorem state exist damp matrix equat posit definit conslxain use damp matrix definit region surround conslxain system start remain bound converg theorem end section mdmm converg constrain minimum necessari penalti strength mdmm usual much less strength penalti method exampl section contain two exampl illustr use bdmm bdmm use find good solut planar travel salesman use enforc mutual inhibit digit result task analog planar travel salesman travel salesman problem given set citi lie find shortest path goe everi citi exactli find shortest path nearli optim much easier find global optim mani heurist algorithm approxim solv travel salesman problemfi solut present section moder effect illustr independ chang durbin willshawfi use elast snake solv snake discret lie element snake point snake local connect neural whose neural output posit snake minim length constraint snake must lie citi closest snake point constraint minim equat quadrat constraint equat piecewis correspond continu potenti energi equat damp system converg state constraint snake start group citi grab onto deform snake get close group grab onto specif order citi local length figur system differenti equat solv equat piecewis equat solv implicit use tridiagon lu solv linear point snake sort bin divid comput find nearest point snake eventu attach citi constrain minim equat reason method approxim citi distribut unti snake numer step time constraint strength tour length longer yield simul anneal time need final citi order scale compar method roughli constraint strength usabl citi problem citi although constraint strength affect snake attach citi constraint paramet adjust seem issu number citi unlik penalti analog decod decod use analog signal noisi channel reconstruct analog perform code space permut space binari perform decod permut nearest permut matrix signal must find nearest matrix signal subject matrix binari exactli one per row one signal matrix result minim constraint first constraint equat forc crisp digit second third constraint mutual inhibit along row column optim equat first constraint use bdmm result undamp order converg constrain mdmm must adequ damp choic seem reason insensit size wide rang damp decod find nearest permut matrix test signal matrix permut matrix plu ratio suppli figur system turn neuron also mani incorrect constraint start eventu system reach permut differenti equat need new matrix appli neural state move toward new conclus field neural differenti optim algorithm find local basic differenti multipli method modif constrain optim improv capabl neural network constrain bdmm mdmm offer mani advantag penalti equat much less stiff penalti larg quadrat term need mdmm order strongli enforc energi terrain method look like steep gentl find minima type energi numer steep penalti term usual sensit dimension differenti multipli method promis techniqu differenti multipli method separ speed fulfil constraint fulfil penalti strength constraint goe constraint energi mani undesir local differenti method allow one choos quickli fulfil bdmm fulfil constraint exactli compat penalti addit term mdmm chang stationari point sometim damp oscil improv bdmm mdmm form differenti directli implement perform constrain optim raw speed analog seem like promis techniqu solv difficult percept tm exist lyapunov function bdmm bdmm converg quadrat mdmm provabl converg local region around optim similar converg global converg properti bdmm mdmm differenti method multipli use way enforc constraint network enforc syntax encourag desir properti crisp paper support bell laboratori fellowship studi linear nonlinear de practic guid ie physiolog nerv hopkin theori optim biolog stabil dynam analog vlsi neural aip neural network comput denker institut numer univers parallel distribut ie,0
65,65,"622 
LEARNING A COLOR ALGORITHM FROM EXAMPLES 
Anya C. Hurlbert and Tomaso A. Poggio 
Artificial Intelligence Laboratory and Department of Brain and Cognitive Sciences, 
Massachusetts Institute of Technology, Cambridge, Massachusetts 02139, USA 
ABSTRACT 
A lightness algorithm that separates surface reflectance from illumination in a 
Mondrian world is synthesized automatically from a set of examples, pairs of input 
(image irradiance) and desired output (surface reflectance). The algorithm, which re- 
sembles a new lightness algorithm recently proposed by Land, is approximately equiva- 
lent to filtering the image through a center-surround receptive field in individual chro- 
matic channels. The synthesizing technique, optimal linear estimation, requires only 
one assumption, that the operator that transforms input into output is linear. This 
assumption is true for a certain class of early vision algorithms that may therefore be 
synthesized in a similar way from examples. Other methods of synthesizing algorithms 
from examples, or ""learning"", such as backpropagation, do not yield a significantly dif- 
ferent or better lightness algorithm in the Mondrian world. The linear estimation and 
backpropagation techniques both produce simultaneous brightness contrast effects. 
The problems that a visual system must solve in decoding two-dimensional images 
into three-dimensional scenes (inverse optics problems) are difficult: the information 
supplied by an image is not sufficient by itself to specify a unique scene. To reduce 
the number of possible interpretations of images, visual systems, whether artificial 
or biological, must make use of natural constraints, assumptions about the physical 
properties of surfaces and lights. Computational vision scientists have derived effective 
solutions for some inverse optics problems (such as computing depth from binocular 
disparity) by determining the appropriate natural constraints and embedding them in 
algorithms. How might a visual system discover and exploit natural constraints on its 
own? We address a simpler question: Given only a set of examples of input images and 
desired output solutions, can a visual system synthesize, or ""learn"", the algorithm that 
converts input to output? We find that an algorithm for computing color in a restricted 
world can be constructed from examples using standard techniques of optimal linear 
estimation. 
The computation of color is a prime example of the difficult problems of inverse 
optics. We do not merely discriminate between different wavelengths of light; we assign 
@ American Institute of Physics 1988 
623 
roughly constant colors to objects even though the light signals they send to our eyes 
change as the illumination varies across space and chromatic spectrum. The compu- 
tatjohn.1 goal underlying color constancy seems to be to extract the invariant surface 
spectral reflectance properties from the image irradiance, in which reflectance and il-' 
lumination are mixed 1. 
Lightness algorithms 2-s, pioneered by Land, assume that the color of an object 
can be specified by its lightness, or relative surface reflectance, in each of three inde- 
pendent chromatic channels, and that lightness is computed in the same way in each 
channel. Computing color is thereby reduced to extracting surface reflectance from the 
image irradiance in a single chromatic channel. 
The image irradiance, s t, is proportional to the product of the illumination inten- 
sity e t and the surface reflectance r t in that channel: 
st(x,y) - rt(x,y)et(x,y). (1) 
This form of the image intensity equation is true for a Lambertinn reflectance model, 
in which the irradiance s t has no specular components, and for appropriately chosen 
color channels 9. Taking the logarithm of both sides converts it to a sum: 
y) = r(x, y) + e(x,y), (2) 
where s = log(s'), r = log(r') and e = log(e'). 
Given s(x, y) alone, the problem of solving Eq. 2 for r(x, y) is underconstrained. 
Lightness algorithms constrain the problem by restricting their domain to a world of 
Mondrians, two-dimensional surfaces covered with patches of random colors 2 and by 
exploiting two constraints in that world: (i) r'(x,y) is uniform within patches but 
has sharp discontinuities at edges between patches and (ii) e'(x,y) varies smoothly 
across the Mondrian. Under these constraints, lightness algorithms can recover a good 
approximation to r(x, y) and so can recover lightness triplets that label roughly constant 
colors l0 
We ask whether it is possible to synthesize from examples an algorithm that ex- 
tracts reflectance from image irradiance, and whether the synthesized algorithm will re- 
semble existing lightness algorithms derived from an explicit analysis of the constraints. 
We make one assumption, that the operator that transforms irradiance into reflectance 
is linear. Under that assumption, motivated by considerations discussed later, we use 
optimal linear estimation techniques to synthesize an operator from examples. The 
examples are pairs of images: an input image of a Mondrian under illumination that 
varies smoothly across space and its desired output image that displays the reflectance 
of the Mondrian without the illumination. The technique finds the linear estimator 
that best maps input into desired output, in the least squares sense. 
For computational convenience we use one-dimensional ""training vectors"" that 
represent vertical scan lines across the Mondrian images (Fig. 1). We generate many 
624 
Input data 
0 SO lOG 150 200 .Se 300 
correct illumination 
60 
0 $0 100 Z$O 200 250 300 
output illumination 
correct reflectance 
tO0 I$0 00 250 700 
output reflectance 
a 
b 
c 
Fig. 1. (a) The input data, a one-dimensional vector 320 pixels long. Its random 
Mondrian reflectance pattern is superimposed on a linear illumination gradient with 
a random slope and offset. (b) shows the corresponding output solution, on the left 
the illumination and on the right reflectance. We used 1500 such pairs of input- 
output examples (each different from the others) to train the operator shown in Fig. 
2. (c) shows the result obtained by the estimated operator when it acts on the input 
data (a), not part of the training set. On the left is the illumination and on the 
right the reflectance, to be compared with (b). This result is fairly typical: in some 
cases the prediction is even better, in others it is worse. 
different input vectors s by adding together different random r and e vectors, according 
to Eq. 2. Each vector r represents a pattern of step changes across space, corresponding 
to one column of a reflectance image. The step changes occur at random pixels and 
are of random amplitude between set minimum and maximum values. Each vector � 
represents a smooth gradient across spa:e with a random offset and slope, corresponding 
to one column of an illumination image. We then arrange the training vectors s and r 
as the columns of two matrices S and R, respectively. Our goal is then to compute the 
optimal solution � of 
LS:R 
where L is a linear operator represented a a matrix. 
625 
It is well known that the solution of this equation that is optimal in the least 
squares sense is 
L = RS + (4) 
where S + is the Moore-Penrose pseudoinverse . We compute the pseudoinverse by 
overconstraining the problem - using many more training vectors than there are number 
of pixels in each vector - and using the straightforward formula that applies in the 
overconstrained case 2: S + = sT(ssT)-. 
The operator L computed in this way recovers a good approximation to the correct 
output vector r when given a new s, not part of the training set, as input (Fig. lc). 
A second operator, estimated in the same way, recovers the illumination e. Acting on 
a random two-dimensional Mondrian L also yields a satisfactory approximation to the 
correct output image. 
Our estimation scheme successfully synthesizes an aigorithm that performs the 
lightness computation in a Mondrian world. What is the algorithm and what is its 
relationship to other lightness algorithms? To answer these questions we examine the 
structure of the matrix L. We assume that, although the operator is not a convolution 
operator, it should approximate one far from the boundaries of the image. That is, 
in its central part, the operator should be space-invariant, performing the same action 
on each point in the image. Each row in the central part of L should therefore be 
the same as the row above but displaced by one element to the right. Inspection of 
the matrix confirmes this expectation. To find the form of L in its center, we thus 
average the rows there, first shifting them appropriately. The result, shown in Fig. 2, 
is a space-invariant filter with a narrow positive peak and a broad, shallow, negative 
surround. 
Interestingly, the filter our scheme synthesizes is very similar to Land's mct recent 
retinex operator 5, which divides the image irradiance at each pixel by a weighted 
average of the irradiance at all pixels in a large surround and takes the logarithm of 
that result to yield lightness 13. The lightness triplets computed by the retinex operator 
agree well with human perception in a Mondrian world. The retinex operator and our 
matrix L both differ from Land's earlier retinex algorithms, which require a non-linear 
thresholding step to eliminate smooth gradients of illumination. 
The shape of the filter in Fig. 2, particularly of its large surround, is also sugges- 
tive of the ""nonclassical"" receptive fields that have been found in V4, a cortical area 
implicated in mechanisms underlying color constancy 14-7 
The form of the space-invariant filter is similar to that derived in our earlier formal 
analysis of the lightness problem s It is qualitatively the same as that which results 
from the direct application of regularization methods exploiting the spatial constraints 
on reflectance and illumination described above 9.s.9 The Fourier transform of the 
filter of Fig. 2 is approximately a bandpass filter that cuts out low frequencies due 
626 
-80 0 +80 
Pixels 
-80 0 +$0 
Pixels 
Fig. 2. The space-invariant part of the estimated operator, obtained by shifting and 
averaging the rows of a 160-pixel-wide central square of the matrix L, trained on a set 
of 1500 examples with linear illumination gradients (see Fig. 1). When logarithmic 
illumination gradients are used, a qualitatively similar receptive field is obtained. In 
a separate experiment we use a training set of one-dimensional Mondrians with either 
linear illumination gradients or slowly varying sinusoidal illumination components 
with random wavelength, phase and amplitude. The resulting filter is shown in 
the inset. The surrounds of both filters extend beyond the range we can estimate 
reliably, the range we show here. 
to slow gradients of illumination and preserves intermediate frequencies due to step 
changes in refiectance. In contrast, the operator that recovers the illumination, e. 
takes the form of a low-pa.ss filter. We stress that the entire operator L is not a 
space-invariant filter. 
In this context, it is clear that the shape of the estimated operator should vary with 
the type of illumination gradient in the training set. We synthesize a second operator 
using a new set of examples that contain equal numbers of vectors with random, sinu- 
soldally varying illumination components and vectors with random, linear illumination 
gradients. Whereas the first operator, synthesized from examples with strictly linear 
illumination gradients, has a broad negative surround that remains virtually constant 
throughout its extent, the new operator's surround (Fig. 2, inset) has a smaller extc.t 
627 
and decays smoothly towards zero from its peak negative value in its center. 
We also apply the operator in Fig. 2 to new input vectors in which the density 
and amplitude of the step changes of reflectance differ greatly from those on which the 
operator is trained. The operator performs well, for example, on an input vector rep- 
resenting one column of an image of a small patch of one reflectance against a uniform 
background of a different reflectance, the entire image under a linear illumination gra- 
dient. This result is consistent with psychophysical experiments that show that color 
constancy of a patch holds when its Mondrian background is replaced by an equivalent 
grey background 20 
The operator also produces simultaneous brightness contrast, as expected from the 
shape and sign of its surround. The output reflectance it computes for a patch of fixed 
input reflectance decreases linearly with increasing average irradiance of the input test 
vector in which the patch appears. Similarly, to us, a dark patch appears darker when 
against a light background than against a dark one. 
This result takes one step towards explaining such illusions as the Koffka Ring 21 
A uniform gray annulus against a bipartite background (Fig. 3a) appears to split into 
two halves of different lightnesses when the midline between the light and dark halves 
of the background is drawn across the annulus (Fig. 3b). The estimated operator 
acting on the Koffka Ring of Fig. 3b reproduces our perception by assigning a lower 
output reflectance to the left half of the annulus (which appears darker to us) than to 
the right half 2 Yet the operator gives this brightness contrast effect whether or not 
the midline is drawn across the annulus (Fig. 3c). Because the operator can perform 
only a linear transformation between the input and output images, it is not surprising 
that the addition of the midline in the input evokes so little change in the output. 
These results demonstrate that the linear operator alone cannot compute lightness in 
all worlds and suggest that an additional operator might be necessary to mark and 
guide it within bounded regions. 
Our estimation procedure is motivated by our previous observation 9,23,s that 
standard regularization algorithms 9 in early vision define linear mappings between 
input and output and therefore can be estimated sociatively under certain condi- 
tions. The technique of optimal linear estimation that we use is closely related to 
optimal Bayesian estimation 9. If we were to ax, sume from the start that the optimal 
linear operator is space-invariant, we could considerably simplify (and streamline) the 
computation by using standard correlation techniques 9.4 
How does our estimation technique compare with other methods of ""learning"" a 
lightness algorithm? We can compute the regularized pseudoinverse using gratient 
descent on a ""neural"" network s with linear unit. Since the pseudoinverse is the 
unique best linear approximation in the L2 norm, a graillent descent method that 
628 
minimizes the square error between the actual output and desired output of a fully 
connected linear network is guaranteed to converge, albeit slowly. Thus gradient de- 
scent in weight space converges to the same result as our first technique, the global 
nfinimum. 
input data pixel 
output reflectance - with edge 
output reflectance - without edge 
Fig. 3. (a) Koffka Ring. (b) Koffka Ring with 
midline drawn across annulus. (c) Horizontal 
scan lines across Koffka Ring. Top: Scan 
line starting at arrow in (b). Middle: Scan 
line at corresponding location in the output of 
linear operator acting on (b). Bottom: Scan line 
at same location in the output of operator acting 
on (a). 
629 
We also compare the linear estimation technique with a ""backpropagation"" net- 
work: gradient descent on a 2-layer network with sigmoid units 25 (32 inputs, 32 
""hidden units"", and 32 linear outputs), using training vectors 32 pixels long. The net- 
work requires an order of magnitude more time to converge to a stable configuration 
than does the linear estimator for the same set of 32-pixel examples. The network's 
performance is slightly, yet consistently, better, neasured as the root-mean-square er- 
ror in output, averaged over sets of at least 2000 new input vectors. Interestingly, the 
backpropagation network and the linear estinator err in the sane way on the same 
input vectors. It is possible that the backpropagation network may show considerable 
inprovement over the linear estimator in a world more complex than the Mondrian one. 
We are presently examining its performance on images with real-world features such 
as shading, shadows, and highlights 26. 
We do not think that our results mean that color constancy may be learned during 
a critical period by biological organisms. It seems more reasonable to consider them 
simply as a demonstration on a toy world that in the course of evolution a visual system 
may recover and exploit natural constraints hidden in the physics of the world. The 
significance of our results lies in the facts that a simple statistical technique may be used 
to synthesize a lightness algorithm from examples; that the technique does as well as 
other techniques such as backpropagation; and that a similar technique may be used for 
other problems in early vision. Furthermore, the synthesized operator resembles both 
Land's psychophysically-tested retinex operator and a neuronal nonclassical receptive 
field. The operator's properties suggest that simultaneous color (or brightness) contrast 
might be the result of the visual system's attempt to discount illumination gradients 
27 
REFERENCES AND NOTES 
1. Since we do not have perfect color constancy, our visual system must not extract 
reflectance exactly. The limits on color constancy might reveal limits on the underlying 
computation. 
2. E.H. Land, Am. Sci. 52, 247 (1964). 
4. 
and S. 
5. 
6. 
E.H. Land and J.J. McCann, J. Opt. Soc. Am. 61, 1 (1971). 
E.H. Land, in Central and Peripheral Mechanisms of Colour Vision, T. Ottoson 
Zeki, Eds., (Macmillan, New York, 1985), pp. 5-17. 
E.H. Land, Proc. Nat. Acad. Sci. USA 83, 3078 (1986). 
B.K.P. Horn, Computer Graphics and Image Processing 3, 277 (1974). 
630 
7. A. Blake, in Central and Peripheral Mechanisms of Colour Vision, T. Ottoson 
and S. Zeki, Eds., (Macmillan, New York, 1985), pp. 45-59. 
8. A. Hurlbert, J. Opt. Soc. Am. A 3, 1684 (1986). 
9. A. Hurlbert and T. Poggio, Artificial Intelligence Laboratory Memo 909, (M.I.T., 
Cambridge, MA, 1987). 
10. r(x,y) can be recovered at best only to within a constant, since Eq. 1 
is invariant under the transformation of r  into ar  and e  into a-e , where a is a 
constant. 
11. A. Albert, Regression and the Moore-Penrose Pseudoinverse, (Acadenfic Press, 
New York, 1972). 
12. The pseudoinverse, and therefore L, may also be computed by recursive tech- 
niques that improve its form as more data become available . 
13. Our synthesized filter is not exactly identical with Land's: the filter of Fig. 
2 subtracts from the value at each point the average value of the logarithm of irra- 
diance at all pixels, rather than the logarithm of the average values. The estimated 
operator is therefore linear in the logarithms, whereas Land's is not. The numerical 
difference between the outputs of the two fdters is small in most cases (Land, personal 
communication), and both agree well with psychophysical results. 
14. R. Desireone, S.J. Schein, J. Moran and L.G. Ungerleider, Vision Res. 25, 
441 (1985). 
15. H.M. Wild, S.R. Butler, D. Carden and J.J. Kulikowski, Nature (London) 313, 
133 (195). 
16. S.M. Zeki, Neuroscience 9, 741 (1983). 
17. S.M. Zeki, Neuroscience 9, 767 (1983). 
18. T. Poggio, et. al., in Proceedings Image Understanding Workshop, L. Bau- 
mann, Ed., (Science Applications International Corporation, McLean, VA, 1985), pp.. 
25-39. 
19. T. Poggio, V. Torre and C. Koch, Nature (London) 317, 314 (1985). 
20. A. Valberg and B. Lange-Malecki, Investigative Ophthalmology and Visual 
Science Supplement 28, 92 (1987). 
21. K. Koffka, Principles of Gestalt Psychology, (Harcourt, Brace and Co., New 
York, 1935). 
22. Note that the operator achieves this effect by subtracting a non-existent illu- 
mination gradient from the input signal. 
23. T. Poggio and A. Hurlbert, Artificial Intelligence Laboratory Working Paper 
264, (M.I.T., Cambridge, MA, 1984). 
24. Estimation of the operator on two-dimensional examples is possible, but com- 
putationally very expensive if done in the same way. The present computer simulations 
require several hours when run on standard serial computers. The two-dimensional case 
631 
will need much more time (our one-dimensional estimation scheme runs orders of mag- 
nitude faster on a CM-1 Connection Machine System with 16K-processors). 
25. D. E. Rumelhart, G.E. Hinton and R.J. Williams, Nature (London) 323, 533 
(1986). 
26. A. Hurlbert, The Computation of Color, Ph.D. Thesis, M.I.T., Cambridge, 
MA, in preparation. 
27. We are grateful to E. Land, E. Hildreth. J. Little, F. Wilczek and D. Hillis 
for reading the draft and for useful discussions. A. Rottenberg developed the routines 
for matrix operations that we used on the Connection Machine. T. Breuel wrote the 
backpropagation simulator. 
", color algorithm exampl hurlbert tomaso poggio intellig laboratori depart brain cognit institut massachusett usa light algorithm separ surfac reflect illumin world synthes automat set pair input desir output new light algorithm recent propos approxim filter imag recept field individu synthes optim linear requir oper transform input output true certain class earli vision algorithm may therefor similar way method synthes algorithm yield significantli better light algorithm mondrian linear estim techniqu produc simultan bright contrast problem visual system must solv decod imag scene optic inform imag suffici specifi uniqu reduc number possibl interpret visual whether artifici must make use natur assumpt physic surfac comput vision scientist deriv effect invers optic problem comput depth binocular determin appropri natur constraint embed might visual system discov exploit natur constraint address simpler given set exampl input imag output visual system algorithm input find algorithm comput color restrict construct exampl use standard techniqu optim linear comput color prime exampl difficult problem invers mere discrimin differ wavelength assign american institut physic constant color object even though light signal send eye illumin vari across space chromat goal underli color constanc seem extract invari surfac reflect properti imag reflect mix algorithm pioneer assum color object specifi rel surfac three chromat light comput way comput color therebi reduc extract surfac reflect irradi singl chromat imag proport product illumin surfac reflect form imag intens equat true lambertinn reflect irradi specular appropri chosen channel take logarithm side convert problem solv algorithm constrain problem restrict domain world surfac cover patch random color two constraint uniform within patch sharp discontinu edg patch vari smoothli light algorithm recov good recov light triplet label roughli constant ask whether possibl synthes exampl algorithm reflect imag whether synthes algorithm exist light algorithm deriv explicit analysi make one oper transform irradi reflect motiv consider discuss use linear estim techniqu synthes oper pair input imag mondrian illumin smoothli across space desir output imag display reflect mondrian without techniqu find linear estim best map input desir least squar comput conveni use vertic scan line across mondrian imag gener mani data og illumin illumin reflect reflect input vector pixel random reflect pattern superimpos linear illumin gradient random slope show correspond output left illumin right use pair exampl differ train oper shown show result obtain estim oper act input part train left illumin compar result fairli predict even other input vector ad togeth differ random accord vector repres pattern step chang across correspond one column reflect step chang occur random pixel random amplitud set minimum maximum vector smooth gradient across random offset correspond one column illumin arrang train vector column two matric goal comput solut linear oper repres well known solut equat optim least sens rs pseudoinvers comput pseudoinvers problem use mani train vector number pixel vector use straightforward formula appli case oper comput way recov good approxim correct vector given new part train input second estim recov illumin act random mondrian also yield satisfactori approxim output estim scheme success synthes aigorithm perform comput mondrian algorithm light answer question examin matrix assum although oper convolut approxim one far boundari central oper perform action point row central part therefor row displac one element inspect matrix confirm find form thu row first shift shown filter narrow posit peak neg filter scheme synthes similar recent oper divid imag irradi pixel weight irradi pixel larg surround take logarithm result yield light light triplet comput retinex oper well human percept mondrian retinex oper differ earlier retinex requir step elimin smooth gradient shape filter particularli larg also recept field found cortic area mechan underli color constanc form filter similar deriv earlier formal light problem qualit result direct applic regular method exploit spatial constraint reflect illumin describ fourier transform approxim bandpass filter cut low frequenc due part estim obtain shift row central squar matrix train set exampl linear illumin gradient logarithm gradient qualit similar recept field separ experi use train set mondrian either illumin gradient slowli vari sinusoid illumin compon random phase result filter shown surround filter extend beyond rang estim rang show slow gradient illumin preserv intermedi frequenc due step oper recov form stress entir oper clear shape estim oper vari type illumin gradient train synthes second oper new set exampl contain equal number vector vari illumin compon vector linear illumin wherea first synthes exampl strictli linear broad neg surround remain virtual constant new surround smaller decay smoothli toward zero peak neg valu also appli oper new input vector densiti amplitud step chang reflect differ greatli oper perform input vector one column imag small patch one reflect uniform differ entir imag linear illumin result consist psychophys experi show color patch hold mondrian background replac equival background oper also produc simultan bright expect sign output reflect comput patch fix reflect decreas linearli increas averag irradi input test patch dark patch appear darker light background dark result take one step toward explain illus koffka ring uniform gray annulu bipartit background appear split halv differ light midlin light dark halv background drawn across annulu estim oper koffka ring reproduc percept assign lower reflect left half annulu appear darker right half yet oper give bright contrast effect whether midlin drawn across annulu oper perform linear transform input output surpris addit midlin input evok littl chang result demonstr linear oper alon can not comput light world suggest addit oper might necessari mark within bound estim procedur motiv previou observ regular algorithm earli vision defin linear map output therefor estim certain techniqu optim linear estim use close relat bayesian estim sume start optim oper could consider simplifi use standard correl techniqu estim techniqu compar method comput regular pseudoinvers use network linear sinc pseudoinvers best linear approxim graillent descent method squar error actual output desir output fulli linear network guarante albeit thu gradient weight space converg result first global data pixel reflect edg reflect without edg koffka koffka ring drawn across horizont line across koffka scan start arrow scan correspond locat output oper act scan line locat output oper act also compar linear estim techniqu gradient descent network sigmoid unit linear use train vector pixel requir order magnitud time converg stabl configur linear estim set yet averag set least new input network linear err way possibl backpropag network may show consider linear estim world complex mondrian present examin perform imag featur highlight think result mean color constanc may learn critic period biolog seem reason consid demonstr toy world cours evolut visual system recov exploit natur constraint hidden physic result lie fact simpl statist techniqu may use synthes light algorithm techniqu well techniqu similar techniqu may use problem earli synthes oper resembl retinex oper neuron nonclass recept properti suggest simultan color contrast result visual attempt discount illumin gradient note sinc perfect color visual system must extract limit color constanc might reveal limit underli land central peripher mechan colour ottoson new usa comput graphic imag process central peripher mechan colour ottoson new hurlbert artifici intellig laboratori memo recov best within sinc invari transform ar regress therefor may also comput recurs improv form data becom avail synthes filter exactli ident filter subtract valu point averag valu logarithm rather logarithm averag estim therefor linear wherea numer output two fdter small case person agre well psychophys moran vision carden natur neurosci neurosci proceed imag understand applic intern torr natur valberg investig ophthalmolog visual supplement principl gestalt brace new note oper achiev effect subtract gradient input poggio artifici intellig laboratori work paper estim oper exampl expens done present comput simul sever hour run standard serial case need much time estim scheme run order faster connect machin system hinton natur comput grate wilczek hilli read draft use rottenberg develop routin matrix oper use connect breuel wrote,0
66,66,"632 
STATIC AND DYNAMIC ERROR PROPAGATION 
NETWORKS WITH APPLICATION TO SPEECH 
CODING 
A J Robinson, F Fallside 
Cambridge University Engineering Department 
Trumpington Street,, Cambridge, England 
Abstract 
Error propagation nets have been shown to be able to learn a variety of tasks in 
which a static input pattern is mapped onto a static output pattern. This paper 
presents a generalisation of these nets to deal with time varying, or dynanic 
patterns, and three possible architectures are explored. As an example, dynanic 
nets are applied to the problem of speech coding, in which a time sequence of 
speech data are coded by one net and decoded by another. The use of dynamic 
nets gives a better signal to noise ratio than that achieved using static nets. 
1. INTRODUCTION 
This paper is based upon the use of the error propagation algorithn of Runnelhart, Hinton 
and Williams  to train a connectionist net. The net is defined as a set of units, each with an 
activation, and weights between units which determine the activations. The algorithm uses a 
gradient descent technique to calculate the direction by which each weight should be changed 
in order to miniraise the summed squared difference between the desired outpnt and the actual 
output. Using this algorithm it is believed that a net can be trained to make an arbitrary 
non-linear mapping of the input units onto the output units if given enough intermediate 
units. This 'static' net can be used as part of a larger system with more complex behaviour. 
The static net has no memory for past inputs, but many problems require the context of 
the input in order to compute the answer. An extension to the static net is developed, the 
'dynamic' net, which feeds back a section of the output to the input, so creating some internal 
storage for context, and allowing a far greater class of problems to be learned. Previously this 
method of training time dependence into nets has suffered from a computational requirement 
which increases linearly with the time span of the desired context. The three architectures 
for dynamic nets presented here overcome this difficulty. 
To illustrate the power of these networks a general coder is developed and applied to the 
problem of speech coding. The non-linear solution found by training a dynamic net coder is 
compared with an established linear solution, and found to have an increased performance as 
measured by the signal to noise ratio. 
2. STATIC ERROR PROPAGATION NETS 
A static net is defined by a set of units and links between the units. Denoting oi as the value 
of the i th unit, and wi,j as the weight of the link between oi and oj, we may divide up the 
units into input units, hidden units and output units. If we assign o0 to a constant to forIn a 
� American Institute of Physics 1988 
633 
bias, the input units run from ox up to On,.,, followed by the hidden units to O.h,  and then 
the output units to o. ..... . The values of the input units are defined by the problem and the 
values of the remaining units are defined by: 
i-1 
net/ ---- 
=0 
oi = f(neti) (2.2) 
where f(x) is any continuous monotonic non-linear function and is known as the activation 
function. The function used the application is: 
2 
- 
These equations define a net which has the maxiinum number of interconnections. This 
arrangement is commonly restricted to a layered structure in which units are only connected 
to the immediately preceding layer. The architecture of these nets is specified by the number 
of input, output and hidden units. Diagrainmatically the static net is transformation of an 
input u, onto the output y, as in figure 1. 
uStatic  
figure 1 
The net is trained by using a gradient descent Mgorithm which minismises an energy 
term, E, defined as the summed squared error between the actual outputs, ol, and the target 
outputs, h. The algorithm also defines an error signal, 61, for each unit: 
E =   (ti-oi) 2 (2.4) 
6i = f'(neti)(ti -- oi) nhid < i _ nout (2.5) 
= ft(neti)  ilOd,i ""inp < i __ ""hid 
j=i+l 
where f'(x) is the derivative of f(t). The error signal and the activations of the units define 
the change in each weight, Awi,j. 
Au'i,i = ioj (2.7) 
where 71 is a constant of proportionality which determines the learning rate. The above 
equations define the error signal, i, for the input units as well as for the hidden units. Thus 
any number of static nets can be connected together, the values of i being passed from input 
units of one net to output units of the preceding net. It is this ability of error propagation 
nets to be 'glued' together in this way that enables the construction of dynamic nets. 
3. DYNAMIC ERROR PROPAGATION NETS 
The essential quality of the dynamic net is is that its behaviour is determined both by the 
external input to the net, and also by its own internal state. This state is represented by the 
634 
activation of a group of units. These units form part of the output of a static net and also 
part of the input to another copy of the same static net in the next tine period. Thus the 
state units link multiple copies of static nets over time to form a dynamic net. 
3.1. DEVELOPMENT FROM LINEAR CONTROL THEORY 
The analogy of a dynamic net in linear systems 2 may be stated as: 
xv+i = Ax v + Bu v (3.1.1) 
Yv = �xv (3.1.2) 
where us, is the input vector, xs, the state vector, and ys, the output vector at the integer time 
p. A, B and C are matrices. 
The structure of the linear systems solution may be implemented as a non-linear dynamic 
net by substituting the matrices A, B and C by static nets, represented by the non-linear 
functions A[.], B[.] and C[.]. The summation operation of Axs, and Bu s, could be achieved 
using a net with one node for each element in x and u and with unity weights from the two 
inputs to the identity activation function f(x) - x. Alternatively this net can be incorporated 
into the A[.] net giving the architecture of figure 2. 
A[.] 
Time 
Delay 
x(p+ y(p+l) 
- 'l I ' 
u(p) 
dynamic i 
net I 
figure 2 figure 3 
The three networks may be combined into one, as in figure 3. Simplicity of architecture 
is not just an aesthetic consideration. If three nets are used then each one must have enough 
computational power for its part of the task, combining the nets means that only the combined 
power must be sufficient and it allows common computations can be shared. 
The error signal for the output Ys,+x, can be calculated by comparison with the desired 
output. However, the error signal for the state units, %, is only given by the net at time p+ 1, 
which is not known at time p. Thus it is impossible to use a single backward pass to train 
this net. It is this difficulty which introduces the variation in the architectures of dynamic 
nets. 
3.2. THE FINITE INPUT DURATION ('FID) DYNAMIC NET 
If the output of a dynamic net, Ys,, is dependent on a finite number of previous inputs, try_/, 
to tts,, or if this assumption is a good approxination, then it is possible to formulate the 
635 
learning algorithm by expansion of the dynamic net for a finite time, as in figure 4. This 
formulation is sinliar to a restricted version of the recurrent net of Rumelhart, Hinton and 
Williams) 
dynamic 
(p-2) 
u(P-l) dynami c 
x (p,) net 
(p-l) 
figure 4 
u(P) 1 
x(p) 
dynamic 
(p) 
x(p+l) 
! 
Consider only the component of the error signal in past instantiations of the nets which 
is the result of the error signal at time t. The error signal for yp is calculated from the target 
output and the error signal for z r is zero. This cmnbined error signal is propagated back 
though the dynamic net at p to yield the error signals for up and x r. Similarly these error 
signals can then be propagated back through the net at t -p, and so on for all relevant inputs. 
The summed error signal is then used to change the weights as for a static net. 
Formalising the FID dynamic net for a general time q, q < p: 
ns is the nunber of state units 
oq,i is the output value of unit i at time q 
tq,i is the target value of unit i at time q 
6q,i is the error value of unit i at time q 
wi,j is the weight between oi and oj 
Awq,i,j is the weight change for this iteration at time q 
Awl,j is the total weight change for this iteration 
These values are calculated in the same way as in a static net, 
i-1 
netq,i - E wi,joq,j (3.2.1) 
oq,i = f(netq,i) (3.2.2) 
q,i -- f'(netq,i)(tq, i -- Oq,i) thi d + n s < i <_ nout (3.2.3) 
---- q+l,i_nh,,l+nmp_n, /1hi d < i  nhid + n, (3.2.4) 
= f'(netq,i)  6q,SwAi inp < i S hid (3..) 
ji+l 
Wq,i, j = lq,iOq,j (3.2.6) 
and the total weight change is given by the summation of the partial weight changes for all 
636 
previous times. 
A w i ,j 
p 
= (3.2.7) 
q=p-P 
P 
= (3.2.8) 
q=p-P 
Thus, it is possible to train a dynamic net to incorporate the information from any time 
period of finite length, and so learn any function which has a finite impulse response.* 
In some situations the approximation to a finite length may not be valid, or the storage 
and computational reluirements of such a net may not be feasible. In such situations another 
approach is possible, the infinite input duration dynamic net. 
3.3. THE INFINITE INPUT DURATION (IID) DYNAMIC NET 
Although the forward pass of the FID net of the previous section is a non-linear process, the 
backward pass computes the effect of small variations on the forward pass, and is a linear 
process. Thus the recursive learning procedure described in the previous section may be 
compressed into a single operation. 
Given the target values for the output of the net at time iv, equations (3.2.3) and (3.2.4) 
define values of e, at the outputs. If we denote this set of e, by D e then equation (3.2.5) 
states that any 6e,i in the net at time p is simply a linear transformation of D e. Writing the 
transformation matrix as S: 
(e,i ---- ,p,i Dp (3.3.1) 
In particular the set of 6e,i which is to be fed back into the network at tiine p- 1 is also 
a linear transformation of D e 
Dv- = TeD e (3.3.2) 
or for an arbitrary time q: 
(3.3.3) 
so substituting equations (3.3.1) and (3.3.3) into equation (3.2.8): 
A w i,j 
= rl  Sq,i H T. Deoq, i (3.3.4) 
q=-oo '=q+l 
= lMe,i,jV e (3.3.5) 
where: 
=  $,i T oq,.i (3.3.6) 
q=--oo '=q+l 
* This is a restriction on the class of functions which can be leaxned, the output will always be affected 
in some way by all previous inputs giving an infinite impulse response performance. 
637 
and note that Mp,i,j can be written in terms of Mp-x,i,j: 
= Sp,op,j + Mp_Li,jT p (3.3.8) 
Hence we can calculate the weight changes for an infinite recursion using only the finite 
matrix M. 
3.3. THE STATE COMPRESSION DYNAMIC NET 
The previous architectures for dynamic nets rely on the propagation of the error signal back 
in tine to define the format of the information in the state units. An alternative approach 
is to use another error propagation net to define the format of the state units. The overall 
architecture is given in figure 5. 
u(p) 
x (p) 
Encoder 
net 
Decoder 
net 
x(p+l) 
- 1 
Translator 
net 
x (p+l)> 
figure 5 
y (p+l) 
The encoder net is trained to code the current input and current state onto the next state, 
while the decoder net is trained to do the reverse operation. The translator net codes the 
next state onto the desired output. This encoding/decoding attempts to represent the current 
input and the current state in the next state, and by the recursion, it will try to represent all 
previous inputs. Feeding errors back from the translator directs this coding of past inputs to 
those which are useful in forming the output. 
3.4. COMPARISON OF DYNAMIC NET ARCHITECTURES 
In coinparing the three architectures for dynamic nets, it is important to consider the conpu- 
rational and memory requirements, and how these requirements scale with increasing context. 
To train an FID net the net must store the past activations of the all the units within 
the time span of the'necessary context. Using this minimal storage, the computational load 
scales proportionally to the time span considered, as for every new input/output pair the 
net must propagate an error signal back though all the past nets. However, if more sets 
of past activations are stored in a buffer, then it is possible to wait until this buffer is full 
before computing the weight changes. As the buffer size increases the computational load in 
638 
calculating the weight changes tends to that of a single backward pass through the units, and 
so becomes independent of the ainount of context. 
The largest natrix required to compute the lid net is M which requires a factor of the 
number of outputs of the net more storage than the weight matrix. This must be updated 
on each iteration, a computational requirement larger than that of the FID net for small 
problems a. However, if this architecture were implemented on a parallel machine it would be 
possible to store the matrix M in a distributed form over the processors, and locally calculate 
the weight changes. Thus, whilst the FID net requires the error signal to be propagated back 
in time in a strictly sequential manner, the IID net may be implemented in parallel, with 
possible advantages on parallel machines. 
The state compression net has memory and computational requirements independent of 
the amount of context. This is achieved at the expense of storing recent information in the 
state units whether it is required to compute the output or not. This results in an increased 
coinputational and memory load over the more efficient FID net when implemented with a 
buffer for past outputs. However, the exclusion of external storage during training gives this 
architecture more biological plausibility, constrained of course by the plausibility of the error 
propagation algorithm itself. 
With these considerations in mind, the FID net was chosen to investigate a 'real world' 
problem, that of the coding of the speech waveform. 
4. APPLICATION TO SPEECH CODING 
The problem of speech coding is one of finding a suitable model to remove redundancy and 
hence reduce the data rate of the speech. The Boltzmann machine learning algorithm has 
already been extended to deal to the dynamic case and applied to speech recognition 4. How- 
ever, previous use of error propagation nets for speech processing has mainly been restricted to 
explicit presentation of the context s'e or explicit feeding back the output units to the input 7,8, 
with some work done in using units with feedback links to themselves �. In a similar area, 
static error propagation nets have been used to perform image coding as well as conventional 
techniques TM. 
4.1. THE ARCHITECTURE OF A GENERAL CODER 
The coding principle used in this section is not restricted to coding speech data. The general 
problem is one of encoding the present input using past input context to form the transmitted 
signal, and decoding this signal using the context of the coded signals to regenerate the original 
input. Previous sections have shown that dynamic nets are able to represent context, so two 
dynamic nets in series form the architecture of the coder, as in figure 6. 
This architecture may be specified by the number of input, state, hidden and transmission 
units. There are as many output units as input units and, in this application, both the 
transmitter and receiver have the same number of state and hidden units. 
The input is combined with the internal state of the transmitter to form the coded signal, 
and then decoded by the receiver using its internal state. Training of the net involves the 
comparison of the input and output to form the error signal, which is then propagated back 
through past instantiations of the receiver and transmitter in the same way as a for a FID 
dynamic net. 
It is useful to introduce noise into the coded signal during the training to reduce the 
information capacity of the transinission line. This forces the dynamic uets to incorporate 
time information, without this constraint both nets can learn a siinple transformation without 
any time dependence. The noise can be used to simulate quantisation of the coded signal so 
639 
input t TX 
Time 
- Delay 
coded signal 
RX 
Time 
 Delay 
figure 6 
output 
quantifying the transmission rate. Unfortunately, a straight implementation of quantisation 
violates the requirement of the activation function to be continuous, which is necessary to 
train the net. Instead quantisation to n levels may be simulated by adding a random value 
distributed uniformly in the range +l/n to -1/n to each of the channels in the coded signal. 
4.2. TRAINING OF THE SPEECH CODER 
The chosen problem was to present a single sample of digitised speech to the input, code to 
a single value quantised to fifteen levels, and then to reconstruct the original speech at the 
output. Fifteen levels was chosen as the point where there is a marked loss in the intelligibility 
of the speech, so implementation of these coding schemes gives an audible improvement. Two 
version of the coder net were implemented, both nets had eight hidden units, with no state 
units for the static time independent case and four state units for the dynamic time dependent 
case. 
The data for this problem was 40 seconds of speech froin a single male speaker, digitised 
to 12 bits at 10kHz and recorded in a laboratory environment. The speech was divided into 
two halves, the first was used for training and the second for testing. 
The static and the dynamic versions of the architecture were trained on about 20 passes 
through the training data. After training the weights were frozen and the inclusion of random 
noise was replaced by true quantisation of the coded representation. A further pass was then 
made through the test data to yield the performance measurements. 
The adaptive training algorithm of Chan  was used to dynamically alter the learning 
rates during training. Previously these machines were trained with fixed learning rates and 
weight update after every sample 3, and the use of the adaptive training algorithm has been 
found to result in a substantially deeper energy minima. Weights were updated after every 
1000 samples, that is about 200 times in one pass of the training data. 
4.3. COMPARISON OF PERFORMANCE 
The performance of a coding schemes can be measured by defining the noise energy as half the 
sumnted squared difference between the actual output and the desired output. This energy 
is the quantity miniinised by the error propagation algorithm. The lower the noise energy in 
relation to the energy of the signal, the higher the performance. 
Three non-connectionist coding schemes were implemented for coinparison with the static 
64O 
and dynamic net coders. In the first the signal is linearly quantised within the dynamic range 
of the original signal. In the second the quantiser is restricted to operate over a reduced 
dynamic range, with values outside that range thresholded to the maximuln and minimum 
outputs of the quantiser. The thresholds of the quantiser were chosen to optimise the signal 
to noise ratio. The third scheme used the technique of Differential Pulse Code Modulation 
(DPCM) 12 which involves a linear filter to predict the speech waveform, and the transmitted 
signal is the difference between the real signal and the predicted signal. Another linear filter 
reconstructs the original signal from the difference signal at the receiver. The filter order of 
the DPCM coder was chosen to be the same as the number of state units in the dynamic net 
coder, thus both coders can store the same amount of context enabling a comparison with 
this established technique. 
The resulting noise energy when the signal energy was normalised to unity, and the cor- 
responding signal to noise ratio are given in table 1 for the five coding techniques. 
coding method normalised signal to noise 
noise energy ratio in dB 
linear, original thresholds 0.071 11.5 
linear, optimum thresholds 0.041 13.9 
static net 0.049 !3.1 
DPCM, optimum thresholds 0.037 14.3 
dynamic net 0.028 15.5 
table 1 
The static net may be compared with the two forms of the linear quantiser. Firsfly note 
that a considerable improvement in the signal to noise ratio may be achieved by reducing the 
thresholds of the quantiser from the extremes of the input. This improvement is achieved 
because the distribution of samples in the input is concentrated around the mean value, with 
very few values near the extremes. Thus many samples are represented with greater accuracy 
at the expense of a few which are thresholded. The static net has a poorer performance than 
the linear quantiser with optimum thresholds. The form of the linear quantiser solution is 
within the class of problems which the static net can represent. It's failure to do so can be 
attributed to finding a local minima, a plateau in weight space, or corruption of the true 
steepest descent direction by noise introduced by updating the weights more than once per 
pass through the training data. 
The dynamic net may be compared with the DPCM coding. The output froin both these 
coders is no longer constrained to discrete signal levels and the resulting noise energy is lower 
than all the previous examples. The dynamic net has a significantly lower noise energy than 
any other coding scheme, although, from the static net example, this is unlikely to be an 
optimal solution. The dynamic net achieves a lower noise energy than the DPCM coder by 
virtue of the non-linear processing at each unit, and the flexibility of data storage in the state 
units. 
As expected from the measured noise energies, there is an improvement in signal quality 
and intelligibility from the linear quantised speech through to the DCPM and dynamic net 
quantised speech. 
5. CONCLUSION 
This report has developed three architectures for dynamic nets. Each architecture can be 
formulated in a way where the computational requirement is independent of the degree of 
context necessary to learn the solution. The FID architecture appears most suitable for 
641 
implementation on a serial processor, the lid architecture has possible advantages for im- 
plementation on parallel processors, and the state compression net has a higher degree of 
biological plausibility. 
Two FID dynamic nets have been coupled together to form a coder, and this has been 
applied to speech coding. Although the dynamic net coder is unlikely to have learned the 
optimum coding strategy, it does demonstrate that dynamic nets can be used to achieve an 
improved performance in a real world task over an established conventional technique. 
One of the authors, A J Robinson, is supported by a maintenance grant front the U.K. 
Science and Engineering Research Council, and gratefully acknowledges this support. 
References 
[1] D. E. Rumelhart, G. E. Hinton, and R. J. Williams. Learning internal representations by 
error propagation. In D. E. Rumelhart and J. L. McClelland, editors, Parallel Distributed 
Processing: Explorations in the Mcrostructure of Cognition. Vol. 1: Foundations., Brad- 
ford Books/MIT Press, Cambridge, MA, 1986. 
[2] O. L. R. Jacobs. Introdwton to Control Theory. Clarendon Press, Oxford, 1974. 
[3] A. J. Robinson and F. Fallside. The Utility Driven Dynamic Error Propagation Net- 
work. Technical Report CUED/F-INFENG/TR.1, Cambridge University Engineering 
Department, 1987. 
[4] R. W. Prager, T. D. Harrison, and F. Fallside. Boltzmann machines for speech recogni- 
tion. Completer Speech and Language, 1:3-27, 1986. 
[5] J. L. Elman and D. Zipset. Learnng the Hidden Structure of Speech. ICS Report 8701, 
University of California, San Diego, 1987. 
[6] A. J. Robinson. Speech Recogiiowth Associative Networks. M.Phil Computer Speech 
and Language Processing thesis , Cambridge University Engineering Department, 1986. 
[7] M. I. Jordan. Serial Order: A Parallel Distributed Processing Approach. ICS Re- 
port 8604, Institute for Cognitive Science, University of California, San Diego, May 
1986. 
[8] D. J. C. MacKay. A Method of Increasing the Contextual Input to Adaptive Pattern 
Recognition Systems. Technical Report RIPRREP/1000/14/87, Research Initiative in 
Pattern Recognition, RSRE, Malvcrn, 1987. 
[9] R. L. Watrous, L. Shastri, and A. H. Waibel. Learned phonetic discrimination using 
connectionist networks. In J. Laver and M. A. Jack, editors, Proceedings of the European 
Conference on Speech Technology, CEP Consultants Ltd, Edinburgh, September 1987. 
[10] G. W. Cottrell, P. Munro, and D Zipset. Image Compression by Back Propagation: An 
Example of Existential Programming. ICS Report 8702, Institute for Cognitive Science, 
University of California, San Diego, Febuary 1986. 
[11] L. W. Chan and F. Fallside. An Adaptive Learnin Algorithm for Back Propagation Net- 
works. Technical Report CUED/F-INFENG/TR.2, Cambridge University Engineering 
Department, 1987, submitted to Computer Speech ad Lanuage. 
[12] L. R. Rabiner and R. W. Schefer. Dgital Processing of Speech Signals. Prentice Hall, 
Englewood Cliffs, New Jersey, 1978. 
", dynam error propag applic speech fallsid univers engin depart england propag net shown abl learn varieti task static input pattern map onto static output paper generalis net deal time three possibl architectur appli problem speech time sequenc data code one net decod use dynam give better signal nois ratio achiev use static introduct paper base upon use error propag hinton william train connectionist net defin set weight unit determin algorithm use descent techniqu calcul direct weight chang order minirais sum squar differ desir outpnt actual use algorithm believ net train make arbitrari map input unit onto output unit given enough intermedi net use part larger system complex static net memori past mani problem requir context input order comput extens static net feed back section output creat intern allow far greater class problem previous train time depend net suffer comput requir increas linearli time span desir three architectur dynam net present overcom illustr power network gener coder develop appli speech solut found train dynam net coder establish linear found increas perform signal nois static error propag net static net defin set unit link denot oi valu th weight link oi may divid input hidden unit output assign constant american institut physic input unit run ox follow hidden unit output unit valu input unit defin problem remain unit defin continu monoton function known activ function use applic equat defin net maxiinum number commonli restrict layer structur unit connect immedi preced architectur net specifi number output hidden diagrainmat static net transform onto output figur net train use gradient descent mgorithm minismis energi defin sum squar error actual target algorithm also defin error nhid nout deriv error signal activ unit defin chang constant proportion determin learn defin error input unit well hidden thu number static net connect valu pass input one net output unit preced abil error propag togeth way enabl construct dynam dynam error propag net essenti qualiti dynam net behaviour determin input also intern state repres group unit form part output static net also input anoth copi static net next thu unit link multipl copi static net time form dynam develop linear control theori analog dynam net linear system may state ax bu input state output vector integ time structur linear system solut may implement dynam substitut matric static repres summat oper bu could achiev net one node element uniti weight two ident activ function altern net incorpor net give architectur figur figur three network may combin figur simplic architectur aesthet three net use one must enough power part combin net mean combin must suffici allow common comput error signal output calcul comparison desir error signal state given net time known time thu imposs use singl backward pass train difficulti introduc variat architectur dynam finit input durat dynam net output dynam depend finit number previou assumpt good possibl formul algorithm expans dynam net finit figur sinliar restrict version recurr net hinton dynami net compon error signal past instanti net result error signal time error signal yp calcul target error signal cmnbine error signal propag back dynam net yield error signal similarli error propag back net relev sum error signal use chang weight static fid dynam net gener time state unit output valu unit time target valu unit time error valu unit time weight oi oj weight chang iter time total weight chang iter valu calcul way static nout nhid ai total weight chang given summat partial weight chang possibl train dynam net incorpor inform time finit learn function finit impuls situat approxim finit length may storag comput net may situat anoth infinit input durat dynam infinit input durat dynam net forward pass fid net previou section pass comput effect small variat forward linear thu recurs learn procedur describ previou section may singl target valu output net time equat valu denot set equat net time simpli linear transform write matrix dp particular set fed back network tiin also linear transform arbitrari time substitut equat equat rl restrict class function output alway affect way previou input give infinit impuls respons note written term calcul weight chang infinit recurs use finit state compress dynam net previou architectur dynam net reli propag error signal back defin format inform state altern approach use anoth error propag net defin format state overal given figur encod net train code current input current state onto next decod net train revers translat net code state onto desir attempt repres current current state next tri repres feed error back translat direct code past input use form comparison dynam net architectur coinpar three architectur dynam import consid memori requir scale increas train fid net net must store past activ unit within time span use minim comput load proport time span everi new pair must propag error signal back though past set past activ store possibl wait buffer full comput weight buffer size increas comput load weight chang tend singl backward pass becom independ ainount largest requir comput lid net requir factor output net storag weight must updat comput requir larger fid net small architectur implement parallel machin would store matrix distribut form local calcul weight whilst fid net requir error signal propag back time strictli sequenti iid net may implement advantag parallel state compress net memori comput requir independ amount achiev expens store recent inform unit whether requir comput output result increas memori load effici fid net implement past exclus extern storag train give biolog constrain cours plausibl error algorithm consider fid net chosen investig code speech applic speech code problem speech code one find suitabl model remov redund reduc data rate boltzmann machin learn algorithm extend deal dynam case appli speech recognit previou use error propag net speech process mainli restrict present context explicit feed back output unit input work done use unit feedback link similar error propag net use perform imag code well convent architectur gener coder code principl use section restrict code speech gener one encod present input use past input context form transmit decod signal use context code signal regener origin previou section shown dynam net abl repres two net seri form architectur figur architectur may specifi number hidden transmiss mani output unit input unit receiv number state hidden input combin intern state transmitt form code decod receiv use intern train net involv input output form error propag back past instanti receiv transmitt way fid use introduc nois code signal train reduc capac transiniss forc dynam uet incorpor without constraint net learn siinpl transform without time nois use simul quantis code signal tx delay signal delay transmiss straight implement quantis requir activ function necessari instead quantis level may simul ad random valu uniformli rang channel code train speech coder chosen problem present singl sampl digitis speech code singl valu quantis fifteen reconstruct origin speech fifteen level chosen point mark loss intellig implement code scheme give audibl two coder net net eight hidden state static time independ case four state unit dynam time depend data problem second speech froin singl male digitis bit hz record laboratori speech divid first use train second static dynam version architectur train pass train train weight frozen inclus random replac true quantis code pass test data yield perform adapt train algorithm chan use dynam alter learn previous machin train fix learn rate updat everi sampl use adapt train algorithm result substanti deeper energi weight updat everi time one pass train comparison perform perform code scheme measur defin nois energi half squar differ actual output desir energi quantiti miniinis error propag lower nois energi energi higher code scheme implement coinparison static dynam net first signal linearli quantis within dynam rang origin second quantis restrict oper reduc valu outsid rang threshold maximuln minimum threshold quantis chosen optimis signal nois third scheme use techniqu differenti puls code modul involv linear filter predict speech transmit differ real signal predict anoth linear filter origin signal differ signal filter order dpcm coder chosen number state unit dynam net thu coder store amount context enabl comparison establish result nois energi signal energi normalis signal nois ratio given tabl five code method normalis signal nois energi ratio origin threshold optimum threshold net optimum threshold net static net may compar two form linear firsfli note consider improv signal nois ratio may achiev reduc quantis extrem improv achiev distribut sampl input concentr around mean valu near thu mani sampl repres greater accuraci expens static net poorer perform linear quantis optimum form linear quantis solut class problem static net failur find local plateau weight corrupt true descent direct nois introduc updat weight per train dynam net may compar dpcm output froin longer constrain discret signal level result nois energi lower previou dynam net significantli lower nois energi code static net unlik dynam net achiev lower nois energi dpcm coder process flexibl data storag state expect measur nois improv signal qualiti intellig linear quantis speech dcpm dynam net conclus report develop three architectur dynam architectur way comput requir independ degre necessari learn fid architectur appear suitabl serial lid architectur possibl advantag parallel state compress net higher degre fid dynam net coupl togeth form speech although dynam net coder unlik learn code demonstr dynam net use achiev perform real world task establish convent support mainten grant front engin research grate acknowledg learn intern represent rumelhart parallel distribut explor control clarendon robinson util driven dynam error propag technic report cambridg univers engin boltzmann machin speech complet speech elman learnng hidden structur ic report san speech associ comput speech languag process thesi cambridg univers engin serial parallel distribut process ic institut cognit univers san may method increas contextu input adapt pattern technic report research initi learn phonet discrimin use laver proceed european speech cep consult septemb imag compress back existenti ic report institut cognit san febuari chan adapt learnin algorithm back propag technic report cambridg univers engin submit comput speech rabin process speech prentic new,0
67,67,"642 
LEARNING BY STATE RECURRENCE DETECFION 
Bruce E. Rosen, James M. Goodwin*, and Jacques J. Vidal 
University of California, Los Angeles, Ca. 90024 
ABSTRACT 
This research investigates a new technique for unsupervised learning of nonlinear 
control problems. The approach is applied both to Michie and Chambers BOXES 
algorithm and to Barto, Sutton and Anderson's extension, the ASE/ACE system, and 
has significantly improved the convergence rate of stochastically based learning 
automata. 
Recurrence learning is a new nonlinear reward-penalty algorithm. It exploits 
information found during learning trials to reinforce decisions resulting in the 
recurrence of nonfailing states. Recurrence learning applies positive reinforcement 
during the exploration of the search space, whereas in the BOXES or ASE algorithms, 
only negative weight reinforcement is applied, and then only on failure. Simulation 
results show that the added information from recurrence learning increases the learning 
rate. 
Our empirical results show that recurrence learning is faster than both basic failure 
driven learning and failure prediction methods. Although recurrence learning has only 
been tested in failure driven experiments, there are goal directed learning applications 
where detection of recurring oscillations may provide useful information that reduces 
the learning time by applying negative, instead of positive reinforcement. 
Detection of cycles provides a heuristic to improve the balance between evidence 
gathering and goal directed search. 
INTRODUCFION 
This research investigates a new technique for unsupervised learning of nonlinear 
control problems with delayed feedback. Our approach is compared to both Michie and 
Chambers BOXES algorithm 1, to the extension by Barto, et al., the ASE (Adaptive 
Search Element) and to their ASE/ACE (Adaptive Critic Element) system 2, and shows 
an improved learning time for stochastically based learning automata in failure driven 
tasks. 
We consider adaptively controlling the behavior of a system which passes 
through a sequence of states due to its internal dynamics (which are not assumed to be 
known a priori) and due to choices of actions made in visited states. Such an adaptive 
controller is often referred to as a learning automaton. The decisions can be 
deterministic or can be made according to a stochastic rule. A learning automaton has 
to discover which action is best in each circumstance by producing actions and 
observing the resulting information. 
This paper was motivated by the previous work of Barto, et al. to investigate 
neuronlike adaptive elements that affect and learn from their environment. We were 
inspired by their current work and the recent attention to neural networks and 
connectionist systems, and have chosen to use the cart-pole control problem 2, to enable 
a comparison of our results with theirs. 
'Permanent address: California State University, Stanislaus; Turlock, California. 
@ American Institute of Physics 1988 
643 
THE CART-POLE PROBLEM 
In their work on the cart-pole problem, Barto, Sutton and Anderson considered a 
learning system composed of an automaton interacting with an environment. The 
problem requires the automaton to balance a pole acting as an inverted pendulum hinged 
on a moveable cart. The cart travels left or right along a bounded one dimensional track; 
the pole may swing to the left or right about a pivot attached to the cart. The automaton 
must learn to keep the pole balanced on the cart, and to keep the cart within the bounds 
of the track. The parameters of the cart/pole system are the cart position and velocity, 
and the pole angle and angular velocity. The only actions available to the automaton are 
the applications of a fixed impulsive force to the cart in either right or left direction; one 
of these actions must be taken. 
This balancing is an extremely difficult problem if there is no a priori knowledge 
of the system dynamics, if these dynamics change with time, or if there is no 
preexisting controller that can be imitated (e.g. Widrow and Smith's 3 ADALINE 
controller). We assumed no a priori knowledge of the dynamics nor any preexisting 
controller and anticipate that the system will be able to deal with any changing 
dynamics. 
Numerical simulations of the cart-pole solution via recurrence learning show 
substantial improvement over the results of Barto et al., and of Michie and Chambers, 
as is shown in figure 1. The algorithms used, and the results shown in figure 1, will 
be discussed in detail below. 
Time 
Until 
Failu 
/ 
 ,.. Hr 
i I 
50 75 110 
Trial No. 
Figure 1' Performance of the ASE, ASE/ACE, Constant Recurrence (HI) and 
Short Recurrence (H2) Algorithms. 
THE GENERAL PROBLEM: ASSIGNMENT OF CREDIT 
The cart-pole problem is one of a class of problems known as ""credit 
assignment ""4, and in particular temporal credit assignment. The recurrence learning 
algorithm is an approach to the general temporal credit assignment problem. It is 
characterized by seeking to improve learning by making decisions about early actions. 
The goal is to find actions responsible for improved or degraded performance at a much 
later time. 
An example is the bucket brigade algorithm 5. This is designed to assign credit to 
rules in the system according to their overall usefulness in attaining their goals. This is 
done by adjusting the strength value (weight) of each rule. The problem is of 
modifying these strengths is to permit rules activated early in the sequence to result in 
successful actions later. 
644 
Samuels considered the credit assignment problem for his checkers playing 
program 6. He noted that it is easy enough to credit the rules that combine to produce a 
triple jump at some point in the game; it is much harder to decide which rules active 
earlier were responsible for changes that made the later jump possible. 
State recurrence learning assigns a strength to an individual rule or action and 
modifies that action's strength (while the system accumulates experience) on the basis 
of the action's overall usefulness in the situations in which it has been invoked. In this 
it follows the bucket brigade paradigm of Holland. 
PREVIOUS WORK 
The problems of learning to control dynamical systems have been studied in the 
past by Widrow and Smith 3, Michie and Chambers 1, Barto, Sutton, and Anderson 2, 
and Connell 7. Although different approaches have been taken and have achieved 
varying degrees of success, each investigator used the cart/pole problem as the basis for 
empirically measuring how well their algorithms work. 
Michie and Chambers 1 built BOXES, a program that learned to balance a pole on 
a cart. The BOXES algorithm choose an action that had the highest average time until 
failure. After 600 trials (a trial is a run ending in eventual failure or by some time limit 
expiration), the program was able to balance the pole for 72,000 time steps. Figure 2a 
describes the BOXES learning algorithm. States are penalized (after a system failure) 
according to recency. Active states immediately preceding a system failure are 
punished most. 
Barto, Sutton and Anderson 2 used two neuronlike adaptive elements to solve the 
control problem. Their ASE/ACE algorithm chose the action with the highest 
probability of keeping the pole balanced in the region, and was able to balance the pole 
for over 60,000 time steps before completion of the 100th trial. 
Figure 2a and 2b: The BOXES and ASE/ACE (Associative Search Elelement - 
Adpafive Critic Element) algorithms 
Figure 2a shows the BOXES (and ASE) learning algorithm paradigm When the 
automaton enters a failure state (C), all states that it has traversed (shaded rectangles) 
are punished, although state B is punished more than state A. (Failure states are those 
at the edges of the diagram.) Figure 2b describes the ASE/ACE learning algorithm. If 
a system failure occurs before a state's expected failure time, the state is penalized. If a 
system failure occurs after its expected failure time, the state is rewarded. State A is 
penalized because a failure occurred at B sooner than expected. State A's expected 
645 
failure time is the time for the automaton to traverse from state A to failure point C. 
When leaving state A, the weights are updated if the new state's expected failure time 
differs from that of state A. 
Anderson 8 used a connectionist system to learn to balance the pole. Unlike the 
previous experiments, the system did provide well-chosen states a priori. On the 
average, 10,000 trials were necessary to learn to balance the pole for 7000 time steps. 
Connell and Utgoff 7 developed an approach that did not depend on partitioning 
the state space into discrete regions. They used Shepard's function9,10 to interpolate 
the degree of desirability of a cart-pole state. The system learned the control task after 
16 trials. However, their system used a knowledge representation that had a priori 
information about the system. 
OTHER RELATED WORK 
Klopfl 1 proposed a more neurological class of differential learning mechanisms 
that correlates earlier changes of inputs with later changes of outputs. The adaptation 
formula used multiplies the change in outputs by the weighted sum of the absolute 
value of the t previous inputs weights (Awj), the '1: previous differences in inputs (Axj), 
and the '1: previous time coefficients (cj). 
Sutton's temporal differences (TD) 12 approach is one of a class of adaptive 
prediction methods. Elements of this class use the sum of previously predicted output 
values multiplied by the gradient and an exponentially decaying coefficient to modify 
the weights. Barto and Sutton 13 used temporal differences as the underlying learning 
procedure for classical conditioning. 
THE RECURRENCE LEARNING METHOD 
DEFINITIONS 
A state is the set of values (or ranges) of parameters sufficient to specify the 
instantaneous condition of the system. 
The input decoder groups the environmental states into equivalence classes: 
elements of one class have identical system responses. Every environmental input is 
mapped into one of n input states. (All further references to ""states"" assumes that the 
input values fall into the discrete ranges determined by the decoder, unless otherwise 
specified.) 
S tates returned to after visiting one or more alternate states recur. 
An action causes the modification of system parameters, which may change the 
system state. However, no change of state need occur, since the altered parameter 
values may be decoded within the same ranges. 
A weight, w(t), is associated with each action for each state, with the probability 
of an allowed action dependent on the current value of its weight. 
A rule determines which of the allowable actions is taken. The rule is not 
deterministic. It chooses an action stochastically, based on the weights. 
Weight changes, Aw(t), are made to reduce the likelihood of choosing an action 
which will cause an eventual failure. These changes are made based on the idea that the 
previous action of an element, when presented with input x(t), had some influence in 
causing a similar pattern to occur again. Thus, weight changes are made to increase the 
likelihood that an element produces the same action f(t) when patterns similar to x(t) 
occur in the future. 
646 
For example, consider the classic problem of balancing a pole on a moving cart. 
The state is specified by the positions and velocities of both the cart and the pole. The 
allowable actions are fixed velocity increments to the right or to the left, and the rule 
determines which action to take, based on the current weights. 
The recurrence learning algorithm presented here is a nonlinear reward-penalty 
method TM. Empirical results show that it is successful for stationary environments. In 
contrast to other methods, it also may be applicable to nonstationary environments'. 
Our efforts have been to develop algorithms that reward decision choices that lead the 
controller/environment to quasi-stable cycles that avoid failure (such as limit cycles, 
converging oscillations and absorbing points). 
Our technique exploits recurrence information obtained during learning trials. 
The system is rewarded upon return to a previous state, however weight changes are 
only permitted when a state transition occurs. If the system returns to a state, it has 
avoided failure. A recurring state is rewarded. A sequence of recurring states can be 
viewed as evidence for a (possibly unstable) cycle. The algorithm forms temporal 
""cause and effect"" associations. 
To optimize performance, dynamic search techniques must balance between 
choosing a search path with known solution costs, and exploring new areas of the 
search space to find better or cheaper solutions. This is known as the two armed bandit 
problem 15, i.e. given a two handed slot machine with one arm's observed reward 
probabilities higher than the other, one should not exclude playing with the arm with 
the lesser payoff. Like the ASE/ACE system, recurrence learning learns while 
searching, in contrast to the BOXES and ASE algorithms which learn only upon 
failure. 
RANGE DECODING 
In our work, as in Barto and others, the real valued input parameters are analyzed 
as members of ranges. This reduces computing resource demands. Only a limited 
number of ranges are allowed for each parameter. It is possible for these ranges to 
overlap, although this aspect of range decoding is not discussed in this paper, and the 
ranges were considered nonoverlapping. When the parameter value falls into one of the 
ranges that range is active. The specification of a state consists of one of the active 
ranges for each of the parameters. If the ranges do not overlap, then the set of 
parameter values specify one unique state; otherwise the set of parameter values may 
specify several states. Thus, the parameter values at any time determine one or several 
active states S i from the set of n possible states. 
The value of each environmental parameter falls into one of a number of ranges, 
which may be different for different parameters. A state is specified by the active range 
for each parameter. 
The set of input parameter values are decoded into one (or more) of n ranges S i, 
0 <= i <= n. For this problem, boolean values are used to describe the activity level of 
a state S i. The activity value of a state is 1 if the state is active, or 0 if it is inactive. 
ACTION DECISIONS 
Our model is the same as that of the BOXES and ASE/ACE systems, where only 
one input (and state) is active at any given time. All states were nonoverlapping and 
mutually exclusive, although there was no reason to preclude them from overlapping 
647 
other than for consistency with the two previous models. In the ASE/ACE system and 
in ours as well, the output decision rule for the controller is based on the weighted sum 
of its inputs plus some stochastic noise. The action (output) decision of the controller 
is either +1 or -1, as given by: 
yi(t) = f/i__ wi(t)xi(t)+ noise(t) / 
1 
(1) 
where 
[_+11 _> 0] 
f(z) = if z < 0 (2) 
and noise is a real randomly (Gaussian) distributed value with some mean g and 
variance 2. An output, f(z), for the car/pole controller is interpreted as a push to the 
left if f(z) = -1 or to the right if f(z) = +1. 
RECURRENCE LEARNING 
The goal of the recurrence learning algorithm is to avoid failure by moving toward 
states that are part of cycles if such states exist, or quasi-stable oscillations if they 
don't. This concept can be compared to juggling. As long as all the balls are in the air, 
the juggler is judged a success and rewarded. No consideration is given to whether the 
balls are thrown high or low, left or right; the controller, like the juggler, tries for the 
most stable cycles. Optimum performance is not demanded from recurrence learning. 
Two heuristics have been devised. The fundamental basis of each of them is to 
reward a state for being repeatedly visited (or repeatedly activated). The first heuristic 
is to reward a state when it is revisited, as part of a cycle in which no failure had 
occurred. The second heuristic augments the first by giving more reward to states 
which participate in shorter cycles. These heuristics are discussed below in detail. 
HEURISTIC HI: If a state has been visited more than once during one trial, 
reward it by reinforcing its weight. 
RATIONALE 
This heuristic assumes that states that are visited more than once have been part of 
a cycle in which no failure had occurred. The action taken in the previous visit is 
assumed to have had some influence on the recurrence. By reinforcing a weight upon 
state revisitation, it is assumed to increase the likelihood that the cycle will occur again. 
No assumptions are made as to whether other states were responsible for the cycle. 
crION 
An action may not immediately cause the environment to change to a different 
state. There may be some delay before a transition, since small changes of parameters 
may be decoded into the same input ranges, and hence the same state. This inertia is 
incorporated into the heuristics. When the same state appears twice in succession, its 
weight is not reinforced, since that would assume that the action, rather than inertia, 
directly caused the state's immediate recurrence. 
648 
THE RECURRENCE EQUATIONS 
The recurrence learning equations stem in part from the weight alteration formula 
used in the ASE system. The weight of a state is a sum of its previous weight, and the 
product of the learning rate (ct), the reward (r), and the state's eligibility (e). 
wi(t+l ) = wi(t) + ctr(t)ei(t) r(t)  {-1,0} (3) 
The eligibility index el(t) is an exponentially decaying trace function. 
ei(t+l ) = 13ei(t ) + (1- 13)Yi(t)xi(t) (4) 
where 0<=13<=1, xi {0,1}, and Yi {-1,1}. 
decision, and [3 determines the decay rate. 
The reward function is: 
r(t) = {-1 when the system fails at timer } 
0 otherwise (5) 
The output value Yi is the last output 
REINFORCEMENT OF CYCLES 
Equations (1) through (5) describe the basic ASE system. Our algorithm extends 
the weight updating procedure as follows: 
wi(t+l ) = wi(t) + ctr(t)ei(t) + ct2r2(t)e2,i(t) 
(6) 
The term ctr(t)ei(t) is the same as in (3), providing failure reinforcement. The 
term Ct2r2(t)e2,i(t) provides reinforcement for success. When state i is eligible (by 
virtue of x i > 0), there is a weight change by the amount: ct 2 multiplied by the reward 
value, r2(t), and the current eligibility e2,i(t). For simplicity, the reward value, r2(t), 
may be taken to be some positive constant, although it need not be; any environmental 
feedback, yielding a reinforcement value as a function of time could be used instead. 
The second eligibility function e2,i(t) yields one of three constant values for HI: -132, 0, 
or 132 according to formula (7) below: 
0 
e2,i(t) = 132xi(t)y(ti,last ) 
if t-ti,last = 1 or ti,last = 0 t 
otherwise 
(7) 
where ti,last is the last time that state was active. If a state has not previously been 
active (i.e. xi(t ) = 0 for all t) then ti,last=0. As the formula shows, e2,i(t) = 0 if the state 
has not been previously visited or if no state transition occurred in the last time step; 
otherwise, e2,i(t) = 132xi(t)y(ti,last). 
The direction (increase or decrease) of the weight change due to the final term in 
(6) is that of the last action taken, Y(ti,last). 
649 
Heuristic HI is called constant recurrence learning because the eligibility function 
is designed to reinforce any cycle. 
HEURISTIC H2: Reward a short cycle more than a longer one. 
Heuristic H2 is called short recurrence learning because the eligibility function is 
designed to reinforce shorter cycle more than longer cycles. 
REINFORCEMENT OF SHORTER CYCLES 
The basis of the second heuristic is the conjecture that short cycles converge more 
easily to absorbing points than long ones, and that long cycles diverge more easily than 
shorter ones, although any cycle can ""grow"" or diverge to a larger cycle. The 
following extension to the our basic heuristic is proposed. 
The formula for the recurrence eligibility function is: 
o 152 
e2,i(t) = (152+t_ti,last) 
if t-ti,last = 1 or ti,last = 0 t 
xi(t) Y(ti,last) otherwise 
(8) 
The current eligibility function e2,i(t) is similar to the previous failure eligibility 
function in (7); however, e2,i(t) reinforces shorter cycles more, because the eligibility 
decays with time. The value returned from e2,i(t) is inversely proportional to the period 
of the cycle from ti,last to t. H2 reinforces converging oscillations; the term 
ct2r2(t)e2,i(t) in (6) ensures weight reinforcement for returning to an already visited 
state. 
Figure 3a and 3b: The Constant Recurrence algorithm and Short Recurrence 
algorithms 
Figure 3A shows the Constant Recurrence algorithm (HI). A state is rewarded 
when it is reactivated by a transition from another state. In the example below, state A 
is reward by a constant regardless of weather the cycle traversed states B or C. Figure 
3b describes the Short Recurrence algorithm (H2). A state is rewarded according to the 
difference between the current time and its last activation time. Small differences are 
rewarded more than large differences In the example below, state A is rewarded more 
650 
when the cycle (through state C) traverses the states shown by the dark heavy line 
rather than when the cycle (through state B) traverses the lighter line, since state A 
recurs sooner when traversing the darker line. 
SIMULATION RESULTS 
We simulated four algorithms: ASE, ASE/ACE and the two recurrence 
algorithms. Each experiment consisted of ten runs of the cart-pole balancing task, each 
consisting of 100 trials. Each trial lasted for 500,000 time steps or until the cart-pole 
system failed (i.e. the pole fell or the cart went beyond the track boundaries). In an 
effort to conserve cpu time, simulations were also terminated when the system achieved 
two consecutive trials each lasting for over 500,000 time steps; all remaining trials were 
assumed to also last 500,000 time steps. This assumption was reasonable: the resulting 
weight space causes the controller to become deterministic regardless of the influence of 
stochastic noise. Because of the long time require to run simulations, no attempts were 
made to optimize parameters of the algorithm. 
As in Barto 2, each trial began with the cart centered, and the pole upright. No 
assumptions were made as to the state space configuration, the desirability of the initial 
states, or the continuity of the state space. 
The first experiment consisted of failure and recurrence reward learning. The 
ASE failure learning runs averaged 1578 time steps until failure after 100 trials*. Next, 
the predictive ASE/ACE system was run as a comparative metric, and it was found that 
this method caused the controller to average 131,297 time steps until failure; the results 
are comparable to that described by Barto, Sutton and Anderson. 
In the next experiment, short recurrence learning system was added to the ASE 
system. Again, ten 100 trial learning session were executed. On the average, the short 
recurrence learning algorithm ran for over 400,736 time steps after 100th trial, betteting 
the ASE/ACE system by 205%. 
In the final experiment, constant recurrence learning with the ASE system was 
simulated. The constant recurrence learning eliminated failure after only 207,562 time 
steps. 
Figure 1 shows the ASE, ASE/ACE, Constant recurrence learning (HI) and 
Short recurrence learning (H2) failure rates averaged over 10 simulation runs. 
DISCUSSION 
Detection of cycles provides a heuristic for the ""two armed bandit"" problem to 
decide between evidence gathering, and goal directed search. The algorithm allows the 
automaton to search outward from the cycle states (states with high probability of 
revisitation) to the more unexplored search space. The rate of exploration is 
proportional to the recurrence learning parameter ct2; as ct 2 is decreased, the influence 
of the cycles governing the decision process also decreases and the algorithm explores 
more of the search space that is not part of any cycle or oscillation path. 
However, there was a relatively large degree of variance in the final trials. The last 
10 trails (averaged over each of the 10 simulations) ranged from 607 to 15,459 time 
steps until failure 
651 
THE FUTURE 
Our future experiments will study the effects of rewarding predictions of cycle 
lengths in a manner similar to the prediction of failure used by the ASE/ACE system. 
The effort will be to minimize the differences of predicted time of cycles in order to 
predict their period. Results of this experiment will be shown in future reports. We 
hope to show that this recurrence prediction system is generally superior to either the 
ASE/ACE predictive system or the short recurrence system operating alone. 
CONCLUSION 
This paper presented an extension to the failure driven learning algorithm based 
on reinforcing decisions that cause an automaton to enter environmental states more 
than once. The controller learns to synthesize the best values by reinforcing areas of 
the search space that produce recurring state visitation. Cycle states, which under 
normal failure driven learning algorithms do not learn, achieve weight alteration from 
success. Simulations show that recurrence reward algorithms show improved overall 
learning of the cart-pole task with a substantial decrease in learning time. 
References
5. 
6. 
7. 
8. 
9. 
10. 
11. 
12. 
13. 
14. 
15. 
D. Michie and R. Chambers, Machine Intelligence, E. Dale and D. Michie, Ed.: 
(Oliver and Boyd, Edinburgh, 1968), p. 137. 
A. Barto, R. Sutton, and C. Anderson, Coins Tech. Rept., No. 82-20, 1982. 
B. Widrow and F. Smith, in Computer and Information Sciences, J. Tou and 
R. Wilcox Eds., (Clever Hume Press, 1964). 
M. Minsky, in Proc. IRE, 49, 8, (1961). 
J. Holland, in Proc. Int. Conf., Genetic Algs. and their Appl., 1985, p. 1. 
A. Samuel, IBM Journ. Res.and Dev. 3, 211, (1959) 
M. Connell and P. Utgoff, in Proc. AAAI-87 (Seattle, 1987), p. 456. 
C. Anderson, Coins Tech. Rept., No. 86-50: Amherst, MA. 1986. 
R. Barnhill, in Mathematical Software III, (Academic Press, 1977). 
L. Schumaker, in Approximation Theory IL (Academic Press, 1976). 
A. H. Klopf, in IEEE Int. Conf. Neural Networks,, June 1987. 
R. Sutton, GTE Tech. Rept. TR87-509.1, GTE Labs. Inc., Jan. 1987 
R. Sutton and A. G. Barto, Tech. Rept. TR87-5902.2 March 1987 
A. Barto and P. Anandan, IEEE Trans. SMC 15, 360 (1985). 
M. Sato, K. Abe, and H. Takeda, IEEE Trans. SMC 14,528 (1984). 
", state recurr detecfion jame jacqu vidal lo research investig new techniqu unsupervis learn nonlinear approach appli michi chamber box sutton significantli improv converg rate stochast base learn learn new nonlinear exploit found learn trial reinforc decis result nonfail recurr learn appli posit reinforc explor search wherea box ase neg weight reinforc simul show ad inform recurr learn increas learn empir result show recurr learn faster basic failur learn failur predict although recurr learn test failur driven goal direct learn applic detect recur oscil may provid use inform reduc learn time appli instead posit cycl provid heurist improv balanc evid goal direct research investig new techniqu unsupervis learn nonlinear problem delay approach compar michi box algorithm extens et ase critic system show improv learn time stochast base learn automata failur driven consid adapt control behavior system pass sequenc state due intern dynam assum due choic action made visit adapt often refer learn decis made accord stochast learn automaton discov action best circumst produc action result paper motiv previou work et investig adapt element affect learn current work recent attent neural network chosen use control problem enabl comparison result california state american institut physic problem work sutton anderson consid system compos automaton interact requir automaton balanc pole act invert pendulum hing moveabl cart travel left right along bound one dimension pole may swing left right pivot attach automaton learn keep pole balanc keep cart within bound paramet system cart posit pole angl angular action avail automaton applic fix impuls forc cart either right left one action must balanc extrem difficult problem priori knowledg system dynam chang control imit widrow adalin assum priori knowledg dynam preexist anticip system abl deal chang simul solut via recurr learn show improv result barto et michi shown figur algorithm result shown figur discuss detail hr perform constant recurr recurr gener assign credit problem one class problem known particular tempor credit recurr learn approach gener tempor credit assign seek improv learn make decis earli goal find action respons improv degrad perform much exampl bucket brigad algorithm design assign credit system accord overal use attain adjust strength valu problem strength permit rule activ earli sequenc result action consid credit assign problem checker play note easi enough credit rule combin produc jump point much harder decid rule activ respons chang made later jump recurr learn assign strength individu rule action strength system accumul basi overal use situat follow bucket brigad paradigm work problem learn control dynam system studi widrow smith michi chamber anderson connel although differ approach taken achiev degre investig use problem basi measur well algorithm chamber built program learn balanc pole box algorithm choos action highest averag time trial trial run end eventu failur time limit program abl balanc pole time figur box learn state penal system activ state immedi preced system failur sutton anderson use two neuronlik adapt element solv algorithm chose action highest keep pole balanc abl balanc pole time step complet box search elel critic algorithm show box learn algorithm paradigm enter failur state state travers although state punish state state edg figur describ learn system failur occur expect failur state failur occur expect failur state state failur occur sooner state expect time time automaton travers state failur point leav state weight updat new expect failur time state use connectionist system learn balanc unlik system provid state trial necessari learn balanc pole time utgoff develop approach depend partit state space discret use interpol degre desir system learn control task system use knowledg represent priori relat work propos neurolog class differenti learn mechan correl earlier chang input later chang adapt use multipli chang output weight sum absolut previou input weight previou differ input previou time coeffici tempor differ approach one class adapt element class use sum previous predict output multipli gradient exponenti decay coeffici modifi barto sutton use tempor differ underli learn classic recurr learn method state set valu paramet suffici specifi condit input decod group environment state equival one class ident system everi environment input one input refer assum valu fall discret rang determin unless otherwis tate return visit one altern state action caus modif system may chang chang state need sinc alter paramet may decod within associ action probabl allow action depend current valu rule determin allow action rule choos action base made reduc likelihood choos action caus eventu chang made base idea action present input influenc similar pattern occur weight chang made increas element produc action pattern similar consid classic problem balanc pole move state specifi posit veloc cart action fix veloc increment right rule action base current recurr learn algorithm present nonlinear empir result show success stationari also may applic nonstationari effort develop algorithm reward decis choic lead cycl avoid failur limit oscil absorb techniqu exploit recurr inform obtain learn system reward upon return previou howev weight chang permit state transit system return recur state sequenc recur state evid algorithm form tempor optim dynam search techniqu must balanc search path known solut explor new area space find better cheaper known two arm bandit given two hand slot machin one observ reward higher one exclud play arm lesser like recurr learn learn contrast box ase algorithm learn upon decod barto real valu input paramet analyz member reduc comput resourc limit rang allow possibl rang although aspect rang decod discuss consid paramet valu fall one rang specif state consist one activ rang set valu specifi one uniqu otherwis set paramet valu may sever paramet valu time determin one sever state set possibl valu environment paramet fall one number may differ differ state specifi activ rang set input paramet valu decod one rang boolean valu use describ activ level state activ valu state state decis model box input activ given state nonoverlap although reason preclud overlap consist two previou system output decis rule control base weight sum input plu stochast action decis control either given nois real randomli distribut valu mean control interpret push right learn goal recurr learn algorithm avoid failur move toward part cycl state oscil concept compar long ball juggler judg success consider given whether thrown high left like tri stabl optimum perform demand recurr heurist fundament basi state repeatedli visit repeatedli first heurist reward state part cycl failur second heurist augment first give reward state particip shorter heurist discuss state visit one reinforc heurist assum state visit part cycl failur action taken previou visit influenc reinforc weight upon assum increas likelihood cycl occur assumpt made whether state respons ion action may immedi caus environ chang differ may delay sinc small chang paramet decod input henc inertia state appear twice sinc would assum rather caus immedi recurr equat recurr learn equat stem part weight alter formula ase weight state sum previou learn rate reward elig elig index exponenti decay trace determin decay reward function system fail timer otherwis output valu yi last output cycl describ basic ase algorithm extend weight updat procedur term provid failur provid reinforc state elig weight chang ct multipli reward current elig reward taken posit although need environment yield reinforc valu function time could use second elig function yield one three constant valu accord formula last time state state previous formula state previous visit state transit occur last time direct weight chang due final term last action hi call constant recurr learn elig function design reinforc reward short cycl longer call short recurr learn elig function reinforc shorter cycl longer shorter cycl basi second heurist conjectur short cycl converg absorb point long long cycl diverg easili although cycl diverg larger extens basic heurist formula recurr elig function otherwis current elig function similar previou failur elig reinforc shorter cycl elig valu return invers proport period cycl reinforc converg term ensur weight reinforc return alreadi visit constant recurr algorithm short recurr show constant recurr algorithm state reward reactiv transit anoth exampl state reward constant regardless weather cycl travers state figur describ short recurr algorithm state reward accord current time last activ small differ larg differ exampl state reward cycl state travers state shown dark heavi line cycl state travers lighter sinc state sooner travers darker result simul four two recurr experi consist ten run balanc trial last time step fail pole fell cart went beyond track conserv cpu simul also termin system achiev consecut trial last time remain trial also last time assumpt result space caus control becom determinist regardless influenc long time requir run attempt optim paramet barto trial began cart pole made state space desir initi continu state first experi consist failur recurr reward failur learn run averag time step failur predict system run compar found method caus control averag time step result compar describ sutton next short recurr learn system ad ase ten trial learn session short learn algorithm ran time step bettet system final constant recurr learn ase system constant recurr learn elimin failur time show constant recurr learn recurr learn failur rate averag simul cycl provid heurist arm problem evid goal direct algorithm allow search outward cycl state high probabl unexplor search rate explor recurr learn paramet ct influenc cycl govern decis process also decreas algorithm explor search space part cycl oscil rel larg degre varianc final last trail rang time failur futur futur experi studi effect reward predict cycl manner similar predict failur use effort minim differ predict time cycl order result experi shown futur show recurr predict system gener superior either predict system short recurr system oper paper present extens failur driven learn algorithm base reinforc decis caus automaton enter environment state control learn synthes best valu reinforc area search space produc recur state cycl failur driven learn algorithm achiev weight alter simul show recurr reward algorithm show improv overal task substanti decreas learn michi machin dale coin widrow comput inform tou wilcox hume genet ibm connel coin mathemat softwar approxim theori il ie neural june gte gte sutton march barto ie smc ie smc,0
68,68,"715 
A COMPUTER SIMULATION OF CEREBRAL NEOCORTEX: 
COMPUTATIONAL CAPABILITIES OF NONLINEAR NEURAL NETWORKS 
Alexander Singer* and John P. Donoghue** 
*Department of Biophysics, Johns Hopkins University, 
Baltimore, MD 21218 (to whom all correspondence should 
be addressed) 
**Center for Neural Science, Brown University, 
Providence, RI 02912 
@ American Institute of Physics 1988 
716 
ABSTRACT
A synthetic neural network simulation of cerebral neocortex was 
developed based on detailed anatomy and ph. ysiology. Processing elements 
possess temporal nonlinearities and connecuon patterns similar to those of 
cortical neurons. The network was able to replicate spatial and temporal 
integration properties found experimentally in neocortex. A certain level of 
randomness was found to be crucial for the robustness of at least some of 
the network's computational capabilities. Emphasis was placed on how 
synthetic simulations can be of use to the study of both artificial and 
biological neural networks. 
A variety of fields have benefited from the use of computer simulations. This is 
true in spite of the fact that general theories and conceptual models are lacking in many 
fields and conlzasts with the use of simulations to explore existing theoretical structures that 
are extremely complex (cf. MacGregor and Lewis, 1977). When theoretical 
superstructures are missing, simulations can be used to synthesize empirical findings into a 
system which can then be studied analytically in and of itself. The vast compendium of 
neuroanatomical and neurophysiological data that has been collected and the concomitant 
absence of theories of brain function (Crick, 1979; Lewin, 1982) makes neuroscience an 
ideal candidate for the application of synthetic simulations. Furthermore, in keeping with 
the spirit of this meeting, neural network simulations which synthesize biological data can 
make contributions to the study of artificial neural systems as general information 
processing machines as well as to the study of the brain. A synthetic simulation of cerebral 
neocortex is presented here and is intended to be an example of how traffic might flow on 
the two-way street which this conference is trying to build between artificial neural network 
modelers and neuroscientists. 
The fact that cerebral neocortex is involved in some of the highest forms of 
information processing and the fact that a wide variety of neurophysiological and 
neuroanatomical data are amenable to simulation motivated the present development of a 
synthetic simulation of neocortex. The simulation itself is comparatively simple; 
nevertheless it is more realistic in terms of its structure and elemental processing units than 
most artificial neural networks. 
The neurons from which our simulation is constructed go beyond the simple 
sigmoid or hard-saturation nonlinearities of most artificial neural systems. For example, 
717 
because inputs to actual neurons are mediated by ion currents whose driving force depends 
on the membrane potential of the neuron, the amplitude of a cell's response to an input, i.e. 
the amplitude of the post-synaptic potential (PSP), depends not only on the strength of the 
synapse at which the input arrives, but also on the state of the neuron at the time of the 
input's arrival. This aspect of classical neuron electrophysiology has been implemented in 
our simulation (figure 1A), and leads to another important nonlinearity of neurons: 
namely, current shunting. Primarily effective as shunting inhibition, excitatory current can 
be shunted out an inhibitory synapse so that the sum of an inhibitory postsynaptic potential 
and an excitatory postsynaptic potential of equal amplitude does not result in mutual 
cancellation. Instead, interactions between the ion reversal potentials, conductance values, 
relative timing of inputs, and spatial locations of synapses determine the amplitude of the 
response in a nonlinear fashion (figure lB) (see Koch, Poggio, and Torre, 1983 for a 
quantitative analysis). These properties of actual neurons have been ignored by most 
artificial neural network designers, though detailed knowledge of them has existed for 
decades and in spite of the fact that they can be used to implement complex computations 
(e.g. Torre and Poggio, 1978; Houchin, 1975). 
The development of action potentials and spatial interactions within the model 
neurons have been simplified in our simulation. Action potentials involve preprogrmm'ned 
fluctuations in the membrane potential of our neurons and result in an absolute and a 
relative refractory period. Thus, during the time a cell is fh'ing a spike synaptic inputs are 
ignored, and immediately following an action potential the neuron is hyperpolarized. The 
modeling of spatial interactions is also limited since neurons are modeled primarily as 
spheres. Though the spheres can be deformed through control of a synaptic weight which 
modulates the amplitudes of ion conductances, detailed dendritic interactions are not 
simulated. Nonetheless, the fact that inhibition is generally closer to a cortical neuron's 
soma while excitation is more distal in a celrs dendritic tree is simulated through the use of 
sUronger inhibitory synapses and relatively weaker excitatory synapses. 
The relative strengths of synapses in a neural network define its connectivity. 
Though initial connectivity is random in many artificial networks, brains can be thought to 
contain a combination of randomness and fixed structure at distinct levels (Szentagothai, 
1978). From a macroscopic perspective, all of cerebral neocortex might be structured in a 
modular fashion analogous to the way the barrel field of mouse somatosensory cortex is 
structured (Woolsey and Van der Loos, 1970). Though speculative, arguments for the 
existence of some sort of anatomical modularity over the entire cortex are gaining ground 
718 
(Mountcastle, 1978; Szentagothai, 1979; Shepherd, in press). Thus, inspired by the 
ban'els of mice and by growing interest in functional units of 50 to 100 microns with on the 
order of 1000 neurons, our simulation is built up of five modules (60 cells each) with more 
dense local interconnections and fewer intermodular contacts. Furthermore, a wide variety 
of neuronal classification schemes have led us to subdivide the gross structure of each 
module so as to contain four classes of neurons: cortico-cortical pyramids, output 
pyramids, spiny stellate or local excitatory cells, and GABAergic or inhibirtory cells. 
At this level of analysis, the impressed structure allows for control over a variety of 
pathways. In our simulation each class of neurons within a module is connected to every 
other class and intermodular connections are provided along pathways from cortico-cortical 
pyramids to inhibitory cells, output pyramids, and cortico-cortical pyramids in immediately 
adjacent modules. A general sense of how strong a pathway is can be inferred from the 
product of the number of synapses a neuron receives from a particular class and the 
strength of each of those synapses. The broad architecture of the simulation is further 
structured to emphasize a three step path: Inputs to the network impact most su:ongly on 
the spiny stellate cells of the module receiving the input; these cells in turn project to 
cortico-cortical pyramidal cells more strongly than they do to other cell types; and finally, 
the pathway from the cortico-cortical pyramids to the output pyramidal cells of the same 
module is also particularly strong. This general architecture (figure 2) has received 
empirical support in many regions of cortex (Jones, 1986). 
In distinction to this synaptic architecture, a fine-grain connectivity is defined in our 
simulated network as well. At a more microscopic level, connectivity in the network is 
random. Thus, within the confines of the architecture described above, the determination 
of which neuron of a particular class is connected to which other cell in a target class is 
done at random. Two distinct levels of connectivity have, therefore, been established 
(figure 3). Together they provide a middle ground between the completely arbitrary 
connectivity of many artificial neural networks and the problem specific connectivities of 
other artificial systems. This distinction between gross synaptic architecture and fine-grain 
connectivity also has intuitive appeal for theories of brain development and, as we shall 
see, has non-trivial effects on the computational capabilities of the network as a whole. 
With defintions for input integration within the local processors, that is within the 
neurons, and with the establishment of connectivity patterns, the network is complete and 
ready to perform as a computational unit. In order to judge the simulation's capabilities in 
some rough way, a qualitative analysis of its response to an input will suffice. Figure 4 
719 
shows the response of the network to an input composed of a small burst of action 
potentials arriving at a single module. The data is displayed as a raster in which time is 
mapped along the abscissa and all the cells of the network are arranged by module and cell 
class along the ordinate. Each marker on the graph represents a single action potential f'n'ed 
by the appropriate neuron at the indicated time. Qualitatively, what is of importance is the 
fact that the network does not remain unresponsive, saturate with activity in all neurons, or 
oscillate in any way. Of course, that the network behave this way was predetermined by 
the combination of the properties of the neurons with a judicious selection of synaptic 
weights and path strengths. The properties of the neurons were fixed from physiological 
data, and once a synaptic architecture was found which produced the results in figure 4, 
that too was fixed. A more detailed analysis of the temporal firing pattern and of the 
distribution of activity over the different cell classes might reveal important network 
properties and the relative importance of various pathways to the overall function. Such an 
analysis of the sensitivity of the network to different path sU:engths and even to intmcellular 
parameters will, however, have to be postponed. Suffice it to say at this point that the 
network, as structured, has some nonzero, finite, non-oscillatory response which, 
qualitatively, might not offend a physiologist judging cortical activity. 
Though the synaptic architecture was tailored manually and fixed so as to produce 
""reasonable"" results, the fine-grain connectivity, i.e. the determination of exactly which 
cell in a class connects to which other cell, was random. An important property of artificial 
(and presumably biological) neural networks can be uncovered by exploiting the distinction 
between levels of connectivity described above. Before doing so, however, a detail of 
neural network design must be made explicit. Any network, either artificial or biological, 
must contend with the time it takes to communicate among the processing elements. In the 
brain, the time it takes for an action potential to travel from one neuron to another depends 
on the conduction velocity of the axon down which the spike is traveling and on the delay 
that occurs at the synapse connecting the cells. Roughly, the total transmission time from 
one cortical neuron to another lies between 1 and 5 milliseconds. In our simulation two 
720 
paradigms were used. In one case, the transmission times between all neurons were 
standardized at 1 msec.* Alternatively, the transmission times were fixed at random, 
though admittedly unphysiological, values between 0.1 and 2 msec. 
Now, if the time it takes for an action potential to travel from one neuron to another 
were fixed for all cells at 1 msec, different fine-grain connectivity patterns are found to 
produce entirely distinct network responses to the same input, in spite of the fact that the 
gross synaptic architecture remained constant. This was true no matter what particular 
synaptic architecture was used. If, on the other hand, one changes the transmission times 
so that they vary randomly between 0.1 and 2 msec, it becomes easy to find sets of 
synaptic strengths that were robust with respect to changes in the fine-grain connectivity. 
Thus, a wide search of path strengths failed to produce a network which was robust to 
changes in fine-grain connectivity in the case of identical transmission times, while a set of 
synaptic weights that produced robust responses was easy to find when the transmission 
times were randomized. Figure 5 summarizes this result. In the figure overall network 
activity is measured simply as the total number of action potentials generated by pyramidal 
cells during an experiment and robustness can be judged as the relative stability of this 
response. The abscissa plots distinct experiments using the same synaptic architecture with 
different fine-grain connectivity patterns. Thus, though the synaptic architecture remains 
constant, the different trials represent changes in which particular cell is connected to which 
other cell. The results show quite dramatically that the network in which the transmission 
times are randomly distributed is more robust with respect to changes in fine-grain 
connectivity than the network in which the transmission times are all 1 msec. 
It is important to note that in either case, both when the network was robust and 
when changes of fine-grain connectivity produced gross changes in network output, the 
synaptic architectures produced outputs like that in figure 4 with some fine-grain 
connectivities. If the response of the network to an input can be considered the result of 
* Because neurons receive varying amounts of input and because integration is performed 
by summating excitatory and inhibitory postsynaptic potentials in a nonlinear way, the time 
each neuron needs to summate its inputs and produce an action potential varies from neuron 
to neuron and from time to time. This then allows for asynchronous firing in spite of the 
identical transmission times. 
721 
some computation, figure 5 reveals that the same computational capability is not robust 
with respect to changes in fine-grain connectivity when transmission times between 
neurons are all 1 msec, but is more robust when these times are randomized. Thus, a 
single computational capability, viz. a response like that in figure 4 to a single input, was 
found to exist in networks with different synaptic architectures and different transmission 
time paradigms; this computational capability, however, varied in terms of its robustness 
with respect to changes in fine-grain connectivity when present in either of the transmission 
time paradigms. 
A more complex computational capability emerged from the neural network 
simulation we have developed and described. If we label two neighboring modules C2 and 
C3, an input to C2 will suppress the response of C3 to a second input at C3 if the second 
input is delayed. A convenient way of representing this spatio-temporal integration 
property is given in figure 6. The ordinate plots the ratio of the normal response of one 
module (say C3) to the response of the module to the same input when an input to a 
neighboring module (say C2) preceeds the input to the original module (C3). Thus, a value 
of one on the ordinate means the earlier spatially distinct input had no effect on the response 
of the module in which this property is being measured. A value less than one represents 
suppression, while values greater than one represent enhancement. On the abscissa, the 
interstimulus interval is plotted. From figure 6, it can be seen that significant suppression 
of the pyramidal cell output, mostly of the output pyramidal cell output, occurs when the 
inputs are separated by 10 to 30 msec. This response can be characterized as a sort of 
dynamic lateral inhibition since an input is suppressing the ability of a neighboring region 
to respond when the input pairs have a particular time course. This property could play a 
variety of role in biological and artificial neural networks. One role for this spatio-temporal 
integration property, for example, might be in detecting the velocity of a moving stimulus. 
The emergent spatio-temporal property of the network just described was not 
explicitly built into the network. Moreover, no set of synaptic weights was able to give rise 
to this computational capability when transmission times were all set to 1 msec. Thus, in 
addition to providing robustness, the random transmission times also enabled a more 
complex property to emerge. The important factor in the appearances of both the 
robustness and the dynamic lateral inhibition was randomization; though it was 
implemented as randomly varying transmission times, random spontaneous activity would 
have played the same role. From the viewpoint, then, of the engineer designing artificial 
neural networks, the neural network presented here has instructional value in spite of the 
722 
fact that it was designed to synthesize biological data. Specifically, it motivates the 
consideration of randomness as a design constraint. 
From the prespective of the biologists attending this meeting, a simple fact will 
reveal the importance of synthetic simulations. The dynamic lateral inhibition presented in 
figure 6 is known to exist in rat somatosensory cortex (Simons, 1985). By deflecting the 
whiskers on a rat's face, Simons was able to stimulate individual ban'els of the postero- 
medial somatosensory ban'el field in combinations which revealed similar spario-temporal 
interactions among the responses of the cortical neurons of the barrel field. The temporal 
suppression he reported even has a time course similar to that of the simulation. What the 
experiment did not reveal, however, was the class of cell in which suppression was seen; 
the simulation located most of the suppression in the output pyramidal cells. Hence, for a 
biologist, even a simple synthetic simulation like the one presented here can make def'mitive 
predictions. What differentiates the predictions made by synthetic simulations from those 
of more general artificial neural systems, of course, is that the slzong biological foundations 
of synthetic simulations provide an easily grasped and highly relevant framework for both 
predictions and experimental verification. 
One of the advertised purposes of this meeting was to ""bring together 
neurobiologists, cognitive psychologists, engineers, and physicists with common interest 
in natural and artificial neural networks."" Towards that end, synthetic computer 
simulations, i.e. simulations which follow known neurophysiological and neuroanatomical 
data as if they comprised a complex recipe, can provide an experimental medium which is 
useful for both biologists and engineers. The simulation of cerebral neocortex developed 
here has information regarding the role of randomness in the the robustness and presence 
of various computational capabilities as well as information regarding the value of distinct 
levels of connectivity to contribute to the design of artificial neural networks. At the same 
time, the synthetic nature of the network provides the biologist with an environment in 
which he can test notions of actual neural function as well as with a system which replicates 
known properties of biological systems and makes explicit predictions. Providing two- 
way interactions, synthetic simulations like this one will allow future generations of 
artificial neural networks to benefit from the empirical findings of biologists, while the 
slowly evolving theories of brain finction benefit from the more generalizable results and 
methods of engineers. 
723 
References 
Crick, F. H. C. (1979) Thinking about the brain, Scientific American, 241:219 - 232. 
Houchin, J. (1975) Direction specificity in cortical responses to moving stimuli -- a simple 
model. Proceedings of the Physiological Society, 247:7 - 9. 
Jones, E.G. (1986) Connectivity of primate sensory-motor cortex, in Cerebral Cortex, 
vol. 5, E.G. Jones and A. Peters (eds), Plenum Press, New York. 
Koch, C., Poggio, T., and Torre, V. (1983) Nonlinear interactions in a dendritic tree: 
Localization, timing, and role in information processing. Proceedings of the 
National Academy of Science, USA, 80:2799 - 2802. 
Lewin, R. (1982) Neuroscientists look for theories, Science, 216:507. 
MacGregor, R.J. and Lewis, E.R. (1977) Neural Modeling, Plenum Press, New York. 
Mountcastle, V. B. (1978) An organizing principle for cerebral function: The unit module 
and the distributed system, in The Mindful Brain, G. M. Edelman and V. B. 
Mountcastle (eds.), MIT Press, Cambridge, MA. 
Shepherd, G.M. (in press) Basic circuit of cortical organization, in Perspectives in Memory 
Research, M.S. Gazzaniga (ed.), MIT Press, Cambridge, MA. 
Simons, D. J. (1985) Temporal and spatial integration in the rat SI vibrissa cortex, Journal 
of Neurophysiology, 54:615 - 635. 
Szenthigothai, J. (1978) Specificity versus (quasi-) randomness in cortical connectivity, in 
Architectonics of the Cerebral Cortex, M. A. B. Brazier and H. Petsche (eds.), 
Raven Press, New York. 
Szentfigothai, J. (1979) Local neuron circuits in the neocortex, in The Neurosciences. 
Fourth Study Program, F. O. Schmitt and F. G. Worden (eds.), MIT Press, 
Cambridge, MA. 
Torre, V. and Poggio, T. (1978) A synaptic mechanism possibly underlying directional 
selectivity to motion, Proceeding of the Royal Society (London)B, 202:409 -416. 
Woolsey, T.A. and Van der Loos, H. (1970) Structural organization of layer IV in the 
somatosensory region (SI) of mouse cerebral cortex, Brain Research, 17:205-242. 
724 
Shunting Inhibition 
Figure 1A: Intracellular records of post-synaptic potentials resulting from single excitatory and 
inhibitory inputs to cells at different resting potentials. 
I PSP Amplitude Dependence on Membrane Potential I 
EPSPs I PSPs 
Resting ,,., Resting [ .._ 
Potential Potential 
= -40 mV = 40mY 
Resting ... Resting 
Potential Potential 
= -60 mV = 20mY 
Resting Resting 
Potential Potential 
= -80 mV = 0 mV 
Resting / Resting 
Potential  .... Potential 
= -100 mV = -20 mV 
Resting 
Potential 
= -120 mV 
Resting  
Potential -,, 
= -40 mV  
Figure lB: Illustration of the current shunting nonlinearity present in the model neurons. Though 
the simultaneous arrival of postsynaptic potentials of equal and opposite amplitude would result 
in no deflection in the membrane potential of a simple linear neuron model, a variety of factors 
contribute to the nonlinear response of actual neurons and of the neurons modeled in the present 
simulation. 
725 
726 
o 
o 
o 
o 
o 
o o 
o 
o 
A 
A A 
A A 
A A 
A A 
o Oo 
o o 
o o 
Spiny Stellate 
Cells 
Output Inhibitory Intracortical 
Pyramidal Cells Cells Pyramidal Cells 
Figure 3: Two levels of connectivity are defined in the network. Gross synaptic architecture is 
defined among classes of cells. Fine-grain connectivity specifies which cell connects to which 
other cell and is determined at random. 
727 
Module 
Module 
4 
Module 
3 
Module 
2 
Module 
1 
Sample Raster 
Input: 333 Hz input, 6 ms duration applied to Module 3 
Currico-cortical 
 pyramids 
�'- - � .' .' '  Inhibitory 
i # cells 
� ' �  Spiny stellale 
't  Outpu! .. cells 
� . � pyramlus 
I I J 
10 20 30 
Time (ms) 
Figure 4: Sample response of the entire network to a small burst of action potentials delivered to 
module 3. 
728 
Robustness With Respect to Connectivity Pattern 
Synaptic Architecture Constant 
o 
r 
4OO 
300 
200 
100 
II 
I 
! 
I I i I 
ii 
� if JI. � 
n B � It ! I � 
Delay times = 1 ms 
Delay 
times random 
Individual Trials with Different Fine-grain Connectivity Patterns 
Figure S: Plot of an arbitrary activity measure (total spike activity in all pyramidal cells) versus 
various instatiations of the same connectional architecture. Along the abscissa are represented the 
different fine-grained patterns of connectivity within a fixed connectional architecture. In one 
case the conductance times between all cells was 1 msec and in the other case the times were 
selected at random from values between 0.1 msec and 2 msec. This experiment shows the greater 
overall stability produced by random conduction times. 
729 
esuodseH e^!tlel 
", comput simul cerebr capabl nonlinear neural network john depart john hopkin md correspond center neural brown ri american institut physic synthet neural network simul cerebr neocortex base detail anatomi process element tempor nonlinear connecuon pattern similar network abl replic spatial tempor properti found experiment certain level found crucial robust least comput emphasi place simul use studi artifici neural varieti field benefit use comput spite fact gener theori conceptu model lack mani conlzast use simul explor exist theoret structur extrem complex gregor theoret simul use synthes empir find studi analyt vast compendium neurophysiolog data collect concomit theori brain function make neurosci candid applic synthet keep spirit neural network simul synthes biolog data contribut studi artifici neural system gener inform machin well studi synthet simul cerebr present intend exampl traffic might flow street confer tri build artifici neural network fact cerebr neocortex involv highest form process fact wide varieti neurophysiolog data amen simul motiv present develop simul simul compar realist term structur element process unit artifici neural neuron simul construct go beyond simpl nonlinear artifici neural input actual neuron mediat ion current whose drive forc depend membran potenti amplitud respons amplitud potenti depend strength input also state neuron time aspect classic neuron electrophysiolog implement simul lead anoth import nonlinear current primarili effect shunt excitatori current shunt inhibitori synaps sum inhibitori postsynapt potenti excitatori postsynapt potenti equal amplitud result mutual interact ion revers conduct time spatial locat synaps determin amplitud nonlinear fashion properti actual neuron ignor neural network though detail knowledg exist spite fact use implement complex comput torr develop action potenti spatial interact within model simplifi action potenti involv membran potenti neuron result absolut refractori time cell spike synapt input immedi follow action potenti neuron spatial interact also limit sinc neuron model primarili though sphere deform control synapt weight amplitud ion detail dendrit interact fact inhibit gener closer cortic excit distal celr dendrit tree simul use urong inhibitori synaps rel weaker excitatori rel strength synaps neural network defin initi connect random mani artifici brain thought combin random fix structur distinct level macroscop cerebr neocortex might structur fashion analog way barrel field mous somatosensori cortex van der though argument sort anatom modular entir cortex gain ground inspir mice grow interest function unit micron simul built five modul cell local interconnect fewer intermodular wide varieti neuron classif scheme led us subdivid gross structur contain four class output spini stellat local excitatori gabaerg inhibirtori level impress structur allow control varieti simul class neuron within modul connect everi class intermodular connect provid along pathway inhibitori output pyramid immedi gener sens strong pathway infer number synaps neuron receiv particular class broad architectur simul emphas three step input network impact spini stellat cell modul receiv cell turn project pyramid cell strongli cell pathway pyramid output pyramid cell also particularli gener architectur receiv support mani region cortex distinct synapt connect defin network microscop connect network within confin architectur describ determin neuron particular class connect cell target class two distinct level connect establish togeth provid middl ground complet arbitrari mani artifici neural network problem specif connect artifici distinct gross synapt architectur also intuit appeal theori brain develop shall effect comput capabl network defint input integr within local within establish connect network complet perform comput order judg capabl rough qualit analysi respons input figur respons network input compos small burst action arriv singl data display raster time along abscissa cell network arrang modul cell along marker graph repres singl action potenti appropri neuron indic import network remain satur activ network behav way predetermin combin properti neuron judici select synapt path properti neuron fix physiolog synapt architectur found produc result figur detail analysi tempor fire pattern activ differ cell class might reveal import network rel import variou pathway overal sensit network differ path even intmcellular suffic say point respons might offend physiologist judg cortic synapt architectur tailor manual fix produc determin exactli class connect import properti artifici presum neural network uncov exploit distinct level connect describ detail network design must made either artifici contend time take commun among process time take action potenti travel one neuron anoth depend conduct veloc axon spike travel delay occur synaps connect total transmiss time cortic neuron anoth lie simul two one transmiss time neuron transmiss time fix admittedli valu time take action potenti travel one neuron anoth fix cell differ connect pattern found entir distinct network respons spite fact synapt architectur remain true matter particular architectur one chang transmiss time vari randomli becom easi find set strength robust respect chang wide search path strength fail produc network robust connect case ident transmiss set weight produc robust respons easi find transmiss figur summar figur overal network measur simpli total number action potenti gener pyramid experi robust judg rel stabil abscissa plot distinct experi use synapt architectur connect though synapt architectur remain differ trial repres chang particular cell connect result show quit dramat network transmiss randomli distribut robust respect chang network transmiss time import note either network robust chang connect produc gross chang network architectur produc output like figur respons network input consid result neuron receiv vari amount input integr perform summat excitatori inhibitori postsynapt potenti nonlinear time neuron need summat input produc action potenti vari neuron neuron time allow asynchron fire spite transmiss figur reveal comput capabl robust respect chang connect transmiss time robust time comput respons like figur singl exist network differ synapt architectur differ transmiss comput vari term robust respect chang connect present either transmiss complex comput capabl emerg neural network develop label two neighbor modul input suppress respons second input second conveni way repres integr given figur ordin plot ratio normal respons one respons modul input input modul prece input origin modul valu one ordin mean earlier spatial distinct input effect respons modul properti valu less one repres valu greater one repres interv figur seen signific suppress pyramid cell mostli output pyramid cell occur separ respons character sort later inhibit sinc input suppress abil neighbor region respond input pair particular time properti could play role biolog artifici neural one role might detect veloc move emerg properti network describ built set synapt weight abl give rise comput capabl transmiss time set provid random transmiss time also enabl properti import factor appear dynam later inhibit though randomli vari transmiss random spontan activ would play engin design artifici neural network present instruct valu spite design synthes biolog motiv random design prespect biologist attend simpl fact import synthet dynam later inhibit present known exist rat somatosensori cortex deflect simon abl stimul individu somatosensori field combin reveal similar among respons cortic neuron barrel tempor report even time cours similar class cell suppress simul locat suppress output pyramid even simpl synthet simul like one present make differenti predict made synthet simul gener artifici neural slzong biolog foundat synthet simul provid easili grasp highli relev framework experiment advertis purpos meet togeth cognit physicist common interest natur artifici neural toward synthet comput simul follow known neurophysiolog neuroanatom compris complex provid experiment medium biologist simul cerebr neocortex develop inform regard role random robust presenc variou comput capabl well inform regard valu distinct connect contribut design artifici neural synthet natur network provid biologist environ test notion actual neural function well system replic properti biolog system make explicit provid synthet simul like one allow futur gener neural network benefit empir find evolv theori brain benefit generaliz result think scientif direct specif cortic respons move stimuli simpl proceed physiolog connect primat cerebr jone peter plenum new nonlinear interact dendrit role inform proceed academi neuroscientist look neural plenum new organ principl cerebr unit modul distribut mind edelman mit basic circuit cortic perspect memori gazzaniga mit tempor spatial integr rat si vibrissa journal specif versu random cortic cerebr brazier petsch new local neuron circuit studi schmitt worden mit synapt mechan possibl underli direct proceed royal societi van der structur organ layer iv region mous cerebr brain inhibit intracellular record potenti result singl excitatori input cell differ rest psp amplitud depend membran potenti psp rest potenti rest potenti rest potenti rest potenti illustr current shunt nonlinear present model though simultan arriv postsynapt potenti equal opposit amplitud would result deflect membran potenti simpl linear neuron varieti factor nonlinear respons actual neuron neuron model present oo stellat inhibitori intracort cell cell pyramid cell two level connect defin gross synapt architectur among class connect specifi cell connect cell determin raster hz ms durat appli modul pyramid inhibitori cell spini stellal cell pyramlu sampl respons entir network small burst action potenti deliv respect connect pattern architectur constant time ms random trial differ connect pattern plot arbitrari activ measur spike activ pyramid versu instati connect along abscissa repres pattern connect within fix connect one conduct time cell msec case time random valu msec experi show greater stabil produc random conduct,2
69,69,"662 
AN ADAPTIVE AND HETERODYNE FILTERING PROCEDURE 
FOR THE IMAGING OF MOVING OBJECTS 
F. H. Schuling, H. A. K. Mastebroek and W. H. Zaagman 
Biophysics Department, Laboratory for General Physics 
Westersingel 34, 9718 CM Groningen, The Netherlands 
ABSTRACT 
Recent experimental work on the stimulus velocity dependent time resolving 
power of the neural units, situated in the highest order optic ganglion of the 
blowfly, revealed the at first sight amazing phenomenon that at this high level of 
the fly visual system, the time constants of these units which are involved in the 
processing of neural activity evoked by moving objects, are -roughly spoken- 
inverse proportional to the velocity of those objects over an extremely wide range. 
In this paper we will discuss the implementation of a two dimensional heterodyne 
adaptive filter construction into a computer simulation model. The features of this 
simulation model include the ability to account for the experimentally observed 
stimulus-tuned adaptive temporal behaviour of time constants in the fly visual 
system. The simulation results obtained, clearly show that the application of such 
an adaptive processing procedure delivers an improved imaging technique of 
moving patterns in the high velocity range. 
A FEW REMARKS ON THE FLY VISUAL SYSTEM 
The visual system of the diptera, including the blowfly Calliphora 
erythrocephala (Mg.) is very regularly organized and allows therefore very precise 
optical stimulation techniques. Also, long term electrophysiological recordings can 
be made relatively easy in this visual system. For these reasons the blowfly (which 
is well-known as a very rapid and 'clever' pilot) turns out to be an extremely 
suitable animal for a systematic study of basic principles that may underlie the 
detection and further processing of movement information at the neural level. 
In the fly visual system the input retinal mosaic structure is precisely 
mapped onto the higher order optic ganglia (lamina, medulla, lobula). This means 
that each neural column in each ganglion in this visual system corresponds to a 
certain optical axis in the visual field of the compound eye. In the lobula complex 
a set of wide-field movement sensitive neurons is found, each of which integrates 
the input signals over the whole visual field of the entire eye. One of these wide 
field neurons, that has been classified as H1 by Hausen I has been extensively 
studied both anatomically 2, 3, 4 as well as electrophysiologically 5, 6, 7 The 
obtained results generally agree very well with those found in behavioral 
optomotor experiments on movement detection 8 and can be understood in terms of 
Reichardts correlation model 9, 10 
The H1 neuron is sensitive to horizontal movement and directionally 
selective: very high rates of action potentials (spikes) up to 300 per second can be 
recorded from this element in the case of visual stimuli which move horizontally 
inward, i.e. from back to front in the visual field (preferred direction), whereas 
movement horizontally outward, i.e. from front to back (null direction) suppresses 
its activity. 
American Institute of Physics 1988 
663 
EXPERIMENTAL RESULTS AS A MODELLING BASE 
When the H1 neuron is stimulated in its preferred direction with a step wise 
pattern displacement, it will respond with an increase of neural activity. By 
repeating this stimulus step over and over one can obtain the averaged response: 
after a 20 ms latency period the response manifests itself as a sharp increase in 
average firing rate followed by a much slower decay to the spontaneous activity 
level. Two examples of such averaged responses are shown in the Post Stimulus 
Time Histograms (PSTH's) of figure 1. Time to peak and peak height are related 
and depend on modulation depth, stimulus step size and spatial extent of the 
stimulus. The tail of the responses can be described adequately by an exponential 
decay toward a constant spontaneous firing rate: 
R(t)=c+a � e(-t/r) 
(l) 
For each setting of the stimulus parameters, the response parameters, 
defined by equation (1), can be estimated by a least-squares fit to the tail of the 
PSTH. The smooth lines in figure 1 are the results of two such fits. 
1%0 = . �/ 
50 
150 W= II�/s 
s0lt'! 
o 200 oo 6oo 80o 
hrne Irnsl 
t(ms) 
300 
3O 
� M=0.40 
o M=010 
 M =o 05 
o 
o 
o 
0.3 I 3 I00 300 
W {'Is ) 
Fig. 1 
Fig.2 
Averaged responses (PSTH's) obtained from the H1 neuron, being 
adapted to smooth stimulus motion with velocities 0.36�/s (top) and 
11 �/s (bottom) respectively. The smooth lines represent least-squares 
fits to the PSTH's of the form R(t)=c+a.e(-t/r). Values of r for the 
two PSTH's are 331 and 24 ms respectively (de Ruyter van Steveninck et 
al.7). 
Fitted values of r as a function of adaptation velocity for three 
modulation depths M. The straight line is a least-squares fit to represent 
the data for M=0.40 in the region w=0.3-100�/s. It has the form 
r=a.w-/ with a=150 ms and/=0.7 (de Ruyter van Steveninck et al.7). 
664 
Figure 2 shows fitted values of the response time constant r as a function of 
the angular velocity of a moving stimulus (a square wave grating in most 
experiments) which was presented to the animal during a period long enough to let 
its visual system adapt to this moving pattern and before the step wise pattern 
displacement (which reveals r) was given. The straight line, described by 
(2) 
(with W in �/s and y in ms) represents a least-squares fit to the data over the 
velocity range from 0.36 to 125 �/s. For this range, r varies from 320 to roughly 
10 ms, with a--150__10 ms and /=0.7_0.05. Defining the adaptation range of r as 
that interval of velocities for which r decreases with increasing velocity, we may 
conclude from figure 2 that within the adaptation range, y is not very sensitive to 
the modulation depth. 
The outcome of similar experiments with a constant modulation depth of the 
pattern (M=0.40) and a constant pattern velocity but with four different values of 
the contrast frequency fc (i.e. the number of spatial periods per second that 
traverse an individual visual axis as determined by the spatial wavelength ns of the 
pattern and the pattern velocity v according to fc=V/s) reveal also an almost 
complete independency of the behaviour of y on contrast frequency. Other 
experiments in which the stimulus field was subdivided into regions with different 
adaptation velocities, made clear that the time constants of the input channels of 
the H1 neuron were set locally by the values of the stimulus velocity in each 
stimulus sub-region. Finally, it was found that the adaptation of y is driven by 
the stimulus velocity, independent of its direction. 
These findings can be summarized qualitatively as follows: in steady state, 
the response time constants y of the neural units at the highest level in the fly 
visual system are found to be tuned locally within a large velocity range 
exclusively by the magnitude of the velocity of the moving pattern and not by its 
direction, despite the directional selectivity of the neuron itself. We will not go 
into the question of how this amazing adaptive mechanism may be hard-wired in 
the fly visual system. Instead we will make advantage of the results derived thus 
far and attempt to fit the experimental observations into an image processing 
approach. A large number of theories and several distinct classes of algorithms to 
encode velocity and direction of movement in visual systems have been suggested 
by, for example, Marr and Ullman 11 and van Santen and Sperling 12 
We hypothesize that the adaptive mechanism for the setting of the time 
constants leads to an optimization for the overall performance of the visual system 
by realizing a velocity independent representation of the moving object. In other 
words: within the range of velocities for which the time constants are found to be 
tuned by the velocity, the representation of that stimulus at a certain level within 
the visual circuitry, should remain independent of any variation in stimulus 
velocity. 
OBJECT MOTION DEGRADATION: MODELLING 
Given the physical description of motion and a linear space invariant model, 
the motion degradation process can be represented by the following convolution 
integral: oo oo 
g(x,y)--f ;(h(x-u,y-v) � f(u,v)) dudv (3) 
665 
where f(u,v) is the object intensity at position (u,v) in the object coordinate 
frame, h(x-u,y-v) is the Point Spread Function (PSF) of the imaging system, 
which is the response at (x,y) to a unit pulse at (u,v) and g(x,y) is the image 
intensity at the spatial position (x,y) as blurred by the imaging system. Any 
possible additive white noise degradation of the already motion blurred image is 
neglected in the present considerations. 
For a review of principles and techniques in the field of digital image 
degradation and restoration, the reader is referred to Harris 13, Sawchuk TM, 
Sondhi 15, Nahi 16, Aboutalib eta/. 17, 18, Hildebrand19, Rajala de Figueiredo 20 
It has been demonstrated first by Aboutalib et al. 17 that for situations in which 
the motion blur occurs in a straight line along one spatial coordinate, say along the 
horizontal axis, it is correct to look at the blurred image as a collection of 
degraded line scans through the entire image. The dependence on the vertical 
coordinate may then be dropped and eq. (3) reduces to: 
g(x) h(x-u) � f(u)du (4) 
Given the mathematical description of the relative movement, the 
corresponding PSF can be derived exactly and equation (4) becomes: 
g(x)= fR h<x- u) � f(u)du (5) 
where R is the extent of the motion blur. Typically, a discrete version of (5), 
applicable for digital image processing purposes, is described by: 
L 
g(k)--T. h(k-1)-f(1) ; k=l .... ,N (6) 
1 
where k and 1 take on integer values and L is related to the motion blur extent. 
According to Aboutalib et al. 18 a scalar difference equation model (M,a,b,c) 
can then be derived to model the motion degradation process: 
x(k+l) = M � x(k)+a � f(k) 
g(k) = b-x(k)+c-f(k) ; k=l,...,N 
(7) 
h(i) = coA(i)+clA(i -1)+ ...... +Cm.(i-m) 
where x(k) is the m-dimensional state vector at position k along a scan line, f(k) is 
the input intensity at position k, g(k) is the output intensity, m is the blur extent, 
N is the number of elements in a line, c is a scalar, M, a and b are constant 
matrices of order (mxm), (mxl) and (lxm) respectively, containing the discrete 
values cj of the blurring PSF h(j) for j=0,...,m and/(.) is the Kronecker delta 
function. 
666 
INFLUENCE OF BOTH TIME CONSTANT AND VELOCITY 
ON THE AMOUNT OF MOTION BLUR IN AN ARTIFICIAL 
RECEPTOR ARRAY 
To start with, we incorporate in our simulation model a PSF, derived from 
equation (1), to model the performance of all neural columnar arranged filters in 
the lobula complex, with the restriction that the time constants r remain fixed 
throughout the whole range of stimulus velocities. Realization of this PSF can 
easily be achieved via the just mentioned state space model. 
300 
250 
200 
150 
10o 
50 
 0 
- 250 
"" 200 
150 
10o 
5O 
0 5 10 15 20 
POSITION IN 
ARTIFICIAL RECEPTOR ARRAY 
Fig.3 
upper part. Demonstration of the effect that an increase in magnitude of 
the time constants of an one-dimensional array of filters will result in 
increase in motion blur (while the pattern velocity remains constant). 
Original pattern shown in solid lines is a square-wave grating with a 
spatial wavelength equal to 8 artificial receptor distances. The three 
other wave forms drawn, show that for a gradual increase increase in 
magnitude of the time constants, the representation of the original 
square-wave will consequently degrade. lower part. A gradual increase in 
velocity of the moving square-wave (while the filter time constants are 
kept fixed) results also in a clear increase of degradation. 
667 
First we demonstrate the effect that an increase in time constant (while the 
pattern velocity remains the same) will result in an increase in blur. Therefore we 
introduce an one dimensional array of filters all being equipped with the same 
time constant in their impulse response. The original pattern shown in square and 
solid lines in the upper part of figure 3 consists of a square wave grating with a 
spatial period overlapping 8 artificial receptive filters. The 3 other patterns drawn 
there show that for the same constant velocity of the moving grating, an increase 
in the magnitude of the time constants of the filters results in an increased blur in 
the representation of that grating. On the other hand, an increase in velocity 
(while the time constants of the artificial receptive units remain the same) also 
results in a clear increase in motion blur, as demonstrated in the lower part of 
figure 3. 
Inspection of the two wave forms drawn by means of the dashed lines in 
both upper and lower half of the figure, yields the conclusion, that (apart from 
rounding errors introduced by the rather small number of artificial filters 
available), equal amounts of smear will be produced when the product of time 
constant and pattern velocity is equal. For the upper dashed wave form the 
velocity was four times smaller but the time constant four times larger than for its 
equivalent in the lower part of the figure. 
ADAPTIVE SCHEME 
In designing a proper image processing procedure our next step is to 
incorporate the experimentally observed flexibility property of the time constants 
in the imaging elements of our device. In figure 4 a a scheme is shown, which 
filters the information with fixed time constants, not influenced by the pattern 
velocity. In figure 4 b a network is shown where the time constants also remain 
fixed no matter what pattern movement is presented, but now at the next level of 
information processing, a spatially differential network is incorporated in order to 
enhance blurred contrasts. 
In the filtering network in figure 4 c, first a measurement of the magnitude 
of the velocity of the moving objects is done by thus far hypothetically introduced 
movement processing algorithms, modelled here as a set of receptive elements 
sampling the environment in such a manner that proper estimation of local pattern 
velocities can be done. Then the time constants of the artificial receptive elements 
will be tuned according to the estimated velocities and finally the same 
differential network as in scheme 4 b, is used. 
The actual tuning mechanism used for our simulations is outlined in figure 
$: once given the range of velocities for which the model is supposed to be 
operational, and given a lower limit for the time constant min (min can be the 
smallest value which physically can be realized), the time constant will be tuned to 
a new value according to the experimentally observed reciprocal relationship, and 
will, for all velocities within the adaptive range, be larger than the fixed minimum 
value. As demonstrated in the previous section the corresponding blur in the 
representation of the moving stimulus will thus always be larger than for the 
situation in which the filtering is done with fixed and smallest time constants 
'min. More important however is the fact that due to this tuning mechanism the 
blur will be constant since the product of velocity and time constant is kept 
constant. So, once the information has been processed by such a system, a velocity 
independent representation of the image will be the result, which can serve as the 
input for the spatially differentiating network as outlined in figure 4 c. 
The most elementary form for this differential filtering procedure is the one 
668 
in which the gradient of two filters K-I and K+I which are the nearest neighbors 
of filter K, is taken and then added with a constant weighing factor to the central 
output K as drawn in figure 4 b and 4 c, where the sign of the gradient depends on 
the direction of the estimated movement. Essential for our model is that we claim 
that this weighing factor should be constant throughout the whole set of filters 
and for the whole high velocity range in which the heterodyne imaging has to be 
performed. Important to notice is the existence of a so-called settling time, i.e. the 
minimal time needed for our movement processing device to be able to accurately 
measure the object velocity. [Note: this time can be set equal to zero in the case 
that the relative stimulus velocity is known a priori, as demonstrated in figure 3]. 
Since, without doubt, within this settling period estimated velocity values will 
come out erroneously and thus no optimal performance of our imaging device can 
be expected, in all further examples, results after this initial settling procedure 
will be shown. 2 3  5 
Fig. 4 
B-' 
C.' 
r  ""-- 
Pattern movement in this figure s to the right. 
A: Network consisting of a set of filters with a fixed, pattern velocity 
independent, time constant in their impulse response. 
Identical network as in figure 4A now followed by a spatially 
differentiating circuitry which adds the weighed gradients of two 
neighboring filter outputs K-I and K+I to the central filter output 
K. 
The time constants of the filtering network are tuned by a 
hypothetical movement estimating mechanism, visualized here as a 
number of receptive elements, of which the combined output tunes 
the filters. A detailed description of this mechanism is shown in 
figure 5. This tuned network is followed by an identical spatially 
differentiating circuit as described in figure 4B. 
669 
Fig. 5 
increasing velocity 
decreasing time constant 
(�/sl 
Detailed description of the mechanism used to tune the time constants. 
The time constant  of a specific neural channel is set by the pattern 
velocity according to the relationship shown in the insert, which is 
derived from eq. (2) with cz=l and /=1. 
ta, J 
POSITION IN ARTIFICIAL RECEPTOR ARRAY 
Fig.6 
Thick lines: square-wave stimulus pattern with a spatial wavelength 
overlapping 32 artificial receptive elements. Thick lines: responses for 6 
different pattern velocities in a system consisting of paralleling neural 
filters equipped with time constants, tuned by this velocity, and followed 
by a spatially differentiating network as described. 
Dashed lines: responses to the 6 different pattern velocities in a filtering 
system with fixed time constants, followed by the same spatial 
differentiating circuitry as before. Note the sharp over- and under 
shoots for this case. 
670 
Results obtained with an imaging procedure as drawn in figure 4 b and 4 c 
are shown in figure 6. The pattern consists of a square wave, overlapping 32 
picture elements. The pattern moves (to the left) with 6 different velocities v, 2v, 
4v, 8v, 12v, 16v. At each velocity only one wavelength is shown. Thick lines: 
square wave pattern. Dashed lines: the outputs of an imaging device as depicted in 
figure 4b: constant time constants and a constant weighing factor in the spatial 
processing stage. Note the large differences between the several outputs. Thin 
continuous lines: the outputs of an imaging device as drawn in figure 4c: tuned 
time constants according to the reciprocal relationship between pattern velocity 
and time constant and a constant weighing factor in the spatial processing stage. 
For further simulation details the reader is referred to Zaagman et al. 21. Now the 
outputs are almost completely the same and in good agreement with the original 
stimulus throughout the whole velocity range. 
Figure 7 shows the effect of the gradient weighing factor on the overall 
filter performance, estimated as the improvement of the deblurred images as 
compared with the blurred image, measured in dB. This quantitative measure has 
been determined for the case of a moving square wave pattern with motion blur 
o 
Fig. 7 
-1 i i i 
0 1 2 3 + 
weighing factor = 
Effect of the weighing factor on the overall filter performance. Curve 
measured for the case of a moving square-wave grating. Filter 
performance is estimated as the improvement in signal to noise ratio: 
i=10. 101og ( 'i""J ((v(i'J)- u(i'J))  1 
.iZj((a(i,j)-u(i,j))' 
where u(i,j) is the original intensity at position (i,j) in the image, v(i,j) 
is the intensity at the same position (i,j) in the motion blurred image and 
a(i,j) is the intensity at (i,j) in the image, generated with the adaptive 
tuning procedure. 
671 
extents comparable to those used for the simulations to be discussed in section IV. 
From this curve it is apparent that for this situation there is an optimum value for 
this weighing factor. Keeping the weight close to this optimum value will result in 
a constant output of our adaptive scheme, thus enabling an optimal deblurring of 
the smeared image of the moving object. 
On the other hand, starting from the point of view that the time constants 
should remain fixed throughout the filtering process, we should had have to tune 
the gradient weights to the velocity in order to produce a constant output as 
demonstrated in figure 6 where the dashed lines show strongly differing outputs of 
a fixed time constant system with spatial processing with constant weight (figure 
4b). In other words, tuning of the time constants as proposed in this section results 
in: 1) the realization of the blur-constancy criterion as formulated previously, and 
2) -as a consequence- the possibility to deblur the obtained image optimally with 
one and the same weighing factor of the gradient in the final spatial processing 
layer over the whole heterodyne velocity range. 
COMPUTER SIMULATION RESULTS AND 
CONCLUSIONS 
The image quality improvement algorithm developed in the present 
contribution has been implemented on a general purpose DG Eclipse S/140 mini- 
computer for our two dimensional simulations. Figure 8 a shows an undisturbed 
image, consisting of 256 lines of each 256 pixels, with 8 bit intensity resolution. 
Figure 8 b shows what happens with the original image if the PSF is modelled 
according to the exponential decay (2). In this case the time constants of all 
spatial information processing channels have been kept fixed. Again, information 
content in the higher spatial frequencies has been reduced largely. The 
implementation of the heterodyne filtering procedure was now done as follows: 
first the adaptation range was defined by setting the range of velocities. This 
means that our adaptive heterodyne algorithm is supposed to operate adequately 
only within the thus defined velocity range and that -in that range- the time 
constants are tuned according to relationship (2) and will always come out larger 
than the minimum value rmi n. For demonstration purposes we set o=1 and B--1 in 
eq. (2), thus introducing the phenomenon that for any velocity, the two 
dimensional set of spatial filters with time constants tuned by that velocity, will 
always produce a constant output, independent of this velocity which introduces 
the motion blur. Figure 8 c shows this representation. It is important to note here 
that this constant output has far more worse quality than any set of filters with 
smallest and fixed time constants rmin would produce for velocities within the 
operational range. The advantage of a velocity independent output at this level in 
our simulation model, is that in the next stage a differential scheme can be 
implemented as discussed in detail in the preceding paragraph. Constancy of the 
weighing factor which is used in this differential processing scheme is guaranteed 
by the velocity independency of the obtained image representation. 
Figure 8 d shows the result of the differential operation with an optimized 
gradient weighing factor. This weighing factor has been optimized based on an 
almost identical performance curve as described previously in figure 7. A clear 
and good restoration is apparent from this figure, though close inspection reveals 
fine structure (especially for areas with high intensities) which is unrelated with 
the original intensity distribution. These artifacts are caused by the phenomenon 
that for these high intensity areas possible tuning errors will show up much more 
pronounced than for low intensities. 
672 
c 
Fig. 8a 
Fig. 8b 
Fig. 8c 
Fig. 8d 
Original 256x256x8 bit picture. 
Motion degraded image with a PSF derived from R(t)=c+a-e(-t/'), 
where ' is kept fixed to 12 pixels and the motion blur extent is 32 
pixels. 
Worst case, i.e. the result of motion degradation of the original image 
with a PSF as in figure 8 b, but with tuning of the time constants based 
on the velocity. 
Restored version of the degraded image using the heterodyne adaptive 
processing scheme. 
In conclusion: a heterodyne adaptive image processing technique, inspired by 
the fly visual system, has been presented as an imaging device for moving objects. 
A scalar difference equation model has been used to represent the motion blur 
degradation process. Based on the experimental results described and on this state 
space model, we developed an adaptive filtering scheme, which produces at a 
certain level within the system a constant output, permitting further differential 
operations in order to produce an optimally aleblurred representation of the 
moving object. 
ACKNOWLEDGEMENTS 
The authors wish to thank mr. Eric Bosman for his expert programming 
673 
assistance, mr. Franco Tommasi for many inspiring discussions and advises during 
the implementation of the simulation model and dr. Rob de Ruyter van Steveninck 
for experimental help. This research was partly supported by the Netherlands 
Organization for the Advancement of Pure Research (Z.W.O.) through the 
foundation Stichting voor Biofysica. 
REFERENCES 
1. K. Hausen, Z. Naturforschung 31c, 629-633 (1976). 
2. N.J. Strausf eld, Atlas of an insect brain (Springer Verlag, Berlin, Heidelberg, 
New York, 1976). 
3. K. Hausen, Biol. Cybern. 45, 143-156 (1982). 
4. R. Hengstenberg, J. Comp. Physiol. 149, 179-193 (1982). 
5. W. H. Zaagman, H. A. K. Mastebroek, J. W. Kuiper, Biol. Cybern. 31, 163-168 
(1978). 
6. H. A. K. Mastebroek, W. H. Zaagman, B. P.M. Lenting, Vision Res. 20, 467- 
474 (1980) 
7. R. R. de Ruyter van Steveninck, W. H. Zaagman, H. A. K. Mastebroek, Biol. 
Cybern., 54, 223-236 (1986). 
8. W. Reichardt, T. Poggio, Q. Rev. Biophys. 9, 311-377 (1976). 
9. W. Reichardt, in Reichardt, W. (Ed.) Processing of optical Data by Organisms 
and Machines (Academic Press, New York, 1969), pp. 465-493. 
10. T. Poggio, W. Reichardt, Q. Rev. Bioph. 9, 377-439 (1976). 
11. D. Marr, S. Ullman, Proc. R. Soc. Lond. 211, 151-180 (1981). 
12. J.P. van Santen, G. Sperling, J. Opt. Soc. Am. A 1, 451-473 (1984). 
13. J. L. Harris SR., J. Opt. $oc. Am. 56, 569-574 (1966). 
14. A. A. Sawchuk, Proc. IEEE, Vol. 60, No. 7, 854-861 (1972). 
15. M. M.Sondhi, Proc. IEEE, Vol. 60, No. 7, 842-853 (1972). 
16. N. E. Nahi, Proc. IEEE, Vol. 60, No. 7, 872-877 (1972). 
17. A. O. Aboutalib, L. M. Silverman, IEEE Trans. On Circuits And Systems T- 
CAS 75, 278-286 (1975). 
18. A. O. Aboutalib, M. S. Murphy, L.M. Silverman, IEEE Trans. Automat. Contr. 
AC 22, 294-302 (1977). 
19. Th. Hildebrand, Biol. Cybern. 36, 229-234 (1980). 
20. S. A. Rajala, R. J.P. de Figueiredo, IEEE Trans. On Acoustics, Speech and 
Signal Processing, Vol. ASSSP-29, No. 5, 1033-1042 (1981). 
21. W. H. Zaagman, H. A. K. Mastebroek, R. R. de Ruyter van Steveninck, IEEE 
Trans, Syst. Man Cybern. SMC 13, 900-906 (1983). 
", adapt heterodyn filter procedur imag move object mastebroek zaagman laboratori gener physic cm netherland experiment work stimulu veloc depend time resolv neural situat highest order optic ganglion reveal first sight amaz phenomenon high level fli visual time constant unit involv neural activ evok move proport veloc object extrem wide paper discuss implement two dimension heterodyn filter construct comput simul featur model includ abil account experiment observ adapt tempor behaviour time constant fli visual simul result clearli show applic adapt process procedur deliv improv imag techniqu pattern high veloc remark fli visual system visual system includ blowfli calliphora regularli organ allow therefor precis stimul long term electrophysiolog record made rel easi visual reason blowfli rapid turn extrem anim systemat studi basic principl may underli process movement inform neural fli visual system input retin mosaic structur precis onto higher order optic ganglia mean neural column ganglion visual system correspond optic axi visual field compound lobula complex set movement sensit neuron integr input signal whole visual field entir one wide classifi hausen extens anatom well electrophysiolog result gener agre well found behavior experi movement detect understood term correl model neuron sensit horizont movement direct high rate action potenti per second element case visual stimuli move horizont back front visual field wherea horizont front back suppress institut physic result model base neuron stimul prefer direct step wise respond increas neural stimulu step one obtain averag ms latenc period respons manifest sharp increas fire rate follow much slower decay spontan activ two exampl averag respons shown post stimulu histogram figur time peak peak height relat depend modul stimulu step size spatial extent tail respons describ adequ exponenti toward constant spontan fire set stimulu respons equat estim fit tail smooth line figur result two irnsl respons obtain smooth stimulu motion veloc smooth line repres form valu ms respect ruyter van steveninck et valu function adapt veloc three depth straight line fit repres data region form ms ruyter van steveninck et show fit valu respons time constant function angular veloc move stimulu squar wave grate present anim period long enough let visual system adapt move pattern step wise pattern reveal straight describ repres fit data rang vari roughli ms defin adapt rang interv veloc decreas increas may figur within adapt sensit modul outcom similar experi constant modul depth constant pattern veloc four differ valu contrast frequenc fc number spatial period per second individu visual axi determin spatial wavelength ns pattern veloc accord reveal also almost independ behaviour contrast stimulu field subdivid region differ made clear time constant input channel neuron set local valu stimulu veloc found adapt driven stimulu independ find summar qualit steadi respons time constant neural unit highest level fli system found tune local within larg veloc rang magnitud veloc move pattern despit direct select neuron go question amaz adapt mechan may fli visual instead make advantag result deriv thu attempt fit experiment observ imag process larg number theori sever distinct class algorithm veloc direct movement visual system suggest marr ullman van santen sperl hypothes adapt mechan set time lead optim overal perform visual system realiz veloc independ represent move within rang veloc time constant found represent stimulu certain level within visual remain independ variat stimulu motion model physic descript motion linear space invari motion degrad process repres follow convolut oo oo dudv object intens posit object coordin point spread function imag respons unit puls imag spatial posit blur imag addit white nois degrad alreadi motion blur imag present review principl techniqu field digit imag reader refer harri sawchuk nahi aboutalib rajala de figueiredo demonstr first aboutalib et situat motion blur occur straight line along one spatial say along correct look blur imag collect line scan entir depend vertic may drop reduc mathemat descript rel psf deriv exactli equat extent motion discret version digit imag process describ take integ valu relat motion blur aboutalib et scalar differ equat model deriv model motion degrad state vector posit along scan input intens posit output blur number element constant order contain discret cj blur psf kroneck delta time constant veloc amount motion blur artifici array start incorpor simul model deriv model perform neural columnar arrang filter lobula restrict time constant remain fix whole rang stimulu realiz psf achiev via mention state space receptor array demonstr effect increas magnitud time constant array filter result motion blur pattern veloc remain pattern shown solid line grate wavelength equal artifici receptor three wave form show gradual increas increas time represent origin consequ lower gradual increas move filter time constant result also clear increas demonstr effect increas time constant veloc remain result increas therefor one dimension array filter equip constant impuls origin pattern shown squar line upper part figur consist squar wave grate period overlap artifici recept pattern drawn show constant veloc move increas magnitud time constant filter result increas blur represent increas veloc time constant artifici recept unit remain also clear increas motion demonstr lower part two wave form drawn mean dash line upper lower half yield error introduc rather small number artifici filter equal amount smear produc product time pattern veloc upper dash wave form four time smaller time constant four time larger lower part scheme design proper imag process procedur next step experiment observ flexibl properti time constant imag element figur scheme inform fix time influenc pattern figur network shown time constant also remain matter pattern movement next level spatial differenti network incorpor order blur filter network figur first measur magnitud veloc move object done thu far hypothet introduc process model set recept element environ manner proper estim local pattern time constant artifici recept element tune accord estim veloc final network scheme actual tune mechan use simul outlin figur given rang veloc model suppos given lower limit time constant valu physic time constant tune new valu accord experiment observ reciproc veloc within adapt larger fix minimum demonstr previou section correspond blur move stimulu thu alway larger filter done fix smallest time constant import howev fact due tune mechan constant sinc product veloc time constant kept inform process veloc represent imag serv spatial differenti network outlin figur elementari form differenti filter procedur one gradient two filter nearest neighbor filter taken ad constant weigh factor central drawn figur sign gradient depend direct estim essenti model claim weigh factor constant throughout whole set filter whole high veloc rang heterodyn imag import notic exist settl time need movement process devic abl accur object time set equal zero case rel stimulu veloc known demonstr figur without within settl period estim veloc valu erron thu optim perform imag devic result initi settl procedur movement figur network consist set filter pattern veloc time constant impuls network figur follow spatial circuitri add weigh gradient two filter output central filter output time constant filter network tune movement estim visual recept combin output tune detail descript mechan shown tune network follow ident spatial circuit describ figur veloc time constant descript mechan use tune time time constant specif neural channel set pattern accord relationship shown artifici receptor array stimulu pattern spatial wavelength artifici recept thick respons pattern veloc system consist parallel neural equip time tune follow spatial differenti network respons differ pattern veloc filter fix time follow spatial circuitri note sharp obtain imag procedur drawn figur shown figur pattern consist squar overlap pattern move differ veloc veloc one wavelength thick wave dash output imag devic depict constant time constant constant weigh factor spatial note larg differ sever thin output imag devic drawn figur tune constant accord reciproc relationship pattern veloc time constant constant weigh factor spatial process simul detail reader refer zaagman et almost complet good agreement origin throughout whole veloc show effect gradient weigh factor overal estim improv deblur imag blur measur quantit measur determin case move squar wave pattern motion blur factor weigh factor overal filter curv case move filter estim improv signal nois origin intens posit intens posit motion blur imag intens gener adapt compar use simul discuss section curv appar situat optimum valu weigh keep weight close optimum valu result constant output adapt thu enabl optim deblur smear imag move start point view time constant remain fix throughout filter tune gradient weight veloc order produc constant output figur dash line show strongli differ output fix time constant system spatial process constant weight tune time constant propos section result realiz criterion formul possibl deblur obtain imag optim weigh factor gradient final spatial process whole heterodyn veloc simul result imag qualiti improv algorithm develop present implement gener purpos dg eclips two dimension figur show undisturb consist line bit intens show happen origin imag psf model exponenti decay case time constant inform process channel kept inform higher spatial frequenc reduc heterodyn filter procedur done adapt rang defin set rang adapt heterodyn algorithm suppos oper adequ within thu defin veloc rang time tune accord relationship alway come larger minimum valu rmi demonstr purpos set thu introduc phenomenon two set spatial filter time constant tune produc constant independ veloc introduc motion figur show import note constant output far wors qualiti set filter fix time constant rmin would produc veloc within advantag veloc independ output level simul next stage differenti scheme discuss detail preced constanc factor use differenti process scheme guarante veloc independ obtain imag show result differenti oper optim weigh weigh factor optim base ident perform curv describ previous figur clear good restor appar though close inspect reveal structur area high unrel origin intens artifact caus phenomenon high intens area possibl tune error show much low bit degrad imag psf deriv kept fix pixel motion blur extent result motion degrad origin imag psf figur tune time constant base version degrad imag use heterodyn adapt heterodyn adapt imag process inspir fli visual present imag devic move scalar differ equat model use repres motion blur base experiment result describ state develop adapt filter produc level within system constant permit differenti order produc optim aleblur represent author wish thank eric bosman expert program franco tommasi mani inspir discuss advis implement simul model rob de ruyter van steveninck experiment research partli support netherland advanc pure research sticht voor naturforschung strausf atla insect brain vision de ruyter van process optic data organ machin new van harri ie circuit system ie de ie speech de ruyter van ie man smc,0
70,70,"674 
PATYEP CLASS DEGENERACY IN AN UNRESTRICTED STORAGE 
DENSITY MEMORY 
Christopher L. Scofield, Douglas L. Reilly, 
Charles Elbaum, Leon N. Cooper 
Nestor, Inc., 1 Richmond Square, Providence, Rhode Island, 
02906. 
ABSTRACT 
The study of distributed memory systems has produced a 
number of models which work well in limited domains. 
However, until recently, the application of such systems to real- 
world problems has been difficult because of storage limitations, 
and their inherent architectural (and for serial simulation, 
computational) complexity. Recent development of memories 
with unrestricted storage capacity and economical feedforward 
architectures has opened the way to the application of such 
systems to complex pattern recognition problems. However, 
such problems are sometimes underspecified by the features 
which describe the environment, and thus a significant portion 
of the pattern environment is often non-separable. We will 
review current work on high density memory systems and their 
network implementations. We will discuss a general learning 
algorithm for such high density memories and review its 
application to separable point sets. Finally, we will introduce an 
extension of this method for learning the probability 
distributions of non-separable point sets. 
INTRODUCTION 
Information storage in distributed content addressable 
memories has long been the topic of intense study. Early 
research focused on the development of correlation matrix 
memories 1, 2, 3, 4 Workers in the field found that memories of 
this sort allowed storage of a number of distinct memories no 
larger than the number of dimensions of the input space. 
Further storage beyond this number caused the system to give 
an incorrect output for a memorized input. 
@ American Institute of Physics 1988 
675 
Recent work on distributed memory systems has focused on 
single layer, recurrent networks. Hopfield 5, 6introduced a 
method for the analysis of settling of activity in recurrent 
networks. This method defined the network as a dynamical 
system for which a global function called the 'energy' (actually a 
Liapunov function for the autonomous system describing the 
state of the network) could be defined. Hopfield showed that 
flow in state space is always toward the fixed points of the 
dynamical system if the matrix of recurrent connections satisfies 
certain conditions. With this property, Hopfield was able to 
define the fixed points as the sites of memories of network 
activity. 
Like its forerunners, the Hopfield network is limited in 
storage capacity. Empirical study of the system found that for 
randomly chosen memories, storage capacity was limited to m _< 
0.15N, where m is the number of memories that could be 
accurately recalled, and N is the dimensionality of the network 
(this has since been improved to m _< N, 7, 8). The degradation of 
memory recall with increased storage density is directly related 
to the proliferation in the state space of unwanted local minima 
which serve as basins of flow. 
UNRESTRICTED STORAGE DENSITY MEMORIES 
Bachman et al. 9 have studied another relaxation system 
similar in some respects to the Hopfield network. However, in 
contrast to Hopfield, they have focused on defining a dynamical 
system in which the locations of the minima are explicitly 
known. 
In particular, they have chosen a system with a Liapunov 
function given by 
E =-I/LZ Qj I[t- xjl- L, (1) 
J 
where E is the total 'energy' of the network, It(0) is a vector 
describing the initial network activity caused by a test pattern, 
and xj, the site of the jth memory, for m memories in R N. L is a 
parameter related to the network size. Then g(0) relaxes to g(T) 
= xj for some memory j according to 
676 
J 
(2) 
This system is isomorphic to the classical electrostatic potential 
between a positive (unit) test charge, and negative charges Qj at 
the sites xj (for a 3-dimensional input space, and L = 1). The N- 
dimensional Coulomb energy function then defines exactly m 
basins of attraction to the fixed points located at the charge sites 
xj. It can been shown that convergence to the closest distinct 
memory is guaranteed, independent of the number of stored 
memories m, for proper choice of N and L 9, 10 
Equation 1 shows that each cell receives feedback from the 
network in the form of a scalar 
]Qj I -xj I 'L (3) 
J 
Importantly, this quantity is the same for all cells; it is as if a 
single virtual cell was computing the distance in activity space 
between the current state and stored states. The result of the 
computation is then broadcast to all of the cells in the network. 
A 2-layer feedforward network implementing such a system has 
been described elsewhere10. 
The connectivity for this architecture is of order m.N, where 
m is the number of stored memories and N is the dimensionality 
of layer 1. This is significant since the addition of a new 
memory m' = m + 1 will change the connectivity by the addition 
of N + 1 connections, whereas in the Hopfield network, addition 
of a new memory requires the addition of 2N + 1 connections. 
An equilibrium feedforward network with similar properties 
has been under investigation for some time 11. This model does 
not employ a relaxation procedure, and thus was not originally 
framed in the language of Liapunov functions. However, it is 
possible to define a similar system if we identify the locations of 
the 'prot6types' of this model as. the locations in state space of 
potentials which satisfy the following conditions 
Ej = -Qj/R o for I t- xj I <)j 
(4) 
:0 for I - xj I >)j. 
677 
where R o is a constant. 
This form of potential is often referred to as the 'square-well' 
potential. This potential may be viewed as a limit of the N- 
dimensional Coulomb potential, in which the 1/R (L =1) well is 
replaced with a square well (for which L >> 1). Equation 4 
describes an energy landscape which consists of plateaus of zero 
potential outside of wells with flat, zero slope basins. Since the 
landscape has only flat regions separated by discontinuous 
boundaries, the state of the network is always at equilibrium, 
and relaxation does not occur. For this reason, this system has 
been called an equilibrium model. This model, also referred to 
as the Restricted Coulomb Energy (RCE) TM model, shares the 
property of unrestricted storage density. 
LEARNING IN HIGH DENSITY MEMORIES 
A simple learning algorithm for the placement of the wells has 
been described in detail elsewhere 11, 12. 
x  
Figure l' 3-layer feedforward network. Cell i 
computes the quantity lit- xil and compares 
to internal threshold )i. 
678 
Reilly et. al. have employed a three layer feedforward 
network (figure 1) which allows the generalization of a content 
addressable memory to a pattern classification memory. 
Because the locations of the minima are explicitly known in the 
equilibrium model, it is possible to dynamically program the 
energy function for an arbitrary energy landscape. This allows 
the construction of geographies of basins associated with the 
classes constituting the pattern environment. Rapid learning of 
complex, non-linear, disjoint, class regions is possible by this 
method 12, 13. 
LEARNING NON-SEPARABLE CLASS REGIONS 
Previous studies have focused on the acquisition of the 
geography and boundaries of non-linearly separable point sets. 
However, a method by which such high density models can 
acquire the probability distributions of non-separable sets has 
not been described. 
Non-separable sets are defined as point sets in the state 
space of a system which are labelled with multiple class 
affiliations. This can occur because the input space has not 
carried all of the features in the pattern environment, or because 
the pattern set itself is not separable. Points may be degenerate 
with respect to the explicit features of the space, however they 
may have different probability distributions within the 
environment. This structure in the environment is important 
information for the identification of patterns by such memories 
in the presence of feature space degeneracies. 
We now describe one possible mechanism for the acquisition 
of the probability distribution of non-separable points. It is 
assumed that all points in some region R of the state space of the 
network are the site of events g(0, Ci) which are examples of 
pattern classes C = {C1,..., CM}. A basin of attraction, Xk(Ci) , 
defined by equation 4, is placed at each site g(0, Ci) unless 
I g(0, Ci)- xj(Ci) I < Ro, 
(5) 
that is, unless a memory at xj (of the class Ci) already contains 
g(0, Ci). The initial values of Qo and R o at Xk(Ci) are a constant for 
all sites xj. Thus as events of the classes C1,...,CM occur at a 
particular site in R, multiple wells are placed at this location. 
679 
If a well xj(Ci)correctly covers an event g(0, Ci) , then the 
charge at that site (which defines the depth of the well) is 
incremented by a constant amount A Qo. In this manner, the 
region R is covered with wells of all classes {C,..., CM}, with the 
depth of well xj(Ci) proportional to the frequency of occurence of 
Ci at xj. 
The architecture of this network is exactly the same as that 
already described. As before, this network acquires a new cell 
for each well placed in the energy landscape. Thus we are able 
to describe the meaning of wells that overlap as the competition 
by multiple cells in layer 2 in firing for the pattern of activity in 
the input layer. 
APPLICATIONS 
This system has been applied to a problem in the area of risk 
assessment in mortgage lending. The input space consisted of 
feature detectors with continuous firing rates proportional to the 
values of 23 variables in the application for a mortgage. For this 
set of features, a significant portion of the space was non- 
separable. 
Figures 2a and 2b illustrate the probability distributions of 
high and low risk applications for two of the features. It is clear 
that in this 2-dimensional subspace, the regions of high and low 
risk are non-separable but have different distributions. 
0.0 Feature 1 1.0 
Prob. = 1.0, 
1000 Patterns 
Prob. = 0.5 
Figure 2a: Probability distribution for High 
and Low risk patterns for feature 1. 
680 
z 
0.0 Feature 2 1.0 
Prob. = 1.0, 
1000 Patterns 
Prob. = 0.5 
Figure 2b' Probability distribution for High 
and Low risk patterns for feature 2. 
Figure 3 depicts the probability distributions acquired by 
the system for this 2-dimensional subspace. In this image, 
circle radius is proportional to the degree of risk: Small circles 
are regions of low risk, and large circles are regions of high 
risk. 
0o�� -ooo oO 
o o 0 
o 
oo o 0 
( � oo � 0 
o o 0 
0 � o Oo o 
0 o 
0o��:��% 
0 o 0  
o Oo 0 
0  0 
 0  o 
0 0 o 
Feature I 
Figure 3: Probability distribition for Low and 
High risk. Small circles indicate low risk 
regions and large circles indicate high risk 
regions. 
681 
Of particular interest is the clear clustering of high and low risk 
regions in the 2-d map. Note that the regions are in fact non- 
linearly separable. 
DISCUSSION 
We have presented a simple method for the acquisition of 
probability distributions in non-separable point sets. This 
method generates an energy landscape of potential wells with 
depths that are proportional to the local probability density of 
the classes of patterns in the environment. These well depths 
set the probability of firing of class cells in a 3-layer 
feedforward network. 
Application of this method to a problem in risk assessment 
has shown that even completely non-separable subspaces may 
be modeled with surprising accuracy. This method improves 
pattern classification in such problems with little additional 
computational burden. 
This algorithm has been run in conjunction with the method 
described by Reilly et. al. ll for separable regions. This combined 
system is able to generate non-linear decision surfaces between 
the separable zones, and approximate the probability 
distributions of the non-separable zones in a seemless manner. 
Further discussion of this system will appear in future reports. 
Current work is focused on the development of a more 
general method for modelling the scale of variations in the 
distributions. Sensitivity to this scale suggests that the 
transition from separable to non-separable regions is smooth 
and should not be handled with a 'hard' threshold. 
ACKNOWI .EDGEMENTS 
We would like to thank Ed Collins and Sushmito Ghosh for their 
significant contributions to this work through the development 
of the mortgage risk assessment application. 
REFERENCES 
[1] Anderson, J.A.: A simple neural network generating an 
interactive memory. Math. Biosci. 14, 197-220 (1972). 
682 
[2] Cooper, L.N.: A possible organization of animal memory and 
learning. In: Proceedings of the Nobel Symposium on Collective 
Properties of Physical Systems, Lundquist, B., Lundquist, S. 
(eds.). (24), 252-264 London, New York: Academic Press 1973. 
[3] Kohonen, T.: Correlation matrix memories. IEEE Trans. 
Comput. 21, 353-359 (1972). 
[4] Kohonen, T.: Associative memory - a system-theoretical 
approach. Berlin, Heidelberg, New York: Springer 1977. 
[5] Hopfield, J.J.: Neural networks and physical systems with 
emergent collective computational abilities. Proc. Natl. Acad. Sci. 
USA 79, 2554-2558 (April 1982). 
[6] Hopfield, J.J.: Neurons with graded response have collective 
computational properties like those of two-state neurons. Proc. 
Natl. Acad. Sci. USA $1, 2088-3092 (May, 1984). 
[7] Hopfield, J.J., Feinstein, D.I., Palmer, R.G.: 'Unlearning' has a 
stabilizing effect in collective memories. Nature 304, 158-159 
(July 1983). 
[8] Potter, T.W.: Ph.D. Dissertation in advanced technology, 
S.U.N.Y. Binghampton, (unpublished). 
[9] Bachmann, C.M., Cooper, L.N., Dembo, A., Zeitouni, O.: A 
relaxation model for memory with high density storage. to be 
published in Proc. Natl. Acad. Sci. USA. 
[10] Dembo, A., Zeitouni, O.: ARO Technical Report, Brown 
University, Center for Neural Science, Providence, R.I., (1987), 
also submitted to Phys. Rev. A. 
[11] Reilly, D.L., Cooper, L.N., Elbaum, C.: A neural model for 
category learning. Biol. Cybern. 45, 35-41 (1982). 
[12] Reilly, D.L., Scofield, C., Elbaum, C., Cooper, L.N.: Learning 
system architectures composed of multiple learning modules. to 
appear in Proc. First Int'l. Conf. on Neural Networks (1987). 
[13] Rimey, R., Gouin, P., Scofield, C., Reilly, D.L.: Real-time 3-D 
object classification using a learning system. Intelligent Robots 
and Computer Vision, Proc. SPIE 726 (1986). 
[14] Reilly, D.L., Scofield, C. L., Elbaum, C., Cooper, L.N: Neural 
Networks with low connectivity and unrestricted memory 
storage density. To be published. 
", class degeneraci unrestrict storag memori dougla leon cooper richmond rhode studi distribut memori system produc model work well limit applic system problem difficult storag inher architectur serial recent develop memori unrestrict storag capac econom feedforward open way applic complex pattern recognit problem sometim underspecifi featur describ thu signific portion pattern environ often current work high densiti memori system discuss gener learn high densiti memori review separ point introduc method learn probabl point storag distribut content address long topic intens earli focus develop correl matrix worker field found memori sort allow storag number distinct memori number dimens input storag beyond number caus system give incorrect output memor american institut physic work distribut memori system focus recurr hopfield analysi settl activ recurr method defin network dynam global function call function autonom system describ could hopfield show state space alway toward fix point system matrix recurr connect satisfi hopfield abl fix point site memori network hopfield network limit empir studi system found chosen storag capac limit number memori could dimension network sinc improv degrad recal increas storag densiti directli relat prolifer state space unwant local minima serv basin storag densiti memori et studi anoth relax system respect hopfield focus defin dynam locat minima explicitli chosen system liapunov given qj total vector initi network activ caus test site jth memori relat network relax xj memori accord system isomorph classic electrostat potenti posit test neg charg qj site xj input coulomb energi function defin exactli attract fix point locat charg site shown converg closest distinct independ number store proper choic show cell receiv feedback form scalar quantiti virtual cell comput distanc activ space current state store result broadcast cell feedforward network implement system describ connect architectur order number store memori dimension layer signific sinc addit new chang connect addit wherea hopfield addit new memori requir addit equilibrium feedforward network similar properti investig time model employ relax thu origin languag liapunov defin similar system identifi locat model locat state space satisfi follow condit xj xj form potenti often refer potenti may view limit coulomb well squar well equat energi landscap consist plateau zero outsid well zero slope sinc flat region separ discontinu state network alway relax system call equilibrium also refer restrict coulomb energi tm share unrestrict storag high densiti memori simpl learn algorithm placement well describ detail elsewher feedforward cell quantiti xil compar intern threshold employ three layer feedforward allow gener content memori pattern classif locat minima explicitli known possibl dynam program function arbitrari energi allow construct geographi basin associ constitut pattern rapid learn class region possibl class region studi focus acquisit boundari separ point method high densiti model probabl distribut set set defin point set state system label multipl class occur input space featur pattern pattern set point may degener respect explicit featur howev differ probabl distribut within structur environ import identif pattern memori presenc featur space describ one possibl mechan acquisit probabl distribut point region state space site event exampl class basin equat place site unless unless memori xj class alreadi contain initi valu qo constant site thu event class occur site multipl well place well cover event site defin depth constant amount cover well class well proport frequenc occur architectur network exactli network acquir new cell well place energi thu abl describ mean well overlap competit multipl cell layer fire pattern activ input system appli problem area risk mortgag input space consist detector continu fire rate proport variabl applic signific portion space illustr probabl distribut low risk applic two clear region high low differ featur pattern probabl distribut high low risk pattern featur featur pattern probabl distribut high low risk pattern featur depict probabl distribut acquir system radiu proport degre small circl region low larg circl region high oo oo oo probabl distribit low small circl indic low risk larg circl indic high risk particular interest clear cluster high low risk note region fact present simpl method acquisit distribut point gener energi landscap potenti well proport local probabl densiti class pattern well depth probabl fire class cell method problem risk assess shown even complet subspac may model surpris method improv classif problem littl addit algorithm run conjunct method reilli separ combin abl gener decis surfac separ approxim probabl zone seemless discuss system appear futur work focus develop method model scale variat sensit scale suggest separ region smooth handl would like thank ed collin sushmito ghosh contribut work develop mortgag risk assess simpl neural network gener possibl organ anim memori proceed nobel symposium collect physic new academ press correl matrix ie associ memori new springer neural network physic system collect comput neuron grade respons collect properti like usa effect collect natur dissert advanc model memori high densiti aro technic brown center neural submit neural model learn architectur compos multipl learn first neural network classif use learn intellig robot comput spie neural low connect unrestrict memori,0
71,71,"683 
A MEAN FIELD THEORY OF LAYER IV OF VISUAL CORTEX 
AND ITS APPLICATION TO ARTIFICIAL NEURAL NETWORKS* 
Christopher L. Scofield 
Center for Neural Science and Physics Department 
Brown University 
Providence, Rhode Island 02912 
and 
Nestor, Inc., 1 Richmond Square, Providence, Rhode Island, 
02906. 
ABSTRACT 
A single cell theory for the development of selectivity and 
ocular dominance in visual cortex has been presented previously 
by Bienenstock, Cooper and Munro 1. This has been extended to a 
network applicable to layer IV of visual cortex2. In this paper 
we present a mean field approximation that captures in a fairly 
transparent manner the qualitative, and many of the 
quantitative, results of the network theory. Finally, we consider 
the application of this theory to artificial neural networks and 
show that a significant reduction in architectural complexity is 
possible. 
A SINGLE LAYER NETWORK AND THE MEAN FIELD 
APPROXIMATION 
We consider a single layer network of ideal neurons which 
receive signals from outside of the layer and from cells within 
the layer (Figure 1). The activity of the ith cell in the network is 
ci =mi d+ ELij cj. (1) 
J 
d is a vector of afferent signals to the network. Each cell 
receives input from n fibers outside of the cortical network 
through the matrix of synapses mi. Intra-layer input to each cell 
is then transmitted through the matrix of cortico-cortical 
synapses L. 
American Institute of Physics 1988 
684 
Afferent 
Signals 
d 
m 1 
Figure 1: The general single layer recurrent 
network. Light circles are the LGN-cortica! 
synapses. Dark circles are the (non- 
modifiable) cortico-cortical synapses. 
We now expand the response of the ith cell into individual 
terms describing the number of cortical synapses traversed by 
the signal d before arriving through synapses Lij at cell i. 
Expanding cj in (1), the response of cell i becomes 
c i = m i d + Z Lij mjd + Z Lij Ljk mk d + Z Lij [Ljk  Lkn mn d +... (2) 
J j j n 
Note that each term contains a factor of the form 
 Lqp mpd. 
P 
This factor describes the first order effect, on cell q, of the 
cortical transformation of the signal d. The mean field 
approximation consists of estimating this factor to be a constant, 
independant of cell location 
 Lqp mpd = N fnd L o = constant. 
p 
(3) 
685 
This assumption does not imply that each cell in the network is 
selective to the same pattern, (and thus that m i = mj ). Rather, 
the assumption is that the vector sum is a constant 
(  Lqp mp) d = (N fn L o) d. 
P 
This amounts to assuming that each cell in the network is 
surrounded by a population of cells which represent, on average, 
all possible pattern preferences. Thus the vector sum of the 
afferent synaptic states describing these pattern preferences is a 
constant independent of location. 
Finally, if we assume that the lateral connection strengths are 
a function only of i-j then Lij becomes a circular matrix so that 
 Lij =  Lji = L o = constant. 
 j 
Then the response of the cell i becomes 
ci=mi d +(Io+Io2+...)fnd. 
(4) 
-- mid + (N L o/(1- L o )) , 
for l Iol < 1 
where we define the spatial average of cortical cell activity  = fn 
d, and N is the average number of intracortical synapses. 
Here, in a manner similar to that in the theory of magnetism, 
we have replaced the effect of individual cortical cells by their 
average effect (as though all other cortical cells can be replaced 
by an 'effective' cell, figure 2). Note that we have retained all 
orders of synaptic traversal of the signal d. 
Thus, we now focus on the activity of the layer after 
'relaxation' to equilibrium. In the mean field approximation we 
can therefore write 
where the mean field 
with 
= (mi- Ix) d (5) 
/x =arh 
a = N ILol (1 + ILol)-l, 
686 
and we asume that 
inhibitory). 
L o < 0 (the network is, on average, 
Afferent 
Signals 
d 
m 1 m n 
L o 
1 L o 
T 
_. 
.' � 
Figure 2: The single layer mean field network. 
Detailed connectivity between all cells of the 
network is replaced with a single (non- 
modifiable) synapse from an 'effective' cell. 
LEARNING IN THE CORTICAL NETWORK 
We will first consider evolution of the network according to a 
synaptic modification rule that has been studied in detail, for 
single cells, elsewhere 1, 3 We consider the LGN - cortical 
synapses to be the site of plasticity and assume for maximum 
simplicity that there is no modification of cortico-cortical 
synapses. Then 
rhi = qb(ci, i) d 
(6) 
gij =0. 
In what follows  denotes the spatial average over cortical cells, 
while c=i denotes the time averaged activity of the i th cortical cell. 
The function  has been discussed extensively elsewhere. Here 
we note that  describes a function of the cell response that has 
both hebbian and anti-hebbian regions. 
687 
This leads to a very complex set of non-linear stochastic 
equations that have been analyzed partially elsewhere 2. In 
general, the afferent synaptic state has fixed points that are 
stable and selective and unstable fixed points that are non- 
selective 1, 2 These arguments may now be generalized for the 
network. In the mean field approximation 
rhi(tx) = qf(ci((x ), ((x)) d = qf[mi(tx) - ix] d 
(7) 
The mean field, tz has a time dependent component fla. This 
varies as the average over all of the network modifiable 
synapses and, in most environmental situations, should change 
slowly compared to the change of the modifiable synapses to a 
single cell. Then in this approximation we can write 
� 
(mi(tx)-tx) = q[mi(tx) - ix] d. 
(8) 
We see that there is a mapping 
mi' < > mi(tx) - (x (9) 
such that for every mi(tz)there exists a corresponding (mapped) 
point mi' which satisfies 
rhi' = �[mi'] d, 
the original equation for the mean field zero theory. It can be 
shown 2, 4 that for every fixed point of mi(tz = 0), there exists a 
corresponding fixed point mi(tz) with the same selectivity and 
stability properties. The fixed points are available to the 
neurons if there is sufficient inhibition in the network (ILol is 
sufficiently large). 
APPLICATION OF THE MEAN FIELD NETWORK TO 
LAYER IV OF VISUAL CORTEX 
Neurons in the primary visual cortex of normal adult cats are 
sharply tuned for the orientation of an elongated slit of light and 
most are activated by stimulation of either eye. Both of these 
properties--orientation selectivity and binocularity--depend on 
the type of visual environment experienced during a critical 
688 
period of early postnatal development. For example, deprivation 
of patterned input during this critical period leads to loss of 
orientation selectivity while monocular deprivation (MD) results 
in a dramatic shift in the ocular dominance of cortical neurons 
such that most will be responsive exclusively to the open eye. 
The ocular dominance shift after MD is the best known and most 
intensively studied type of visual cortical plasticity. 
The behavior of visual cortical cells in various rearing 
conditions suggests that some cells respond more rapidly to 
environmental changes than others. In monocular deprivation, 
for example, some cells remain responsive to the closed eye in 
spite of the very large shift of most cells to the open eye- Singer 
et. al. 5 found, using intracellular recording, that geniculo-cortical 
synapses on inhibitory interneurons are more resistant to 
monocular deprivation than are synapses on pyramidal cell 
dendrites. Recent work suggests that the density of inhibitory 
GABAergic synapses in kitten striate cortex is also unaffected by 
MD during the cortical period 6, 7 
These results suggest that some LGN-cortical synapses modify 
rapidly, while others modify relatively slowly, with slow 
modification of some cortico-cortical synapses. Excitatory LGN- 
cortical synapses into excitatory cells may be those that modify 
primarily. To embody these facts we introduce two types of 
LGN-cortical synapses: those (mi) that modify and those (Zk) 
that remain relatively constant. In a simple limit we have 
rfii = b(ci,) d 
and (10) 
Zk= O. 
We assume for simplicity and consistent with the above 
physiological interpretation that these two types of synapses are 
confined to two different classes of cells and that both left and 
right eye have similar synapses (both m i or both zk)on a given 
cell. Then, for binocular cells, in the mean field approximation 
(where binocular terms are in italics) 
ci(oc) = (mi- oc )d = (mli - (zl).d 1 + (m[- otr).d r 
Ck(OC) = (Zk- OC )d = (z[- od).d 1 + (z[- otr).d r, 
689 
where dl(r) are the explicit left (right) eye time averaged signals 
arriving form the LGN. Note that tzl(r) contain terms from 
modifiable and non-modifiable synapses: 
(xl(r) = a (lrnl(r) + }:l(r)). 
Under conditions of monocular deprivation, the animal is reared 
with one eye closed. For the sake of analysis assume that the 
right eye is closed and that only noise-like signals arrive at 
cortex from the right eye. Then the environment of the cortical 
cells is: 
d = (dJ, n) (12) 
Further, assume that the left eye synapses have reached their 
selective fixed point, selective to pattern d 1. Then (m I, m[)= 
(ml*, xi) with Ixil << Im}*l. Following the methods of BCM, a local 
linear analysis of the (- function is employed to show that for 
the closed eye 
xi = a (1 - )a)-lk r. 
(13) 
where , = Nm/N is the ratio of the number modifiable cells to the 
total number of cells in the network. That is, the asymptotic 
state of the closed eye synapses is a scaled function of the mean- 
field due to non-modifiable (inhibitory) cortical cells. The scale 
of this state is set not only by the proportion of non-modifiable 
cells, but in addition, by the averaged intracortical synaptic 
strength L o. 
Thus contrasted with the mean field zero theory the deprived 
eye LGN-cortical synapses do not go to zero. Rather they 
approach the constant value dependent on the average inhibition 
produced by the non-modifiable cells in such a way that the 
asymptotic output of the cortical cell is zero (it cannot be driven 
by the deprived eye). However lessening the effect of inhibitory 
synapses (e.g. by application of an inhibitory blocking agent such 
as bicuculine) reduces the magnitude of a so that one could once 
more obtain a response from the deprived eye. 
690 
We find, consistent with previous theory and experiment, 
that most learning can occur in the LGN-cortical synapse, for 
inhibitory (cortico-cortical) synapses need not modify. Some 
non-modifiable LGN-cortical synapses are required. 
THE MEAN FIELD APPROXIMATION AND 
ARTIFICIAL NEURAL NETWORKS 
The mean field approximation may be applied to networks in 
which the cortico-cortical feedback is a general function of cell 
activity. In particular, the feedback may measure the difference 
between the network activity and memories of network activity. 
In this way, a network may be used as a content addressable 
memory. We have been discussing the properties of a mean 
field network after equilibrium has been reached. We now focus 
on the detailed time dependence of the relaxation of the cell 
activity to a state of equilibrium. 
Hopfield 8 introduced a simple formalism for the analysis of 
the time dependence of network activity. In this model, 
network activity is mapped onto a physical system in which the 
state of neuron activity is considered as a 'particle' on a potential 
energy surface. Identification of the pattern occurs when the 
activity 'relaxes' to a nearby minima of the energy. Thus 
minima are employed as the sites of memories. For a Hopfield 
network of N neurons, the intra-layer connectivity required is of 
order N 2. This connectivity is a significant constraint on the 
practical implementation of such systems for large scale 
problems. Further, the Hopfield model allows a storage capacity 
which is limited to m < N memories8, 9 This is a result of the 
proliferation of unwanted local minima in the 'energy' surface. 
Recently, Bachmann et al. 10, have proposed a model for the 
relaxation of network activity in which memories of activity 
patterns are the sites of negative 'charges', and the activity 
caused by a test pattern is a positive test 'charge'. Then in this 
model, the energy function is the electrostatic energy of the 
(unit) test charge with the collection of charges at the memory 
sites 
E = -l/L, Z Qj I g- xj I -L, (14) 
J 
691 
where It(0) is a vector describing the initial network activity 
caused by a test pattern, and xj, the site of the jth memory. L is 
a parameter related to the network size. 
This model has the advantage that storage density is not 
restricted by the the network size as it is in the Hop field model, 
and in addition, the architecture employs a connectivity of order 
mxN. Note that at each stage in the settling of It(t) to a memory 
(of network activity) xj, the only feedback from the network to 
each cell is the scalar 
Qjlg-xjl -L (15) 
J 
This quantity is an integrated measure of the distance of the 
current network state from stored memories. Importantly, this 
measure is the same for all cells; it is as if a single virtual cell 
was computing the distance in activity space between the 
current state and stored states. The result of the computation is 
then broadcast to all of the cells in the network. This is a 
generalization of the idea that the detailed activity of each cell in 
the network need not be fed back to each cell. Rather some 
global measure, performed by a single 'effective' cell is all that is 
sufficient in the feedback. 
DISCUSSION 
We have been discussing a formalism for the analysis of 
networks of ideal neurons based on a mean field approximation 
of the detailed activity of the cells in the network. We find that 
a simple assumption concerning the spatial distribution of the 
pattern preferences of the cells allows a great simplification of 
the analysis. In particular, the detailed activity of the cells of 
the network may be replaced with a mean field that in effect is 
computed by a single 'effective' cell. 
Further, the application of this formalism to the cortical layer 
IV of visual cortex allows the prediction that much of learning in 
cortex may be localized to the LGN-cortical synaptic states, and 
that cortico-cortical plasticity is relatively unimportant. We find, 
in agreement with experiment, that monocular deprivation of 
the cortical cells will drive closed-eye responses to zero, but 
chemical blockage of the cortical inhibitory pathways would 
reveal non-zero closed-eye synaptic states. 
692 
Finally, the mean field approximation allows the development 
of single layer models of memory storage that are unrestricted 
in storage density, but require a connectivity of order mxN. This 
is significant for the fabrication of practical content addressable 
memories. 
I would like to thank Leon Cooper for many helpful discussions 
and the contributions he made to this work. 
*This work was supported 
the Army Research Office 
and #DAAG-29-84-K-0202. 
by the Office of Naval Research and 
under contracts #N00014-86-K-0041 
References
[1] Bienenstock, E. L., Cooper, L. N & Munro, P. W. (1982) J. 
Neuroscience 2, 32-48. 
[2] Scofield, C. L. (1984) Unpublished Dissertation. 
[3] Cooper, L. N, Munro, P. W. & Scofield, C. L. (1985) in Synaptic 
Modification, Neuron Selectivity and Nervous System 
Organization, ed. C. Levy, J. A. Anderson & S. Lehmkuhle, 
(Erlbaum Assoc., N.J.). 
[4] Cooper, L. N & Scofield, C. L. (to be published) Proc. Natl. Acad. 
$ci. USA.. 
[5] Singer, W. (1977) Brain Res. 134, 508-000. 
[6] Bear, M. F., Schmechel D. M., & Ebner, F. F. (1985) J. Neurosci. 
5, 1262-0000. 
[7] Mower, G. D., White, W. F., & Rustad, R. (1986) Brain Res. 380, 
253-000. 
[8] Hopfield, J. J. (1982) Proc. Natl. Acad. Sci. USA 79, 2554-2558. 
[9] Hopfield, J. J., Feinstein, D. I., & Palmer, R. G. (1983) Nature 
304, 158-159. 
[10] Bachmann, C. M., Cooper, L. N, Dembo, A. & Zeitouni, O. (to be 
published) Proc. Natl. Acad. Sci. USA. 
", mean field theori layer iv visual cortex applic artifici neural scofield neural scienc physic depart univers rhode island richmond rhode singl cell theori develop select domin visual cortex present previous cooper munro extend applic layer iv visual paper present mean field approxim captur fairli manner mani result network consid applic theori artifici neural network signific reduct architectur complex singl layer network mean field consid singl layer network ideal neuron signal outsid layer cell within layer activ ith cell network elij vector affer signal cell input fiber outsid cortic network matrix synaps input cell transmit matrix institut physic gener singl layer recurr light circl dark circl expand respons ith cell individu describ number cortic synaps travers signal arriv synaps lij cell cj respons cell becom lij mjd ljk mk lij lkn mn term contain factor form lqp factor describ first order cell transform signal mean field consist estim factor cell locat lqp mpd fnd assumpt impli cell network thu mj assumpt vector sum constant lqp fn amount assum cell network popul cell possibl pattern thu vector sum synapt state describ pattern prefer independ assum later connect strength function lij becom circular matrix lij lji respons cell becom mid iol defin spatial averag cortic cell activ fn averag number intracort manner similar theori replac effect individu cortic cell effect though cortic cell replac figur note retain synapt travers signal focu activ layer mean field approxim therefor write mean field ilol asum network singl layer mean field connect cell replac singl synaps cortic network first consid evolut network accord modif rule studi elsewher consid lgn cortic site plastic assum maximum modif follow denot spatial averag cortic denot time averag activ th cortic function discuss extens note describ function cell respons hebbian lead complex set stochast analyz partial elsewher affer synapt state fix point select unstabl fix point argument may gener mean field approxim mean tz time depend compon averag network modifi environment chang compar chang modifi synaps approxim write see map everi exist correspond satisfi origin equat mean field zero everi fix point exist fix point select fix point avail suffici inhibit network mean field network iv visual cortex primari visual cortex normal adult cat tune orient elong slit light activ stimul either select type visual environ experienc critic earli postnat depriv pattern input critic period lead loss select monocular depriv result dramat shift ocular domin cortic neuron respons exclus open ocular domin shift md best known studi type visual cortic behavior visual cortic cell variou rear suggest cell respond rapidli chang monocular cell remain respons close eye larg shift cell open singer use intracellular inhibitori interneuron resist depriv synaps pyramid cell recent work suggest densiti inhibitori synaps kitten striat cortex also unaffect cortic period result suggest synaps modifi other modifi rel slow excitatori synaps excitatori cell may modifi embodi fact introduc two type modifi remain rel simpl limit assum simplic consist interpret two type synaps two differ class cell left eye similar synaps given binocular mean field approxim binocular term oc oc explicit left eye time averag signal form note contain term condit monocular anim rear one eye sake analysi assum eye close signal arriv right environ cortic assum left eye synaps reach fix select pattern ixil follow method local analysi function employ show close eye ratio number modifi cell number cell asymptot close eye synaps scale function due cortic scale state set proport averag intracort synapt contrast mean field zero theori depriv synaps go rather constant valu depend averag inhibit cell way output cortic cell zero can not driven depriv howev lessen effect inhibitori applic inhibitori block agent reduc magnitud one could obtain respons depriv consist previou theori learn occur synaps need synaps mean field approxim neural network mean field approxim may appli network feedback gener function cell feedback may measur differ network activ memori network network may use content address discuss properti mean network equilibrium focu detail time depend relax cell state introduc simpl formal analysi time depend network activ map onto physic system neuron activ consid potenti identif pattern occur nearbi minima thu employ site hopfield connect requir connect signific constraint implement system larg scale hopfield model allow storag capac limit result unwant local minima bachmann et propos model network activ memori activ site neg activ test pattern posit test energi function electrostat energi test charg collect charg memori qj xj vector describ initi network activ test site jth paramet relat network model advantag storag densiti network size hop field architectur employ connect order note stage settl memori network feedback network cell scalar quantiti integr measur distanc network state store singl virtual cell comput distanc activ space state store result comput broadcast cell idea detail activ cell network need fed back rather perform singl cell discuss formal analysi ideal neuron base mean field approxim detail activ cell find simpl assumpt concern spatial distribut prefer cell allow great simplif detail activ cell network may replac mean field effect singl applic formal cortic layer visual cortex allow predict much learn may local synapt plastic rel agreement monocular depriv cortic cell drive respons blockag cortic inhibitori pathway would synapt mean field approxim allow develop singl layer model memori storag unrestrict storag requir connect order signific fabric practic content address would like thank leon cooper mani help discuss contribut made work support armi research offic offic naval research contract unpublish synapt neuron select nervou system anderson brain schmechel brain usa natur,2
72,72,"693 
Teaching Artificial Neural Systems to Drive: 
Manual Training Techniques for Autonomous Systems 
J. F. Shepanskl and S. A. Macy 
TRW, Inc. 
One Space Park, O2/1779 
Redondo Beach, CA 90278 
ABSTRACT
We have developed a methodology for manually training autonomous control systems 
based on artificial neural systems (ANS). In applications where the rule set governing an expert's 
decisions is difficult to formulate, ANS can be used to extract rules by associating the information 
an expert receives with the actions he. takes. Properly constructed networks imitate rules of 
behavior that permits them to function autonomously when they are trained on the spanning set 
of possible situations. This training can be provided manually, either under the direct supervision 
of a system trainer, or indirectly using a background mode where the network assimilates training 
data as the expert performs his day-to-day tasks. To demonstrate these methods we have trained 
an ANS network to drive a vehicle through simulated freeway traffic. 
Introduction 
Computational systems employing fine grained parallelism are revolutionizing the way we 
approach a number of long standing problems involving pattern recognition and cognitive process- 
ing. The field spans a wide variety of computational networks, from constructs emulating neural 
functions, to more crystalline configurations that resemble systolic arrays. Several titles are used 
to describe this broad area of research, we use the term artificial neural systems (ANS). Our con- 
cern in this work is the use of ANS for manually training certain types of autonomous systems 
where the desired rules of behavior are difficult to formulate. 
Artificial neural systems consist of a number of processing elements interconnected in a 
weighted, user-specified fashion, the interconnection weights acting as memory for the system. 
Each processing element calculate an output value based on the weighted sum of its inputs. In 
addition, the input data is correlated with the output or desired output (specified by an instructive 
agent) in a training rule that is used to adjust the interconnection weights. In this way the net- 
work learns patterns or imitates rules of behavior and decision making. 
The particular ANS architecture we use is a variation of Rummelhart et. al. [1] multi-layer 
perceptton employing the generalized delta rule (GDR). Instead of a single, multi-layer rruc- 
ture, our final network has a a multiple component or ""block"" configuration where one block' 
output feeds into another (see Figure 3). The training methodology we have developed is nor 
tied to a particular training rule or architecture and should work well with alternative networks 
like Grossberg's adaptive resonance model[2]. 
� American Institute of Physics 1988 
694 
The equations describing the network are derived and described in detail by Rumelhart et. 
al.[1]. In summary, they are: 
Transfer function: o i - (l+e-Sj) -, S i =  wj,.ol; (1) 
i0 
Weight adaptation rule: Aw. =(1-ot.)rl.Sio i + cr.Au,r'vi�u; (2) 
Error calculation: i ---�i(1- %')  tS,wi, (3) 
where o i is the output of processing element j or a sensor input, % is the interconnection weight 
leading from element i to j, n is the number of inputs to j, Aw is the adjustment of w, q is the 
training constant, a is he training ""momentum,"" $i is the calculated error for element j, and m 
is the fanout of a given element. Element zero is a constant input, equal to one, so hat Wio is 
equivalent to the bias threshold of element j. The (1-a) factor in equation (2) differs from stau- 
dard GDR formulation, but. it is useful for keeping track of the relative magnitudes of the two 
terms. For he network's output layer the summation in equation (3) is replaced with the 
difference between he desired and actual output value of element j. 
These networks are usually trained by presenting the system with sets of input/output data 
vectors in cyclic fashion, the entire cycle of database presentation repeated dozens of times. This 
method is effective when he training agent is a computer operating in batch mode, but would be 
intolerable for a human instructor. There are two developments that will help real-time human 
training. The first is a more efficient incorporation of data/response patterns into a network. The 
second, which we are addressing in this paper, is a suitable environment wherein a man and ANS 
network can iteract in training situation with minimum inconvenience or boredom on the 
human's part. The ability to systematically train networks in this fashion is extremely useful for 
developing certain types of expert systems including automatic signal processors, autopilots, 
robots and other autonomous machines. We report a number of techniques aimed at facilitating 
this type of training, and we propose a general method for teaching these networks. 
System Development 
Our work focuses on the utility of ANS for system control. It began as an application of 
Barto and Sutton's associative search network[3]. Although their approach was useful in a 
number of ways, it fell short when we tried to use it for capturing the subtleties of human 
decision-making. In response we shifted our emphasis from constructing goal functions for 
automatic learning, to methods for training networks using direct human instruction. An integral 
part of this is the development of suitable interfaces between humans, networks and he outside 
world or simulator. In this section we will report various approaches to hese ends, and describe a 
general methodology for manually teaching ANS networks. To demonstrate these techniques we 
taught a network to drive a robot vehicle down a simulated highway in traffic. This application 
combines binary decision making and control of continuous parameters. 
Initially we investigated he use of automatic learning based on goal functions[3] for train- 
ing control systems. We trained a network-controlled vehicle to maintain acceptable following 
distances from cats ahead of it. On a graphics workstation, a one lane circular track was 
695 
constructed and occupied by two vehicles: a network-controlled robot car and a pace car that 
varied its speed at random.. Input data to the network consisted of the separation distance and 
the sleed of the robot vehicle. The values of a goal function were translated into desired output 
for GDR training. Output controls consisted of three binary decision elements: 1) accelerate one 
increment of speed, 2) maintain speed, and 3) decelerate one increment of speed. At all times 
the desired output vector had exactly one of these three elements active. The goal function was 
quadratic witIx a minimum corresponding to the optimal following distance. Although it had no 
direct control over the simulation, the goal function positively or negatively reinforced the 
system's behav ior. 
The network was given complete control of the robot vehicle, and the human trainer had 
no influence except the ability to start and terminate training. This proved unsatisfactory because 
the initial system behavior--governed by random interconnection weights--was very unstable. The 
robot tended to run over the car in front of it before significant training occurred. By carefully 
halting and restarting training we achieved stable system behavior. At first the following distance 
maintained by the robot car oscillated as if the vehicle was attached by a spring to the pace car. 
This activity gradually damped. After about one thousand training steps the vehicle maintained 
the optimal following distance and responded quickly to changes in the pace car's speed. 
Constructing composite goal functions to promote more sophisticated abilities proved 
difficult, even ill-defined, because there were many unspecified parameters. To generate goal 
functions for these abilities would be similar to conventional programming--the type of labor we 
want to circumvent using ANS. On the other hand, humans are adept at assessing complex situa- 
tions and making decisions based on qualitative data, but their ""goal functions"" are difficult if not 
impossible to capture analytically. One attraction of ANS is that it can imitate behavior based on 
these elusive rules without formally specifying them. At this point we turned our efforts to 
manual training techniques. 
The initially trained network was grafted into a larger system aad augmented with addi- 
tional inputs: distance and speed information on nearby pace cars in a secod traffic lane, and an 
output control signal governing lane changes. The original network's ability to maintain a safe 
following distance wa retained intact. Th grafting procedure is one of two methods we studied 
for adding new abilities to an existins system. (The second, which employs a block structure, is 
described below.) The network remained in direct control of the robot vehicle, but a human 
trainer instructed it when and when not to change lanes. His commands were interpreted as the 
desired output and used in the GDR training algorithm. This technique, which we call coaching, 
proved useful and the network quickly correlated its environmental inputs with the teacher's 
instructions. The network became adept at changing lanes and weaving through traffic. We found 
that the network took on the behavior pattern of its trainer. A conservative teacher produced a 
timid network, while an aggressive trainer produced a network that tended to cut off other auto- 
mobiles and squeeze through tight openings. Despite its success, the coaching method of training 
did not solve the problem of initial network instability. 
The stability problem was solved by giving the trainer direct control over the simulation. 
The system configuration (Figure 1), allows the expert to exert control or release it to the net- 
work. During initial training the expert is in the driver's seat while the network acts the role of 
696 
apprentice. It receives sensor information, predicts system commands, and compares its predic- 
tions against the desired output (ie. the trainer's commands). Figure 2 shows the daa and com- 
mand flow in detail. Input data is processed through different channels and presented to the 
trainer and network. Where visual and audio formats are effective for humans, the network uses 
information in vector form. This differentiation of data presentation is a limitation of the system; 
removing it is a usk for future research. The trainer issues control commands in accordance with 
his assigned task while the network takes the trainer's actions as desired system responses and 
correlates these with the input. We refer to this procedure as master/apprentice training, network 
training proceeds invisibly in the background as the expert proceeds with his day to day work. It 
avoids the instability problem because the network is free to make errors without the adverse 
consequence of throwing the operating environment into disarray. 
World (--> sensors) Network Expert 
or 
Simulation  Actuation - - J  Commands 
Figure 1. A scheme for manually training ANS nelworks. Input data is received by both 
the network and trainer. The trainer issues commands that are actuated (solid command 
line), or he coaches the network in how it ought to respond (broken command line). 
.. Preprocessing _ 
for human 
Input 
data 
Preprocessing 
for network - 
I 
Human  Commands 
expefi 
Predicted 
Network  commands 
Training 
Coaching/emphasis 
Actuation 
F'7Jre 2. Data and command flow in the training system. Input data is processed and presented 
to the trainer and network. In master/apprentice training (solid command line), the trainers 
orders are sctuated and the network treats his commands as the system's desired output. In 
coaching, the network's predicted commands are actuated (broken command line), and the 
trainer influences weight adaptation by specifying the desired system output and controlling 
Ihe values of training constams-his ""suggestions"" are not directly actuated. 
Once initial, bckground Iraining is complete, he expert proceeds in a more formal 
manner to teach the network. He re]eases control of the command system to the network in 
order to evaluste its behavior and weaknesses. He then resumes control and works through a 
697 
series of scenarios designed to train the network out of its bad behavior. By switching back and 
forth between human and network control, the expert assesses the network's reliability and 
teaches correct responses as needed. We find master/apprentice training works well for behavior 
involving continuous functions, like steering. On the other hand, coaching is appropriate for deci- 
sion functions, like when the car ought to pass. Our methodology employs both techniques. 
The Driving Network 
The fully developed freeway simulation consists of a two lane highway that is made of 
joined straight and curved segments which vaxy at random in length (and curvature). Several 
pace cars move at random speeds near the robot vehicle. The network is given the tasks of track- 
ing the road, negotiating curx'es, returning to the road if placed fax afield, maintaining safe dis- 
tances from the pace cars, and changing lanes when appropriate. Instead of a single multi-layer 
structure, the network is composed of two blocks; one controls the steering and the other regu- 
lates speed and decides when the vehicle should change lanes (Figure 3). The first block receives 
information about the position and speed of the robot vehicle relative to other cars in its vicinity. 
Its output is used to determine the automobile's speed and whether the robot should change 
lanes. The passing signal is converted to a lane assignment based on the cat's current lane posi- 
tion. The second block receives the lane assignment and dta pertinent to the position and often- 
tation of the vehicle with respect to the road. The output is used to determine the steering angle 
of the robot car. 
Block 1 Inputs Outputs 
Constant   
Speed 
Dist. Ahead, PL ,..  _ 
Dist. Ahead, OL "" v l Speed 
Rel. Speed Ahead, PL 
Rel. Speed Ahead, OL t 
Rel. Speed Behind, OL 
Convert lane change to lane number 
Block 2/, '/ 
./' Constant   
[ _ Rel. Orientation   
 Lane Number  m.- �  � Steering Angle 
Lateral Dist. 
Curvature �  
Figure 3. The two blocks of the driving ANS network. Heavy arrows indicate total interconnectivity 
between layers. PL designates the traffic lane presently occupied by the robot vehicle, OL refers 
to the other lane, curvature refers to the road, lane number is either 0 or 1, relative orientation and 
lateral distance relers to the robot cars dire(lion and position relative to the road's direction and 
center line, respectively. 
698 
The input data is displayed in pictorial and textual form to the driving instructor. He views 
the road and neatby vehicles from the perspective of the driver's seat or overhead. The network 
receives information in the form of a vector whose elements have been scaled to unitary order, 
O(1). Wide ranging input parameters, like distance, ate compressed using the hyperbolic tangent 
or logarithmic functions. In each block, the input layer is totally interconnected to both the out- 
put and a hidden layer. Our scheme trains in real time, and as we discuss later, it trains more 
smoothly with a small modification of the training algorithm. 
Output is interpreted in two ways: as a binary decision or as a continuously varying param- 
eter. The first simply compares the sigmoid output against a threshold. The second scales the 
output to an appropriate range for its application. For example, on he steering output element, a 
0.5 value is interpreted as a zero steering angle. Left and right turns of varying degrees are ini- 
tiated when this output is above or below 0.5, respectively. 
;l'he network is divided into two blocks that can be trained separately. Beside being con- 
ceptually easier to understand, we find this component approach is easy to train systematically. 
Because each block has a restricted, well-defined set of tasks, the trainer can concentrate 
specifically on those functions without being concerned that other aspects of the network behavior 
ate deteriorating. 
We trained the system from bottom up, first teaching the network to stay on the road, 
negotiate curves, change lanes, and how to return if the vehicle strayed off the highway. Block 2, 
responsible for steering, learned these skills in a few minutes using the master/apprentice mode. 
It tended to steer more slowly than a human but further training progressively improved its 
responsiveness. 
We experimented with different training constants and ""momentum"" values. Large 
values, about 1, caused weights to change too coarsely. q values an order of magnitude smaller 
worked well. We found no advantage in using momentum for this method of training, in fact, 
the system responded about three times more slowly when  =0.9 hn whe the momentr 
term was dropped. Our stamdatd training pataneters were q =0.2, and c 
Figure 4. Typical behavior of a network-controlled vehicle (dark rectangle) when trained by 
a) a conservative drive, and b) a mctdess driver. Speed is indicated by the length of the arrows. 
After Block 2 was trained, we gave steering control to the network and concentrated on 
teaching the network to change lanes and djust speed. Speed control in this case was a continu- 
ous vatiable and was best taught using master/apprentice training. On the other had, the binary 
decision to change lanes was best taught by coaching. About ten minutes of training were needed 
to teach the network to weave through traffic. We found that the network readily adapts the 
699 
behavioral pattern of its trainer. A conservative trainer generated a network that hardly ever 
passed, while an aggressive trainer produced a network that drove recklessly and tended to cut off 
other-cars (Figure 4). 
Discussion 
One of the strengths of expert systems based on ANS is that the use of input data in the 
decision making and control process does not have to be specified. The network adapts its inter- 
nal weights to conform to input/output correla.ions it discovers. It is important, however, that 
data used by the human expert is also available to the network. The different processing of sen- 
sor data for man and net,-ork may have important consequences, key information may be 
presented to the man but not the machine. 
This difference in data processing is particularly worrisome for image data where human 
ability to extract detail is vastly superior to our automatic image processing capabilities. Though 
we would not require an image processing system to understand images, it would have to extract 
relevant information from cluttered backgrounds. Until we have sufficiently sophisticated algo- 
rithms or networks to do this, our efforts at constructing expert systems which handle image data 
are handicapped. 
Scaling input data to the unitary order of magnitude is important for training stability. This 
is evident from equations (1) and (2). The sigmoid transfer function ranges from 0.1 to 0.9 in 
approxima(ely four units, that is, over an O(1) domain. If system response must change in reac- 
tion to a large, O(n) swing of a given input parameter, the weight associated with that input will 
be trained toward an O(n-) magnitude. On the other hand, if the same system responds to an 
input whose range is O(1), its associated weight will also be O(1). The weight adjustment equa- 
tion does not recognize differences in weight magnitude, therefore relatively small weights will 
undergo wild magnitude adjustments and converge weakly. On the other hand, if all input param- 
eters age of the same magnitude their associated weights will reflect this and the training constant 
can be adjusted for gentle weight convergence. Because the output of hidden units are con- 
strained between zero and one, O(1) is a good target range for input parameters. Both the hyper- 
bolic tangent and logarithmic functions are useful for scaling wide ranging inputs. A useful form 
of the latter is 
[l+ln(x/o)] if 
z' = x/o if - o<:r <o, (4) 
- [l+ln(- x/o)] if 
where cr>0 and defines the limits of the intermediate linear section, and  is a scaling factor. 
This symmetric logarithmic function is continuous in its first derivative, and useful when network 
behavior should change slowly as a parameter increases without bound. On the other hand, if the 
system should approach a limiting behavior, the tanh function is appropriate. 
Weight adaptation is also complicated by relaxing the common practice of restricting inter- 
connections to adjacent layers. Equation {3) shows that the calculated error for a hidden layer- 
given comparable weights, fanouts and output errors-will be one quarter or ]ess than that of the 
700 
output layer. This is caused by the slope factor, 0i(1- oi). The difference in error magnitudes is 
not noticeable in networks restricted to adjacent layer interconnectivity. But when this constraint 
is releed the effect of errors originating directly from an output unit has 4  times the magnitude 
and effect of an error originating from a hidden unit removed d layers from the output layer. 
Compared to the corrections arising from the output units, those from the hidden units have little 
influence on weight adjustment, and the power of a multilayer structure is weakened. The system 
will train if we restrict connections to adjacent layers, but it trains slowly. To compensate for this 
effect we attenuate the error magnitudes originating from the output layer by the above factor. 
This heuristic procedure works well and facilitates smooth learning. 
Though we have made progress in real-time learning systems using GDR, compared to 
humans-who can learn from a single data presentation-they remain relatively sluggish in learning 
and response rates. We are interested in improvements of the GDR algorithm or alternative 
architectures that facilitate one-shot or rapid learning. In the latter case we are considering least 
squares restoration techniques[4] and Grossberg and Carpenter's adaptive resonance models[3,5]. 
The construction of automated expert systems by observation of human personnel is 
attractive because of its efficient use of the expert's time and effort. Though the classic AI 
approach of rule base inference is applicable when such rules are clear cut and well organized, too 
often a human expert can not put his decision making process in words or specify the values of 
parameters that influence him. The attraction of ANS based systems is that imitations of expert 
behavior emerge as a natural consequence of their training. 
References
1) D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Learning Internal Representations by 
Error Propagation,"" in Parallel Diatruted Processing: Ezplorations in the Microstructure of Cognition, 
Vol. I, D. E. Rumelhart and J. L. McClelland (Eds.), chap. 8, (198�), Bradford Books/MIT Press, 
Cambridge 
2) S. Grossberg, Studies of Mind and Brain, (1982), Reidel, Boston 
3) A. Barto and R. Sutton, ""Landmark Learning: An Illustration of Associative Search,"" Biologb 
eal Cybernetics, 42, (1981), p. I 
4) A. Rosenreid and A. Kak, Digital Picture Processing, Vol. 1, chap. 7, (1982), Academic Press, 
New York 
5) G. A. Carpenter and S. Grossberg, ""A Massively Parallel Architecture for a Self-organizing 
Neural Pattern Recognition Machine,"" Computer Vision, Graphics and Image Processing, I7, 
(1987), p.54 
", artifici neural system train techniqu autonom system shepanskl maci space ca develop methodolog manual train autonom control system artifici neural system applic rule set govern difficult an use extract rule associ inform expert receiv action properli construct network imit rule permit function autonom train span set possibl train provid either direct supervis system indirectli use background mode network assimil train expert perform demonstr method train an network drive vehicl simul freeway system employ fine grain parallel revolution way number long stand problem involv pattern recognit cognit field span wide varieti comput construct emul neural crystallin configur resembl systol sever titl use describ broad area use term artifici neural system work use an manual train certain type autonom system desir rule behavior difficult neural system consist number process element interconnect interconnect weight act memori process element output valu base weight sum input data correl output desir output instruct train rule use adjust interconnect way learn pattern imit rule behavior decis particular an architectur use variat rummelhart employ gener delta rule instead final network multipl compon configur one feed anoth figur train methodolog develop particular train rule architectur work well altern network adapt reson american institut physic equat describ network deriv describ detail rumelhart adapt output process element sensor interconnect weight element number input aw adjust train calcul error element fanout given element zero constant equal wio bia threshold element factor equat differ gdr use keep track rel magnitud two output layer summat equat replac desir actual output valu element network usual train present system set data cyclic entir cycl databas present repeat dozen effect train agent comput oper batch would human two develop help human first effici incorpor pattern address suitabl environ wherein man an train situat minimum inconveni boredom abil systemat train network fashion extrem use certain type expert system includ automat signal autonom report number techniqu aim facilit type propos gener method teach develop work focus util an system began applic associ search although approach use fell short tri use captur subtleti human respons shift emphasi construct goal function method train network use direct human integr develop suitabl interfac network outsid section report variou approach describ methodolog manual teach an demonstr techniqu network drive robot vehicl simul highway applic binari decis make control continu investig use automat learn base goal control train vehicl maintain accept follow cat ahead graphic one lane circular track occupi two robot car pace car speed input data network consist separ distanc robot valu goal function translat desir output gdr output control consist three binari decis acceler one maintain deceler one increment time desir output vector exactli one three element goal function ix minimum correspond optim follow although control goal function posit neg reinforc behav network given complet control robot human trainer influenc except abil start termin prove unsatisfactori initi system random interconnect tend run car front signific train care restart train achiev stabl system first follow distanc robot car oscil vehicl attach spring pace activ gradual one thousand train step vehicl maintain optim follow distanc respond quickli chang pace composit goal function promot sophist abil prove even mani unspecifi gener goal abil would similar convent type labor circumv use human adept assess complex make decis base qualit difficult captur one attract an imit behavior base elus rule without formal specifi point turn effort train initi train network graft larger system aad augment distanc speed inform nearbi pace car traffic control signal govern lane origin abil maintain safe distanc retain graft procedur one two method studi ad new abil existin employ block network remain direct control robot human instruct chang command interpret output use gdr train call use network quickli correl environment input network becam adept chang lane weav found network took behavior pattern conserv teacher produc aggress trainer produc network tend cut squeez tight despit coach method train solv problem initi network stabil problem solv give trainer direct control system configur allow expert exert control releas initi train expert seat network act role receiv sensor predict system compar desir output figur show flow input data process differ channel present visual audio format effect network use vector differenti data present limit futur trainer issu control command accord assign task network take action desir system respons refer procedur network proce invis background expert proce day day instabl problem network free make error without advers throw oper environ network expert actuat command scheme manual train an input data receiv network trainer issu command actuat command coach network ought respond command preprocess human network command command data command flow train input data process present trainer train command trainer sctuat network treat command desir predict command actuat command influenc weight adapt specifi desir system output control valu train directli irain expert proce formal teach control command system network evalust behavior resum control work scenario design train network bad switch back human network expert assess reliabl correct respons find train work well behavior continu like coach appropri like car ought methodolog employ drive network fulli develop freeway simul consist two lane highway made straight curv segment vaxi random length sever car move random speed near robot network given task negoti return road place fax maintain safe pace chang lane instead singl network compos two one control steer speed decid vehicl chang lane first block receiv posit speed robot vehicl rel car output use determin speed whether robot chang pass signal convert lane assign base current lane second block receiv lane assign pertin posit vehicl respect output use determin steer angl robot input output ol speed speed pl speed ol speed ol lane chang lane number constant orient lane number steer angl two block drive an heavi arrow indic total interconnect pl design traffic lane present occupi robot ol refer curvatur refer lane number either rel orient distanc reler robot car posit rel direct input data display pictori textual form drive view road neatbi vehicl perspect seat network inform form vector whose element scale unitari wide rang input like ate compress use hyperbol tangent logarithm input layer total interconnect hidden scheme train real discuss train small modif train interpret two binari decis continu vari first simpli compar sigmoid output second scale appropri rang steer output valu interpret zero steer left right turn vari degre output network divid two block train besid easier find compon approach easi train block set trainer concentr function without concern aspect network behavior train system bottom first teach network stay chang return vehicl stray block learn skill minut use tend steer slowli human train progress improv experi differ train constant larg caus weight chang valu order magnitud smaller found advantag use momentum method system respond three time slowli stamdatd train typic behavior vehicl train conserv mctdess speed indic length block gave steer control network concentr network chang lane speed control case vatiabl best taught use binari chang lane best taught ten minut train need teach network weav found network readili adapt pattern conserv trainer gener network hardli ever aggress trainer produc network drove recklessli tend cut strength expert system base an use input data make control process network adapt weight conform use human expert also avail differ process data man may import key inform may man differ data process particularli worrisom imag data human extract detail vastli superior automat imag process though would requir imag process system understand would extract inform clutter suffici sophist network effort construct expert system handl imag data input data unitari order magnitud import train evid equat sigmoid transfer function rang four system respons must chang swing given input weight associ input train toward system respond whose rang associ weight also weight adjust recogn differ weight therefor rel small weight wild magnitud adjust converg input age magnitud associ weight reflect train constant adjust gentl weight output hidden unit zero good target rang input tangent logarithm function use scale wide rang use form latter defin limit intermedi linear scale symmetr logarithm function continu first use network chang slowli paramet increas without approach limit tanh function adapt also complic relax common practic restrict adjac equat show calcul error hidden compar fanout output one quarter caus slope differ error magnitud notic network restrict adjac layer constraint effect error origin directli output unit time magnitud effect error origin hidden unit remov layer output correct aris output hidden unit littl weight power multilay structur system train restrict connect adjac train compens attenu error magnitud origin output layer heurist procedur work well facilit smooth made progress learn system use compar learn singl data remain rel sluggish learn respons interest improv gdr algorithm altern facilit rapid latter case consid least restor grossberg adapt reson construct autom expert system observ human personnel effici use time though classic ai rule base infer applic rule clear cut well human expert put decis make process word specifi valu influenc attract an base system imit expert emerg natur consequ intern represent parallel ezplor microstructur rumelhart clelland bradford studi mind boston barto illustr associ biologb rosenreid digit pictur academ york carpent massiv parallel architectur pattern recognit comput graphic imag,2
73,73,"701 
DISCOVERING STRUCTURE FROM MOTION IN 
MONKEY, MAN AND MACHINE 
Ralph M. Siegel* 
The Salk Institute of Biology, La Jolla, Ca. 92037 
ABSTRACT 
The ability to obtain three-dimensional structure from visual motion is 
important for survival of human and non-human primates. Using a parallel process- 
ing model, the current work explores how the biological visual system might solve 
this problem and how the neurophysiologist might go about understanding the 
solution. 
INTRODUCTION 
Psychophysical experiments have shown that monkey and man are equally 
adept at obtaining three dimensional structure from motionL In the present work, 
much effort has been expended mimicking the visual system. This was done for one 
main reason: the model was designed to help direct physiological experiments in the 
primate. It was hoped that if an approach for understanding the model could be 
developed, the approach could then be directed at the primate's visual system. 
Early in this century, von Helmholtz 2 described the problem of extracting 
three-dimensional structure from motion: 
Suppose, for instance, that a person is standing still in a thick woods, 
where it is impossible for him to distinguish, except vaguely and roughly, 
in the mass of foliage and branches all around him what belongs to one 
tree and what to another, or how far apart the separate trees are, etc. But 
the moment he begins to move forward, everything disentangles itself, 
and immediately he gets an apperception of the material content of the 
woods and their relation to each other in space, just as if he were looking 
at a good stereoscopic view of it. 
If the object moves, rather than the observer, the perception of three- 
dimensional structure from motion is still obtained. Object-centered structure from 
motion is examined in this report. Lesion studies in monkey have demonstrated that 
two extra-striate visual cortices called the middle temporal area (abbreviated MT 
*Current address: Laboratory of Neurobiology, The Rockefeller University, 1230 
York Avenue, New York, NY 10021 
@ American Institute of Physics 1988 
702 
or V5) and the roedial superior temporal area (MST) 3,4 are involved in obtaining 
structure from motion. The present model is meant to mimic the V5oMST part of 
the cortical circuitry involved in obtaining structure from motion. The model 
attempts to determine if the visualimage corresponds to a three-dimensional object. 
THE STRUCTURE FROM MOTION STIMULUS 
The problem that the model solved was the same as that posed in the studies 
of monkey and man 1. Structured and unstructured motion displays of a hollow, 
orthographically projected cylinder were computed (Figure 1). The cylinder rotates 
about its vertical axis. The unstructured stimulus was generated by shuffling the 
velocity vectors randomly on the display screen. The overall velocity and spatial 
distribution for the two displays are identical; only the spatial relationships have 
been changed in the unstructured stimulus. Human subjects report that the points 
are moving on the surface of a hollow cylinder whenviewing the structured stimulus. 
With the unstructured stimulus, most subjects report that they have no sense of 
three-dimensional structure. 
A. Rotating Cylinder 
B. Orthographic C. Unstructured 
Projection Display 
Figure 1. The structured and unstructured motion stimulus. A) ""N"" points are 
randomly placed on the surface of a cylinder. B) The points are orthographically pro- 
jected. The motion gives a strong percept of a hollow cylinder. C) The unstructured 
stimulus was generated by shuffling the velocity vectors randomly on the screen. 
FUNCTIONAL ARCHITECTURE OF THE MODEL 
Aswith the primate subjects, the modelwas required to only indicate whether 
or not the display was structured. Subjects were not required to describe the shape, 
velocity or size of the cylinder. Thus the output cell* of the model signaled ""1"" if 
*By cell, I mean a processing unit of the model which may correspond to a single 
neuron or group of neurons. The term neuron refers only to the actual wetware 
in the brain. 
703 
structured and ""0"" if not structured. This output layer corresponds to the cortical 
area MST of macaque monkey which appear to be sensitive to the global organiza- 
tion of the motion image 5. It is not known if MST neurons will distinguish between 
structured and unstructured images. 
The input t.o the model was based on physiological studies in the macaclue 
monkey. Neurons in area V5 have a retinotopic representation of visual space 6,7. 
V=V O 
 v< <v o 
-0 
-3 -2 -1 0 1 2 3 
retinal position (deg) 
Figure 2. The receptive field of an input 
layer cell. The optimal velocity is ""Vo"". 
For each retinotopic location there is 
an encoding of awide range of veloci- 
ties 8. Thus in the model's input rep- 
resentation, there were cells that 
represent different combinations of 
velocity and retinotopic spatial posi- 
tion. Furthermore motion velocity 
neurons in V5 have a center-sur- 
round opponent organization 9. The 
width of the receptive fields was 
taken from the data of Albright et 
al. 8. A typical receptive field of the 
model is shown in Figure 2. 
It was possible to determine what the activity of the input cells would be for 
the rotating cylinder given this representation. The activation pattern of the set of 
input cells was computed by convolving the velocity points with the difference of 
gaussians. The activity of the 100 input cells for an image of 20 points, with an an- 
gular velocity of 8�/sec is presented in Figure 3. 
_3 � Retinotopic map 3 
Structure = 1 
_3 � Retinotopic map 
o o o o.,eo 
O0 
O0 
0oooooo 
Structure = 0 
Figure 3. The input cell's activation pattern for a structured and unstructured stimu- 
lus. The circles correspond to the cells of the input layer. The contours were com- 
704 
puted using a linear interpolation between the individual cells. The horizontal axis 
corresponds to the position along the horizontal meridian. The vertical axis corre- 
sponds to the speed along the horizontal meridian. Thus activation of a cell in the 
upper right hand coruer of the graph correspond to a velocity of 30�/sec towards the 
right at a location of 3 � to the right along the horizontal meridian. 
Inspection of this input pattern suggested that the problem of detecting 
three-dimensional structure from motion may be reduced to a pattern recognition 
task. The problem was then: ""Given a sparsely sampled input motion flow field, de- 
termine whether it corresponds best to a structured or unstructured object."" 
Itwas next necessary to determine the connections between the two input and 
output layers such that the model will be able to correctly signal structure or no struc- 
ture (1 or 0) over a wide range of cylinder radii and rotational velocities. A parallel 
distributed network of the type used by Rosenberg and Sejnowski 10 provided the 
functional architecture (Figure 4). 
O 
Figure 4. The parallel architecture used to extract structure 
from motion. The input layer (I), corresponding to area V5, 
mapped the position and speed along the horizontal axis. 
The output layer (O) corresponded to area MST that, it is 
proposed, signals structure or not. The middle layer (M) 
may exist in either V5 or MST. 
The input layer of cells was fully connected to the middle layer of cells. The 
middle layer of cells represented an intermediate stage of processing and may be in 
either V5 or MST. All of the cells of the middle layer were then fully connected to 
the output cell. The inputs from cells of the lower layer to the next higher level were 
summed linearly and then ""thresholded"" using the Hill equation X3/(X 3 + 0.53). 
The weights between the layers were initially chosen between +1. The values of the 
weights were then adjusted using back-propagation methods (steepest descent) so 
that the network would ""learn"" to correctly predict the structure of the input image. 
The model learned to correctly perform the task after about 10,000 iterations 
(Figure 5). 
Figure 5. The ""education"" of the network to 
Erro perform the structure from motion problem. 
The iteration number is plotted against the 
mean square error. The error is defined as the 
difference between the model's prediction and 
the known structure. The model was trained on 
a set of structured and unstructured cylinders 
with a wide range of radii, number of points, 
0 and rotational velocities. 
10000 20000 30000 40000 
Iteration number 
705 
PSYCHOPHYSICAL PERFORMANCE OF THE MODEL 
The model's performance was comparable to that of monkey and man with 
respect to fraction of structure and number of points in the display (Figure 6). The 
model was indeed performing a global analysis as shown by allowing the model to 
view only a portion of the image. Like man and monkey, the moders performance 
suffers. Thus it appears that the moders performance was quite similar to known 
monkey and human psychophysics. 
1. Output 18 I 
0.8. .- monkey . 
 man 
0.6. --- machine 0.6. 
0.4. 0.4.  monkey 
� - man 
0.2. 0.2. ---' machine 
0 0 
0 0.2 0.4 0.6 0.8 1 0 32 64 96 128 
Fraction structure Number of points 
Figure 6. Psychophysical performance of the model. A. The effect of varying the 
fraction of structure. As the fraction of structure increase, the moders performance 
improves. Thirty repetitions were averaged for each value of structure for the model. 
The fraction of structure is defined as (1-Rs/Rc), where R s is the radius of shuffling 
of the motion vectors and R c is the radius of the cylinder. The human and monkey 
data are taken from psychophysical studies 1. 
HOW IS IT DONE? 
The model has similar performance to monkey and man. It was next possible 
to examine this artificial network in order to obtain hints for studying the biological 
system. Following the approach of an electrophysiologist, receptive field maps for 
all the cells of the middle and output layers were made by activating individual input 
cells. The receptive field of some middle layer cells are shown in Figure 7. The layout 
of these maps are quite similar to that of Figure 4. However, now the activity of one 
cell in the middle layer is plotted as a function of the location and speed of a motion 
stimulus in the input layer. One could imagine that an electrode was placed in one 
of the cells of the middle layer while the experimentalist moved a bar about the 
706 
horizontal meridian with different locations and speeds. The activity of the cell is 
then plotted as a function of position and space. 
Retinotopie map 
3 � 
oo 
Figure 7. The activity of two different cells in the middle layer. Activity is plotted 
as a contour map as a function of horizontal position and speed. Dotted lines 
indicate inhibition. 
These middle layer receptive field maps were interesting because they 
appear to be quite simple and symmetrical. In some, the inhibitory central regions 
of the receptive field were surrounded by excitatory regions (Figure 7A). Comple- 
mentary cells were also found. In others, there are inhibitory bands adjacent to 
excitatory bands (Figure 7B). The above results suggest that neurons involved in 
extracting structure from motion may have relatively simple receptive fields in the 
spatial velocity domain. These receptive fields might be thought of as breaking the 
image down into component parts (i.e. a basis set). Correct recombination of these 
second order cells could then be used to detect the presence of a three-dimensional 
structure. 
The output cell also had a simple receptive field again with interesting 
symmetries (Figure 8). However, the receptive field analysis is insufficient to 
indicate the role of the cell. Therefore in order to properly understand the ""mean- 
ing"" of the cell's receptive field, it is necessary to use 
stimuli that are ""real world relevant""- in this case the 
structure from motion stimuli. The output cell would 
give its maximal response only when a cylinder stimulus 
is presented. 
Figure 8. The receptive field map of the output layer cell. 
Nothing about this receptive field structure indicates the 
cell is involved in obtaining structure from motion. 
707 
This work predicts that neurons in cortex involved in extracting structure 
from motion will have relatively simple receptive fields. In order to test this 
hypothesis, it will be necessary to make careful maps of these cells using small 
patches of motion (Figure 9). Known qualitative results in areas V5 and MST are 
consistent with, but do not prove, this hypothesis. As well, it will be necessary to use 
""relevant"" stimuli (e.g. three-dimensional objects). If such simple receptive fields 
are indeed used in structure from motion, then support will be found for the idea that 
a simple cortical circuit (e.g. center-surround) can be used for many different visual 
analyses. 
Fix point 
Motion patches consist- 
ing of random dots with 
variable velocity. 
Figure 9. It may be necessary to make careful 
maps of these neurons using small patches of 
motion, in order to observe the postulated simple 
receptive field properties of cortical neurons involved in extracting structure from 
motion. Such structures may not be apparent using hand moved bar stimuli. 
DISCUSSION 
In conclusion, it is possible to extract the three-dimensional structure of a 
rotating cylinder using a parallel network based on a similar functional architecture 
as found in primate cortex. The present model has similar psychophysics to monkey 
and man. The receptive field structures that underlie the present model are simple 
when viewed using a spatial-velocity representation. It is suggested that in order to 
understand how the visual system extracts structure from motion, quantitative 
spatial-velocity maps of cortical neurons involved need to be made. One also needs 
to use stimuli derived from the ""real world"" in order to understand how they may 
be used in visual field analysis. There are similarities between the shapes of the 
receptive fields involved in analyzing structure from motion and receptive fields in 
striate cortex 11. It maybe that similar cortical mechanisms and connections are used 
to perform different functions in different cortical areas. Lastly, this model demon- 
strates that the use of parallel architectures that are closely modeled on the cortical 
representation is a computationally efficient means to solve problems in vision. Thus 
as a final caveat, I would like to advise the creators of networks that solve 
ethologically realistic problems to use solutions that evolution has provided. 
708 
REFERENCES 
1. R.M. Siegel and R.A. Andersen, Nature (Lond.) (1988). 
2. H. yon Helmholtz, Treatise on Physiological Optics (Dover Publications, N.Y., 
1910), p. 297. 
3. R.M. Siegel and R.A. Andersen, Soc. Neurosci. Abstr., 12, p. 1183 (1986). 
4. R.M. Siegel and R.A. Andersen, Localization of function in extra-striate cortex: 
the effect of ibotenic acid lesions on motion sensitivity in Rhesus monkey, (in 
preparation). 
5. K. Tanaka, K. Hikosaka, H. Saito, M. Yukie, Y. Fukada, and E. Iwai, J., Neurosci., 
fi, pp. 134-144 (1986). 
6. S.M. Zeki, Brain Res., 35, pp. 528-532 (1971). 
7. J.H.R. Maunsell and D.C. Van Essen, J. Neurophysiol., 49, pp. 1127-1147 (1983). 
8. T.D. Albright, R. Desimone, and C.G. Gross, J. Neurophysiol., 51, pp. 16-31 
(1984). 
9. J. Allman, F. Miezen, and E. McGuinness, Ann. Rev. Neurosci., 8, pp. 407-430 
(1985). 
10. C.R. Rosenberg and T.J. Sejnowski, in: Reports of the Cognitive Neuropsychol- 
ogy Laboratory, John-Hopkins University (1986). 
11. D.H. Hubel and T.N. Wiesel, Proc. R. Soc. Lond. B., 198, pp.l-59 (1977). 
This work was supported by the Salk Institute for Biological Studies, The San Diego 
Supercomputer Center, and PHS NS07457-02. 
", structur motion man machin salk institut la abil obtain structur visual motion surviv human use parallel current work explor biolog visual system might solv problem neurophysiologist might go understand experi shown monkey man equal obtain three dimension structur present effort expend mimick visual done one model design help direct physiolog experi hope approach understand model could approach could direct visual von helmholtz describ problem extract structur person stand still thick imposs except vagu mass foliag branch around belong one far apart separ tree moment begin move everyth disentangl immedi get appercept materi content relat look good stereoscop view object rather percept structur motion still structur examin lesion studi monkey demonstr visual cortic call middl tempor area mt current laboratori rockefel new ny american institut physic roedial superior tempor area involv obtain present model meant mimic mst part cortic circuitri involv obtain structur model determin visualimag correspond structur motion stimulu problem model solv pose studi monkey man structur unstructur motion display project cylind comput cylind rotat vertic unstructur stimulu gener shuffl vector randomli display overal veloc spatial two display spatial relationship chang unstructur human subject report point move surfac hollow cylind whenview structur unstructur subject report sens rotat cylind orthograph unstructur display structur unstructur motion point place surfac point orthograph motion give strong percept hollow unstructur gener shuffl veloc vector randomli architectur model primat modelwa requir indic whether display subject requir describ size thu output model signal mean process unit model may correspond singl group term neuron refer actual wetwar output layer correspond cortic mst macaqu monkey appear sensit global motion imag known mst neuron distinguish unstructur input model base physiolog studi macaclu neuron area retinotop represent visual space posit recept field input optim veloc retinotop locat encod awid rang thu input cell differ combin retinotop spatial furthermor motion veloc oppon organ recept field data albright et typic recept field shown figur possibl determin activ input cell would rotat cylind given activ pattern set cell comput convolv veloc point differ activ input cell imag veloc present figur retinotop map retinotop map input activ pattern structur unstructur circl correspond cell input contour use linear interpol individu horizont axi posit along horizont vertic axi speed along horizont thu activ cell right hand coruer graph correspond veloc toward locat right along horizont input pattern suggest problem detect structur motion may reduc pattern recognit problem spars sampl input motion flow whether correspond best structur unstructur next necessari determin connect two input layer model abl correctli signal structur wide rang cylind radii rotat parallel network type use rosenberg sejnowski provid architectur parallel architectur use extract structur input layer correspond area posit speed along horizont output layer correspond area mst signal structur middl layer exist either input layer cell fulli connect middl layer layer cell repres intermedi stage process may cell middl layer fulli connect output input cell lower layer next higher level linearli use hill equat weight layer initi chosen valu adjust use method network would correctli predict structur input model learn correctli perform task iter network perform structur motion iter number plot squar error defin predict known model train set structur unstructur cylind wide rang number rotat number perform model perform compar monkey man fraction structur number point display inde perform global analysi shown allow model portion like man moder perform thu appear moder perform quit similar known human output monkey man machin monkey man machin structur number point psychophys perform effect vari fraction structur moder perform thirti repetit averag valu structur fraction structur defin radiu shuffl motion vector radiu human monkey taken psychophys studi model similar perform monkey next possibl examin artifici network order obtain hint studi biolog follow approach recept field map cell middl output layer made activ individu input recept field middl layer cell shown figur layout map quit similar figur activ one middl layer plot function locat speed motion input one could imagin electrod place one cell middl layer experimentalist move bar meridian differ locat activ cell plot function posit map activ two differ cell middl activ plot contour map function horizont posit dot line middl layer recept field map interest quit simpl inhibitori central region recept field surround excitatori region cell also inhibitori band adjac band result suggest neuron involv structur motion may rel simpl recept field veloc recept field might thought break compon part basi correct recombin order cell could use detect presenc output cell also simpl recept field interest recept field analysi insuffici role therefor order properli understand recept necessari use world case motion output cell would maxim respons cylind stimulu recept field map output layer recept field structur indic involv obtain structur work predict neuron cortex involv extract structur motion rel simpl recept order test necessari make care map cell use small motion known qualit result area mst necessari use stimuli simpl recept field inde use structur support found idea simpl cortic circuit use mani differ visual point patch random dot may necessari make care neuron use small patch order observ postul simpl field properti cortic neuron involv extract structur structur may appar use hand move bar possibl extract structur cylind use parallel network base similar function architectur found primat present model similar psychophys monkey recept field structur underli present model simpl view use suggest order visual system extract structur quantit map cortic neuron involv need one also need use stimuli deriv order understand may use visual field similar shape field involv analyz structur motion recept field cortex mayb similar cortic mechan connect use perform differ function differ cortic model use parallel architectur close model cortic comput effici mean solv problem thu final would like advis creator network solv realist problem use solut evolut siegel natur yon treatis physiolog optic siegel siegel local function effect iboten acid lesion motion sensit rhesu brain maunsel van rosenberg report cognit univers hubel work support salk institut biolog san diego ph,0
74,74,"709 
TIME-SEQUENTIAL SELF-ORGANIZATION OF HIERARCHICAL 
NEURAL NETWORKS 
Ronald H. Silverman 
Cornell University Medical College, New York, NY 10021 
Andrew S. Noetzel 
Polytechnic University, Brooklyn, NY 11201 
ABSTRACT 
Self-organization of multi-layered networks can be realized 
by time-sequential organization of successive neural layers. 
Lateral inhibition operating in the surround of firing cells in 
each layer provides for unsupervised capture of excitation 
patterns presented by the previous layer. By presenting patterns 
of increasing complexity, in co-ordination with network self- 
organization, higher levels of the hierarchy capture concepts 
implicit in the pattern set. 
INTRODUCTION 
A fundamental difficulty in self-organization of 
hierarchical, multi-layered, networks of simple neuron-like cells 
is the determination of the direction of adjustment of synaptic 
link weights between neural layers not directly connected to input 
or output patterns. Several different approaches have been used 
to address this problem. One is to provide teaching inputs to the 
cells in internal layers of the hierarchy. Another is use of 
back-propagated error signals 1'2 from the uppermost neural layer, 
which is fixed to a desired outu pattern. A third is the 
""competitive learning"" mechanism, in which a Hebbian synaptic 
modification rule is used, with mutual inhibition among cells of 
each layer preventing them from becoming conditioned to the same 
patterns. 
The use of explicit teaching inputs is generally felt to be 
undesirable because such signals must, in essence, provide 
individual direction to each neuron in internal layers of the 
network. This requires extensive control signals, and is somewhat 
contrary to the notion of a self-organizing system. 
Back-propagation provides direction for link weight 
modification of internal layers based on feedback from higher 
neural layers. This method allows true self-organization, but at 
the cost of specialized neural pathways over which these feedback 
signals must travel. 
In this report, we describe a simple feed-forward method for 
self-organization of hierarchical neural networks. The method is 
a variation of the technique of competitive learning. It calls 
for successive neural layers to initiate modification of their 
afferent synaptic link weights only after the previous layer has 
completed its own self-organization. Additionally, the nature of 
the patterns captured can be controlled by providing an organized 
American Institute of Physics 1988 
710 
group of pattern sets which would excite the lowermost (input) 
layer of the network in concert with training of successive 
layers. Such a collection of pattern sets might be viewed as a 
""lesson plan."" 
MODEL 
The network is composed of neuron-like cells, organized in 
hierarchical layers. Each cell is excited by variably weighted 
afferent connections from the outputs of the previous (lower) 
layer. Cells of the lowest layer take on the values of the input 
pattern. The cells themselves are of the McCulloch-Pitts type: 
they fire only after their excitation exceeds a threshold, and are 
otherwise inactive. Let Si(t) s{0,1} be the state of cell i at 
time t. Let wij , a real number ranging from 0 to 1, be the 
weight, or strength, of the synapse connecting cell i to cell j. 
Let eij be the local excitation of cell i at the synaptic 
connection from cell j. The excitation received along each 
synaptic connection is integrated locally over time as follows: 
eij(t) = eij(t-1) + wijSi(t) (1) 
Synaptic connections may, therefore be viewed as capacitive. 
The total excitation, Ej, is the sum of the local excitations of 
cell j. 
Ej(t) = eij (t) (2) 
The use of the time-integrated activity of a synaptic 
connection between two neurons, instead of the more usual 
instantaneous classification of neurons as ""active"" or ""inactive"", 
permits each synapse to provide a statistical measure of the 
activity of the input, which is assumed to be inherently 
stochastic. It also embodies the principle of learning based on 
locally available information and allows for implementations of 
the synapse as a capacitive element. 
Over time, the total excitation of individual neurons on a 
give layer will increase. When excitation exceeds a threshold, 
then the neuron fires, otherwise it is inactive. 
Sj (t) = 1 if Ej (t) > 0 (3) 
else 
sj (t) = 0 
During a neuron's training phase, a modified Hebbian rule 
results in changes in afferent synaptic link weights such that, 
upon firing, synapses with integrated activity greater than mean 
activity are reinforced, and those with less than mean activity 
are weakened. More formally, if Sj(t) = 1 then the synapse 
weights are modified by 
wij (t) = wij(t-1) + sign(eij (t) - O/n)k'sine(wij) (4) 
Here, n represents the fan-in to a cell, and k is a small, 
positive constant. The ""sign"" function specifies the direction of 
change and the ""sine"" function determines the magnitude of 
change. The sine curve provides the property that intermediate 
711 
link weights are subject to larger modifications than weights near 
zero or saturation. This helps provide for stable end-states 
after learning. 
Another effect of the integration of synaptic activity may be 
seen. A synapse of small weight is allowed to contribute to the 
firing of a cell (and hence have its weight incremented) if a 
series of patterns presented to the network consistently excite 
that synapse. The sequence of pattern presentations, therefore, 
becomes a factor in network self-organization. 
Upon firing, the active cell inhibits other cells in its 
vicinity (lateral inhibition). This mechanism supports 
unsupervised, competitive learning. By preventing cells in the 
neighborhood of an active cell from modifying their afferent 
connections in response to a pattern, they are left available for 
capture of new patterns. Suppose there are n cells in a 
particular level. The lateral inhibitory mechanism is specified 
as follows: 
If S(t) = 1 then 
eik(t) = 0 for all i, or k = (j-m)mod(n) to (j+m)mod(n) (5) 
Here, m specifies the size of a ""neighborhood."" A neighborhood 
significantly larger than a pattern set will result in a number of 
untrained cells. A neighborhood smaller than the pattern set will 
tend to cause cells to attempt to capture more than one pattern. 
Schematic representations of an individual cell and the 
network organization are provided in Figures 1 and 2. 
It is the pattern generator, or ""instructor"", that controls 
the form that network organization will take. The initial set of 
patterns are repeated until the first layer is trained. Next, a 
new pattern set is used to excite the lowermost (trained) level of 
the network, and so, induce training in the next layer of the 
hierarchy. Each of the patterns of the new set is composed of 
elements (or subpatterns) of the old set. The structure of 
successive pattern sets is such that each set is either a more 
complex combination of elements from the previous set (as words 
are composed of letters) or a generalization of some concept 
implicit in the previous set (such as line orientation). 
Network organization, as described above, requires some 
exchange of control signals between the network and the 
instructor. The instructor requires information regarding firing 
of cells during training in order to switch to a new patterns 
appropriately. Obviously, if patterns are switched before any 
cells fire, learning will either not take place or will be smeared 
over a number of patterns. If a single pattern excites the 
network until one or more cells are fully trained, subsequent 
presentation of a non-orthogonal pattern could cause the trained 
cell to fire before any naive cell because of its saturated link 
weights. The solution is simply to allow gradual training over 
the full complement of the pattern set. After a few firings, a 
new pattern should be provided. After a layer has been trained, 
the instructor provides a control signal to that layer which 
permanently fixes the layer's afferent synaptic link weights. 
712 
Excitation 
Lateral 
Inhibtio[ 
Lateral 
Inhibtion 
Excitatory Inputs 
Fig. 1. Schematic of neuron. 
Shading of afferent synaptic connections 
indicates variations in levels of local 
time-integrated excitation. 
Fig. 2. Schematic of network showing 
lateral inhibition and forward excitation. 
Shading of neurons, indicating degree of 
training, indicates time-sequential 
organization of successive neural layers. 
713 
SIMULATIONS 
AS an example, simulations were run in which a network was 
taught to differentiate vertical from horizontal line 
orientation. This problem is of interest because it represents a 
case in which pattern sets cannot be separated by a single layer 
of connections. This is so because the set of vertical (or 
horizontal) lines has activity at all positions within the input 
matrix. 
Two variations were simulated. In the firs simulation, the 
input was a 4x4 matrix. This was completely connected with 
unidirectional links to 25 cells. These cells had fixed 
inhibitory connections to the nearest five cells on either side 
(using a circular arrangement), and excited, using complete 
connectivity, a ring of eight cells, with inhibition over the 
nearest neighbor on either side. 
Initially, all excitatory link weights were small, random 
numbers. Each pattern of the initial input consisted of a single 
active row or column in the input matrix. Active elements had, 
during any clock cycle, a probability of 0.5 of being ""on"", while 
inactive elements had a 0.05 probability of being ""on."" 
After exposure to the initial pattern set, all cells on the 
first layer captured some input pattern, and all eight patterns 
had been captured by two or more cells. 
The next pattern set consisted of two subsets of four 
vertical and four horizontal lines. The individual lines were 
presented until a few firings took place within the trained layer, 
and then another line from the same subset was used to excite the 
network. After the upper layer responed with a few firings, and 
some training occured, the other set was used to excite the 
network in a similar manner. After five cycles, all cells on the 
uppermost layer had become sensitive, in a postionally independent 
manner, to lines of a vertical or a horizontal orientation. Due 
to lateral inhibition, adjacent cells developed opposite 
orientation specificities. 
In the second simulation, a 6x6 input matrix was connected to 
six cells, which were, in turn, connected to two cells. For this 
network, the lateral inhibitory range extended over the entire set 
of cells of each layer. The initial input set consisted of six 
patterns, each of which was a pair of either vertical lines or 
horizontal lines. After excitation by this set, each of the six 
middle level cells became sensitized to one of the input 
patterns. Next, the set of vertical and horizontal patterns were 
grouped into two subsets: vertical lines and horizontal lines. 
Individual patterns from one subset were presented until a cell, 
of the previously trained layer, fired. After one of the two 
cells on the uppermost layer fired, the procedure was repeated 
with the pattern set of opposite orientation. After 25 cycles, 
the two cells on the uppermost layer had developed opposite 
orientation specificities. Each of these cells was shown to be 
responsive, in a positionally independent manner, to any single 
714 
line of appropriate orientation. 
CONCLUSION 
Competitive learning mechanisms, when applied sequentially to 
successive layers in a hierarchical structure, can capture pattern 
elements, at lower levels of the hierarchy, and their 
generalizations, or abstractions, at higher levels. 
In the above mechanism, learning is externally directed, not 
by explicit teaching signals or back-propagation, but by provision 
of instruction sets consisting of patterns of increasing 
complexity, to be input to the lowermost layer of the network in 
concert with successive organization of higher neural layers. 
The central difficulty of this method involves the design of 
pattern sets - a procedure whose requirements may not be obvious 
in all cases. The method is, however, attractive due to its 
simplicity of concept and design, providing for multi-level self- 
organization without direction by elaborate control signals. 
Several research goals suggest themselves: 1) simplification 
or elimination of control signals, 2) generalization of rules for 
structuring of pattern sets, 3) extension of this learning 
principle to recurrent networks, and 4) gaining a deeper 
understanding of the role of time as a factor in network self- 
organization. 
REFERENCES 
1. D. E. Rumelhart and G.E. Hinton, Nature 323, 533 (1986). 
2. K. A. Fukushima, Biol. Cybern. 55, 5 (1986). 
3. D. E. Rumelhart and D. Zipser, Cog. Sci. 9, 75 (1985). 
", hierarch network silverman univers medic new ny noetzel ny network realiz organ success neural inhibit oper surround fire cell layer provid unsupervis captur excit present previou present pattern increas network higher level hierarchi captur concept pattern fundament difficulti network simpl cell determin direct adjust synapt weight neural layer directli connect input output sever differ approach use address one provid teach input intern layer anoth use error signal uppermost neural fix desir third hebbian synapt rule mutual inhibit among cell layer prevent becom condit use explicit teach input gener felt signal provid direct neuron intern layer requir extens control somewhat notion provid direct link weight intern layer base feedback higher method allow true cost special neural pathway feedback must describ simpl method hierarch neural method variat techniqu competit call success neural layer initi modif synapt link weight previou layer natur pattern captur control provid organ institut physic pattern set would excit lowermost network concert train success collect pattern set might view network compos organ cell excit variabl weight connect output previou cell lowest layer take valu input cell fire excit exce let state cell let wij real number rang synaps connect cell cell eij local excit cell synapt cell excit receiv along connect integr local time connect therefor view total sum local excit use activ synapt two instead usual classif neuron synaps provid statist measur assum inher also embodi principl learn base avail inform allow implement synaps capacit total excit individu neuron layer excit exce neuron otherwis ej train modifi hebbian rule chang affer synapt link weight synaps integr activ greater mean less mean activ synaps modifi repres function specifi direct function determin magnitud sine curv provid properti intermedi weight subject larger modif weight near help provid stabl effect integr synapt activ may synaps small weight allow contribut cell henc weight pattern present network consist excit sequenc pattern factor network activ cell inhibit cell mechan support competit prevent cell activ cell modifi affer respons left avail new suppos cell later inhibitori mechan specifi specifi size neighborhood larger pattern set result number neighborhood smaller pattern set caus cell attempt captur one represent individu cell organ provid figur pattern control form network organ initi set repeat first layer pattern set use excit lowermost level induc train next layer pattern new set compos old structur pattern set set either combin element previou set word compos gener concept previou set line describ requir control signal network instructor requir inform regard fire cell train order switch new pattern pattern switch learn either take place smear number singl pattern excit one cell fulli subsequ pattern could caus train fire naiv cell satur link solut simpli allow gradual train full complement pattern pattern layer instructor provid control signal layer fix affer synapt link input schemat affer synapt connect variat level local schemat network show inhibit forward indic degre indic success neural simul run network differenti vertic horizont line problem interest repres pattern set can not separ singl layer set vertic line activ posit within input variat complet connect link cell fix connect nearest five cell either side circular use complet ring eight inhibit neighbor either excitatori link weight random pattern initi input consist singl row column input activ element clock probabl element probabl exposur initi pattern cell layer captur input eight pattern captur two next pattern set consist two subset four four horizont individu line fire took place within train anoth line subset use excit upper layer respon train set use excit similar five cell layer becom postion independ line vertic horizont due later adjac cell develop opposit second input matrix connect connect two later inhibitori rang extend entir set cell initi input set consist six pair either vertic line excit six level cell becam sensit one input set vertic horizont pattern two vertic line horizont pattern one subset present previous train one two uppermost layer procedur repeat pattern set opposit two cell uppermost layer develop opposit cell shown posit independ singl appropri learn appli sequenti layer hierarch captur pattern lower level higher learn extern explicit teach signal provis instruct set consist pattern increas input lowermost layer network success organ higher neural central difficulti method involv design set procedur whose requir may obviou method attract due concept provid without direct elabor control research goal suggest simplif elimin control gener rule pattern extens learn recurr gain deeper role time factor network rumelhart natur rumelhart,2
75,75,"840 
LEARNING IN NETWORKS OF 
NONDETERMINISTIC ADAPTIVE LOGIC ELEMENTS 
Richard C. Windecker* 
AT&T Bell Laboratories, Middletown, NJ 07748 
ABSTRACT 
This paper presents a model of nondeterministic adaptive automata that are 
constructed from simpler nondeterministic adaptive information processing 
elements. The first half of the paper describes the model. The second half discusses 
some of its significant adaptive properties using computer simulation examples. 
Chief among these properties is that network aggregates of the model elements can 
adapt appropriately when a single reinforcement channel provides the same positive 
or negative reinforcement signal to all adaptive elements of the network at the same 
time. This holds for multiple-input, multiple-output, multiple-layered, 
combinational and sequential networks. It also holds when some network elements 
are ""hidden"" in that their outputs are not directly seen by the external 
environment. 
INTRODUCTION 
There are two primary motivations for studying models of adaptive automata 
constructed from simple parts. First, they let us learn things about real biological 
systems whose properties are difficult to study directly: We form a hypothesis 
about such systems, embody it in a model, and then see if the model has reasonable 
learning and behavioral properties. In the present work, the hypothesis being tested 
is: that much of an animal's behavior as determined by its nervous system is 
intrinsically nondeterministic; that learning consists of incremental changes in the 
probabilities governing the animal's behavior; and that this is a consequence of the 
animal's nervous system consisting of an aggregate of information processing 
elements some of which are individually nondeterministic and adaptive. The second 
motivation for studying models of this type is to find ways of building machines 
that can learn to do (artificially) intelligent and practical things. This approach has 
the potential of complementing the currently more developed approach of 
programming intelligence into machines. 
We do not assert that there is necessarily a one-to-one correspondence 
between real physiological neurons and the postulated model information processing 
elements. Thus, the model may be loosely termed a ""neural network model,"" but is 
more accurately described as a model of adaptive automata constructed from simple 
adaptive parts. 
The main ideas in this paper were conceived and initially developed while the 
author was at the University of Chiang Mai, Thailand (1972-73). The ideas were 
developed further and put in a form consistent with existing switching and 
automata theory during the next four years. For two of those years, the author 
was at the University of Guelph, Ontario, supported of National Research 
Council of Canada Grant #A6983. 
@ American Institute of Physics 1988 
841 
It almost certainly has to be a property of any acceptable model of animal 
learning that a single reinforcement channel providing reinforcement to all the 
adaptive elements in a network (or subnetwork) can effectively cause that network 
to adapt appropriately. Otherwise, methods of providing separate, specific 
reinforcement to all adaptive elements in the network must be postulated. Clearly, 
the environment reinforces an animal as a whole and the same reinforcement 
mechanism can cause the animal to adapt to many types of situation. Thus, the 
reinforcement system is non-specific to particular adaptive elements and particular 
behaviors. The model presented here has this property. 
The model described here is a close cousin to the family of models recently 
described by Barto and coworkers 1-4 The most significant difference are: 1) In 
the present model, we define the timing discipline for networks of elements more 
explicitly and completely. This particular timing discipline makes the present 
model consistent with a nondeterministic extension of switching and automata 
theory previously described 5. 2) In the present model, the reinforcement algorithm 
that adjusts the weights is kept very simple. With this algorithm, positive and 
negative reinforcement have symmetric and opposite effects on the weights. This 
ensures that the logical signals are symmetric opposites of each other. (Even small 
differences in the reinforcement algorithm can make both subtle as well as profound 
differences in the behavior of the model.) We also allow, null, or zero, 
reinforcement. 
As in the family of models described by Barto, networks constructed within 
the present model can get ""stuck"" at a suboptimal behavior during learning and 
therefore not arrive at the optimal adapted state. The complexity of the Barto 
reinforcement algorithm is designed partly to overcome this tendency. In the 
present work, we emphasize the use of training strategies when we wish to ensure 
that the network arrives at an optimal state. (In nature, it seems likely that getting 
""stuck"" at suboptimal behavior is common.) In all networks studied so far, it has 
been easy to find strategies that prevent the network from getting stuck. 
The chief contributions of the present work are: 1) The establishment of a 
close connection between these types of models and ordinary, nonadaptive, 
switching and automata theory 5. This makes the wealth of knowledge in this area, 
especially network synthesis and analysis methods, readily applicable to the study 
of adaptive networks. 2) The experimental demonstration that sequential 
(""recurrent"") nondeterministic adaptive networks can adapt appropriately. Such 
networks can learn to produce outputs that depend on the recent sequence of past 
inputs, not just the current inputs. 3) The demonstration that the use of training 
strategies can not only prevent a network from getting stuck, but may also result in 
more rapid learning. Thus, such strategies may be able to compensate, or even 
more than compensate, for reduced complexity in the model itself. References 
2-4 and 6 provide a comprehensive background and guide to the 
literature on both deterministic and nondeterministic adaptive automata including 
those constructed from simple parts and those not. 
THE MODEL ADAPTIVE ELEMENT 
The model adaptive element postulated in this work is a nondeterministic, 
adaptive generalization of threshold logic 7. Thus, we call these elements 
Nondeterministic Adaptive Threshold-logic gates (NATs). The output chosen by a 
NAT at any given time is not a function of its inputs. Rather, it is chosen by a 
stochastic process according to certain probabilities. It is these probabilities that 
are a function of the inputs. 
A NAT is like an ordinary logic gate in that it accepts logical inputs that are 
two-valued and produces a logical output that is two-valued. We let these values be 
842 
+1 and -1. A NAT also has a timing input channel and a reinforcement input 
channel. The NAT operates on a three-part cycle: 1) Logical input signals are 
changed and remain constant. 2) A timing signal is received and the NAT selects a 
new output based on the inputs at that moment. The new output remains 
constant. 3) A reinforcement signal is received and the weights are incremented 
according to certain rules. 
Let N be the number of logical input channels, let xi represent the i th input 
signal, and let z be the output. The NAT has within it N+I ""weights,"" 
Wo, w, ..., wv. The weights are confined to integer values. For a given set of 
inputs, the gate calculates the quantity W: 
W = Wo + WlX + w2x2 + wsx3 + .... + WNXN = Wo + -"" (1) 
Then the probability that output z = q-1 is chosen is: 
w 
P(z = q- 1) = I  --- 
VO' - � 
�  '/v' 
I  
dx = f e- (2) 
where  = x/v/-er. (An equivalent formulation is to let the NAT generate a 
random number, w, according to the normal distribution with mean zero and 
variance tr 2. Then if W >-w, the gate selects the output z = +1. If 
W -w, the gate se]ects output z= -1. If W= -w, the gate selects output 
-1 or + 1 with equal probability.) 
Reinforcement signals, R, may have one of three values: q-l, --1, and 0 
representing positive, negative, and no reinforcement, respectively. If +1 
reinforcement is received, each weight is incremented by one in the direction that 
makes the current output, z, more likely to occur in the future when the same 
inputs are applied; if-1 reinforcement is received, each weight is incremented in 
the direction that makes the current output less likely; if 0 reinforcement is 
received, the weights are not changed. These rules may be summarized: AWo = zR 
and AWl = xizR for i > 0. 
NATs operate in discrete time because if the NAT can choose output +1 or 
-1, depending on a stochastic process, it has to be told when to select a new 
output. It cannot ""run freely,"" or it could be constantly changing output. Nor can 
it change output only when its inputs change because it may need to select a new 
output even when they do not change. 
The normal distribution is used for heuristic reasons. If a real neuron (or an 
aggregate of neurons) uses a stochastic process to produce nondeterministic 
behavior, it is likely that process can be described by the normal distribution. In 
any case, the exact relationship between P(z ---- +1) and W is not critical. What is 
important is that P(z = +1) be monotonically increasing in W, go to 0 and 1 
asymptotically as W goes to -oe and + oe, respectively, and equal 0.5 at W -- 0. 
The parameter tr is adjustable. We use 10 in the computer simulation 
experiments described below. Experimentally, values near 10 work reasonably well 
for networks of NATs having few inputs. Note that as tr goes to zero, the behavior 
of a NAT approximates that of an ordinary deterministic adapt, ire threshold logic 
gate with the difference that the output for the case W = 0 is not arbitrary: The 
NAT will select output + 1 or --1 with equal probability. 
Note that for all values of W, the probabilities are greater than zero that 
either + 1 or --1 will be chosen, although for large values of W (relative to tr) for all 
843 
practical purposes, the behavior is deterministic. There are many values of the 
weights that cause the NAT to approximate the behavior of a deterministic 
threshold logic gate. or the same reasons that deterministic threshold logic gates 
cannot realize all 2 2 functions of N variables 7, so a NAT cannot learn to 
approximate any deterministic function; only the threshold logic functions. 
Note also that when the weights are near zero, a NAT adapts most rapidly 
when both positive and negative reinforcement are used in approximately equal 
amounts. As the NAT becomes more likely to produce the appropriate behavior, 
the opportunity to use negative reinforcement decreases while the opportunity to 
use positive reinforcement increases. This means that a NAT cannot learn to 
(nearly) always select a certain output if negative reinforcement alone is used. 
Thus, positive reinforcement has an important role in this model. (In most 
deterministic models, positive reinforcement is not useful.) 
Note further that there is no hysteresis in NAT learning. For a given 
configuration of inputs, a +1 output followed by a +1 reinforcement has exactly the 
same effect on all the weights as a --1 output followed by a -1 reinforcement. So 
the order of such events has no effect on the final values of the weights. 
Finally, if only negative reinforcement is applied to a NAT, independent of 
output, for a particular combination of inputs, the weights will change in the 
direction that makes IV tend toward zero and once there, follow a random walk 
centered on zero. (The further Wis from zero, the more likely its next step will be 
toward zero.) If all possible input combinations are applied with more or less equal 
probability, all the weights will tend toward zero and then follow random walks 
centered on zero. In this case, the NAT will select +1 or --1 with more or less 
equal probability without regard to its inputs. 
NETWORKS 
NATs may be connected together in networks (NAT-nets). The inputs to a 
NAT in such a network can be selected from among: 1) the set of inputs to the 
entire network, 2) the set of outputs from other NATs in the network, and 3) its 
own output. The outputs of the network may be chosen from among: 1) the inputs 
to the network as a whole, and 2) the outputs of the various NATs in the network. 
Following Ref. 5, we impose a timing discipline on a NAT-net. The network is 
organized into layers such that each NAT belongs to one layer. Letting L be the 
number of layers, the network operates as follows: 1) All NATs in a given layer 
receive timing signals at the same time and select a new output at the same time. 
2) Timing signals are received by the different layers, in sequence, from i to L. 3) 
Inputs to the network as a whole are levels that may change only before Layer 1 
receives its timing signal. Similarly, outputs from the network as a whole are 
available to the environment only after Layer L has received its timing signal. 
Reinforcement to the network as a whole is accepted only after outputs are made 
available to the environment. The same reinforcement signal is distributed to all 
NATs in the network at the same time. 
With these rules, NAT-nets operate through a sequence of timing cycles. In 
each cycle: 1) Network inputs are changed. 2) Layers 1 through L select new 
outputs, in sequence. 3) Network outputs are made available to the environment. 
4) Reinforcement is received from the environment. We call each such cycle a 
""trial"" and a sequence of such trials is a ""session."" 
This model is very general. If, for each gate, inputs are selected only from 
among the inputs to the network as a whole and from the outputs of gates in layers 
preceding it in the timing cycle, then the network is combinational. In this case, the 
probability of the network producing a given output configuration is a function of 
the inputs at the start of the timing cycle. If at least one NAT has one input from a 
844 
NAT in the same layer or from a subsequent layer in the timing cycle, then the 
network is sequential. In this case, the network may have ""internal states"" that 
allow it to remember information from one cycle to the next. Thus, the 
probabilities governing its choice of outputs may depend on inputs in previous 
cycles. So sequential NAT-nets may have short-term memory embodied in internal 
states and long-term memory embodied in the weights. In Ref. 5, we showed that 
sequential networks can be constructed by adding feedback paths to combinational 
networks and any sequential network can be put in this standard form. 
In information-theoretic terms: 1) A NAT-net with no inputs and some 
outputs is an ""information source."" 2) A NAT-net with both inputs and outputs is 
an information ""channel."" 3) A combinational NAT-net is ""memory-less"" while a 
sequential NAT-net has memory. In this context, note that a NAT-net may operate 
in an environment that is either deterministic or nondeterministic. Both the logical 
and the reinforcement inputs can be selected by stochastic processes. Note also 
that nondeterministic and deterministic elements as well as adaptive and 
nonadaptive elements can be combined in one network. (It may be that the 
decision-making parts of an animal's nervous system are nondeterministic and 
adaptive while the information transmitting parts (sensory data-gathering and the 
motor output parts) are deterministic and nonadaptive.) 
One capability that combinational NAT-nets possess is that of ""pattern 
recognizers."" A network having many inputs and one or a few outputs can 
""recognize"" a small subset of the potential input patterns by producing a particular 
output pattern with high probability when a member of the recognized subset 
appears and a different output pattern otherwise. In practice, the number of 
possible input patterns may be so large that we cannot present them all for training 
purposes and must be content to train the network to recognize one subset by 
distinguishing it (with different output pattern) from another subset. In this case, 
if a pattern is subsequently presented to the network that has not been in one of 
the training sets, the probabilities governing its output may approach one or zero, 
but may well be closer to 0.5. The exact values will depend on the details of the 
training period. If the new pattern is similar to those in one of the training sets, the 
NAT-net will often have a high probability of producing the same output as for that 
set. This associative property is the analog of the well known associative property 
in deterministic models. If the network lacks sufficient complexity for the 
separation we wish to make, then it cannot be trained. For example, a single N- 
input NAT cannot be trained to recognize any arbitrary set of input patterns by 
selecting the -t-1 output when one of them is presented and -1 otherwise. It can 
only be trained to make separations that correspond to threshold functions. 
A combinational NAT-net can also produce patterns. By analogy with a 
pattern recognizer, a NAT-net with none or a few inputs and a larger number of 
outputs can learn for each input pattern to produce a particular subset of the 
possible output patterns. Since the mapping may be few-to-many, instead of 
many-to-few, the goal of training in this case may or may not be to have the 
network approximate deterministic behavior. Clearly, the distinction between 
pattern recognizers and pattern producers is somewhat arbitrary: in general, NAT- 
nets are pattern transducers that map subsets of input patterns into subsets of 
output patterns. A sequential network can ""recognize"" patterns in the time- 
sequence of network inputs and produce patterns in the time-sequence of outputs. 
SIMULATION EXPERIMENTS 
In this Section, we discuss computer simulation results for three types of 
multiple-element networks. For two of these types, certain strategies are used to 
train the networks. In general, these strategies have two parts that alternate, as 
845 
needed. The first part is a general scheme for providing network inputs and 
reinforcement that tends to train all elements in the network in the desired 
direction. The second part is substituted temporarily when it becomes apparent 
that the network is getting stuck in some suboptimal behavior. It is focussed on 
getting the network unstuck. The strategies used here are intuitive. In general, 
there appear to be many strategies that will lead the network to the desired 
behavior. While we have made some attempt to find strategies that are reasonably 
efficient, it is very unlikely that the ones used are optimal. Finally, these strategies 
have been tested in hundreds of training sessions. Although they worked in all such 
sessions, there may be some (depending on the sequence of random numbers 
generated) in which they would not work. 
In describing the networks simulated, Figs. 1-3, we use the diagramatic 
conventions defined in Ref. 5: We put all NATs in the same layer in a vertical line, 
with the various layers arranged from left to right in their order in the timing cycle. 
Inputs to the entire network come in from the left; outputs go out to the right. 
Because the timing cycle is fixed, we omit the timing inputs in these figures. For 
similar reasons, we also omit the reinforcement inputs. 
In the simulations described here, the weights in the NATs start at zero 
making the network outputs completely random in the sense that on any given 
trial, all outputs are equally likely to occur, independent of past or present inputs. 
As learning proceeds, some or all the weights become large, so that the NAT-net's 
selection of outputs is strongly influenced by some or all of its inputs and internal 
connections. (Note that if the weights do not start at zero, they can be driven close 
to zero by using negative reinforcement.) In general, the optimum behavior toward 
which the network adapts is deterministic. However, because the probabilities are 
never identically equal to zero or one, we apply an arbitrary criterion and say that a 
NAT-net has learned the appropriate behavior when that criterion is satisfied. In 
real biological systems, we cannot know the weights or the exact probabilities 
governing the behavior of the individual adaptive elements. Therefore, it is 
appropriate to use a criterion based on observable behavior. For example, the 
criterion might be that the network selects the correct response (and continues to 
receive appropriate reinforcement) 25 times in a row. 
Note that NAT-nets can adapt appropriately when the environment is not 
deliberately trying to make the them behave in a particular way. For example, the 
environment may provide inputs according to some (not necessarily deterministic) 
pattern and there may be some independent mechanism that determines whether 
the NAT-net is responding appropriately or not and provides the reinforcement 
accordingly. One paradigm for this situation is a game in which the NAT-net and 
the environment are players. The reinforcement scheme is simple: if, according to 
the rules of the game, the NAT-net wins a play (= trial) of the game, reinforcement 
is + 1 , if it loses, -1. 
For a NAT-net to adapt appropriately in this situation, the game must consist 
of a series of similar plays. If the game is competitive, the best strategy a given 
player has depends on how much information he has about the opponent and vice 
versa. If a player assumes that his opponent is all-knowing, then his best strategy is 
to minimize his maximum loss and this often means playing at random, or a least 
according to certain probabilities. If a player knows a lot about how his opponent 
plays, his best strategy may be to maximize gain. This often means playing 
according to some deterministic strategy. 
The example networks described here are special cases of three types: pattern 
producing (combinational multiple-output) networks, pattern recognizing 
(combinational multiple-input, multiple-layered, few-output) networks, and game 
playing (sequential) networks. The associative properties of NATs and NAT-nets 
846 
are not emphasized here because they are analogous to the well known associative 
properties of other related models. 
A Class of Simple Pattern Producing Networks 
A simple class of pattern producing 
networks consists of the single-layer type 
shown in Fig. 1. Each of M NATs in such a 
network has no inputs, only an output. As a 
consequence, each has only one weight, w 0. 
The network is a simple, adaptive, information 
source. 
Consider first the case in which the ':% 
network contains only one NAT and we wish to ' 
� ; 
train it to always produce a simple ""pattern,"" 
: : 
+1. We give positive reinforcement when it  : 
selects q- 1 and negative reinforcement 
otherwise. If w0 starts at 0, it will quickly 
gr.ow large making the probability of selecting 
q-1 approach unity. The criterion we use for Fig. 1. A Simple Pattern 
deciding that the network is trained is that it Producing Network 
produce a string of 25 correct outputs. Table I 
shows that in 100 sessions, this one-NAT network selected +1 output for the next 
25 trials starting, on average, at trial 13. 
Next consider a network with two NATs. They can produce four different 
output patterns. If both weights are 0, they will produce each of the patterns with 
equal probability. But they can be trained to produce one pattern (nearly) all the 
time. If we wish to train this subnetwork to produce the pattern (in vector 
notation) [q-1 q-l], one strategy is to give no 
reinforcement if it produces patterns [-1 +1] or M Min Ave Max 
[+1-1], give it positive reinforcement if it 
produces [+1 +1] and negative reinforcement if 1 1 13 26 
it produces [-1-1]. Table I shows that in 100 2 8 25 43 
sessions, this network learned to produce the 4 18 35 60 
desired pattern (by producing a string of 25 8 44 70 109 
correct outputs) in about 25 trials. Because we 16 49 115 215 
initially gave reinforcement only about 50% of 
the time, it took longer to train two NATS Table I. Training Times For 
than one. Networks Per Fig. 1. 
Next, consider the 16-NAT network in 
Fig. 1. Now there are 216 possible patterns the network can produce. When all the 
weights are zero, each has probability 2 -16 of being produced. An ineffective 
strategy for training this network is to provide positive reinforcement when the 
desired pattern is produced, negative reinforcement when its opposite is produced, 
and zero reinforcement otherwise. A better strategy is to focus on one output of the 
network at a time, training each NAT separately (as above) to have a high 
probability of producing the desired output. Once all are trained to a relatively 
high level, the network as a whole has a reasonable chance of producing exactly the 
correct output. Now we can provide positive reinforcement when it does and no 
reinforcement otherwise. With this two-stage hybrid strategy, the network will 
soon meet the training criterion. The time it takes to train a network of M 
elements with a strategy of this type is roughly proportional to M, not 2 (M- 1), as 
for the first strategy. 
847 
A still more efficient strategy is to alternate between a general substrategy 
and a substrategy focussed on keeping the network from getting ""stuck."" One 
effective general substrategy is to give positive reinforcement when more than half 
of the NATs select the desired output, negative reinforcement when less than half 
select the desired output, and no reinforcement when exactly half select the desired 
output. This substrategy starts out with approximately equal amounts of positive 
and negative reinforcement being applied. Soon, the network selects more than half 
of the outputs correctly more and more of the time. Unfortunately, there will tend 
to be a minority subset with low probability of selecting the correct output. At this 
stage, we must recognize this subset and switch to a substrategy that focuses on the 
elements of this subset following the strategy for one or two elements, above. When 
all NATs have a sufficiently high probability of selecting the desired output, 
training can conclude with the first substrategy. 
The strategies used to obtain the results for M = 4,8, and 16 in Table I were 
slightly more complicated variants of this two-part strategy. In all of them, a 
running average was kept of the number of right responses given by each NAT. 
Letting Ci be the ""correct"" output for zi, the running average after the t th trial, 
Ji( t), is: 
Ai(t) = BAi(t- 1) + Cizi(t) 
where B is a fraction generally in the range 0.75 to 0.9. If Ai(t) for a particular i 
gets too far below the combined average for all i, then training focuses on the i 
element until its average improves. The significance of the results given in Table I 
is not the details of the strategies used, nor how close the training times may be to 
the optimum. Rather, it is the demonstration that training strategies exist such 
that the training time grows significantly more slowly than in proportion to M. 
A Simple Pattern Recognizing Network 
As mentioned above, there are fewer 
threshold logic functions of N variables (for 
N  1) than the total possible functions. 
For N = 2, there are 14. The remining two 
are the ""exclusive or"" (XOR) and its 
complement. Multi-layered networks are 
needed to realize these functions, and an Fig. 2. A Two-Element Network 
important test of any adaptive network That Learns XOR 
model is its ability to learn XOR. The 
network in Fig. 2 is one of the simplest networks capable of learning this function. 
Table II gives the results of 100 training sessions with this network. The strategy 
used to obtain these 
results again had two Network Function Min Ave Max 
parts. The general part Fig. 2 OR 18 57 106 
consisted of supplying Fig. 2 XOR 218 681 1992 
each of the four possible Ref. 2 XOR ~700 -3500 ~ 14,300 
input patterns to the Ref. 8 XOR 2232 - - 
network in rotation, 
giving appropriate Table II. Training Times For The 
reinforcement each trial. Network In Fig. 2. 
The second part involved 
keeping a running average (similar to Eq. (3)) of the responses of the network by 
input combination. When the average for one combination fell significantly behind 
848 
the average for all, training was focused on just that combination until performance 
improved. The criterion used for deciding when training was complete was a 
sequence of 50 correct responses (for all input patterns together). 
For comparison, Table II shows results for the same network trained to realize 
the normal OR function. Also shown for comparison are numbers taken from Refs. 
2 and 8 for the equivalent network in those different models. These are 
nondeterministic and deterministic models, respectively. The numbers from Ref. 2 
are not exactly comparable with the present results for several reasons. These 
include: 1) The criterion for judging when the task was learned was not the same; 
2) In Ref. 2, the ""wrong"" reinforcement was deliberately applied 10% of the time to 
test learning in this situation; 3) Neither model was optimized for the particular 
task at hand. Nonetheless, if these (and other) differences were taken into account, 
it is likely that the NAT-net would have learned the XOR function significantly 
faster. 
The significance of the present results is that they suggest that the use of a 
training strategy can not only prevent a network from getting stuck, but may also 
facilitate more rapid learning. Thus, such strategies can compensate, or more than 
compensate, for reduced complexity in the reinforcement algorithm. 
A Simple Game-Playing Network 
Here, we consider NAT-nets in the context of the game of ""matching 
pennies."" In this game, each player has a stack of pennies. At each play of the 
game, each player places one of his pennies, heads up or heads down, but covered, in 
front of him. Each player uncovers his penny at the same time. If they match, 
player A adds both to his stack, otherwise, player B takes both. 
Game theory says that the strategy of each player that minimizes his 
maximum loss is to play heads and tails at random. Then A cannot predict B's 
behavior and at best can win 50% of the time and likewise for B with respect to A. 
This is a conservative strategy on the part of each player because each assumes that 
the other has (or can derive through a sequence of plays), and can use, information 
about the other player's strategy. Here, we make the different assumption that: 1) 
Player B does not play at random, 2) Player B has no information about A's 
strategy, and 3) Player B is incapable of inferring any information about A through 
a sequence of plays and in any event is incapable of changing its strategy. Then, if 
A has no information about B's pattern of playing at the start of the game, A's best 
course of action is to try to infer a non-random pattern in B's playing through a 
sequence of plays and subsequently take advantage of that knowledge to win more 
often than 50% of the time. An adaptive NAT-net, as A, can adapt appropriately 
in situations of this type. For example, suppose a single NAT of the type in Fig. 1 
plays A, where -1 output means heads, -1 output means tails. A third agent 
supplies reinforcement -1 if the NAT wins a play, -1 otherwise. Suppose B plays 
heads with 0.55 probability and tails with 0.45 probability. Then A will learn over 
time to play heads 100% of the time and thereby maximize its total winnings by 
winning 55% of the time. 
A more complicated situation is the following. Suppose B repeats its own 
move two plays ago $0% of the time, and plays the opposite 20% of the time. A 
NAT-net with the potential to adapt to this strategy and win 80% of the time is 
shown in Fig. 3. This is a sequential network shown in the standard form of a 
combinational network (in the dotted rectangle) plus a feedback path. The input to 
the network at time t is B's play at t - 1. The output is A's move. The top NAT 
selects its output at time t based partly on the bottom NAT's output at time 
t - 1. The bottom NAT selects its output at t - I based on its input at that time 
which is B's output at t - 2. Thus, the network as a whole can learn to select its 
849 
output based on B's play two time increments past. 
resulted in the network learning to do this 
98 times. On average, it took 468 plays 
(Min 20, max 4137) to reach the point at 
which the network repeated B's move two 
times past on the next 50 plays. For ", network adapt logic element bell nj paper present model nondeterminist adapt automata simpler nondeterminist adapt inform process first half paper describ second half discuss signific adapt properti use comput simul among properti network aggreg model element appropri singl reinforc channel provid posit neg reinforc signal adapt element network hold sequenti also hold network element output directli seen extern two primari motiv studi model adapt automata simpl let us learn thing real biolog whose properti difficult studi form hypothesi embodi see model reason behavior present hypothesi test much behavior determin nervou system learn consist increment chang govern consequ nervou system consist aggreg inform process individu nondeterminist second studi model type find way build machin learn intellig practic approach potenti complement current develop approach intellig assert necessarili correspond real physiolog neuron postul model inform process model may loos term network accur describ model adapt automata construct simpl main idea paper conceiv initi develop univers chiang thailand idea put form consist exist switch theori next four two author univers support nation research canada grant american institut physic almost certainli properti accept model anim singl reinforc channel provid reinforc element network effect caus network adapt method provid specif adapt element network must environ reinforc anim whole reinforc caus anim adapt mani type system particular adapt element particular model present model describ close cousin famili model recent barto cowork signific differ present defin time disciplin network element particular time disciplin make present consist nondeterminist extens switch automata previous describ present reinforc algorithm adjust weight kept posit reinforc symmetr opposit effect logic signal symmetr opposit small reinforc algorithm make subtl well profound behavior also famili model describ network construct within present model get suboptim behavior learn arriv optim adapt complex barto algorithm design partli overcom emphas use train strategi wish ensur network arriv optim seem like get suboptim behavior network studi easi find strategi prevent network get chief contribut present work establish connect type model automata theori make wealth knowledg network synthesi analysi readili applic studi adapt experiment demonstr sequenti nondeterminist adapt network adapt learn produc output depend recent sequenc past current demonstr use train prevent network get may also result rapid strategi may abl even reduc complex model refer provid comprehens background guid determinist nondeterminist adapt automata includ construct simpl part model adapt element model adapt element postul work gener threshold logic call element adapt gate output chosen given time function chosen process accord certain probabl function nat like ordinari logic gate accept logic input produc logic output let valu nat also time input channel reinforc input nat oper logic input signal remain time signal receiv nat select output base input new output remain reinforc signal receiv weight increment certain number logic input let xi repres th input let nat within weight confin integ given set gate calcul quantiti wo wnxn wo probabl output chosen equival formul let nat gener accord normal distribut mean zero tr gate select output gate output gate select output equal may one three weight increment one direct current like occur futur reinforc weight increment direct make current output less reinforc weight rule may awo awl oper discret time nat choos output depend stochast told select new can not could constantli chang chang output input chang may need select new even normal distribut use heurist real neuron use stochast process produc nondeterminist like process describ normal exact relationship monoton increas go goe equal paramet tr use comput simul describ valu near work reason well network nat note tr goe behavior nat approxim ordinari determinist ire threshold logic differ output case select output equal valu probabl greater zero although larg valu behavior mani valu caus nat approxim behavior determinist logic reason determinist threshold logic gate realiz function variabl nat can not learn determinist threshold logic also weight near nat adapt rapidli posit neg reinforc use approxim equal nat becom like produc appropri opportun use neg reinforc decreas opportun posit reinforc mean nat can not learn alway select certain output neg reinforc alon posit reinforc import role posit reinforc hysteresi nat given output follow reinforc exactli effect weight output follow order event effect final valu neg reinforc appli independ particular combin weight chang make iv tend toward zero follow random walk wi like next step possibl input combin appli less equal weight tend toward zero follow random walk nat select less probabl without regard may connect togeth network input network select set input set output nat output network may chosen input network output variou nat impos time disciplin network layer nat belong one let network oper nat given layer time signal time select new output time signal receiv differ network whole level may chang layer time output network whole environ layer receiv time network whole accept output made reinforc signal distribut network oper sequenc time network input layer select new network output made avail reinforc receiv call cycl sequenc trial model input select input network whole output gate layer time network network produc given output configur function input start time least one nat one input layer subsequ layer time network may rememb inform one cycl govern choic output may depend input previou sequenti may memori embodi intern memori embodi show network construct ad feedback path combin sequenti network put standard input input output inform combin note may oper environ either determinist logic reinforc input select stochast note also nondeterminist determinist element well adapt element combin one may part nervou system nondeterminist inform transmit part output determinist capabl combin possess network mani input one output small subset potenti input pattern produc particular pattern high probabl member recogn subset differ output pattern number input pattern may larg can not present train must content train network recogn one subset differ output anoth pattern subsequ present network one train probabl govern output may approach one may well closer exact valu depend detail new pattern similar one train often high probabl produc output associ properti analog well known associ properti determinist network lack suffici complex wish can not singl nat can not train recogn arbitrari set input pattern output one present train make separ correspond threshold combin also produc analog none input larger number learn input pattern produc particular subset output sinc map may instead goal train case may may approxim determinist distinct recogn pattern produc somewhat pattern transduc map subset input pattern subset sequenti network pattern network input produc pattern experi discuss comput simul result three type two certain strategi use strategi two part first part gener scheme provid network input tend train element network desir second part substitut temporarili becom appar network get stuck suboptim focuss network strategi use appear mani strategi lead network desir made attempt find strategi reason unlik one use strategi test hundr train although work may sequenc random number would describ network use diagramat defin put nat layer vertic variou layer arrang left right order time entir network come output go time cycl omit time input also omit reinforc simul describ weight nat start zero network output complet random sens given output equal like independ past present learn weight becom output strongli influenc input intern weight start driven close zero use neg optimum behavior toward network adapt probabl ident equal zero appli arbitrari criterion say learn appropri behavior criterion biolog can not know weight exact probabl behavior individu adapt use criterion base observ might network select correct respons continu appropri time adapt appropri environ tri make behav particular may provid input accord necessarili may independ mechan determin whether respond appropri provid reinforc one paradigm situat game environ reinforc scheme accord rule win play reinforc adapt appropri game must consist seri similar game best strategi given depend much inform oppon vice player assum oppon best strategi minim maximum loss often mean play least certain player know lot oppon best strategi may maxim often mean play determinist exampl network describ special case three pattern pattern recogn game associ properti nat emphas analog well known associ relat class simpl pattern produc network simpl class pattern produc consist type nat one network inform first case contain one nat wish alway produc simpl give posit reinforc neg reinforc start quickli larg make probabl select approach criterion use simpl pattern network train produc network string correct tabl network select output next trial trial consid network two produc four differ weight produc pattern train produc one pattern wish train subnetwork produc pattern vector one strategi give produc pattern min ave max give posit reinforc neg reinforc produc tabl show network learn produc pattern produc string gave reinforc took longer train two nat tabl train time network per consid network possibl pattern network probabl ineffect train network provid posit reinforc pattern neg reinforc opposit zero reinforc better strategi focu one output train nat separ high produc desir train rel network whole reason chanc produc exactli provid posit reinforc hybrid network meet train time take train network strategi type roughli proport first still effici strategi altern gener substrategi substrategi focuss keep network get one gener substrategi give posit reinforc half nat select desir neg reinforc less half desir reinforc exactli half select desir substrategi start approxim equal amount posit neg reinforc network select half output correctli tend minor subset low probabl select correct must recogn subset switch substrategi focus subset follow strategi one two nat suffici high probabl select desir conclud first strategi use obtain result tabl complic variant averag kept number right respons given ci output run averag th fraction gener rang particular far combin averag train focus averag signific result given tabl detail strategi close train time may demonstr train strategi exist train time grow significantli slowli proport simpl pattern recogn network mention fewer logic function variabl total possibl remin two network realiz network test adapt network learn xor abil learn one simplest network capabl learn ii give result train session strategi obtain two network function min ave max gener part suppli xor four possibl xor pattern xor appropri tabl train time network second part involv run averag respons network averag one combin fell significantli behind averag train focus combin perform criterion use decid train complet correct respons input pattern tabl ii show result network train realiz normal also shown comparison number taken equival network differ determinist number exactli compar present result sever criterion judg task learn reinforc deliber appli time learn neither model optim particular differ taken like would learn xor function significantli signific present result suggest use strategi prevent network get may also rapid strategi reduc complex reinforc simpl network consid context game player stack play player place one head head player uncov penni add player take theori say strategi player minim loss play head tail can not predict best win time likewis respect conserv strategi part player assum deriv sequenc inform make differ assumpt play player inform player incap infer inform sequenc play event incap chang inform pattern play start best action tri infer pattern play play subsequ take advantag knowledg win adapt adapt appropri situat suppos singl nat type output mean output mean third agent reinforc nat win suppos play probabl tail learn play head time therebi maxim total win complic situat suppos repeat two play ago play opposit potenti adapt strategi win time sequenti network shown standard form network dot plu feedback input network time play output top nat output time base partli bottom output time bottom nat select output base input time output network whole learn select base play two time increment network learn took play max reach point network repeat move two past next,1
76,76,"73O 
Analysis of distributed representation of 
constituent structure in connectionist systems 
Paul Smolensky 
Department of Computer Science, University of Colorado, Boulder, CO 80309-0430 
Abstract 
A general method, the tensor product representation, is described for the distributed representation of 
value/variable bindings. The method allows the fully distributed representation of symbolic structures: 
the roles in the structures, as well as the fillers for those roles, can be arbitrarily non-local. Fully and 
partially localized special cases reduce to existing cases of connectionist representations of structured 
data; the tensor product representation generalizes these and the few existing examples of fully 
distributed representations of structures. The representation saturates gracefully as larger structures 
are represented; it permits recursive construction of complex representations from simpler ones; it 
respects the independence of the capacities to generate and maintain multiple bindings in parallel; it 
extends naturally to continuous structures and continuous representational patterns; it permits values to 
also serve as variables; it enables analysis of the interference of symbolic structures stored in 
associative memories; and it leads to characterization of optimal distributed representations of roles 
and a recirculation algorithm for learning them. 
Introduction 
Any model of complex information processing in networks of simple processors must solve the 
problem of representing complex structures over network elements. Connectionist models of realistic 
natural language processing, for example, must employ computationally adequate representations of 
complex sentences. Many connectionists feel that to develop connectionist systems with the 
computational power required by complex tasks, distributed representations must be used: an 
individual processing unit must participate in the representation of multiple items, and each item must 
be represented as a pattern of activity of multiple processors. Connectionist models have used more or 
less distributed representations of more or less complex structures, but little if any general analysis of 
the problem of distributed representation of complex information has been carded out. This paper 
reports results of an analysis of a general method called the tensor product representation. 
The language-based formalisms traditional in AI permit the construction of arbitrarily complex 
structures by piecing together constituents. The tensor product representation is a connectionist 
method of combining representations of constituents into representations of complex structures. If the 
constituents that are combined have distributed representations, completely distributed representations 
of complex structures can result: each part of the network is responsible for representing multiple 
constituents in the structure, and each constituent is represented over multiple units. The tensor 
product representation is a general technique, of which the few existing examples of fully distributed 
representations of structures are particular cases. 
The tensor product representation rests on identifying natural counterparts within connectionist 
computation of certain fundamental elements of symbolic computation. In the present analysis, the 
problem of distributed representation of symbolic structures is characterized as the problem of taking 
complex structures with certain relations to their constituent symbols and mapping them into activity 
vectors--patterns of activation--with corresponding relations to the activity vectors representing their 
constituents. Central to the analysis is identifying a connectionist counterpart of variable binding: a 
method for binding together a distributed representation of a variable and a distributed representation 
of a value into a distributed representation of a variable/value binding--a representation which can 
co-exist on exactly the same network units with representations of other variable/value bindings, with 
American Institute of Physics 1988 
731 
limited confusion of which variables are bound to which values. 
In summary, the analysis of the tensor product representation 
(1) provides a general technique for constructing fully distributed representations of 
arbitrarily complex structures; 
(2) clarifies existing representations found in particular models by showing what particular 
design decisions they embody; 
(3) allows the proof of a number of general computational properties of the representation; 
(4) identifies natural counterparts within connectionist computation of elements of symbolic 
computation, in particular, variable binding. 
The recent emergence to prominence of the connectionist approach to AI raises the question of the 
relation between the nonsymbolic computation occurring in connectionist systems and the symbolic 
computation traditional in AI. The research reported here is part of an attempt to marry the two types 
of computation, to develop for AI a form of computation that adds crucial aspects of the power of 
symbolic computation to the power of connectionist computation: massively parallel soft constraint 
satisfaction. One way to marry these approaches is to implement serial symbol manipulation in a 
connectionist system ,2. The research described here takes a different tack. In a massively parallel 
system the processing of symbolic structures--for example, representations of parsed sentences--need 
not be limited to a series of elementary manipulations: indeed one would expect the processing to 
involve massively parallel soft constraint satisfaction. But in order for such processing to occur, a 
satisfactory answer must be found for the question: How can symbolic structures, or structured data in 
general, be naturally represented in connectionist systems? The difficulty here tums on one of the 
most fundamental problems for relating symbolic and connectionist computation: How can variable 
binding be naturally performed in connectionist systems? 
This paper provides an overview of a lengthy analysis reported elsewhere 3 of a general 
connectionist method for variable binding and an associated method for representing structured data. 
The purpose of this paper is to introduce the basic idea of the method and survey some of the results; 
the reader is referred to the full report for precise definitions and theorems, more extended examples, 
and proofs. 
The problem 
Suppose we want to represent a simple structured object, say a sequence of elements, in a 
connectionist system. The simplest method, which has been used in many models, is to dedicate a 
network processing unit to each possible element in each possible position 4. This is a purely local 
representation. One way of looking at the purely local representation is that the binding of 
constituents to the variables representing their positions is achieved by dedicating a separate unit to 
every possible binding, and then by activating the appropriate individual units. 
Purely local representations of this sort have some advantages �, but they have a number of serious 
problems. Three immediately relevant problems are these: 
(1) The number of units needed is #elements * #positions; most of these processors are 
inactive and doing no work at any given time. 
(2) The number of positions in the structures that can be represented has a fixed, rigid upper 
limit. 
(3) If there is a notion of similar elements, the representation does not take advantage of this: 
similar sequences do not have similar representations. 
The technique of distributed representation is a well-known way of coping with the first and third 
problems -4. If elements are represented as patterns of activity over a population of processing units, 
and if each unit can participate in the representation of many elements, then the number of elements 
that can be represented is much greater than the number of units, and similar elements can be 
represented by similar patterns, greatly enhancing the power of the network to learn and take 
advantage of generalizations. 
732 
Distributed representations of elements in structures (like sequences) have been successfully used 
in many models ,4,5.5-s. For each position in the structure, a pool of units is dedicated. The element 
occurring in that position is represented by a pattern of activity over the units in the pool. 
Note that this technique goes only part of the way towards a truly distributed representation of the 
entire structure. While the values of the variables def'ming the roles in the structure are represented by 
distributed patterns instead of dedicated units, the variables themselves are represented by localized, 
dedicated pools. For this reason I will call this type of representation semi-local. 
Because the representation of variables is still local, semi-local representations retain the second of 
the problems of purely local representations listed above. While the generic behavior of connectionist 
systems is to gradually overload as they attempt to hold more and more information, with dedicated 
pools representing role variables in structures, there is no loading at all until the pools are 
exhausted--and then there is complete saturation. The pools are essentially registers, and the 
representation of the structure as a whole has more of the characteristics of von Neumann storage than 
connectionist representation. A fully distributed connectionist representation of structured data would 
saturate gracefully. 
Because the representation of variables in semi-local representations is local, semi-local 
representations also retain part of the third problem of purely local representations. Similar elements 
have similar representations only if they occupy exactly the same role in the structure. A notion of 
similarity of roles cannot be incorporated in the semi-local representation. 
Tensor product binding 
There is a way of viewing both the local and semi-local representations of structures that makes a 
generalization to fully distributed representations immediately apparent. Consider the following 
structure: strings of length no more than four letters. Fig. 1 shows a purely local representation and 
Fig. 2 shows a semi-local representation (both of which appeared in the letter-perception model of 
McCleiland and Rumelhartn3). In each case, the variable binding has been viewed in the same way. 
On the left edge is a set of imagined units which can represent an element in the structure--a filler of a 
role; these are the filler units. On the bottom edge is a set of imagined units which can represent a 
role: these are the role units. The remaining units are the ones really used to represent the structure: 
the binding units. They are arranged so that there is one for each pair of filler and role units. 
In the purely local case, both the filler and the role are represented by a ""pattern of activity"" 
localized to a single unit. In the semi-local case, the idler is represented by a distributed pattern of 
activity but the role is still represented by a localized pattern. In either case, the binding of the filler to 
the role is achieved by a simple product operation: the activity of each binding unit is the product of 
the activities of the associated filler and role unit. In the vocabulary of matrix algebra, the activity 
representing the value/variable binding forms a matrix which is the outer product of the activity vector 
representing the value and the activity vector representing the variable. In the terminology of vector 
spaces, the value/variable binding vector is the tensor product of the value vector and the variable 
vector. This is what I refer to as the tensor product representation for variable bindings. 
Since the activity vectors for roles in Figs. 1 and 2 consist of all zeroes except for a single activity 
of 1, the tensor product operation is utterly trivial. The local and semi-local cases are trivial special 
cases of a general binding procedure capable of producing completely distributed representations. Fig. 
3 shows a distributed case designed for visual transparency. Imagine we are representing speech data, 
and have a sequence of values for the energy in a particular formant at successive times. In Fig. 3, 
distributed patterns are used to represent both the energy value and the variable to which it is bound: 
the position in time. The particular binding shown is of an energy value 2 (on a scale of 1--4) to the 
time 4. The peaks in the patterns indicate the value and variable being represented. 
733 
Filler 
(Letter) 
� 
 � 
o o 
� 
0 0 0 ' 0 
e e e  
o � o o 
o o o o 
o o o o 
o � o o 
o � o o 
Q o � � o � o o 
Role (Position) Role (Position) 
Fig. 1. Purely local representation of strings. Fig. 2. Semi-local representation of strings. 
If the patterns representing the value and variable being bound together are not as simple as those 
used in Fig. 3, the tensor product pattern representing the binding will not of course be particularly 
visually informative. Such would be the case if the patterns for the fillers and roles in a structure were 
defined with respect to a set of filler and role features:. such distributed bindings have been used 
effectively by McClelland and Kawamoto is and by Derthick 9�. The exl'eme mathematical 
simplicity of the tensor product operation makes feasible an analysis of the general, fully distributed 
case. 
Each binding unit in the tensor product representation corresponds to a pair of imaginary role and 
filler units. A binding unit can be readily interpreted semantically if its corresponding filler and role 
units can. The activity of the binding unit indicates that in the structure being represented an element 
is present which possesses the feature indicated by the corresponding filler unit and which occupies a 
role in the structure which possesses the feature indicated by the corresponding role unit. The binding 
unit thus detects a conjunction of a pair of f'dler and role features. (Higher-order conjunctions will 
arise later.) 
A structure consists of multiple fillerRole bindings. So far we have only discussed the 
representation of a single binding. In the purely local and semi-local cases, there are separate pools for 
different roles, and it is obvious how to combine bindings: simultaneously represent them in the 
separate pools. In the ease of a fully distributed tensor product binding (eg., Fig. 3), each single 
binding is a pattern of activity that extends across the entire set of binding units. The simplest 
possibility for combining these patterns is simply to add them up; that is, to superimpose all the 
bindings on top of each other. In the special cases of purely local and semi-local representations, this 
procedure reduces trivially to simultaneously representing the individual fillers in the separate pools. 
734 
Filler 
(Energy) 
0 0 0 @ 0 
0 0 � e e 
o o 
0 0 � e 
Role (Time) 
Fig. 3. A visually transparent fully distributed tensor product representation. 
The process of superimposing the separate bindings produces a representation of structures with 
the usual connectionist properties. If the patterns representing the roles are not too similar, the 
separate bindings can all be kept straight. It is not necessary for the role patterns to be non- 
overlapping, as they are in the purely local and semi-local cases; it is sufficient that the patterns be 
linearly independent. Then there is a simple operation that will correctly extract the filler for any role 
from the representation of the structure as a whole. If the patterns are not just linearly independent, 
but are also orthogonal, this operation becomes quite direct; we will get to it shortly. For now, the 
point is that simply superimposing the separate bindings is sufficient. If the role patterns are not too 
similar, the separate bindings do not interfere. The representation gracefully saturates if more and 
more roles are filled, since the role patterns being used lose their distinctness once their number 
approaches that of the role units. 
Thus problem (2) listed above, shared by purely local and semi-local representations, is at last 
removed in fully distributed tensor product representations: they do not accomodate structures only up 
to a certain rigid limit, beyond which they are completely saturated; rather, they saturate gracefully. 
The third problem is also fully addressed, as similar roles can be represented by similar patterns in the 
tensor product representation and then generalizations both across similar fillers and across similar 
roles can be learned and exploited. 
The clef'tuition of the tensor product representation of structured data can be summed up as follows: 
(a) Let a set S of structured objects be given a role decomposition: a set of fillers, F, a set of 
roles R, and for each object s a corresponding set of bindings 
[(s) = {f/r: f fills role r in s }. 
(b) Let a connectionist representation of the fillers F be given; f is represented by the activity 
vector f. 
(c) Let a connectionist representation of the roles R be given; r is represented by the activity 
735 
vector r. 
(d) Then the corresponding tensor product representation of s is f/r.(s)fr (where  
denotes the tensor product operation). 
In the next section I will discuss a model using a fully distributed tensor product representation, 
which will require a brief consideration of role decompositions. I will then go on to summarize general 
properties of the tensor product representation. 
Role decompositions 
The most obvious role decompositions are positional decompositions that involve fixed position 
slots within a structure of pre-determined form. In the case of a string, such a role would be the ira 
position in the string; this was the decomposition used in the examples of Figs. 1 through 3. Another 
example comes from McClelland and Kawamoto's modeP s for learning to assign case roles. They 
considered sentences of the form The N V the N2 with the N3; the four roles were the slots for the 
three nouns and the verb. 
A less obvious but sometimes quite powerful role decomposition involves not fixed positions of 
elements but rather their local context. As an example, in the case of strings of letters, such roles 
might be r_y = is preceded by x and followed by y, for various letters x and y. 
Such a local context decomposition was used to considerable advantage by Rumelhart and 
McClelland in their model of learning the morphophonology of the English past tense2L Their 
structures were strings of phonetic segments, and the context decomposition was well-suited for the 
task because the generalizations the model needed to learn involved the transformations undergone by 
phonemes occurring in different local contexts. 
Rumelhart and McClelland's representation of phonetic strings is an example of a fully distributed 
tensor product representation. The fiflers were phonetic segments, which were represented by a 
pattern of phonetic features, and the roles were nearest-neighbor phonetic contexts, which were also 
represented as distributed patterns. The distributed representation of the roles was in fact itself a 
tensor product representation: the roles themselves have a constituent structure which can be further 
broken down through another role decomposition. The roles are indexed by a left and right neighbor; 
in essence, a string of two phonetic segments. This sating too can be decomposed by a context 
decomposition; the fifler can be taken to be the left neighbor, and the role can be indexed by the right 
neighbor. Thus the vowel [i] in the word week is bound to the role r, k, and this role is in turn a 
binding of the filler [w] in the sub-role r' k. The pattern for [i ] is a vector i of phonetic features; the 
pattern for [w] is another such vector of features w, and the pattern for the sub-role r'  is a third 
vector k consisting of the phonetic features of [k]. The binding for the [i] in week is thus i(wk). 
Each unit in the representation represents a third-order conjunction of a phonetic feature for a central 
segment together with two phonetic features for its left and right neighbors. [To get precisely the 
representation used by Rumelhart and McClefland, we have to take this tensor product representation 
of the roles (eg. r ) and throw out a number of the binding units generated in this further 
decomposition; only certain combinations of features of the left and right neighbors were used. The 
distributed representation of letter triples used by Touretzky and Hinton  can be viewed as a similar 
third-order tensor product derived from nested context decompositions, with some binding units 
thrown away--in fact, all binding units off the main diagonal were discarded.] 
This example illustrates how role decompositions can be iterated, leading to iterated tensor product 
representations. Whenever the riflers or roles of one decomposition are structured objects, they can 
themselves be further reduced by another role decomposition. 
It is often useful to consider recursive role decompositions in which the fillers are the same type of 
object as the original structure. It is clear from the above definition that such a decomposition cannot 
be used to generate a tensor product representation. Nonetheless, recursive role decompositions can 
be used to relate the tensor product representation of complex structures to the tensor product 
representations of simpler structures. For example, consider Lisp binary tree structures built from a set 
A of atoms. A non-recursive decomposition uses A as the set of fillers, with each role being the 
736 
occupation of a certain position in the tree by an atom. From this decomposition a tensor product 
representation can be constructed. Then it can be seen that the operations car, cdr, and cons 
correspond to certain linear operators car, cdr, and cons in the vector space of activation vectors. Just 
as complex S-expressions can be constructed from atoms using cons, so their connecfionist 
representations can be constructed from the simple representation of atoms by the application of cons. 
(This serial ""construction"" of the complex representation from the simpler ones is done by the analyst, 
not necessarily by the network; cons is a static, descriptive, mathematical operator--not necessarily a 
transformation to be carried out by a network.) 
Binding and unbinding in connectionist networks 
So far, the operation of binding a value to a variable has been described mathematically and 
pictured in Figs. 1-3 in terms of ""imagined"" filler units and role units. Of course, the binding 
operation can actually be performed in a network if the rillHr and role units are really there. Fig. 4 
shows one way this can be done. The triangular junctions are Hinton's multiplicative connectionsZ2: 
the incoming activities from the role and filler units are multiplied at the junction and passed on to the 
binding unit. 
Binding Units 
Filler 
Units 
Role Units 
Fig. 4. A network for tensor product binding and unbinding. 
""Unbinding"" can also be performed by the network of Fig. 4. Suppose the tensor product 
representation of a structure is present in the binding units, and we want to extract the filler for a 
particular role. As mentioned above, this can be done accurately if the role patterns are linearly 
independent (and if each role is bound to only one filler). It can be shown that in this case, for each 
role there is a pattern of activity which, if set up on the role units, will lead to a pattern on the rifler 
units that represents the corresponding filler. (If the role vectors are orthogonal, this pattern is the 
same as the role pattern.) As in Hinton's model e�, it is assumed here that the triangular junctions work 
in all directions, so that now they take the product of activity coming in from the binding and role units 
and pass it on to the filler units, which sum all incoming activity. 
737 
The network of Fig. 4 can bind one value/variable pair at a time. In order to build up the 
representation of an entire structure, the binding units would have to accumulate activity over an 
extended period of time during which all the individual bindings would be performed serially. 
Multiple bindings could occur in parallel if part of the apparatus of Fig. 4 were duplicated: this 
requires several copies of the sets of filler and role units, paired up with triangular junctions, all 
feeding into a single set of binding units. 
Notice that in this scheme there are two independent capacities for parallel binding: the capacity to 
generate bindings in parallel, and the capacity to maintain bindings simultaneously. The former is 
determined by the degree of duplication of the filler/role unit sets (in Fig. 4, for example, the parallel 
generation capacity is 1). The parallel maintenance capacity is determined by the number of possible 
linearly independent role patterns, i.e. the number of role units in each set. It is logical that these two 
capacities should be independent, and in the case of the human visual and linguistic systems it seems 
that our maintenance capacity far exceeds our generation capacity 21. Note that in purely local and 
semi-local representations, there is a separate pool of units dedicated to the representation of each role, 
so there is a tendency to suppose that the two capacities are equal. As long as a connectionist model 
deals with structures (like four-letter words) that are so small that the number of bindings involved is 
within the human parallel generation capacity, there is no harm done. But when connectionist models 
address the human representation of large structures (like entire scenes or discourses), it will be 
important to be able to maintain a large number of bindings even though the number that can be 
generated in parallel is much smaller. 
Further properties and extensions 
Continuous structures. It can be argued that underlying the connectionist approach is a 
fundamentally continuous formalization of computation 13. This would suggest that a natural 
connectionist representation of structure would apply at least as well to continuous structures as to 
discrete ones. It is therefore of some interest that the tensor product representation applies equally 
well to structures characterized by a continuum of roles: a ""string"" extending through continuous time, 
for example, as in continuous speech. In place of a sum over a discrete set of bindings, i fi  ri we 
have an integral over a continuum of bindings: It f(t)r(t)dt This goes over exactly to the discrete 
case if the fillers are discrete step-functions of time. 
Continuous patterns. There is a second sense in which the tensor product representation 
extends naturally to the continuum. If the patterns representing fillers and/or roles are continuous 
curves rather than discrete sets of activities, the tensor product operation is still well-defined. (Imagine 
Fig. 3 with the filler and role patterns being continuous peaked curves instead of discrete 
approximations; the binding pattern is then a continuous peaked two-dimensional surface.) In this case, 
the vectors f and/or r are members of infinite-dimensional function spaces; regarding them as patterns 
of activity over a set of processors would require an infinite number of processors. While this might 
pose some problems for computer simulation, the case where f and/of r are functions rather than 
finite-dimensional vectors is not particularly problematic analytically. And if a problem with a 
continuum of roles is being considered, it may be desirable to assume a continuum of linearly 
independent role vectors: this requires considering infinite-dimensional representations. 
Values as variables. Treating both values and variables symmetrically as done in the tensor 
product representation makes it possible for the same entity to simultaneously serve both as a value 
and as a variable. In symbolic computation it often happens that the value bound to one variable is 
itself a variable which in turn has a value bound to it. In a semi-local representation, where variables 
are localized pools of units and values are patterns of activity in these pools, it is difficult to see how 
the same entity can simultaneously serve as both value and variable. In the tensor product 
representation, both values and variables are patterns of activity, and whether a pattern is serving as a 
""variable"" or ""value""r both---might be merely a matter of descriptive preference. 
738 
Symbolic structures in associative memories. The mathematical simplicity of the tensor 
product representation makes it possible to characterize conditions under which a set of symbolic 
structures can be stored in an associative memory without interference. These conditions involve an 
interesting mixture of the numerical character of the associative memory and the discrete character of 
the stored data. 
Learning optimal role patterns by recirculation. While the use of distributed patterns to 
represent constituents in structures is well-known, the use of such patterns to represent roles in 
structures poses some new challenges. In some domains, features for roles are familiar or easy to 
imagine; eg,, features of semantic roles in a case-frame semantics. But it is worth considering the 
problem of distributed role representations in domain-independent terms as well. The patterns used to 
represent roles determine how information about a stmcture's fillers will be coded, and these role 
patterns have an effect on how much information can subsequently be extracted from the 
representation by connectionist processing. The challenge of making the most information available 
for such future extraction can be posed as follows. Assume enough apparatus has been provided to do 
all the variable binding in parallel in a network like that of Fig. 4. Then we can dedicate a set of role 
units to each role; the pattern for each role can be set up once and for all in one set of role units. Since 
the activity of the role units provide multipliers for filler values at the triangular junctions, we can treat 
these fixed role patterns as weights on the lines from the filler units to the binding units. The problem 
of finding good role patterns now becomes the problem of finding good weights for encoding the 
fillers into the binding units. 
Now suppose that a second set of connections is used to try to extract all the fillers from the 
representation of the structure in the binding units. Let the weights on this second set of connections 
be chosen to minimize the mean-squared differences between the extracted fdler patterns and the 
actual original filler patterns. Let a set of role vectors be called optimal if this mean-squared error is as 
small as possible. 
It rams out that optimal role vectors can be characterized fairly simply both algebraically and 
geometrically (with the help of results from Williams24). Furthermore, having imbedded the role 
vectors as weights in a connectionist net, it is possible for the network to learn optimal role vectors by 
a fairly simple learning algorithm. The algorithm is derived as a gradient descent in the mean-squared 
error, and is what G. E. Hinton and J. L. McClelland (unpublished communication) have called a 
recirculation algorithm: it works by circulating activity around a closed network loop and training on 
the difference between the activities at a given node on successive passes. 
Acknowledgements 
This research has been supported by NSF grants IRI-8609599 and ECE-8617947, by the Sloan 
Foundation's computational neuroscience program, and by the Department of Computer Science and 
Institute of Cognitive Science at the University of Colorado at Boulder. 
739 
References 
1. D. S. Touretzky & G. E. Hinton. Proceedings of the International Joint Conference on Artificial 
Intelligence, 238-243 (1985). 
2. D. S. Touretzky. Proceedings of the 8th Conference of the Cognitive Science Society, 522-530 
(1986). 
3. P. Smolensky. Technical Report CU-CS-355-87, Department of Computer Science, University 
of Colorado at Boulder (1987). 
4. J.L. McClelland & D. E. Rumelhart. PsychologicalReview 88,375-407 (1981). 
5. D.E. Rumelhart & J. L. McClelland. Psychological Review 89, 60-94 (1982). 
6. M. Fanty. Technical Report 174, Department of Computer Science, University of Rochester 
(1985). 
7. J.A. Feldman. The Behavioral and Brain Sciences 8,265-289 (1985). 
8. J. L. McClelland & J. L. Elman. In J. ", distribut represent structur connectionist system smolenski comput univers co gener tensor product describ distribut represent method allow fulli distribut represent symbol role well filler arbitrarili fulli local special case reduc exist case connectionist represent structur tensor product represent gener exist exampl fulli represent represent satur grace larger structur permit recurs construct complex represent simpler independ capac gener maintain multipl bind natur continu structur continu represent permit valu serv enabl analysi interfer symbol structur store lead character optim distribut represent role recircul algorithm learn model complex inform process network simpl processor must solv repres complex structur network connectionist model realist languag must employ comput adequ represent mani connectionist feel develop connectionist system power requir complex distribut represent must process unit must particip represent multipl item must repres pattern activ multipl connectionist model use distribut represent less complex littl gener analysi problem distribut represent complex inform card paper result analysi gener method call tensor product formal tradit ai permit construct arbitrarili complex piec togeth tensor product represent connectionist combin represent constitu represent complex combin distribut complet distribut represent complex structur part network respons repres multipl constitu repres multipl tensor represent gener exist exampl fulli distribut structur particular tensor product represent rest identifi natur counterpart within connectionist certain fundament element symbol present distribut represent symbol structur character problem take structur certain relat constitu symbol map activ correspond relat activ vector repres central analysi identifi connectionist counterpart variabl bind togeth distribut represent variabl distribut represent valu distribut represent represent exactli network unit represent institut physic confus variabl bound analysi tensor product represent provid gener techniqu construct fulli distribut represent complex clarifi exist represent found particular model show particular decis allow proof number gener comput properti identifi natur counterpart within connectionist comput element symbol variabl recent emerg promin connectionist approach ai rais question nonsymbol comput occur connectionist system symbol tradit research report part attempt marri two type develop ai form comput add crucial aspect power comput power connectionist massiv parallel soft constraint one way marri approach implement serial symbol manipul system research describ take differ massiv parallel process symbol represent pars limit seri elementari inde one would expect process massiv parallel soft constraint order process answer must found symbol structur data natur repres connectionist difficulti tum one fundament problem relat symbol connectionist variabl natur perform connectionist paper provid overview lengthi analysi report elsewher gener method variabl bind associ method repres structur purpos paper introduc basic idea method survey reader refer full report precis definit extend problem want repres simpl structur say sequenc simplest use mani dedic process unit possibl element possibl posit pure local one way look pure local represent bind variabl repres posit achiev dedic separ unit possibl activ appropri individu local represent sort advantag number seriou three immedi relev problem number unit need processor work given number posit structur repres rigid upper notion similar represent take advantag sequenc similar techniqu distribut represent way cope first third element repres pattern activ popul process unit particip represent mani number element repres much greater number similar element similar greatli enhanc power network learn take represent element structur success use mani model posit pool unit element posit repres pattern activ unit techniqu goe part way toward truli distribut represent valu variabl role structur repres pattern instead dedic variabl repres reason call type represent represent variabl still represent retain second problem pure local represent list gener behavior connectionist gradual overload attempt hold dedic repres role variabl load pool complet pool essenti structur whole characterist von neumann storag fulli distribut connectionist represent structur data would represent variabl represent also retain part third problem pure local similar element similar represent occupi exactli role notion role can not incorpor product bind way view local represent structur make fulli distribut represent immedi consid follow string length four show pure local represent show represent appear model cleiland variabl bind view left edg set imagin unit repres element filler filler bottom edg set imagin unit repres role remain unit one realli use repres bind arrang one pair filler role pure local filler role repres singl idler repres distribut pattern role still repres local either bind filler role achiev simpl product activ bind unit product activ associ filler role vocabulari matrix activ bind form matrix outer product activ vector valu activ vector repres terminolog vector bind vector tensor product valu vector variabl refer tensor product represent variabl activ vector role consist zero except singl activ tensor product oper utterli local case trivial special gener bind procedur capabl produc complet distribut show distribut case design visual imagin repres speech sequenc valu energi particular formant success pattern use repres energi valu variabl posit particular bind shown energi valu scale peak pattern indic valu variabl role pure local represent represent pattern repres valu variabl bound togeth simpl tensor product pattern repres bind cours particularli would case pattern filler role structur respect set filler role distribut bind use clelland kawamoto derthick mathemat tensor product oper make feasibl analysi fulli distribut bind unit tensor product represent correspond pair imaginari role bind unit readili interpret semant correspond filler role activ bind unit indic structur repres element present possess featur indic correspond filler unit occupi structur possess featur indic correspond role bind thu detect conjunct pair role conjunct structur consist multipl role far discuss singl pure local separ pool obviou combin simultan repres eas fulli distribut tensor product bind singl pattern activ extend across entir set bind simplest combin pattern simpli add superimpos top special case pure local reduc trivial simultan repres individu filler separ visual transpar fulli distribut tensor product process superimpos separ bind produc represent structur usual connectionist pattern repres role bind kept necessari role pattern pure local suffici pattern simpl oper correctli extract filler role represent structur pattern linearli also oper becom quit get simpli superimpos separ bind role pattern separ bind represent grace satur role sinc role pattern use lose distinct number role problem list share pure local last fulli distribut tensor product accomod structur certain rigid beyond complet satur third problem also fulli similar role repres similar pattern product represent gener across similar filler across similar learn tensor product represent structur data sum let set structur object given role set set object correspond set bind fill role let connectionist represent filler repres activ let connectionist represent role repres activ correspond tensor product represent tensor product next section discuss model use fulli distribut tensor product requir brief consider role go summar gener tensor product decomposit obviou role decomposit posit decomposit involv fix posit within structur case role would ira decomposit use exampl anoth come clelland learn assign case sentenc form four role slot noun less obviou sometim quit power role decomposit involv fix posit rather local case string role preced follow variou letter local context decomposit use consider advantag rumelhart clelland model learn morphophonolog english past string phonet context decomposit gener model need learn involv transform undergon occur differ local represent phonet string exampl fulli distribut product fifler phonet repres phonet role phonet also distribut distribut represent role fact product role constitu structur anoth role role index left right string two phonet sate decompos context fifler taken left role index right thu vowel word week bound role role turn filler pattern vector phonet anoth vector featur pattern third consist phonet featur bind week thu unit represent repres conjunct phonet featur central togeth two phonet featur left right get precis use rumelhart take tensor product represent role throw number bind unit gener certain combin featur left right neighbor represent letter tripl use touretzki hinton view similar tensor product deriv nest context bind unit bind unit main diagon exampl illustr role decomposit lead iter tensor product whenev rifler role one decomposit structur reduc anoth role often use consid recurs role decomposit filler type origin clear definit decomposit can not use gener tensor product recurs role decomposit use relat tensor product represent complex structur tensor product simpler consid lisp binari tree structur built set decomposit use set role certain posit tree decomposit tensor product seen oper con certain linear oper con vector space activ complex construct atom use connecfionist construct simpl represent atom applic serial complex represent simpler one done necessarili con mathemat necessarili carri unbind connectionist network oper bind valu variabl describ mathemat term filler unit role bind actual perform network hr role unit realli one way triangular junction multipl incom activ role filler unit multipli junction pass unit unit network tensor product bind also perform network suppos tensor product structur present bind want extract filler mention done accur role pattern linearli role bound one shown pattern activ set role lead pattern rifler repres correspond role vector pattern role model assum triangular junction work take product activ come bind role unit pass filler sum incom network bind one pair order build entir bind unit would accumul activ period time individu bind would perform bind could occur parallel part apparatu sever copi set filler role pair triangular singl set bind scheme two independ capac parallel capac bind capac maintain bind former degre duplic unit set parallel capac parallel mainten capac determin number possibl independ role number role unit logic two case human visual linguist system seem mainten capac far exce gener capac note pure local separ pool unit dedic represent tendenc suppos two capac long connectionist model structur small number bind involv human parallel gener harm connectionist model human represent larg structur entir scene abl maintain larg number bind even though number parallel much properti extens argu underli connectionist approach continu formal comput would suggest natur represent structur would appli least well continu structur therefor interest tensor product represent appli equal structur character continuum extend continu continu place sum discret set fi ri integr continuum goe exactli discret filler discret second sens tensor product represent natur pattern repres filler role continu rather discret set tensor product oper still filler role pattern continu peak curv instead discret bind pattern continu peak vector member function regard pattern activ set processor would requir infinit number might problem comput case function rather vector particularli problemat problem role may desir assum continuum linearli role requir consid treat valu variabl symmetr done tensor represent make possibl entiti simultan serv valu symbol comput often happen valu bound one variabl variabl turn valu bound variabl local pool unit valu pattern activ difficult see entiti simultan serv valu tensor product valu variabl pattern whether pattern serv mere matter descript structur associ mathemat simplic tensor represent make possibl character condit set symbol store associ memori without condit involv mixtur numer charact associ memori discret charact store optim role pattern use distribut pattern constitu structur use pattern repres role pose new featur role familiar easi featur semant role worth consid distribut role represent term pattern use role determin inform filler role effect much inform subsequ extract connectionist challeng make inform avail futur extract pose assum enough apparatu provid variabl bind parallel network like dedic set role pattern role set one set role sinc activ role unit provid multipli filler valu triangular treat fix role pattern weight line filler unit bind problem find good role pattern becom problem find good weight encod bind suppos second set connect use tri extract filler structur bind let weight second set connect chosen minim differ extract fdler pattern origin filler let set role vector call optim error ram optim role vector character fairli simpli algebra help result imbed role weight connectionist possibl network learn optim role vector fairli simpl learn algorithm deriv gradient descent hinton clelland call work circul activ around close network loop train differ activ given node success research support nsf grant sloan comput neurosci depart comput scienc cognit scienc univers colorado touretzki proceed intern joint confer artifici proceed confer cognit scienc technic report depart comput univers colorado boulder clelland review rumelhart psycholog review technic report depart comput univers rochest behavior brain scienc clelland,1
77,77,"74O 
SPATIAL ORGANIZATION OF NEURAL NETWORKS: 
A PROBABILISTIC MODELING APPROACH 
A. Stafylopati s 
M. Dikaiakos 
D. Kontoravdi s 
National Technical University of Athens, Department of Electri- 
cal Engineering, Computer Science Division, 157 73 Zographos, 
Athens, Greece. 
ABSTRACT 
The aim of this paper is to explore the spatial organization of 
neural networks under Markovian assumptions, in what concerns the be- 
haviour of individual cells and the interconnection mechanism. Space- 
organizational properties of neural nets are very relevant in image 
modeling and pattern analysis, where spatial computations on stocha- 
stic two-dimensional image fields are involved. As a first approach 
we develop a random neural network model, based upon simple probabi- 
listic assumptions, whose organization is studied by means of dis- 
crete-event simulation. We then investigate the possibility of ap- 
proximating the random network's behaviour by using an analytical ap- 
proach originating from the theory of general product-form queueing 
networks. The neural network is described by an open network of no- 
des, in which customers moving from node to node represent stimula- 
tions and connections between nodes are expressed in terms of sui- 
tably selected routing probabilities. We obtain the solution of the 
model under different disciplines affecting the time spent by a sti- 
mulation at each node visited. Results concerning the distribution 
of excitation in the network as a function of network topology and 
external stimulation arrival pattern are compared with measures ob- 
tained from the simulation and validate the approach followed. 
INTRODUCTION 
Neural net models have been studied for many years in an attempt 
to achieve brain-like performance in computing systems. These models 
are composed of a large number of interconnected computational ele- 
ments and their structure reflects our present understanding of the 
organizing principles of biological nervous systems. In the begin- 
ing, neural nets, or other equivalent models, were rather intended 
to represent the logic arising in certain situations than to provide 
an accurate description in a realistic context. However, in the last 
decade or so the knowledge of what goes on in the brain has increased 
tremendously. New discoveries in natural systems, make it now rea- 
sonable to examine the possibilities of using modern technology in 
order to synthesige sys.ems that have some of the properties of real 
neural systems 8,9,10,1 
In the original neural net model developed in 1943 by McCulloch 
and Pitts 1,2 the network is made of many interacting components, 
known as the ""McCulloch-Pitts cells"" or ""formal neurons"", which are 
simple logical units with two possible states changing state accord- 
American Institute of Physics 1988 
741 
ing to a threshold function of their inputs. Related automata moel. 
have been used later for gene control systems (genetic networks) , 
in which genes are represented as binary automata changing state ac- 
cording to boolean functions of their inputs. Boolean networks con- 
stitute a more general model, whose dynamical behaviour has been stu- 
died extensively. Due to the large number of elements, the exact 
structure of the connections and the functions of individual compo- 
nents are generally unknown and assumed to be distributed at random. 
Several studies on these random boolean networks 5,6 have shown that 
they exhibit a surprisingly stable behaviour in what concerns their 
temporal and spatial organization. However, very few formal analyti- 
cal results are available, since most studies concern statistical 
descriptions and computer simulations. 
The temporal and spatial organization of random boolean networks 
is of particular interest in the attempt of understanding the proper- 
ties of such syste.ms, and models originating from the theory of sto- 
chastic processes l seem to be very useful. Spatial properties of 
neural nets are most important in the field of image recognition 12. 
In the biological eye, a level-normalization computation is pe.rformed 
by the layer of horizontal cells, which are fed by the immediately 
preceding layer of hotoreceptors. The horizontal cells take the 
outputs of the receptors and average them spatial ly, this average 
being weighted on a nearest-neighbor basis. This procedure corres- 
ponds to a mechanism for determining the brightness level of pixels 
in an image field by using an array of processing elements. The 
principle of local computation is usually adopted in models used for 
representing and generating textured images. Among the stochastic 
models applied to analyzi the parameters of image fields, the ran- 
dom Markov field model /, seems to give a suitably structured re- 
presentation, which is mainly due to the application of the marko- 
vian property in space. This type of modeling constitutes a promi- 
sing alternative in the study of spatial organization phenomena in 
neural nets. 
The approach taken in this paper aims to investigate some as- 
pects of spatial organization under simple stochastic assumptions. 
In the next section we develop a model for random neural networks 
assuming boolean operation of individual cells. The behaviour of 
this model, obtained through simulation experiments, is then appro- 
ximated by using techniques from the theory of queueing networks. 
The approximation yields quite interesting results as illustrated by 
various examples. 
THE RANDOM NETWORK MODEL 
We define a random neural network as a set of elements or cells, 
each one of which can be in one of two different states: firing or 
quiet. Cells are interconnected to form an NxN grid, where each grid 
point is occupied by a cell. We shall consider only connections be- 
tween neighbors, so that each cell is connected to 4 among the other 
cells- two input and two output cells (the output of a cell is equal 
'to its internal state and it is sent to its output cells which use 
.it as one of their inputs). The network topology is thus specified 
742 
by its incidence matrix A of dimension MxM, where M=N 2. This matrix 
takes a simple form in the case of neighbor-connection considered 
here. We further assume a periodic structure of connections in what 
concerns inputs and outputs; we will be interested in the following 
two types of networks depending upon the period of reproduction for 
elementary square modules 5, as shown in Fig.l: 
- Propagative nets (Period 1) 
- Looping nets (Period 2) 
(a) 
(b) m  
Fig.1. (a) Propagative connections, (b) Looping connections 
At the edges of the grid, circular connections are established (mo- 
dulo N), so that the network can be viewed as supported by a torus. 
The operation of the network is non-autonomous: changes of sta- 
te are determined by both the interaction among cells and the influ- 
ence of external stimulations. We assume that stimulations arrive 
from the outside world according to a Poisson process with parameter 
A. Each arriving stimulation is associated with exactly one cell of 
the network; the cell concerned is determined by means of a given 
discrete probability distribution qi (l<_i<_M), considering an one-di- 
mensional labeling of the M cells. 
The operation of each individual cell is asynchronous and can be 
described in terms of the following rules: 
- A quiet cell moves to the firing state if it receives an arriving 
stimulation or if a boolean function of its inputs becomes true. 
- A firing cell moves to the quiet state if a boolean function of its 
inputs becomes false. 
- Changes of state imply a reaction delay of the cell concerned; the- 
se delays are independent identically distributed random variables 
following a negative exponential distribution with parameter V. 
According to these rules, the operation of a cell can be viewed as il- 
lustrated by Fig.2, where the horizontal axis represents time and th 
numbers 0,1,2 and 3 represent phases of an operation cycle. Phases 1 
and 3, as indicated in Fig.2, correspond to reaction delays. In this 
sense, the quiet and firing states, as defined in the beginingofthis 
section, represent the aggregates of phases 0,1 and 2,3 respectively. 
External stimulations affect the receiving cell only when itisinpha- 
se O; otherwise we consider that the stimulation is lost. In the sa- 
me way, we assume that changes of the value of the input boolean func- 
.ion do not affect the operation of the cell during phases I and 3. The 
conditions are checked onlyat the end of the respective reaction delay. 
743 
quiet 
s ta te 
firing state 
0 
Fig.2. Changes of state for individual cells 
The above defined model includes some features of the original 
McCulloch-Pitts cells 1,2 . In fact, itrepresents an asynchronous 
counterpart of the latter, in which boolean functions are considered 
instead of threshold functions. However, it can be shown that any 
McCulloch and Pitts' neural network can be implemented by a boolean 
network designed in an appropriate fashion 5. In what follows,wewill 
consider that the firing condition for each individual cell is de- 
termined by an ""or"" function of its inputs. 
Under the assumptions adopted, the evolution of the network in 
time can be described by a continuous-parameter Markov process. How- 
ever, the size of the state-space and the complexity of the system 
are such that no analytical solution is tractable. The spatial orga- 
nization of the network could be expressed in terms of the steady- 
state probability distribution for the Markov process. A more useful 
representation is provided by the marginal probability distributions 
for all cells in the network, or equivalently by the probability of 
being in the firing state for each cell. This measure expresses the 
level of excitation for each point in the grid. 
We have studied the behaviour of the above model by means of si- 
mulation experiments for various cases depending upon the network si- 
ze, the connection type, the distribution of external stimulation ar- 
rivals on the grid and the parameters A and V. Some examples are il- 
lustrated in the last section, in comparison with results obtained 
using the approach discussed in the next section. The estimations ob- 
tained concern the probability of being in the firing state for all 
cells in the network. The simulation was implemented according to 
the ""batched means"" method; each run was carried out until tliewidth 
of the 95% confidence interval was less that 10% of the estimated 
mean value for each cell, or until a maximum number of events had 
been simulated depending upon the size of the network. 
THE ANALYTICAL APPROACH 
The neural network model considered in the previous section exhi- 
bited the markovian property in both time and space. Markovianity in 
space, expressed by the principle of ""neighbor-connections"", is the 
basic feature of Markov random fields 7,14, as already discussed. Our 
idea is to attempt an approximation of the random neural network mo- 
del by using a well-known model, which is markovian in time, and ap- 
plying the constraint of markovianity in space. The model considered 
is an open queueing network, which belongs to the general class of 
queueing networks admitting a product-form solution 4. In fact, one 
could distinguish several comm6n features in the two network models. 
744 
A neural network, in general, receives information in the form of ex- 
ternal stimulation signals and performs some computation on this in- 
formation, which is represented by changes of its state. The opera- 
tion of the network can be viewed as a flow of excitement among the 
cells and the spatial distribution of this excitement represents the 
response of the network to the information received. This kindof ope- 
ration is particularly relevant in the processing of image fields. On 
the other hand, in queueing networks, composed of a number of service 
station nodes, customers arrive from the outside world and spend some 
time in the network, during which they more from node to node, wait- 
ing and receiving service at each node visited. Following the exter- 
nal arrival pattern, the interconnection of nodes and the other net- 
work parameters, the operation of the network is characterized by a 
distribution of activity among the nodes. 
Let us now consider a queueing network, where nodes represent 
cells and customers represent stimulations moving from cell to cell 
following the topology of the network. Our aim is to define the net- 
work's characteristics in a way to match those of the neural net mo- 
del as much as possible. Our queueing network model is completely 
specified by the following assumRtions: 
- The network is composed of M=N L nodes arranged on an NxN rectangu- 
lar grid, as in the previous case. Interconnections are expressed by 
means of a matrix R of routing probabilities: rij !l<i,j<M) repre- 
sents the probability that a stimulation (cuStomer} TeavTng node i 
will next visit node j. Since it is anopen network, after visiting an 
arbitrary number of cells, stimulations may eventually leave the net- 
work. Let .rio denote the probability of leaving the network upon lea- 
ving node 1. In What follows, we will assume that rio:s for all nodes. 
In what concerns the routing proba6ilities ri. i, they are determined 
by the two interconnection schemata considered in the previous sec- 
tion (propagative and looping connections): each node i has two out- 
put nodes j, for which the routing probabilities are equally distri- 
buted. Thus, rij:(1-s)/2 for the two output nodes of i and equal to 
zero for all other nodes in the network. 
- External stimulation arrivals follow a Poisson process with parame- 
ter A and are routed to the nodes according to the probability dis- 
tribution qi (l<_i<_M) as in the previous section. 
- Stimulations receive a ""service time"" at each node visited. Service 
times are independent identically distributed random variables, which 
are exponentially distributed with parameter V. The time spent by a 
stimulation at a node depends also upon the ""service discipline"" 
adopted. We shall consider two types of service disciplines according 
to the general queueing network model 4: the first-come-first-served 
(FCFS) discipline, where customers are served in the order of their 
arrival to the node, and the infinite-server (IS) discipline, where 
a customer's service is immediately assumed upon arrival to the node, 
as if there were always a server available for each arriving custo- 
mer (the second type includes no waiting delay). We will refer to the 
above two types of nodes as type i and type 2 respectively. In either 
case, all nodes of the network will be of the same type. 
The steady-state solution of the above network is a straight- 
forward application of the general BCMP theorem 4 according to the 
745 
simple assumptions considered. The state of the system is described 
.by the vector (kl,k2,...,kM), where ki is the number of customers 
present t node i. We first define the traffic intensity Pi for each 
node i as 
Pi = Aei/v , i : 1,2,...,M (1) 
where the quantities {ei} are the solution of the following set of 
linear equations: 
M 
ei = qi +  e.r i = 1,2, ,M (2) 
j=l j ji ' '"" 
It can be easily seen that, in fact, e i represents the average num- 
ber of visits a customer makes to node i during his sojourn in the 
network. The existence of a steady-state distribution for the system 
depends on the solution of the above set. Following the general theo- 
rem 4, the joint steady-state distribution takes the form of a pro- 
duct of independent distributions for the nodes: 
Where 
p(kl,k2,...,kM) : l(kl)P2(k2)...PM(kM) 
(3) 
k i 
(1-Pi)p i (Type 1) 
Pi(ki ) : k i (4) 
-Pi Pi 
e k---. (Type 2) 
provided that the stability condition Pi<l is satisfied for type 1 
nodes. 
The product form solution of this type of network expresses the 
idea of global and local balance which is characteristic of ergodic 
Markov processes. We can then proceed to deriving the desired measure 
fOP each node in the network; we are interested in the probability of 
being active for each node, which can be interpreted as the probabi- 
lity that at least one customer is present at the node: 
I Pi (Type 1) 
P(ki>O):l-Pi(O) : (5} 
1-e -�i (Type 2} 
The variation in space of the above quantity will be studied with res- 
pect to the corresponding measure obtained from simulation experi- 
ments for the neural network model. 
NUMERICAL AND SIMULATION EXAMPLES 
Simulations and numerical solutions of the queueing network mo- 
el were run for different values of the parameters. The network si- 
zes considered are relatively small but can provide useful informa- 
tion on the patial organization of the networks. For both types of 
service discipline discussed in the previous section, the approach 
followed yields a very good approximation of the network's organiza- 
tion in most regions of the rectangular grid. The choice of the pro- 
bability s of leaving the network plays a critical role in the beha- 
746 
i I I I 
I11 
(a) i I I X (b) 
I1 , ><2 >4 
><Y,, x ./ 
I I 
I I _ 
I xxxx x 
Fig.3. A 10x10 network with A=I, V=I and propagative connections. 
External stimulations are uniformly distributed over a 3x3 square 
on the upper left corner of the grid. (a) simulation (b) Queueing 
network approach with s=0.05 and type 2 nodes. 
(a) (b) 
Fig.4. The network of Fig.3 with A=2 (a) Simulation (b) Queueing 
network approach with s=0.08 and type 2 nodes. 
viour of the queueing model,and must have a non-zero value in order 
for the network to be stable. Good results are obtained for very 
small values of s; in fact, this parameter represents the phenomenon 
of excitation being ""lost"" somewhere in the network. Graphical re- 
presentations for various cases are shown in Figures 3-7. We have 
used a coloring of five ""grey levels"", defined by dividing into five 
segments the interval between the smallest and the largest value of 
the probability on the grid; the normalization is performed with res- 
pect to simulation results. This type of representation is less ac- 
curate than directly providing numerical values, but is more clear 
for describing the organization of the system. In each case, the 
results shown for the queueing model concern only one type of nodes, 
the one that best fits the simulation results, which is type 2 in 
the majority of cases examined. The graphical representation illu- 
strates the structuring of the distribution of excitation on the 
grid in terms of functionally connected regions of high and low 
747 
(a) 
(b) 
Fig.5. A 10x10 network with A:I, V:I and looping connections. 
External stimulations are uniformly distributed over a 4x4 
square on the center of the grid. (a) Simulation (b) Queueing 
network approach with s=0.07 and type 2 nodes. 
(a) (b) 
I! 
Fig.6. The network of Fig.5 with h=0.5 (a) Simulation (b) Queue- 
ing network approach with s=0.03 and type 2 nodes. 
excitation. We notice that clustering of nodes mainly follows the 
spatial distribution of external stimulations and is more sharply 
structured in the case of looping connections. 
CONCLUSION 
We have developed in this paper a simple continuous-time pro- 
babilistic model of neural nets in an attempt to investigate their 
spatial organization. The model incorporates some of the main fea- 
tures of the McCulloch-Pitts ""formal neurons"" model and assumes boo- 
lean operation of the elementary cells. The steady-state behaviour 
of the model was approximated by means of a queueing network model 
with suitably chosen parameters. Results obtained from the solution 
of the above approximation were compared with simulation results of 
the initial model, which validate the approximation. This simpli- 
fied approach is a first step in an attempt to study the organiza- 
748 
I I I 
I I I 
IFdX 
x 
(b) 
Fig.7. A 16x16 network with A=I, V=I and looping connections. 
External stimulations are uniformly distributed over two 4x4 
squares on the upper left and lower right corners of the grid. 
(a) Simulation (b) Queueing network approach with s:0.05 and 
type I nodes. 
74q 
tional properties of neural nets by means of markovian modeling te- 
chniques. 
REFERENCES 
1. W. S. McCulloch, W. Pitts, ""A Logical Calculus of the Ideas Im- 
manent in Nervous Activity"", Bull. of Math. Biophysics 5, 115- 
133 (1943). 
2. M. L. Min�ky, Computation: Finite and Infinite Machines (Pren- 
tice Hall, 1967). 
3. S. Kauffman, ""Behaviour of Randomly Constructed Genetic Nets"", 
in Towards a Theoretical Biology, Ed. C. H. Waddington (Edin- 
burgh University Press, 1970). 
4. F. Baskett, K. M. Chandy, R. R. Muntz, F. G. Palacios, ""Open, 
Closed and Mixed Networks of Queues with Different Classes of 
Customers"", J. ACM, 22 (1975). 
5. H. Atlan, F. Fogelman-Souli, J. Salomon, G. Weisbuch, ""Random 
Boolean Networks"", Cyb. and Syst. 12 (1981). 
6. F. Folgeman-Souli, E. Goles-Chacc, G. Weisbuch, ""Specific Roles 
of the Different Boolean Mappings in Random Networks"", Bull. of 
Math. Biology, Vol.44, No 5 (1982). 
7. G. R. Cross, A. K. Jain, ""Markov Random Field Texture Models"", 
IEEE Trans. on PAMI, Vol. PAMI-5, No I (1983). 
8. E. R. Kandel, J. H. Schwartz, Principles of Neural Science, 
(Elsevier, N.Y., 1985). 
9. J. J. Hopfield, D. W. Tank, ""Computing with Neural Circuits: 
A Model"", Science, Vol. 233, 625-633 (1986). 
10. Y. S. Abu-Mostafa, D. Psaltis, ""Optical Neural Computers"", 
Scient. Amer., 256, 88-95 (1987). 
11. R. P. Lippmann, ""An Introduction to Computing with Neural Nets"", 
IEEE ASSP Mag. (Apr. 1987). 
12. C. A. Mead, ""Neural Hardware for Vision"", Eng. and Scie. (June 
1987). 
13. E. Gelenbe, A. Stafylopatis, ""Temporal Behaviour of Neural Net- 
works"", IEEE First Intern. Conf. on Neural Networks, San Diego, 
CA (June 1987). 
14. L. Onural, ""A Systematic Procedure to Generate Connected Binary 
Fractal Patterns with Resolution-varying Texture"", Sec. Intern. 
Sympt. on Comp. and Inform. Sciences, Istanbul, Turkey (Oct. 
1987). 
", organ neural probabilist model approach stafylopati dikaiako kontoravdi technic univers depart comput scienc aim paper explor spatial organ network markovian concern individu cell interconnect properti neural net relev imag pattern spatial comput imag field first approach develop random neural network base upon simpl whose organ studi mean investig possibl random behaviour use analyt origin theori gener queue neural network describ open network custom move node node repres connect node express term select rout obtain solut differ disciplin affect time spent node result concern distribut excit network function network topolog stimul arriv pattern compar measur simul valid approach net model studi mani year attempt achiev perform comput model compos larg number interconnect comput structur reflect present understand principl biolog nervou neural equival rather intend repres logic aris certain situat provid accur descript realist last knowledg goe brain increas new discoveri natur make examin possibl use modern technolog properti real system origin neural net model develop culloch pitt network made mani interact logic unit two possibl state chang state institut physic threshold function relat automata use later gene control system gene repres binari automata chang state boolean function boolean network gener whose dynam behaviour due larg number exact connect function individu gener unknown assum distribut studi random boolean network shown exhibit surprisingli stabl behaviour concern spatial formal result sinc studi concern statist comput tempor spatial organ random boolean network particular interest attempt understand model origin theori process seem spatial properti net import field imag recognit biolog comput layer horizont fed immedi layer horizont cell take receptor averag spatial averag weight procedur mechan determin bright level pixel imag field use array process local comput usual adopt model use gener textur among stochast appli paramet imag markov field model seem give suitabl structur mainli due applic properti type model constitut altern studi spatial organ phenomena approach taken paper aim investig spatial organ simpl stochast next section develop model random neural network boolean oper individu behaviour obtain simul use techniqu theori queue approxim yield quit interest result illustr random network model defin random neural network set element one one two differ fire cell interconnect form grid occupi shall consid connect cell connect among two input two output cell output cell equal intern state sent output cell use one network topolog thu specifi incid matrix dimens matrix simpl form case consid assum period structur connect input interest follow type network depend upon period reproduct squar modul shown propag net loop net propag loop connect edg circular connect establish network view support oper network chang determin interact among cell extern assum stimul arriv outsid world accord poisson process paramet arriv stimul associ exactli one cell cell concern determin mean given probabl distribut qi consid label oper individu cell asynchron term follow quiet cell move fire state receiv arriv boolean function input becom fire cell move quiet state boolean function becom chang state impli reaction delay cell delay independ ident distribut random variabl neg exponenti distribut paramet oper cell view horizont axi repres time repres phase oper phase indic correspond reaction quiet fire defin beginingofthi repres aggreg phase stimul affect receiv cell otherwis consid stimul assum chang valu input boolean affect oper cell phase check onlyat end respect reaction ta te state chang state individu cell defin model includ featur origin cell itrepres asynchron boolean function consid threshold shown culloch neural network implement boolean design appropri fashion fire condit individu cell function assumpt evolut network describ markov size complex system analyt solut spatial network could express term probabl distribut markov use provid margin probabl distribut cell equival probabl fire state measur express excit point studi behaviour model mean experi variou case depend upon network connect distribut extern stimul grid paramet exampl last comparison result obtain approach discuss next estim concern probabl fire state simul implement accord run carri tliewidth confid interv less estim valu maximum number event simul depend upon size analyt approach neural network model consid previou section markovian properti time markovian express principl featur markov random field alreadi attempt approxim random neural network use markovian constraint markovian model consid open queue belong gener class network admit solut one distinguish sever featur two network neural receiv inform form stimul signal perform comput repres chang network view flow excit among spatial distribut excit repres network inform kindof particularli relev process imag queue compos number servic custom arriv outsid world spend node receiv servic node follow arriv interconnect node oper network character activ among us consid queue node repres custom repres stimul move cell cell topolog aim defin characterist way match neural net much queue network model complet follow network compos node arrang previou interconnect express matrix rout rij probabl stimul tng node next visit node sinc anopen visit number stimul may eventu leav let denot probabl leav network upon node assum concern rout determin two interconnect schemata consid previou loop node two node rout probabl equal two output node equal node extern stimul arriv follow poisson process rout node accord probabl qi previou stimul receiv node servic independ ident distribut random exponenti distribut paramet time spent node depend also upon shall consid two type servic disciplin accord gener queue network model custom serv order servic immedi assum upon arriv alway server avail arriv second type includ wait refer two type node type type either node network solut network applic gener bcmp theorem accord assumpt state system describ vector ki number custom node first defin traffic intens pi quantiti solut follow set qi ji easili seen repres averag visit custom make node sojourn exist distribut system solut follow gener joint distribut take form independ distribut pi stabil condit satisfi type product form solut type network express global local balanc characterist ergod proceed deriv desir measur op node interest probabl activ interpret least one custom present pi variat space quantiti studi correspond measur obtain simul neural network simul exampl numer solut queue network run differ valu network consid rel small provid use organ type disciplin discuss previou approach yield good approxim region rectangular choic leav network play critic role network propag stimul uniformli distribut squar upper left corner simul queue approach type network simul queue approach type queue must valu order network good result obtain valu paramet repres phenomenon excit somewher graphic variou case shown figur color five defin divid five interv smallest largest valu probabl normal perform simul type represent less directli provid numer clear describ organ shown queue model concern one type one best fit simul type major case graphic represent structur distribut excit term function connect region high low network loop stimul uniformli distribut center simul queue approach type network simul network approach type notic cluster node mainli follow distribut extern stimul sharpli case loop develop paper simpl model neural net attempt investig model incorpor main model assum oper elementari behaviour model approxim mean queue network model suitabl chosen result obtain solut approxim compar simul result initi valid approach first step attempt studi network loop stimul uniformli distribut two upper left lower right corner simul queue network approach properti neural net mean markovian model logic calculu idea nervou biophys finit infinit machin randomli construct genet toward theoret waddington univers mix network queue differ class role differ boolean map random random field textur principl neural neural neural introduct comput neural assp hardwar behaviour neural ie first neural san systemat procedur gener connect binari pattern turkey,0
78,78,"75O 
A DYNAMICAL APPROACH TO TEMPORAL PATTERN 
PROCESSING 
W. Scott Stornetta 
Stanford University, Physics Department, Stanford, Ca., 94305 
Tad Hogg and B. A. Huberman 
Xerox Palo Alto Research Center, Palo Alto, Ca. 94304 
ABSTRACT 
Recognizing patterns with temporal context is important for 
such tasks as speech recognition, motion detection and signature 
verification. We propose an architecture in which time serves as its 
own representation, and temporal context is encoded in the state of the 
nodes. We contrast this with the approach of replicating portions of the 
architecture to represent time. 
As one example of these ideas, we demonstrate an architecture 
with capacitive inputs serving as temporal feature detectors in an 
otherwise standard back propagation model. Experiments involving 
motion detection and word discrimination serve to illustrate novel 
features of the system. Finally, we discuss possible extensions of the 
architecture. 
INTRODUCTION 
Recent interest in connectionist, or ""neural"" networks has emphasized their 
ability to store, retrieve and process patterns 1'2. For most applications, the patterns to 
be processed are static in the sense that they lack temporal context. 
Another important class consists of those problems that require the processing 
of temporal patterns. In these the information to be learned or processed is not a 
particular pattern but a sequence of patterns. Such problems include speech 
processing, signature verification, motion detection, and predictive signal 
processing 3'8. 
More precisely, temporal pattern processing means that the desired output 
depends not only on the current input but also on those preceding or following it as 
well. This implies that two identical inputs at different time steps might yield 
different desired outputs depending on what patterns precede or follow them. 
There is another feature characteristic of much temporal pattern processing. 
Here an entire sequence of patterns is recognized as a single distinct category, 
@ American Institute of Physics 1988 
751 
generating a single output. A typical example of this would be the need to recognize 
words from a rapidly sampled acoustic signal. One should respond only once to the 
appearance of each word, even though the word consists of many samples. Thus, each 
input may not produce an output. 
With these features in mind, there are at least three additional issues which 
networks that process temporal patterns must address, above and beyond those that 
work with static patterns. The first is how to represent temporal context in the state of 
the network. The second is how to train at intermediate time steps before a temporal 
pattern is complete. The third issue is how to interpret the outputs during recognition, 
that is, how to tell when the sequence has been completed. Solutions to each of these 
issues require the construction of appropriate input and output representations. This 
paper is an attempt to address these issues, particularly the issue of representing 
temporal context in the state of the machine. We note in passing that the recognition 
of temporal sequences is distinct from the related problem of generating a sequence, 
given its first few members 9A0'11. 
TEMPORAL CLASSIFICATION 
With some exceptions 10'12, in most previous work on temporal problems the 
systems record the temporal pattern by replicating part of the architecture for each 
time step. In some instances input nodes and their associated links are replicated 3'4. In 
other cases only the weights or links are replicated, once for each of several time 
delays ?'8. In either case, this amounts to mapping the temporal pattern into a spatial 
one of much higher dimension before processing. 
These systems have generated significant and encouraging results. However, 
these approaches also have inherent drawbacks. First, by replicating portions of the 
architecture for each time step the amount of redundant computation is significantly 
increased. This problem becomes extreme when the signal is sampled very 
frequently 4. Next, by relying on replications of the architecture for each time step, the 
system is quite inflexible to variations in the rate at which the data is presented or size 
of the temporal window. Any variability in the rate of the input signal can generate an 
input pattern which bears little or no resemblance to the trained pattern. Such 
variability is an important issue, for example, in speech recognition. Moreover, having 
a temporal window of any fixed length makes it manifestly impossible to detect 
contextual effects on time scales longer than the window size. An additional difficulty 
is that a misaligned signal, in its spatial representation, may have very little 
resemblance to the correctly aligned training signal. That is, these systems typically 
suffer from not being translationally invariant in time. 
Networks based on relaxation to equilibrium ll'13'14 also have difficulties for 
use with temporal problems. Such an approach removes any dependence on initial 
752 
conditions and hence is difficult to reconcile directly with temporal problems, which by 
their nature depend on inputs from earlier times. Also, if a temporal problem is to be 
handled in terms of relaxation to equilibrium, the equilibrium points themselves must 
be changing in time. 
A NON-REPLICATED, DYNAMIC ARCHITECTURE 
We believe that many of the difficulties mentioned above are tied to the 
attempt to map an inherently dynamical problem into a static problem of higher 
dimension. As an alternative, we propose to represent the history of the inputs in the 
state of the nodes of a system, rather than by adding additional units. Such an 
approach to capturing temporal context shows some very immediate advantages over 
the systems mentioned above. First, it requires no replication of units for each distinct 
time step. Second, it does not fix in the architecture itself the window for temporal 
context or the presentation rate. These advantages are a direct result of the decision to 
let time serve as its own representation for temporal sequences, rather than creating 
additional spatial dimensions to represent time. 
In addition to providing a solution to the above problems, this system lends 
itself naturally to interpretation as an evolving dynamical system. Our approach 
allows one to think of the process of mapping an evolving input into a discrete 
sequence of outputs (such as mapping continuous speech input into a sequence of 
words) as a dynamical system moving from one attractor to another 15. 
As a preliminary example of the application of these ideas, we introduce a 
system that captures the temporal context of input patterns without replicating units 
for each time step. We modify the conventional back propagation algorithm by making 
the input units capacitive. In contrast to the conventional architecture in which the 
input nodes are used simply to distribute the signal to the next layer, our system 
performs an additional computation. Specifically, let Xi be the value computed by an 
input node at time t i , and I t be the input signal to this node at the same time. Then the 
node computes successive values according to 
Xi+l= aIi+ t + dXi (1) 
where a is an input amplitude and d is a decay rate. Thus, the result computed by an 
input unit is the sum of the current input value multiplied by a, plus a fractional part, 
d, of the previously computed value of the input unit. In the absence of further input, 
this produces an exponential decay in the activation of the input nodes. The value for d 
is chosen so that this decay reaches 1/e of its original value in a time  characteristic of 
the time scale for the particular problem, i.e., d=e 'r, where r is the presentation rate. 
The value for a is chosen to produce a specified maximum value for X, given by 
753 
aImax/(1-d). We note that Eq. (1) is equivalent to having a non-modifiable recurrent 
link with weight d on the input nodes, as illustrated in Fig. 1. 
o o 
Fig. 1: Schematic architecture with capacitive inputs. The input nodes 
compute values according to Eq. (1). Hidden and output units are 
identical to standard back propagation nets. 
The processing which takes place at the input node can also be thought of in 
terms of an infinite impulse response (IIR) digital filter. The infinite impulse response 
of the filter allows input from the arbitrarily distant past to influence the current 
output of the filter, in contrast to methods which employ fixed windows, which can be 
viewed in terms of finite impulse response (FIR) filters. The capacitive node of Fig. 1 is 
equivalent to pre-processing the signal with a filter with'transfer function a/(1-dz'l). 
This system has the unique feature that a simple transformation of the 
parameters a and d allows it to respond in a near-optimal way to a signal which differs 
from the training signal in its rate. Consider a system initially trained at rate r with 
decay rate d and amplitude a. To make use of these weights for a different presentation 
rate, r', one simply adjusts the values a 'and d'according to 
d' = d r/r' (2) 
1 - d' 
a' = a 1-d (3) 
754 
These equations can be derived by the following argument. The general idea is 
that the values computed by the input nodes at the new rate should be as close as 
possible to those computed at the original rate. Specifically, suppose one wishes to 
change the sampling rate from r to nr, where n is an integer. Suppose that at a time t o 
the computed value of the input node is X 0. [f this node receives no additional input, 
then after m time steps, the computed value of the input node will be X0 dm. For the 
more rapid sampling rate, X0 drn should be the value obtained after nm time steps. 
Thus we require 
Xo dm= Xod'mn (4) 
which leads to Eq. (2) because n-rr. Now suppose that an input I is presented m 
times in succession to an input node that is initially zero. After the rn th presentation, 
the computed value of the input node is 
1 -d TM 
aI 1-d (5) 
Requiring this value to be equal to the corresponding value for the faster presentation 
rate after nm time steps leads to Eq. (3). These equations, then, make the computed 
values of the input nodes identical, independent of the presentation rate. Of course, 
this statement only holds exactly in the limit that the computed values of the input 
nodes change only infinitesimally from one time step to the next. Thus, in practice, one 
must insure that the signal is sampled frequently enough that the computed value of 
the input nodes is slowly changing. 
The point in weight space obtained after initial training at the rate r has two 
desirable properties. First, it can be trained on a signal at one sampling rate and then 
the values of the weights arrived at can be used as a near-optimal starting point to 
further train the system on the same signal but at a different sampling rate. 
Alternatively, the system can respond to temporal patterns which differ in rate from 
the training signal, without any retraining of the weights. These factors are a result of 
the choice of input representation, which essentially present the same pattern to the 
hidden unit and other layers, independent of sampling rate. These features highlight 
the fact that in this system the weights to some degree represent the temporal pattern 
independent of the rate of presentation. In contrast, in systems which use temporal 
windows, the weights obtained after training on a signal at one sampling rate would 
have little or no relation to the desired values of the weights for a different sampling 
rate or window size. 
755 
EXPERIMENTS 
As an illustration of this architecture and related algorithm, a three-layer, 
15-30-2 system was trained to detect the leftward or rightward motion of a gaussian 
pulse moving across the field of input units with sudden changes in direction. The 
values of d and a were 0.7788 and 0.4424, respectively. These values were chosen to 
give a characteristic decay time of 4 time steps with a maximum value computed by 
the input nodes of 2.0. The pulse was of unit height with a half-width, o, of 1.3. Figure 
2 shows the input pulse as well as the values computed by the input nodes for leftward 
or rightward motion. Once trained at a velocity of 0.1 unit per sampling time, the 
velocity was varied over a wide range, from a factor of 2 slower to a factor of 2 faster as 
shown in Fig. 3. For small variations in velocity the system continued to correctly 
identify the type of motion. More impressive was its performance when the scaling 
relations given in Eqs. (2) and (3) were used to modify the amplitude and decay rate. In 
this case, acceptable performance was achieved over the entire range of velocities 
tested. This was without any additional retraining at the new rates. The difference in 
performance between the two curves also demonstrates that the excellent performance 
of the system is not an anomaly of the particular problem chosen, but characteristic of 
rescaling a and d according to Eqs. (2) and (3). We thus see that a simple use of 
capacitive links to store temporal context allows for motion detection at variable 
velocities. 
A second experiment involving speech data was performed to compare the 
system's performance to the time-delay-neural-network of Watrous and Shastri $. In 
their work, they trained a system to discriminate between suitably processed acoustic 
signals of the words ""no"" and ""go."" Once trained on a single utterance, the system was 
able to correctly identify other samples of these words from the same speaker. One 
drawback of their approach was that the weights did not converge to a fixed point. We 
were therefore particularly interested in whether our system could converge smoothly 
and rapidly to a stable solution, using the same data, and yet generalize as well as 
theirs did. This experiment also provided an opportunity to test a solution to the 
intermediate step training problem. 
The architecture was a 16-30-2 network. Each of the input nodes received an 
input signal corresponding to the energy (sampled every 2.5 milliseconds) as a 
function of time in one of 16 frequency channels. The input values were normalized to 
lie in the range 0.0 to 1.0. The values of d and a were 0.9944 and 0.022, respectively. 
These values were chosen to give a characteristic decay time comparable to the length 
of each word (they were nearly the same length), and a maximum value computed by 
the input nodes of 4.0. For an input signal that was part of the word ""no"", the training 
signal was (1.0, 0.0), while for the word ""go"" it was (0.0, 1.0). Thus the outputs that 
were compared to the training signal can be interpreted as evidence for one word or the 
other at each time step. The error shown in Fig. 4 is the sum of the squares of the 
756 
difference between the desired outputs and the computed outputs for each time step, 
for both words, after training up to the number of iterations indicated along the x-axis. 
a) input wavepacket 
2 3 4 5 6 7 8 9 
b) righ.tward . 
2 3 4 5 6 7 8 9 10 
c) left.ward / 
In to 
2 3 4 5 6 7 8 9 10 
Fig. 2: a) Packet presented to input nodes. The x-axis represents the 
input nodes. b) Computed values from input nodes during rightward 
motion. c) Computed values during leftward motion. 
757 
c 
o 
r 
r 
e 
c 
t 
lOO 
8O 
6O 
4O 
2O 
I I I I 
.5 1.0 1.5 2.0 
V'/V 
Fig. 3: Performance of motion detection experiment for various 
velocities. Dashed curve is performance without scaling and solid 
curve is with the scaling given in Eqs. (2) and (3). 
125.0 
e 
r 
r 
o 
r 
100.0 
75.0 
50.0 
25.0 
0.0 
I I I I 
0 500 1000 1500 2000 2500 
iterations 
Fig. 4: Error in no/go discrimination as a function of the number of 
training iterations. 
Evidence for each word was obtained by summing the values of the respective 
nodes over time. This suggests a mechanism for signaling the completion of a 
sequence: when this sum crosses a certain threshold value, the sequence (in this case, 
the word) is considered recognized. Moreover, it may be possible to extend this 
mechanism to apply to the case of connected speech: after a word is recognized, the 
sums could be reset to zero, and the input nodes reinitialized. 
Once we had trained the system on a single utterance, we tested the 
performance of the resulting weights on additional utterances of the same speaker. 
758 
Preliminary results indicate an ability to correctly discriminate between ""no"" and 
""go."" This suggests that the system has at least a limited ability to generalize in this 
task domain. 
DISCUSSION 
At a more general level, this paper raises and addresses some issues of 
representation. By choosing input and output representations in a particular way, we 
are able to make a static optimizer work on a temporal problem while still allowing 
time to serve as its own representation. In this broader context, one realizes that the 
choice of capacitive inputs for the input nodes was only one among many possible 
temporal feature detectors. 
Other possibilities include refractory units, derivative units and delayed spike 
units. Refractory units would compute a value which was some fraction of the current 
input. The fraction would decrease the more frequently and recently the node had been 
""on"" in the recent past. A derivative unit would have a larger output the more rapidly 
a signal changed from one time step to the next. A delayed spike unit might have a 
transfer function of the form Itne 'at, where t is the time since the presentation of the 
signal. This is similar to the function used by Tank and Hopfield 7, but here it could 
serve a different purpose. The maximum value that a given input generated would be 
delayed by a certain amount of time. By similarly delaying the training signal, the 
system could be trained to recognize a given input in the context of signals not only 
preceding but also following it. An important point to note is that the transfer 
functions of each of these proposed temporal feature detectors could be rescaled in a 
manner similar to the capacitive nodes. This would preserve the property of the system 
that the weights contain information about the temporal sequence to some degree 
independent of the sampling rate. 
An even more ambitious possibility would be to have the system train the 
parameters, such as d in the capacitive node case. It m/y be feasible to do this in the 
same way that weights are trained, namely by taking the partial of the computed error 
with respect to the parameter in question. Such a system may be able to determine the 
relevant time scales of a temporal signal and adapt accordingly. 
ACKNOWLEDGEMENTS 
We are grateful for fruitful discussions with Jeff Kephart and the help of 
Raymond Watrous in providing data from his own experiments. This work was 
partially supported by DARPA ISTO Contract # N00140-86-C-8996 and ONR 
Contract # N00014-82-0699. 
759 
References
10. 
11. 
12. 
13. 
14. 
15. 
D. Rumelhart, ed., Parallel Distributed Processing, (MIT Press, Cambridge, 
1986). 
J. Denker, ed., Neural Networks for Computing, AIP Conf. Proc., 151 (1986). 
T. J. Sejnowski and C. R. Rosenberg, NETtalk: A Parallel Network that Learns to 
Read Aloud, Johns Hopkins Univ. Report No. JHU/EECS-86/01 (1986). 
J.L. McClelland and J.L. Elman, in Parallel Distributed Processing, vol. II, p. 58. 
W. Keirstead and B.A. Huberman, Phys. Rev. Lett. 56, 1094 (1986). 
A. Lapedes and R. Farber, Nonlinear Signal Processing Using Neural Networks, 
Los Alamos preprint LA-UR-87-2662 (1987). 
D. Tank and J. Hopfield, Proc. Nat. Acad. Sci., 84, 1896 (1987). 
R. Watrous and L. Shastri, Proc. 9th Ann. Conf Cog. Sci. Soc., (Lawrence 
Erlbaum, Hillsdale, 1987), p. 518. 
P. Kanerva, Self-Propagating Search: A Unified Theory of Memory, Stanford 
Univ. Report No. CSLI-84-7 (1984). 
M.I. Jordan, Proc. 8th Ann. Conf Cog. Sci. Soc., (Lawrence Erlbaum, Hillsdale, 
1986), p. 531. 
J. Hopfield, Proc. Nat. Acad. Sci., 79, 2554 (1982). 
S. Grossberg, The Adaptive Brain, vol. II, ch. 6, (North-Holland, Amsterdam, 
1987). 
G. Hinton and T. J. Sejnowski, in Parallel Distributed Processing, vol. I, p. 282. 
B. Gold, in Neural Networks for Computing, p. 158. 
T. Hogg and B.A. Huberman, Phys. Rev. A32, 2338 (1985). 
", dynam approach tempor pattern scott stornetta physic hogg huberman palo alto research palo pattern tempor context import task speech motion detect signatur propos architectur time serv tempor context encod state contrast approach replic portion repres one exampl demonstr architectur capacit input serv tempor featur detector standard back propag experi involv detect word discrimin serv illustr novel discuss possibl extens interest network emphas retriev process pattern pattern process static sens lack tempor import class consist problem requir process tempor inform learn process pattern sequenc problem includ speech signatur motion predict signal tempor pattern process mean desir output current input also preced follow impli two ident input differ time step might yield desir output depend pattern preced follow anoth featur characterist much tempor pattern entir sequenc pattern recogn singl distinct american institut physic singl typic exampl would need recogn rapidli sampl acoust one respond even though word consist mani may produc featur least three addit issu process tempor pattern must beyond static first repres tempor context state second train intermedi time step tempor third issu interpret output tell sequenc solut requir construct appropri input output attempt address particularli issu repres context state note pass recognit tempor sequenc distinct relat problem gener first member classif except previou work tempor problem record tempor pattern replic part architectur instanc input node associ link replic case weight link sever time either amount map tempor pattern spatial much higher dimens system gener signific encourag approach also inher replic portion time step amount redund comput significantli problem becom extrem signal sampl reli replic architectur time quit inflex variat rate data present size tempor variabl rate input signal gener pattern bear littl resembl train import speech tempor window fix length make manifestli imposs detect effect time scale longer window addit difficulti misalign spatial may littl correctli align train system typic translat invari base relax equilibrium also difficulti tempor approach remov depend initi henc difficult reconcil directli tempor natur depend input earlier tempor problem term relax equilibrium point must chang dynam architectur believ mani difficulti mention tie map inher dynam problem static problem higher propos repres histori input node rather ad addit captur tempor context show immedi advantag system mention requir replic unit distinct fix architectur window tempor present advantag direct result decis time serv represent tempor rather creat spatial dimens repres addit provid solut system lend natur interpret evolv dynam approach one think process map evolv input discret output map continu speech input sequenc dynam system move one attractor anoth preliminari exampl applic introduc captur tempor context input pattern without replic unit time modifi convent back propag algorithm make input unit contrast convent architectur node use simpli distribut signal next system addit let xi valu comput node time input signal node comput success valu accord xi input amplitud decay result comput unit sum current input valu multipli plu fraction previous comput valu input absenc produc exponenti decay activ input valu chosen decay reach origin valu time characterist time scale particular present valu chosen produc specifi maximum valu given note equival recurr weight input illustr schemat architectur capacit input node valu accord hidden output unit standard back propag process take place input node also thought infinit impuls respons digit infinit impuls respons filter allow input arbitrarili distant past influenc current contrast method employ fix term finit impuls respons capacit node signal filter function system uniqu featur simpl transform allow respond way signal differ train signal consid system initi train rate rate amplitud make use weight differ present one simpli adjust valu equat deriv follow gener idea valu comput input node new rate close comput origin suppos one wish sampl rate suppos time comput valu input node node receiv addit time comput valu input node rapid sampl drn valu obtain nm time requir lead suppos input present success input node initi rn th comput valu input node tm valu equal correspond valu faster present nm time step lead make comput input node independ present statement hold exactli limit comput valu input chang infinitesim one time step one insur signal sampl frequent enough comput valu input node slowli point weight space obtain initi train rate two train signal one sampl rate valu weight arriv use start point train system signal differ sampl system respond tempor pattern differ rate train without retrain factor result choic input essenti present pattern unit independ sampl featur highlight fact system weight degre repres tempor pattern rate system use tempor weight obtain train signal one sampl rate would littl relat desir valu weight differ sampl window illustr architectur relat system train detect leftward rightward motion gaussian move across field input unit sudden chang valu chosen characterist decay time time step maximum valu comput input node puls unit height figur show input puls well valu comput input node leftward rightward train veloc unit per sampl vari wide factor slower factor faster small variat veloc system continu correctli type impress perform scale given use modifi amplitud decay accept perform achiev entir rang veloc without addit retrain new differ two curv also demonstr excel perform system anomali particular problem characterist accord thu see simpl use link store tempor context allow motion detect variabl second experi involv speech data perform compar perform watrou shastri train system discrimin suitabl process acoust word train singl system correctli identifi sampl word one approach weight converg fix therefor particularli interest whether system could converg smoothli rapidli stabl use yet gener well experi also provid opportun test solut step train architectur input node receiv signal correspond energi everi time one frequenc input valu normal rang valu valu chosen give characterist decay time compar length word nearli maximum valu comput input node input signal part word train word thu output compar train signal interpret evid one word time error shown sum squar desir output comput output time train number iter indic along input wavepacket packet present input repres comput valu input node rightward comput valu leftward oo perform motion detect experi variou dash curv perform without scale solid scale given error discrimin function number word obtain sum valu respect suggest mechan signal complet sum cross certain threshold sequenc consid may possibl extend appli case connect word could reset input node train system singl test result weight addit utter result indic abil correctli discrimin suggest system least limit abil gener gener paper rais address issu choos input output represent particular abl make static optim work tempor problem still allow serv broader one realiz capacit input input node one among mani possibl featur possibl includ refractori deriv unit delay spike refractori unit would comput valu fraction current fraction would decreas frequent recent node recent deriv unit would larger output rapidli signal chang one time step delay spike unit might function form itn time sinc present similar function use tank hopfield could differ maximum valu given input gener would certain amount similarli delay train could train recogn given input context signal also follow import point note transfer propos tempor featur detector could rescal similar capacit would preserv properti system weight contain inform tempor sequenc degre sampl even ambiti possibl would system train capacit node feasibl way weight name take partial comput error respect paramet system may abl determin time scale tempor signal adapt grate fruit discuss jeff kephart help watrou provid data work support darpa isto contract onr parallel distribut neural network aip sejnowski parallel network learn john hopkin report clelland parallel distribut keirstead laped nonlinear signal process use neural alamo preprint tank watrou conf unifi theori stanford report conf adapt hinton parallel distribut neural network hogg,1
79,79,"760 
A NOVEL NET THAT LEARNS 
SEQUENTIAL DECISION PROCESS 
G.Z. SUN, Y.C. LEE and H.H. CHEN 
Department of Physics and Astronomy 
and 
Institute for Advanced Computer Studies 
UNIVERSITY OF MARYLAND,COLLEGE PARK,MD 20742 
ABSTRACT 
We propose a new scheme to construct neural networks to classify pat- 
terns. The new scheme has several novel features: 
We focus attention on the important attributes of patterns in ranking 
order. Extract the most important ones first and the less important 
ones later. 
2. In training we use the information as a measure instead of the error 
function. 
3. A multi-perceptron-like architecture is formed auomatically. Decision 
is made according to the tree structure of learned attributes. 
This new scheme is expected to self-organize and perform well in large scale 
problems. 
� American Institute of Physics 1988 
761 
I INTRODUCTION 
It is well known that two-layered perceptron with binary connections but no 
hidden units is unsuitable as a classifier due to its limited power [1]. It cannot 
solve even the simple exclusive-or problem. Two extensions have been pro- 
osed to remedy this problem. The first is to use higher order connections 
]. It has been demonstrated that high order connections could in many 
cases solve the problem with speed and high accuracy [3], [4]. The repre- 
sentations in general are more local than distributive. The main drawback 
is however the combinatorial explosion of the number of high-order terms. 
Some kind of heuristic judgement has to be made in the choice of these terms 
to be represented in the network. 
A second proposal is the multi-layered binary network with hidden units 
5]. These hidden units function as features extracted from the bottom input 
ayer to facilitate the classification of patterns by the output units. In order 
to train the weights, learning algorithms have been proposed that back- 
propagate the errors from the visible output layer to the hidden layers for 
eventual adaptation to the desired values. The multi-layered networks enjoy 
great popularity in their flexibility. 
However, there are also problems in implementing the multi-layered nets. 
Firs fly, there is the problem of allocating the resources. Namely, how many 
hidden units would be optimal for a particular problem. If we allocate too 
many, it is not only wasteful but also could negatively affect the performance 
of the network. Since too many hidden units implies too many free param- 
eters to fit specifically the training patterns. Their ability to generalize to 
noval test patterns would be adversely affected. On the other hand, if too 
few hidden units were allocated then the network would not have the power 
even to represent the trainig set. How could one judge beforehand how many 
are needed in solving a problem? This is similar to the problem encountered 
in the high order net in its choice of high order terms to be represented. 
Secondly, there is also the problem of scaling up the network. Since the 
network represents a parallel or coorperative process of the whole system, 
each added unit would interact with every other units. This would become 
a serious problem when the size of our patterns becomes large. 
Thirdly, there is no sequential communication among the patterns in the 
conventional network. To accomplish a cognitive function we would need 
the patterns to interact and communicate with each other as the human 
reasoning does. It is difficult to envision such an interacton in current systems 
which are basically input-output mappings. 
2 THE NEW SCHEME 
In this paper, we would like to propose a scheme that constructs a network 
taking advantages of both the parallel and the sequential processes. 
We note that in order to classify patterns, one has to extract the intrinsic 
features, which we call attributes. For a complex pattern set, there may 
be a large number of attributes. But differnt attributes may have different 
762 
ranking of importance. Instead of extracing them all simultaneously it may 
be wiser to extract them sequentially in order of its importance [6], [7]. Here 
the importance of an attribute is determined by its ability to partition the 
pattern set into sub-categories. A measure of this ability of a processing unit 
should be based on the extracted information. For simplicity, let us assume 
that there are only two categories so that the units have only binary output 
values 1 and 0 ( but the input patterns may have analog representations). We 
call these units, including their connection weights to the input layer, nodes. 
For given connection weights, the patterns that are classified by a node as 
in category i may have their true classifications either i or O. Similarly, the 
patterns that are classified by a node as in category 0 may also have their 
true classifications either I or O. As a result, four groups of patterns are 
formed: (1,1), (0,0), (1,0), (0,1). We then need to judge on the efficiency of 
the node by its ability to split these patterns optimally. To do this we shall 
construct the impurity fuctions for the node. Before splitting, the impurity 
of the input patterns reaching the node is given by 
Ib -' _pb logpb _ po b logpo b (1) 
where P} = N/N is the probability of being truely classified as in category 
1, and P0  - No/N is the probability of being truely classified as in category 
O. After splitting, the patterns are channelled into two branches, the impurity 
becomes 
I. =-P  P(j, 1)logP(j, 1)- P  P(j,O)logP(j,O) (2) 
j=O,1 j=O,l 
where P -- Ni/N is the probability of being classified by the node as in 
category 1, P = NobiN is the probability of being classified by the node as 
in category O, and P(j, i) is the probability of a pattern, which should be in 
category j, but is classified by the node as in category i. The difference 
AI -- h -/' (3) 
represents the decrease of the impurity at the node after splitting. It is the 
quantity that we seek to optimize at each node. The logarithm in the im- 
purity function come from the information entropy of Shannon and Weaver. 
For all practical purpose, we found the. optimization of (3) the same as max- 
imizing the entropy [6] 
S N No 2 (_)2]+No Noo 2 .No)2 
- (00) 
(4) 
where Ni is the number of training patterns classified by the node as in 
category i, Nij is the number of training patterns with true classification in 
category i but classified by the node as in category j. Later we shall call the 
terms in the first bracket Sa and the second S2. Obviously, we have 
Ni = Noi + N i , i -- O, 1 
763 
After we trained the first unit, the training patterns were split into two 
branches by the unit. If the classificaton in either one of these two branches 
is pure enough, or equivalently either one of S and $2 is fairly close to 1, 
then we would terminate that branch ( or branches ) as a leaf of the decision 
tree, and classify the patterns as such. On the other hand, if either branch is 
not pure enough, we add additional node to split the pattern set further. The 
subsequent unit is trained with only those patterns channeled through this 
branch. These operations are repeated until all the branches are terminated 
as leaves. 
3 LEARNING ALGORITHM 
We used the stochastic gradient descent method to learn the weights of each 
node. The training set for each node axe those patterns being channeled to 
this node. As stated in the previous section, we seek to maximize the entropy 
function S. The learning of the weights is therefore conducted through 
Where r/is the learning rate. 
following equation 
os 
Using analog units 
we have 
OS 
,'xws = owj (5) 
The gradient of S can be calculated from the 
1 No:  . ann N; ONo 
N [(1 + (1 
_ 
No: o. ONto No ONoo 
(1 - 2-o)  + (1 - 2o ) ] 
Or _. 
1 
I + exp(-- Z.i WjI) 
O0 r 
_ or(1 - O"")q 
(6) 
(7) 
(8) 
Furthermore, let A r = 1 or 0 being the true answer for the input pattern r, 
then 
N 
Nis = r__ [iAr + (1-i)(1- Ar) ] [jO r + (1-j)(1- Or)] (9) 
Substituting these into equation (5), we get 
[ N,, N,o N o N'] O""(1 - Or)I; (10) 
AWj=2r i 2A""(  No)+ No 2 ] 
In applying the formula (10),instead of calculating the whole summation at 
once, we update the weights for each pattern individually. Meanwhile we 
update Nij in accord with equation (9). 
764 
Figure 1: The given classification tree, where 0,02 and Oa are chosen to be 
all zeros in the numerical example. 
4 AN EXAMPLE 
To illustrate our method, we construct an example which is itself a decision 
tree. Assuming there are three hidden variables al, a2, aa, a pattern is given 
by a ten-dimensional vector Ia, I2, ..., Ira, constructed from the three hidden 
variables as follows 
I1 -- al-{-a3 I6 -- 2a3 
12 = 2a -- a2 b -- a3 - al 
I3 -- a3 -- 2a2 Is = 2al + 3a3 
I4 = a + 2a2 + 3a3 I9 = 4a3 -- 3a 
I$ = 5a--4a4 Lo = 2a-{-2a2-{-2a3. 
A given pattern is classified as either 1 (yes) or 0 (no) according to the 
corresponding values of the hidden variables a, a2, aa. The actual decision 
is derived from the decision tree in Fig. 1. 
In order to learn this classification tree, we construct a training set of 5000 
patterns generated by randomly chosen values a, a2, aa in the interval -1 to 
+1. We randomly choose the initial weights for each node, and terminate 
765 
S= 0.79 
S, = 0.60 
S2 = 0.87' 
(2519/55) 
S :0.65 
'Sz = O. 88 
 (1617/il4) 
S = 0.85 
S= 0.75 
n4 
S: 0.90/ 
(92/5) -/ 
S=0.96 
Figure 2: The learned classification tree structure 
a branch as a leaf whenever the branch entropy is greater than 0.80. The 
entropy is started at S = 0.65, and terminated at its maximum value S = 
0.79 for the first node. The two branches of this node have the entropy 
fuction valued at Sa = 0.61, S2 = 0.87 respectively. This corrosponds to 
2446 patterns channeled to the first branch and 2554 to the second. Since 
S2 > 0.80 we terminate the second branch. Among 2554 patterns channeled 
to the second branch there are 2519 patterns with true classification as no and 
35 /es which are considered as errors. After completing the whole training 
process, there are totally four nodes automatically introduced. The final 
result is shown in a tree structure in Fig.2. 
The total errors classified by the learned tree are 3.4 % of the 5000 trainig 
patterns. After trainig we have tested the result using 10000 novel patterns, 
the error among which is 3.2 %. 
5 SUMMARY 
We propose here a new scheme to construct neural network that can au- 
tomatically learn the attributes sequentially to facilitate the classification 
of patterns according to the ranking importance of each attribute. This 
scheme uses information as a measure of the performance of each unit. It is 
766 
self-organized into a presumably optimal structure for a specific task. The 
sequential learning procedure focuses attention of the network to the most 
important attribute first and then branches out' to the less important at- 
tributes. This strategy of searching for attributes would alleviate the scale 
up problem forced by the overall parallel back-propagation scheme. It also 
avoids the problem of resource allocation encountered in the high-order net 
and the multi-layered net. In the example we showed the performance of the 
new method is satisfactory. We expect much better performance in problems 
that demand large size of units. 
6 acknowledgement 
This work is partially supported by AFOSR under the grant 87-0388. 
References 
[1] M. Minsky and S. Papert, Perceptton, MIT Press Cambridge, Ma(1969). 
[2] 
Y.C. Lee, G. Doolen, H.H. Chen, G.Z. Sun, T. Maxwell, H.Y. Lee and 
C.L. Giles, Machine Learning Using A High Order Connection Netwe- 
ork, Physics D22,776-306 (1986). 
[3] 
H.H. Chen, Y.C. Lee, G.Z. Sun, H.Y. Lee, T. Maxwell and C.L. Giles, 
High Order Connection Model For Associate Memory, AIP Proceedings 
Vol.151,p.86, Ed. John Denker (1986). 
[4] 
T. Maxwell, C.L. Giles, Y.C. Lee and H.H. Chen, Nonlinear Dynamics 
of Artificial Neural System, AIP Proceedings Vol.151,p.299, Ed. John 
Denker(1986). 
[5] D. Rummenlhart and J. McClelland, Parallel Distributive Processing, 
MIT Press(1986). 
[6] L. Breiman, J. Friedman, R. Olshen, C.J. Stone, Classification and Re- 
gression Trees,Wadsworth Belmont, California(1984). 
[7] J.R. Quinlan, Machine Learning, Vol.1 No.1(1986). 
", novel net learn decis process lee chen physic astronomi advanc comput studi propos new scheme construct neural network classifi new scheme sever novel focu attent import attribut pattern rank extract import one first less import train use inform measur instead error architectur form decis made accord tree structur learn new scheme expect perform well larg scale american institut physic introduct well known perceptron binari connect unit unsuit classifi due limit power can not even simpl two extens remedi first use higher order connect demonstr high order connect could mani solv problem speed high accuraci gener local main drawback howev combinatori explos number kind heurist judgement made choic term repres second propos binari network hidden unit hidden unit function featur extract bottom input facilit classif pattern output order train learn algorithm propos error visibl output layer hidden layer adapt desir network enjoy popular also problem implement problem alloc mani unit would optim particular alloc wast also could neg affect perform sinc mani hidden unit impli mani free fit specif train abil gener test pattern would advers hidden unit alloc network would power repres trainig could one judg beforehand mani need solv similar problem encount high order net choic high order term also problem scale sinc repres parallel coorper process whole ad unit would interact everi would becom seriou problem size pattern becom sequenti commun among pattern accomplish cognit function would need pattern interact commun human difficult envis interacton current system basic new scheme would like propos scheme construct network advantag parallel sequenti note order classifi one extract intrins call complex pattern may larg number differnt attribut may differ instead extrac simultan may wiser extract sequenti order import import attribut determin abil partit set measur abil process unit base extract let us assum two categori unit binari output input pattern may analog includ connect weight input given connect pattern classifi node categori may true classif either classifi node categori may also classif either four group pattern need judg effici node abil split pattern shall impur fuction impur input pattern reach node given po logpo probabl trueli classifi categori probabl trueli classifi categori pattern channel two impur probabl classifi node probabl classifi node categori probabl classifi node categori differ decreas impur node seek optim logarithm function come inform entropi shannon practic found optim entropi noo ni number train pattern classifi node nij number train pattern true classif classifi node categori later shall call first bracket sa second noi train first train pattern split two classificaton either one two branch pure equival either one fairli close would termin branch branch leaf decis classifi pattern either branch pure add addit node split pattern set unit train pattern channel oper repeat branch termin learn algorithm use stochast gradient descent method learn weight train set node axe pattern channel state previou seek maxim entropi learn weight therefor conduct learn equat analog unit owj gradient calcul ann onto onoo let true answer input pattern ar equat get appli formula calcul whole summat updat weight pattern meanwhil nij accord equat given classif oa chosen zero numer exampl illustr construct exampl decis assum three hidden variabl pattern given vector construct three hidden follow al lo given pattern classifi either accord valu hidden variabl actual decis deriv decis tree order learn classif construct train set gener randomli chosen valu aa interv randomli choos initi weight termin learn classif tree structur branch leaf whenev branch entropi greater start termin maximum valu first two branch node entropi valu sa corrospond pattern channel first branch sinc termin second among pattern channel second branch pattern true classif consid complet whole train total four node automat final shown tree structur total error classifi learn tree trainig trainig test result use novel error among summari propos new scheme construct neural network learn attribut sequenti facilit classif pattern accord rank import use inform measur perform presum optim structur specif learn procedur focus attent network attribut first branch less import strategi search attribut would allevi scale problem forc overal parallel also problem resourc alloc encount net exampl show perform method expect much better perform problem demand larg size acknowledg work partial support afosr grant minski mit press lee machin learn use high order connect physic maxwel order connect model associ aip proceed john denker lee nonlinear dynam artifici neural aip proceed john rummenlhart parallel distribut classif machin,2
80,80,"767 
SELF-ORGANIZATION OF ASSOCIATIVE DATABASE 
AND ITS APPLICATIONS 
Hisashi Suzuki and Suguru Arimoto 
Osaka University, Toyonaka, Osaka 560, Japan 
ABSTRACT 
An efficient method of self-organizing associative databases is proposed together with 
applications to robot eyesight systems� The proposed databases cn associate ny input 
with some output. In the first half prt of discussion, n algorithm of self-organization is 
proposed. From an aspect of hardware, it produces a new style of neural network. In the 
latter half part, an pplicability to handwritten letter recognition and that to an autonomous 
mobile robot system are demonstrated. 
INTRODUCTION 
Let  mpping f: X --, Y be given. Here, X is a finite or infinite set, and Y is another 
finite or infinite set. A learning machine observes any set of pairs (x, y) sampled randomly 
from X x Y. (X x Y means the Cartesian product of X and Y.) And, it computes some 
estimate f: X --, Y of f to make small, the estimation error in some measure. 
Usually we say that: the faster the decrease of estimation error with increase of the num- 
ber of samples, the better the learning machine. However, such expression on performance 
is incomplete. Since, it lacks consideration on the candidates of f of f assumed prelimi- 
narily. Then, how should we find out good learning machines? To clarify this conception, 
let us discuss for a while on some types of learning machines. And, let us advance the 
understanding of the self-organization of associative database. 
� Parameter Type 
An ordinary type of learning machine assumes an equation relatin x's and y's with 
parameters being indefi^nite,namely, a structure of f. It is equivalent to define implicitly a 
set 1  of candidates of f. (F is some subset of mappings from X to Y.) And, it computes 
values of the parameters based on the observed samples. We call such type a parameter 
type. 
For a learning machine defined well, if 1   f, f pproaches f as the number of samples 
increases. In the alternative case, however, some estimation error remains eternally. Thus, 
a problem of designing  learning machine returns to find out a proper structure of f in this 
sense. 
On the other hand, the assumed structure of f is demanded to be as compact as possible 
to achieve a fast learning. In other words, the number of parameters should be small. Since, 
if the parameters are few, some f can be uniquely determined even though the observed 
samples are few. However, this demand of being proper contradicts to that of being compact. 
Consequently, in the parameter type, the better the compactness of the assumed structure 
that is proper, the better the learning machine. This is the most elementary conception 
when we design learning ma&ines. 
� Universality and Ordinary Neural Networks 
Now suppose that a sufficient knowledge on f is given though j itself is unknown. In 
this case, it is comparatively easy to find out proper and compact structures of j. In the 
alternative case, however, it is sometimes difficult. A possible solution is to give up the 
compactness and assume an almighty structure that can cover various f's. A combination 
of some orthogonal bases of the infinite dimension is such a structure. Neural networks '2 
are its approximations obtained by truncating finitely the dimension for implementation� 
@ American Institute of Physics 1988 
768 
A min topic in designing neural networks is to establish such desirable structures of f. 
This work includes developing practical procedures that compute values of coefiScients from 
the observed samples. Such discussions are fiourishing since 1980 while many efiScient meth- 
ods have been proposed. Recently, even hardware units computing coefiScients in pardlid 
for speed-up are sold, e.g., ANZA, Mark III, Odyssey and 
Nevertheless, in neural networks, there always exists a danger of some error remaining 
eternally in estimating f. Precisely speaking, suppose that a combination of the bases of a 
finite number can define a structure of f essentially. In other words, suppose that P /, or 
f is located near 1 '. In such case, the estimation error is none or negligible. However, if f 
is distant from i', the estimation error never becomes negligible. Indeed, many researches 
report that the following situation appears when f is too complex. Once the estimation 
error converges to some value (> 0) as the number of samples increases, it decreases hardly 
even though the dimension is heighten. This property sometimes is a considerable defect of 
neural networks. 
� Recursive Type 
The recursive type is founded on another methodology of learning that should be as 
follows. At the initial stage of no sample, the set F0 (instead of notation ) of candidates 
of f' equals to the set of all mappings from X to Y. After observing the first sample 
(x,,) � X x Y, & is reduced to  so that f(x) =  for any f � . Aaer observing 
th eona sample (xa, ya) � X x Y, g is further reduced to Pa so that f() = yx and 
f(xa) = ya for any f � P. Thus, the candidate set P becom gruy smM1  observaaon 
of samples proceeds. The f after observing i-staples, which we write fi, is one of the most 
hkehhood timation of f selected in . Hence, contrily to the pameter type, the 
recursive type guantees surely that f approhes to f  the number of samples increase. 
The recursive type, if observes a sample (xi, Yi), rewrit vMues A-()'s to A()'s for 
some 's correlated to the staple. Hence, this type h an architecture composed of a rule 
for rewriting and a free memory spce. Such architecture for natury a nd of dtabase 
that builds up magement syste of data in a self-orgizing way. However, this datable 
differs kom ordiny on in the following sense. It does not only record the samples Mready 
observed, but computes some estimation of f(x} for any x � X. We cM1 such datable  
socitive datable. 
The first subject in constructing sociative datables is how we estabhsh the rule for 
rewriting. For this purpose, we Mapt a measure cMled the dissimilarity. Here,  dissilarity 
means a mapping d: X x X  {reals > 0} such that for any (x, ) � X x X, d(x, ) > 0 
whenever f(x) � (). However, it is not necessily aea,a with  single formula. It is 
definable with, for example, a collection of rules written in forms of ""if ... then ...."" 
The dissilarity d defines a structure of f locy in X x Y. Hence, even though 
the knowledge on f is imperfect, we can reflect it on d in some heuristic way. Hence, 
contrarily to neurM networks, it is possible to celerate the speed of leaning by establishing 
d wall. Especiy, we c eily find out simple d's for those f's which process anMocy 
information like a human. (See the pplications in this paper.) And, for such f's, the 
rursive type shows strongly its effectiveness. 
We denote a sequence of observed sampl by (x, y), (xa, ya),"" '. One of the simplest 
constructions of associative databases fi after observing i-staples (i = 1, 2,.-.) is as follows� 
Algorithm 1. At the initiM stage, let S0 be the empty set. For every i = 
1,2,..., let A-(x) for any x � X equM some y* such that (x*,y*) � Si- and 
(1) 
Furthermore, d (xi, y) to S_ to produce S, i.e., S = S_ u {(xi, yi)}. 
769 
Another version improved to economize the memory is as follows. 
Algorithm 2. At the initial stage, let So be composed of an arbitrary element 
in X x Y. For every i = 1, 2,-.-, let fi-l(a:) for any a: � X equal some ,* such 
that (x*, ?,,*) � Si-1 and 
d(x,x'): rain 
Furthermore, if fi-l(a:i) :/: ' then let S = Si-1, or dad (a:i,q) to Si-1 to 
produce Si, i.e., Si: Si-10 {(a:i, 'i)}. 
In either construction, fl approaches to f as i increases. However, the computation time 
grows proportionally to the size of Si. The second subject in constructing associative 
databases is what addressing rule we should employ to economize the computation time. In 
the subsequent chapters, a construction of associative database for this purpose is proposed. 
It manages data in a form of binary tree. 
SELF-ORGANIZATION OF ASSOCIATIVE DATABASE 
Given a sample sequence (xl, ?,q), (x, ?,,a),..., the algorithm for constructing associative 
database is as follows. 
Algorithm 3.' 
Step l(Initialization): Let (a:[rootl,,[root]) = (aq,q). Here, a:[-] and ,[-] are 
warlables assigned for respective nodes to memorize data. Furthermore, let t = 1. 
Step 2: Increase t by 1, and put a:t in. After reset a pointer n to the root, repeat 
the following until n axrives at some terminal node, i.e., le. 
Notations  and 2 mean the descendant nodes of ,. If d(a:,,a:[a]) < 
d(,,tl), let n: a. Otherwise, let n: 
Step 3: Display g,[n] as the related information. Next, put g, in. If ,[n] = q, bak 
to step 2. Otherwise, first establish new descendant nodes a and h. Secondly, 
let 
: (2) 
(x[h],y[iz]) = (:rt,yt). (3) 
Finally, back to step 2. Here, the loop of step 2-3 can be stopped at any time 
and also can be continued. 
Now, suppose that gate elements, namely, artificial ""synapses"" that play the role of branch- 
ing by d are prepared. Then, we obtain a new style of neural network with gate elements 
being randomly connected by this algorithm. 
LETTER HECOGNITION 
Recently, the vertical slitting method for recognizing typographic English letters 3, the 
elastic matching method for recognizing handwritten discrete English letters 4, the global 
training and fuzzy logic search method for recognizing Chinese characters written in square 
style , etc. axe published. The self-organization of associative database realizes the recogni- 
tion of handwritten continuous English letters. 
770 
Fig. 1. Source document. 
Wi ndow --' B�undary 
Fig. 2. Windowing. 
0 1000 2000 3000 4000 0 1000 
Nuner of samples 
2000 3000 4000 
Number of samples 
Fig. 3. An experiment result. 
An image scanner takes a document image (Fig. 1). The letter recognizer uses a par- 
allelogram window that at least can cover the maximal letter (Fig. 2), and processes the 
sequence of letters while shifting the window. That is, the recognizer scans a word in a 
slant direction. And, it places the window so that its left vicinity may be on the first black 
point detected. Then, the window catches a letter and some part of the succeeding letter. 
If recognition of the head letter is performed, its end position, namely, the boundary line 
between two letters becomes known. Hence, by starting the scanning from this boundary 
and repeating the above operations, the recognizer accomplishes recurslvely the task. Thus 
the major problem comes to identifying the head letter in the window. 
Considering it, we define the following. 
� Regard window images as x's, and define X accordingly. 
� For a (x, :) � X x X, denote by_/} a black point in the left area from the boundary on 
window image . Project each B onto window image x. Then, measure the Euclidean 
distance 5 between/} and a black point B on x being the dosest to/}. Let d(_x, :) be 
the summation of 5's for all black points/}'s on  divided by the number of B's. 
� Regard couples of the ""reading"" and the position of boundary as y's, and define Y 
accordingly. 
An operator teaches the recognizer in interaction the relation between window image and 
reading&boundary with algorithm 3. Precisely, if the recalled reading is incorrect, the 
operator teaches a correct reading via the console. Moreover, if the boundary position is 
incorrect, he teaches a correct position via the mouse. 
Fig. 1 shows partially a document image used in this experiment. Fig. 3 shows the 
change of the number of nodes and that of the recognition rate defined as the relative 
frequency of correct answers in the past 1000 trials. Specifications of the window are height 
= 20dot, width = 10dot, and slant angular = 68deg. In this example, the levels of tree 
were distributed in 6-19 at time 4000 and the recognition rate converged to about 74%. 
Experimentally, the recognition rate converges to about 60-85% in most cases, and to 95% at 
a rare case. However, it does not attain 100% since, e.g., ""c"" and ""e"" are not distinguishable 
because of excessive fluctuation in writing. If the consistency of the x, ?,,-rdation is not 
assured like this, the number of nodes increases endlessly (cf. Fig. 3). Hence, it is clever to 
stop the learning when the recognition rate attains some upper limit. To improve further 
the recognition rate, we must consider the spelling of words. It is one of future subjects. 
771 
OBSTACLE AVOIDING MOVEMENT 
Various systems of camera type autonomous mobile robot are reported flourishingly 6-1�. 
The system made up by the authors (Fig. 4) also belongs to this category. Now, in math- 
ematical methodologies, we solve usually the problem of obstacle avoiding movement as 
a cost minimization problem under some cost criterion established artificially. Contrarily, 
the self-organization of associative database reproduces faithfully the cost criterion of an 
operator. Therefore, motion of the robot after learning becomes very natural. 
Now, the length, width and height of the robot are all about 0.7m, and the weight is 
about 30kg. The visual angle of camera is about 55deg. The robot has the following three 
factors of motion. It turns less than 4-30deg, advances less than lm, and controls speed less 
than 3km/h. The experiment was done on the passageway of width 2.5m inside a building 
which the authors' laboratories exist in (Fig. 5). Because of an experimental intention, we 
arrange boxes, smoking stands, gas cylinders, stools, handcarts, etc. on the passage way at 
random. We let the robot take an image through the camera, recall a similar image, and 
trace the route preliminarily recorded on it. For this purpose, we define the following. 
Let the camera face 28deg downward to take an image, and process it through a low 
pass filter. Scanning verticMly the filtered image from the bottom to the top, search 
the first point C where the luminanee changes excessively. Then, substitute all points 
from the bottom to C for white, and all points from C to the top for black (Fig. 6). 
(If no obstacle exists just in front of the robot, the white area shows the ""free"" area 
where the robot can move around.) Regard binary 32 x 32dot images processed thus 
as a:'s, and define X accordingly. 
For every (x, :) e X x X, let d(x, :) be the number of black points on the exclusive-or 
image between x and E, 
Regard as ?,,'s the images obtained by drawing routes on images a:'s, and define Y 
accordingly. 
The robot superimposes, on the current camera image a:, the route recalled for a:, and 
inquires the operator instructions. The operator judges subjectively whether the suggested 
route is appropriate or not. In the negative answer, he draws a desirable route on a: with the 
mouse to teach a new , to the robot. This operation defines implicitly a sample sequence 
of (a:, ,) reflecting the cost criterion of the operator. 
t 
moni tot dl splay 
Mouse 
rwor-ariven  
wheel yen  .'toni ball 
Mobile unit (robot) Stationary unit 
Fig. 4. Configuration of 
autonomous mobile robot system. 
22 ; 11 
Room/ 13 - 
14 
23 
, 24 
Block 
nber 
North 
Fig. 5. Experimental 
environment. 
772 
Wal I 
A reprocessing 
Fig. 6. Processing for 
obstacle avoiding movement. 
Canera image 
Preprocess ing  
 Course 
suggest ion 
x  
Fig. 7. Processing for 
position identification. 
We define the satisfaction rate by the relative frequency of acceptable suggestions of 
route in the past 100 trials. In a typical experiment, the change of satisfaction rate showed 
a similar tendency to Fig. 3, and it attains about 95% axound time 800. Here, notice that 
the rest 5% does not mean directly the percentage of collision. (In practice, we prevent the 
collision by adopting some supplementary measure.) At time 800, the number of nodes was 
145, d the levels of tree were distributed in �;-17. 
The proposed method reflects delicately various characters of operator. For exarnple, a 
robot trained by an operator O moves slowly with enough space against obstacles while one 
trained by other operator O' brushes quickly against obstacles. This fat gives us a hint 
on a method of printing ""characters"" into machines. 
POSITION IDENTIFICATION 
The robot can identify its position by recalling a similar landscape with the position data 
to a camera image. For this purpose, in principle, it suffices to regard camera images and 
position data as a:'s and ?,,'s, respectively. However, the memory capacity is finite in actuaJ 
computers. Hence, we cannot but compress the carhera images at a slight loss of information. 
Such compression is admlttable as long as the precision of position identification is in  
aceptable area. Thus, the major problem comes to find out some suitable compression 
method. 
In the experimental environment (Fig. 5), juts axe on the passageway at intervals of 
3.6ra, and each section between adjacent juts has at most one door. The robot identifies 
roughly from a surrounding landscape which section itself places in. And, it uses temporarily 
a triangulax surveying technique if an exact measure is necessary. To realize the former task, 
we define the following. 
Turn the camera to take a paatorama image of 360deg. Scanning horizontally the 
center line, substitute the points where the luminanee excessively changes for blak 
d the other points for white (Fig. ?). Regaxd binary 360dot line images processed 
thus as a:'s, and define X acordingly. 
For every (a:, :) � X x X, project each black point J on : onto a:. And, measure the 
Euclidean distce 5 between j and a blak point A on a: being the closest to 4. Let 
the summation of 5 be S. Similarly, calculate , by exchging the roles of a: and :. 
Denoting the numbers of A's and J's respectively by n and , define 
773 
(4) 
� Regard positive integers lbeled on sections as y's (cf. Fig. 5), nd define Y ccord- 
ingly. 
In the learning mode, the robot checks exactly its position with  counter tlt is reset pe- 
riodically by the operator. The robot runs rbitraily on the passageways within 18m axe 
and learns the relation between lndscpes nd position dt. (Position identification be- 
yond 18m re is clieved by crossing plural dtbses one another.) This task is utomtlc 
excepting the periodic reset of counter, nmely, it is  kind of learning without teacher. 
We define the identlfiction rte by the relative frequency of correct recalls of position 
dt in the past 100 trials. In  typical example, it converged to bout 83% round time 
400. At time 400, the number of levels was 202, ad the levels of tree were distributed in 5- 
22. Since the identification failures of 17% cn be rejected by considering the trajectory, no 
problem rises in practical use. In order to improve the identification rte, the compression 
rtio of camer images must be loosened. Such possibility depends on improvement of the 
lrdwre in the future. 
Fig. 8 shows n example of ctual motion of the robot based on the dtbase for obstacle 
voiding movement nd that for position identification. This exaxnple corresponds to  case 
of moving from 14 to 23 in Fig. 5. Here, the time interval per frame is bout 40sec. 
Fig. 8. Actual motion of the robot. 
774 
CONCLUSION 
A method of self-orgazizing associative databases was proposed with the application to 
robot eyesight systems. The machine decomposes a global structure unknown into a set of 
local structures known and learns universally any input-output response. This framework 
of problem implies a wide application area other than the examples shown in this paper. 
A defect of the algorithm 3 of self-orgazization is that the tree is balanced well only 
for a subclass of structures of f. A subject imposed us is to widen the class. A probable 
solution is to abolish the aAdressing rule depending directly on values of d and, insteaA, to 
establish another rule depending on the distribution function of values of d. It is now under 
investigation. 
REFERENCES 
o 
o 
10. 
Hopfield, J. J. and D. W. Tank, ""Computing with Neural Circuit: A Model,"" 
Science 233 (1986), pp. 625--633. 
Rumelhaxt, D. E. et al., ""Learning Representations by Back-Propagating Er- 
rors,"" Nature 323 (1986), pp. 533-536. 
Hull, J. J., ""Hypothesis Generation in a Computational Model for Visual Word 
Recognition,"" IEEE Expert, Fall (1986), pp. 63-70. 
Kurtzberg, J. M., ""Feature Analysis for Symbol Recognition by Elastic Match- 
ing,"" IBM J. Res. Develop. 31-1 (1987), pp. 91-95. 
Wang, Q. R. azd C. Y. Suen, ""Large Tree Classifier with Heuristic Search and 
Global Training,"" IEEE Trans. Pattern. Anal. &Mach. Intell. PAMI 9-1 
(1987) pp. 91-102. 
Brooks, R. A. et al, ""Self Calibration of Motion and Stereo Vision for Mobile 
Robots,"" 4th Int. Symp. of Robotics Research (1987), pp. 267-276. 
Goto, Y. and A. Stentz, ""The CMU System for Mobile Robot Navigation,"" 1987 
IEEE Int. Conf. on Robotics & Automation (1987), pp. 99-105. 
Madarasz, R. et al., ""The Design of an Autonomous Vehicle for the Disabled,"" 
IEEE Jour. of Robotics & Automation RA 2-3 (1986), pp. 117-125. 
Triendl, E. and D. J. Kriegman, ""Stereo Vision and Navigation within Build- 
ings,"" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 1725-1730. 
Turk, M. A. et al., ""Video RoaA-Following for the Autonomous Land Vehicle,"" 
1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 273-279. 
", associ databas applic suzuki suguru arimoto osaka japan effici method associ databas propos togeth robot eyesight propos databas associ input first half algorithm aspect produc new style neural half handwritten letter recognit autonom robot system finit infinit anoth infinit learn machin observ set pair sampl randomli mean cartesian product comput make estim error say faster decreas estim error increas better learn express perform lack consider candid assum find good learn clarifi us discuss type learn let us advanc associ paramet type ordinari type learn machin assum equat structur equival defin implicitli candid subset map comput paramet base observ call type paramet learn machin defin number sampl altern estim error remain problem design learn machin return find proper structur assum structur demand compact possibl achiev fast number paramet paramet uniqu determin even though observ demand proper contradict paramet better compact assum structur better learn elementari concept design learn univers ordinari neural network suppos suffici knowledg given though compar easi find proper compact structur sometim possibl solut give assum almighti structur cover variou combin orthogon base infinit dimens neural network approxim obtain truncat finit dimens american institut physic topic design neural network establish desir structur work includ develop practic procedur comput valu scient observ discuss fiourish sinc mani scient even hardwar unit comput scient pardlid mark odyssey neural alway exist danger error remain estim precis suppos combin base number defin structur suppos locat near estim error none distant estim error never becom mani research follow situat appear estim converg valu number sampl decreas hardli though dimens properti sometim consider defect recurs type recurs type found anoth learn initi stage set notat candid equal set map observ first sampl reduc aaer observ sampl reduc pa yx ya candid set becom observaaon sampl observ write one select type sure number sampl recurs observ sampl mue correl type architectur compos rule rewrit free memori architectur build data databl kom follow record sampl mreadi comput estim databl first subject construct databl estabhsh rule mapt measur mled map singl collect rule written form defin structur even though knowledg reflect heurist possibl speed lean establish find simpl process like type show strongli denot sequenc observ one simplest associ databas fi observ let empti everi let produc version improv econom memori initi let compos arbitrari element everi let equal rain let dad either fl approach comput time proport size second subject construct associ address rule employ econom comput subsequ construct associ databas purpos manag data form binari associ databas sampl sequenc algorithm construct associ let assign respect node memor let increas put reset pointer repeat follow axriv termin mean descend node let let display relat put step first establish new descend node back step loop step stop time also suppos gate artifici play role obtain new style neural network gate element randomli connect hecognit vertic slit method recogn typograph english letter match method recogn handwritten discret english letter global fuzzi logic search method recogn chines charact written squar axe associ databas realiz handwritten continu english sourc sampl sampl experi imag scanner take document imag letter recogn use window least cover maxim letter process letter shift recogn scan word place window left vicin may first black window catch letter part succeed recognit head letter end boundari line two letter becom start scan boundari repeat recogn accomplish recurslv thu major problem come identifi head letter defin regard window imag defin denot black point left area boundari imag project onto window imag measur euclidean black point dosest let summat black divid number regard coupl posit boundari defin oper teach recogn interact relat window imag algorithm recal read teach correct read via boundari posit teach correct posit via show partial document imag use show number node recognit rate defin rel correct answer past specif window height width slant angular level tree distribut time recognit rate converg recognit rate converg rare attain distinguish excess fluctuat consist like number node increas endlessli clever learn recognit rate attain upper improv recognit must consid spell one futur avoid movement system camera type autonom mobil robot report flourishingli system made author also belong solv usual problem obstacl avoid movement cost minim problem cost criterion establish associ databas reproduc faith cost criterion motion robot learn becom width height robot weight visual angl camera robot follow three turn less advanc less control speed less experi done passageway width insid build laboratori exist experiment smoke ga passag way let robot take imag recal similar rout preliminarili record defin camera face downward take process low scan mli filter imag bottom search first point luminane chang substitut point bottom point top black obstacl exist front white area show area robot move regard binari imag process thu defin everi let number black point imag obtain draw rout imag defin robot current camera imag rout recal oper oper judg subject whether suggest appropri neg draw desir rout teach new oper defin implicitli sampl sequenc reflect cost criterion tot dl splay yen ball unit stationari unit configur mobil robot experiment process avoid imag ing cours ion process defin satisfact rate rel frequenc accept suggest past typic chang satisfact rate show similar tendenc attain axound time notic rest mean directli percentag prevent adopt supplementari time number node level tree distribut propos method reflect delic variou charact train oper move slowli enough space obstacl one oper brush quickli give us hint method print identif robot identifi posit recal similar landscap posit data camera suffic regard camera imag data memori capac finit can not compress carhera imag slight loss compress admlttabl long precis posit identif major problem come find suitabl compress experiment environ jut axe passageway interv section adjac jut one robot identifi surround landscap section place use temporarili triangulax survey techniqu exact measur realiz former defin camera take paatorama imag scan horizont substitut point luminane excess chang point white regaxd binari line imag process defin everi project black point onto measur point closest let summat calcul role number respect defin regard posit integ section defin learn robot check exactli posit counter reset robot run passageway within learn relat posit identif cross plural one task period reset kind learn without defin rel frequenc correct recal posit past typic converg time time number level level tree distribut sinc identif failur reject consid practic order improv identif compress imag must possibl depend improv show exampl motion robot base obstacl movement posit exaxnpl correspond case move time interv per frame actual motion method associ databas propos applic eyesight machin decompos global structur unknown set structur known learn univers framework problem impli wide applic area exampl shown defect algorithm tree balanc well subclass structur subject impos us widen probabl abolish adress rule depend directli valu anoth rule depend distribut function valu neural et represent natur gener comput model visual word ie fall analysi symbol recognit elast ibm azd tree classifi heurist search ie pami et calibr motion stereo vision mobil robot research cmu system mobil robot robot autom et design autonom vehicl robot autom ra vision navig within ie robot autom et autonom land ie robot autom,0
81,81,"775 
A NEURAL-NETWORK SOLUTION TO THE CONCENTRATOR 
ASSIGNMENT PROBLEM 
Gene A. Tagliarini 
Edward W. Page 
Department of Computer Science, Clemson University, Clemson, SC 
29634-1906 
ABSTRACT 
Networks of simple analog processors having neuron-like properties have 
been employed to compute good solutions to a variety of optimization prob- 
lems. This paper presents a neural-net solution to a resource allocation prob- 
lem that arises in providing local access to the backbone of a wide-area com- 
munication network. The problem is described in terms of an energy function 
that can be mapped onto an analog computational network. Simulation results 
characterizing the performance of the neural computation are also presented. 
INTRODUCTION 
This paper presents a neural-network solution to a resource allocation 
problem that arises in providing access to the backbone of a communication 
network. In the field of operations research, this problem was first known as 
the warehouse location problem and heuristics for finding feasible, suboptimal 
solutions have been developed previously.2, a More recently it has been known 
as the multifacility location problem4 and as the concentrator assignment prob- 
lem. 
THE HOPFIELD NEURAL NETWORK MODEL 
The general structure of the Hopfield neural network models, 6, ? is illus- 
trated in Fig. 1. Neurons are modeled as amplifiers that have a sigmoid input/ 
output curve as shown in Fig. 2. Synapses are modeled by permitting the out- 
put of any neuron to be connected to the input of any other neuron. The 
strength of the synapse is modeled by a resistive connection between the output 
of a neuron and the input to another. The amplifiers provide integrative analog 
summation of the currents that result from the connections to other neurons as 
well as connection to external inputs. To model both excitatory and inhibitory 
synaptic links, each amplifier provides both a normal output V and an inverted 
output V. The normal outputs range between 0 and 1 while the inverting am- 
plifier produces corresponding values between 0 and -1. The synaptic link be- 
tween the output of one amplifier and the input of another is defined by a 
conductance Tij which connects one of the outputs of amplifier j to the input of 
amplifier i. In the Hopfield model, the connection between neurons i and j is 
made with a resistor having a value Rij= 1/Ti . To provide an excitatory synap- 
tic connection (positive Ti), the resistor is connected to the normal output of 
This research was supported by the U.S. Army Strategic Defense Command. 
American Institute of Physics 1988 
776 
I1 
I2 
I3 I4 
inputs 
T42 
! 
V 1 V 2 V 3 V 4 outputs 
Fig. 1. Schematic for a simplified 
Hopfield network with four neurons. 
1 
I 
-u 0 +u 
Fig. 2. Amplifier input/output 
relationship 
amplifier j. To provide an inhibitory connection (negative Tij), the resistor is 
connected to the inverted output of amplifier j. The connections among the 
neurons are defined by a matrix T consisting of the conductances Tij. Hop- 
field has shown that a symmetric T matrix (Ti = Ti) whose diagonal entries 
are all zeros, causes convergence to a stable state in which the output of each 
amplifier is either 0 or 1. Additionally, when the amplifiers are operated in the 
high-gain mode, the stable states of a network of n neurons correspond to the 
local minima of the quantity 
n n n 
E= (-1/2)  Z TijViV j - Z Vii i (1) 
i=l j=l i=l 
where Vi is the output of the i th neuron and Ii is the externally supplied input 
to the i th neuron. Hopfield refers to E as the computational energy of the sys- 
tem. 
THE CONCENTRATOR ASSIGNMENT PROBLEM 
Consider a collection of n sites that are to be connected to m concentra- 
tors as illustrated in Fig. 3(a). The sites are indicated by the shaded circles 
and the concentrators are indicated by squares. The problem is to find an 
assignment of sites to concentrators that minimizes the total cost of the assign- 
ment and does not exceed the capacity of any concentrator. The constraints 
that must be met can be summarized as follows: 
a) Each site i ( i = 1, 2,..., n ) is connected to exactly one concentrator; 
and 
777 
b) Each concentrator j ( j = 1, 2,..., m ) is connected to no more than kj 
sites (where k i is the capacity of concentrator j). 
Figure 3(b) illustrates a possible solution to the problem represented in Fig. 
3(a). 
[] 
O 
O 
� � 
[] Concentrators � Sites 
(a). Site/concentrator map (b). Possible assignment 
Fig. 3. Example concentrator assignment problem 
If the cost of assigning site i to concentrator j is cii, then the total cost of 
a particular assignment is 
n m 
total cost =   xij cij (2) 
i:l j:l 
where xij = 1 only if we actually decide to assign site i to concentrator j and is 0 
otherwise. There are m n possible assignments of sites to concentrators that 
satisfy constraint a). Exhaustive search techniques are therefore impractical 
except for relatively small values of m and n. 
THE NEURAL NETWORK SOLUTION 
This problem is amenable to solution using the Hopfield neural network 
model. The Hopfield model is used to represent a matrix of possible assign- 
ments of sites to concentrators as illustrated in Fig. 4. Each square corresponds 
778 
CONCENTRATORS 
1 2 j rn 
2 
SITES . i ,,, ,,, i1,,, ,,,,' [[ The darkly shaded neu- 
ron corresponds to the 
hypothesis that site i 
[ [ should be assigned to 
. n 1! [llJ concentrator j. 
SLACK ' in+2 , ! g , 
Fig. 4. Concentrator assignment array 
to a neuron and a neuron in row i and column j of the upper n rows of the 
array represents the hypothesis that site i should be connected to concentrator 
j. If the neuron in row i and column j is on, then site i should be assigned to 
concentrator j; if it is off, site i should not be assigned to concentrator j. 
The neurons in the lower sub-array, indicated as ""SLACK"", are used to 
implement individual concentrator capacity constraints. The number of slack 
neurons in a column should equal the capacity (expressed as the number sites 
which can be accommodated) of the corresponding concentrator. While it is 
not necessary to assume that the concentrators have equal capacities, it was 
assumed here that they did and that their cumulative capacity is greater than or 
equal to the number of sites. 
To enable the neurons in the network illustrated above to compute solu- 
tions to the concentrator problem, the network must realize an energy function 
in which the lowest energy states correspond to the least cost assignments. The 
energy function must therefore favor states which satisfy constraints a) and b) 
above as well as states that correspond to a minimum cost assignment. The 
energy function is implemented in terms of connection strengths between neu- 
rons. The following section details the construction of an appropriate energy 
function. 
779 
THE ENERGY FUNCTION 
Consider the following energy equation: 
E: A  ( Vi j I ) 2  n+k: 
- + B (JVij - kj )2 
i:l j:l j:l i=l 
(3; 
m n+k. 
+ C   Jvij (1-Vij) 
j:l i:l 
where Vii is the output of the amplifier in row i and column j of the neuron 
matrix, m and n are the number of concentrators and the number of sites 
respectively, and kj is the capacity of concentrator j. 
The first term will be minimum when the sum of the outputs in each row 
of neurons associated with a site equals one. Notice that this term influences 
only those rows of neurons which correspond to sites; no term is used to coerce 
the rows of slack neurons into a particular state. 
The second term of the equation will be minimum when the sum of the 
outputs in each column equals the capacity kj of the corresponding concentra- 
tor. The presence of the k slack neurons in each column allows this term to 
enforce the concentrator capacity restrictions. The effect of this term upon the 
upper sub-array of neurons (those which correspond to site assignments) is 
that no more than k sites will be assigned to concentrator j. The number of 
neurons to be turned on in column j is kj; consequently, the number of neu- 
rons turned on in column j of the assignment sub-array will be less than or 
equal to kj 
The third term causes the energy function to favor the ""zero"" and ""one"" 
states of the individual neurons by being minimum when all neurons are in one 
or the other of these states. This term influences all neurons in the network. 
In summary, the first term enforces constraint a) and the second term 
enforces constraint b) above. The third term guarantees that a choice is actu- 
ally made; it assures that each neuron in the matrix will assume a final state 
near zero or one corresponding to the xij term of the cost equation (Eq. 2). 
After some algebraic re-arrangement, Eq. 3 can be written in the form of 
Eq. 1 where 
T ij,kl = { A * 8(i,k) * (1-8(j,1)) + B * 8(j,1) * (1-8(i,k)), if i<n and k<n 
C * 8(j,1) * (1-8(i,k)), if i>n or k>n. (4) 
Here quadruple subscripts are used for the entries in the matrix T. Each entry 
indicates the strength of the connection between the neuron in row i and col- 
umn j and the neuron in row k and column 1 of the neuron matrix. The func- 
tion delta is given by 
780 
1, ifi:j (5) 
8( i , j ) = 0, otherwise. 
The A and B terms specify inhibitions within a row or a column of the upper 
sub-array and the C term provides the column inhibitions required for the 
neurons in the sub-array of slack neurons. 
Equation 3 specifies the form of a solution but it does not include a term 
that will cause the network to favor minimum cost assignments. To complete 
the formulation, the following term is added to each Tij,n: 
D* 8(j,1) * (1-8(i,k)) 
(cost[i,j] + cost[k, 1]) 
where cost[ i, j ] is the cost of assigning site i to concentrator j. The effect of 
this term is to reduce the inhibitions among the neurons that correspond to low 
cost assignments. The sum of the costs of assigning both site i to concentrator j 
and site k to concentrator 1 was used in order to maintain the symmetry of T. 
The external input currents were derived from the energy equation (Eq.3) 
and are given by 
2*kj,ifi<n 
I ij = 2 * kj- 1, otherwise. (6) 
This exemplifies a technique for combining external input currents which arise 
from combinations of certain basic types of constraints. 
AN EXAMPLE 
The neural network solution for a concentrator assignment problem con- 
sisting of twelve sites and five concentrators was simulated. All sites and con- 
centrators were located within the unit square on a randomly generated map. 
For this problem, it was assumed that no more than three sites could be 
assigned to a concentrator. The assignment cost matrix and a typical assign- 
ment resulting from the simulation are shown in Fig. 5. It is interesting to 
notice that the network proposed an assignment which made no use of concen- 
trator 2. 
Because the capacity of each concentrator kj was assumed to be three 
sites, the external input current for each neuron in the upper sub-array was 
Iij= 6 
while in the sub-array of slack neurons it was 
Iij= 5. 
The other parameter values used in the simulation were 
A=B=C=-2 
and 
D=0.1. 
781 
SITES 
A 
B 
C 
D 
E 
F 
G 
H 
J 
K 
L 
.47 
.72 
.95 
.88 
.31 
.25 
.17 
CONCENTRATORS 
2 3 4 
28 .55 
75 
71 
78 
62 
.81 
39 
38 
56 
51 76 46 
39 77 41 
81 
67 
84 
33 
60 1 
54 52 
76 .66 
05 .71 
5 
.46 
.63 
.92 
.82 
.� 
.� 
� 
.56 
.51 
.48 
.38 
.18 
Fig. 5. The concentrator assignment cost matrix with choices circled. 
Since this choice of parameters results in a T matrix that is symmetric 
and whose diagonal entries are all zeros, the network will converge to the 
minima of Eq. 3. Furthermore, inclusion of the term which is weighted by the 
parameter D causes the network to favor minimum cost assignments. 
To evaluate the performance of the simulated network, an exhaustive 
search of all solutions to the problem was conducted using a backtracking algo- 
rithm. A frequency distribution of the solution costs associated with the assign- 
ments generated by the exhaustive search is shown in Fig. 6. For comparison, 
a histogram of the results of one hundred consecutive runs of the neural-net 
simulation is shown in Fig. 7. Although the neural-net simulation did not find 
a global minimum, ninety-two of the one hundred assignments which it did 
find were among the best 0.01% of all solutions and the remaining eight were 
among the best 0.3%. 
CONCLUSION 
Neural networks can be used to find good, though not necessarily opti- 
mal, solutions to combinatorial optimization problems like the concentrator 
782 
Frequency 
4000000 
3500000 
3000000 
2500000 
2000000 
1500000 
1000000 
500000 
0 
3.2 4.2 
Cost 
5.2 6.2 7.2 8.2 
Frequency 
25 
20 
15 
10 
5 
Cost 
3.2 3.4 3.6 3.8 4.0 4.2 
Fig. 6. Distribution of assignment 
costs resulting from an exhaustive 
search of all possible solutions. 
Fig. 7. Distribution of assignment 
costs resulting from 100 consecu- 
tive executions of the neural net 
simulation. 
assignment problem. In order to use a neural network to solve such problems, 
it is necessary to be able to represent a solution to the problem as a state of the 
network. Here the concentrator assignment problem was successfully mapped 
onto a Hopfield network by associating each neuron with the hypothesis that a 
given site should be assigned to a particular concentrator. An energy function 
was constructed to determine the connections that were needed and the result- 
ing neural network was simulated. 
While the neural network solution to the concentrator assignment prob- 
lem did not find a globally minimum cost assignment, it very effectively re- 
jected poor solutions. The network was even able to suggest assignments which 
would allow concentrators to be removed from the communication network. 
REFERENCES 
1. A. S. Tanenbaum, Computer Networks (Prentice-Hall: Englewood Cliffs, 
New Jersey, 1981), p. 83. 
2. E. Feldman, F. A. Lehner and T. L. Ray, Manag. Sci. V12, 670 (1966). 
3. A. Kuehn and M. Hamburger, Manag. Sci. V9, 643 (1966). 
4. T. Aykin and A. J. G. Babu, J. of the Oper. Res. Soc. V38, N3, 241 (1987). 
5. J. J. Hopfield, Proc. Natl. Acad. Sci. U.S. A., V79, 2554 (1982). 
6. J. J. Hopfield and D. W. Tank, Bio. Cyber. V52, 141 (1985). 
7. D. W. Tank and J. J. Hopfield, IEEE Trans. on Cir. and Sys. CAS-33, N5, 
533 (1986). 
", solut concentr problem tagliarini page comput clemson sc simpl analog processor properti employ comput good solut varieti optim paper present solut resourc alloc aris provid local access backbon problem describ term energi function map onto analog comput simul result perform neural comput also paper present solut resourc alloc aris provid access backbon commun field oper problem first known warehous locat problem heurist find suboptim develop recent known multifacil locat concentr assign hopfield neural network model gener structur hopfield neural network neuron model amplifi sigmoid curv shown synaps model permit neuron connect input synaps model resist connect output neuron input amplifi provid integr analog current result connect neuron connect extern model excitatori inhibitori amplifi provid normal output invert normal output rang invert produc correspond valu synapt link output one amplifi input anoth defin tij connect one output amplifi input hopfield connect neuron resistor valu provid excitatori connect resistor connect normal output research support armi strateg defens institut physic output schemat simplifi network four amplifi provid inhibitori connect resistor invert output amplifi connect among defin matrix consist conduct shown symmetr matrix whose diagon entri caus converg stabl state output either amplifi oper stabl state network neuron correspond minima quantiti vii vi output th neuron ii extern suppli input th hopfield refer comput energi concentr assign problem collect site connect illustr site indic shade circl concentr indic problem find site concentr minim total cost exceed capac constraint must met summar site connect exactli one concentr connect kj capac concentr illustr possibl solut problem repres concentr site map possibl assign exampl concentr assign problem cost assign site concentr total cost particular assign cost xij cij xij actual decid assign site concentr possibl assign site concentr constraint exhaust search techniqu therefor impract rel small valu neural network solut problem amen solut use hopfield neural network hopfield model use repres matrix possibl site concentr illustr squar correspond rn darkli shade correspond site assign concentr concentr assign array neuron neuron row column upper row repres hypothesi site connect concentr neuron row column site assign site assign concentr neuron lower indic use individu concentr capac number slack column equal capac number site correspond necessari assum concentr equal cumul capac greater number enabl neuron network illustr comput concentr network must realiz energi function lowest energi state correspond least cost function must therefor favor state satisfi constraint well state correspond minimum cost function implement term connect strength follow section detail construct appropri energi energi function follow energi vi kj jvij vii output amplifi row column neuron number concentr number site kj capac concentr first term minimum sum output row neuron associ site equal notic term influenc row neuron correspond term use coerc row slack neuron particular second term equat minimum sum column equal capac kj correspond presenc slack neuron column allow term concentr capac effect term upon neuron correspond site site assign concentr number turn column number turn column assign less kj third term caus energi function favor individu neuron minimum neuron one term influenc neuron first term enforc constraint second term constraint third term guarante choic assur neuron matrix assum final state zero one correspond xij term cost equat algebra written form quadrupl subscript use entri matrix entri strength connect neuron row neuron row column neuron delta given term specifi inhibit within row column upper term provid column inhibit requir slack specifi form solut includ term caus network favor minimum cost complet follow term ad cost assign site concentr effect term reduc inhibit among neuron correspond low sum cost assign site concentr site concentr use order maintain symmetri extern input current deriv energi equat given ij exemplifi techniqu combin extern input current aris combin certain basic type exampl neural network solut concentr assign problem twelv site five concentr site locat within unit squar randomli gener assum three site could assign cost matrix typic result simul shown interest network propos assign made use capac concentr kj assum three extern input current neuron upper slack neuron paramet valu use simul concentr assign cost matrix choic choic paramet result matrix symmetr whose diagon entri network converg inclus term weight caus network favor minimum cost evalu perform simul exhaust solut problem conduct use backtrack frequenc distribut solut cost associ gener exhaust search shown histogram result one hundr consecut run shown although simul find global one hundr assign among best solut remain eight best network use find though necessarili solut combinatori optim problem like concentr distribut assign result exhaust possibl distribut assign result execut neural net order use neural network solv necessari abl repres solut problem state concentr assign problem success map hopfield network associ neuron hypothesi site assign particular energi function construct determin connect need neural network neural network solut concentr assign find global minimum cost effect poor network even abl suggest assign allow concentr remov commun comput network englewood lehner kuehn aykin hopfield tank ie,0
82,82,"783 
USING NEURAL NETWORKS TO IMPROVE 
COCHLEAR IMPLANT SPEECH PERCEPTION 
Manoel F. Tenorio 
School of Electrical Engineering 
Purdue University 
West Lafayette, IN 47907 
ABSTRACT 
An increasing number of pr(foundly deaf patients suffering from sen- 
sorineural deafness are using cooblear implants as prostheses. After the 
implant, sound can be detected through the electrical stimulation of the 
remaining peripheral auditory nervous system. Although great progress has 
been achieved in this area, no useful speech recognition has been attained 
with either single or multiple channel cooblear implants. 
Coding evidence suggests that it is necessary for any implant which 
would effectively couple with the natural speech perception system to simu- 
late the temporal dispersion and other phenomena found in the natural 
receptors, and currently not implemented in any cooblear implants. To this 
end, it is presented here a computational model using artificial neural net- 
works (ANN) to incorporate the natural phenomena in the artificial 
cochlear. 
The ANN model presents a series of advantages to the implementation 
of such systems. First, the hardware requirements, with constraints on 
power, size, and processing speeds, can be taken into account together with 
the development of the underlining software, before the actual neural struc- 
tures are totally defined. Second, the ANN model, since it is an abstraction 
of natural neurons, carries the necessary ingredients and is a close mapping 
for implementing the necessary functions. Third, some of the processing, 
like sorting and majority functions, could be implemented more efficiently, 
requiring only local decisions. Fourth, the ANN model allows function 
modifications through parametric modification (no software recoding), which 
permits a variety of fine-tuning experiments, with the opinion of the 
patients, to be conceived. Some of those will permit the user some freedom 
in system modification at real-time, allowing finer and more subjective 
adjustments to fit differences on the condition and operation of individual's 
remaining peripheral auditory system. 
1. INTRODUCTION 
The study of the model of sensory receptors can be carried out either 
via trying to understand how the natural receptors process incoming signMs 
and build a representation code, or via the construction of artificial replace- 
ments. In the second case, we are interested in to what extent those 
artificial counterparts have the ability to replace the natural receptors. 
Several groups are now carrying out the design of artificial sensors. 
Artificial cochleas seem to have a number of different designs and a tradition 
of experiments. These make them now available for widespread use as 
prostheses for patients who have sensorineura] deafness caused by hair 
damage. 
� American Institute of Physics 1988 
784 
Although surgery is required for such implants, their performance has 
reached a level of maturity to induce patients to seek out these devices 
voluntarily. Unfortunately, only partial acoustic information is obtained by 
severely deaf patients with cochlear prosthesis. Useful patterns for speech 
communication are not yet 'fully recognizable through auditory prostheses. 
This problem with artificial receptors is true for both single implants, that 
stimulate large sections of the cochlea with signals that cover a large portion 
of the spectrum [4,5], and multi channel implants, that stimulate specific 
regions of the cochlea with specific portions of the auditory spectrum [3,13]. 
In this paper, we tackle the problem of artificial cochlear implants 
through the used of neurocomputing tools. The receptor model used here 
was developed by Gerald Wasserman of the Sensory Coding Laboratory, 
Department of Psychological Sciences, Purdue University [20], and the 
implants were performed by Richard Miyamoto of the Department of Otolar- 
yngology, Indiana University Medical School [11]. 
The idea is to introduce with the cochlear implant, the computation 
that would be performed otherwise by the natural receptors. It would there- 
fore be possible to experimentally manipulate the properties of the implant 
and measure the effect of coding variations on behavior. The model was 
constrained to be portable, simple to implant, fast enough computationally 
for on-line use, and built with a flexible paradigm, which would allow for 
modification of the different parts of the model, without having to recon- 
struct it entirely. In the next section, we review parts of the receptor model, 
and discuss the block diagram of the implant. Section 3 covers the limita- 
tions associated with the technique, and discusses the results obtained with 
a single neuron and one feedback loop. Section 4 discusses the implementa- 
tions of these models using feedforward neural networks, and the computa- 
tional advantages for doing so. 
2. COCHLEAR IMPLANTS AND THE NEURON MODEL 
Although patients cannot reliably recognize randomly chosen spoken 
words to them (when implanted with either multichannel or single channel 
devices), this is not to say that no information is extracted from speech. If 
the vocabulary is reduced to a limited set of words, patients perform 
significantly better than chance, at associating the word with a member of 
the set. 
For these types of experiments, single channel implants correspond to 
reported performance of 14% to 20% better than chance, with 62% perfor- 
mance being the highest reported. For multiple channels, performances of 
95% were reported. So far no one has investigated the differences in perfor- 
mance between the two types of implants. Since the two implants have so 
many differences, it is difficult to point out the cause for the better perfor- 
mance in the multiple channel case. 
The results of such experiments are encouraging, and point to the fact 
that cochlea implants need only minor improvement to be able to mediate 
ad-lib speech perception successfully. Sensory coding studies have suggested 
a solution to the implant problem, by showing that the representation code 
generated by the sensory system is task dependent. This evidence came 
from comparison of intracellular recordings taken from a single receptor of 
intact subjects. 
This coding evidence suggests that the temporal dispersion (time 
integration) found in natural receptors would be a necessary part of any 
785 
cochlear implant. Present cochlear implants have no dispersion at all. Fig- 
ure 2 shows the block diagram for a representative cochlear implant, the 
House-Urban stimulator. The acoustic signal is picked up by the micro- 
phone, which sends it to an AM oscillator. This modulation step is neces- 
sary to induce an electro-magnetic coupling between the external and inter- 
nal coil. The internal coil has been surgically implanted, and it is connected 
to a pair of wires implanted inside and outside the cochlea. 
Just incorporating the temporal dispersion model to an existing device 
would not replicate the fact that in natural receptors, temporal dispersion 
appears in conjunction to other operations which are strongly non linear. 
There are operations like selection of a portion of the spectrum, rectification, 
compression, and time-dispersion to be considered. 
In figure 3, a modified implant is shown, which takes into consideration 
some of these operations. It is depicted as a single-channel implant, 
although the ultimate goal is to make it multichannel. Details of the opera- 
tion of this device can be found elsewhere [21]. Here, it is important to men- 
tion that the implant would also have a compression/rectification function, 
and it would receive a feedback from the integrator stage in order to control 
its gain. 
3. CHARACTERISTICS AND RESULTS OF THE IMPLANTS 
The above model has been implemented as an off-line process, and then 
the patients were exposed to a preprocessed signal which emulated the 
operation of the device. It is not easy to define the amount of feedback 
needed in the system or the amount of time dispersion. It could also be that 
these parameters are variable across different conditions. Another variance 
in the experiment is the amount of damage (and type) among different indi- 
viduals. So, these parameters have to be determined clinically. 
The coupling between the artificial receptor and the natural system also 
presents problems. If a physical connection is used, it increases the risk of 
infections. When inductive methods are used, the coupling is never ideal. If 
portability and limited power is of concern in the implementation, then the 
limited energy available for coupling has to be used very effectively. 
The computation of the receptor model has to be made in a way to 
allow for fast implementation. The signal transformation is to be computed 
on-line. Also, the results from clinical studies should be able to be incor- 
porated fairly easily without having to reengineer the implant. 
Now we present the results of the implementation of the transfer func- 
tion of figure 4. Patients, drawn from a population described elsewhere 
[11,12,14], were given spoken sentences processed off-line, and simultaneously 
presented with a couple of words related to the context. Only one of them 
was the correct answer. The patient had two buttons, one for each alterna- 
tive; he/she was to press the button which corresponded to the correct alter- 
native. The results are shown in the tables below. 
(Average of the population) 
Percentage of correct alternatives 
No disp. 67% 
0.1 msec 78% 
0.3 msec 85% 
Best performance 
786 
1 msec 76% 
3 msec 72 
Table I: Phoneme discrimination in a two-alternate task. 
Percentage of correct alternatives 
No disp. 50% 
1.0 msec 76% Best performance 
Table II: Sentence comprehension in a two-alternative task. 
There were quite a lot of variations in the performance of the different 
patients, some been able to perform better at different dispersion and 
compression amounts than the average of the population. Since one cannot 
control the amount of damage in the system of each patient or differences in 
individuals, it is hard to predict the ideal values for a given patient. 
Nevertheless, the improvements observed are of undeniable value in improv- 
ing speech perception. 
4. THE NEUROCOMPUTING MODEL 
In studying the implementation of such a system for on-line use, yet 
flexible enough to produce a carry-on device, we look at feedforward neuro- 
computer models as a possible answer. First, we wanted a model that easily 
produced a parallel implementation, so that the model could be expanded in 
a multichannel environment without compromising the speed of the system. 
Figure 5 shows the initial idea for the implementation of the device as a Sin- 
gle Instruction Multiple Data (SIMD) architecture. 
The implant would be similar to the one described in Figure 4, except 
that the transfer function of the receptor would be performed by a two layer 
feed forward network (Figure 6). Since there is no way of finding out the 
values of compression and dispersion apart from clinical trials, or even if 
these values do change in certain conditions, we need to create a structure 
that is flexible enough to modify the program structure by simple manipula- 
tion of parameters. This is also the same problem we would face when try- 
ing to expand the system to a multichannel implant. Again, neuromorphic 
models provided a nice paradigm in which the dataflow and the function of 
the program could be altered by simple parameter (weight) change. 
For this first implementation we chose to use the no-contact inductive 
coupling method. The drawback of this method is that all the information 
has to be compressed in a single channel for reliable transmission and cross 
talk elimination. 
Since the inductive coupling of the implant-is critical at every cycle, the 
most relevant information must be picked out of the processed signal. This 
information is then given all the available energy, and after all the coupling 
loss, it should be sufficient to provide for speech pattern discrimination. In a 
multichannel setting, this corresponds to doing a sorting of all the n signals 
in the channels, selecting the m highest signals, and adding them up for 
modulation. In a naive single processor implementation, this could 
correspond to n 2 comparisons, and in a multiprocessor implementation, 
log(n) comparisons. Both are dependent on the number of signals to be 
787 
sorted. 
We needed a scheme in which the sorting time would be constant with 
the number of channels, and would be easily implementable in analog circui- 
try, in case this became a future route. Our scheme is shown in Figure 7. 
Each channel is connected to a threshold element, whose threshold can be 
varied externally. A monotonically decreasing function scans the threshold 
values, from the highest possible value of the output to the lowest. The out- 
put of these elements will be high corresponding to the values that are the 
highest first. These output are summed with a quasi-integrator with thres- 
hold set to m. This element, when high, disables the scanning functions; and 
it corresponds to having found the m highest signals. This sorting is 
independent of the number of channels. 
The output of the threshold units are fed into sigma-pi units which 
gates the signals to be modulated. The output of these units are summed 
and correspond to the final processed signal (Figure 8). 
The user has full control of the characteristics of this device. The 
number of channels can be easily altered; the number of components allowed 
in the modulation can be changed; the amount of gain, rectification- 
compression, and dispersion of each channel can also be individually con- 
trolled. The entire system is easily implementable in analog integrated cir- 
cuits, once the clinical tests have determine the optimum operational 
characteristics. 
CONCLUSION 
We have shown that the study of sensory implants can enhance our 
understanding of the representation schemes used for natural sensory recep- 
tors. In particular, implants can be enhanced significantly if the effects of 
the sensory processing and transfer functions are incorporated in the model. 
We have also shown that neuromorphic computing paradigm provides a 
parallel and easily modifiable framework for signal processing structures, 
with advantages that perhaps cannot be offered by other technology. 
We will soon start the use of the first on-line portable model, using a 
single processor. This model will provide a testbed for more extensive clini- 
cal trials of the implant. We will then move to the parallel implementation, 
and from there, possibly move toward analog circuitry implementation. 
Another route for the use of neuromorphic computing in this domain is 
possibly the use of sensory recordings from healthy animals to train self- 
organizing adaptive learning networks, in order to design the implant 
transfer functions. 
REFERENCES 
[1] 
[2] 
Bilger, R.C.; Black, F.O.; Hopkinson, N.T.; and Myers, E.N., 
""Implanted auditory prosthesis: An evaluation of subjects presently 
fitted with cochlear implants,"" Otolaryngology, 1977, Vol. 84, pp. 677- 
682. 
Bilger, R.C.; Black, F.O.; Hopkinson, N.T.; Myers, E.N.; Payne, J.L.; 
Stenson, N.R.; Vega, A.; and Wolf, R.V., ""Evaluation of subjects 
presently fitted with implanted auditory prostheses,"" Annals of Otol- 
ogy, Rhinology, and Laryngology, 1977, Vol. 86(Supp. 38), pp. 1-176. 
788 
[3] 
[4] 
[5] 
[6] 
[7] 
[9] 
[lO] 
[11] 
[12] 
[13] 
[14] 
[15] 
[16] 
Eddington, D.K.; Dobelle, W.H.; Brackmann, D.E.; Mladejovsky, M.G.; 
and Parkin, J., ""Place and periodicity pitch by stimulation of multiple 
scala tympani electrodes in deaf volunteers,"" American Society for 
Artificial Internal Organs, Transactions, 1978, Vol. 24, pp. 1-5. 
House, W.F.; Berliner, K.; Crary, W.; Graham, M.; Luckey, R.: Norton, 
N.; Selters, W.; Tobin, H.; Urban, J.; and Wexler, M., Cochlear 
implants,"" Annals of Otology, Rhinology and Laryngology, 1976, Vol. 
85(Supp. 27), pp. 1-93. 
House, W.F. and Urban, J., ""Long term results of electrode implanta- 
tion and electronic stimulation of the cochlea in man,"" Annals of Otol- 
ogy, Rhinology and Laryngology, 1973, Vol. 82, No. 2, pp. 504-517. 
Ifukube, T. and White, R.L., ""A speech processor with lateral inhibi- 
tion for an eight channel cochlear implant and its evaluation,"" IEEE 
Trans. on Biomedical Engineering, November 1987, Vol. BME-34, No. 
11. 
Kong, K.-L., and Wasserman, G.S., ""Changing response measures 
alters temporal summation in the receptor and spike potentials of the 
Limulus lateral eye,"" Sensory Processes, 1978, Vol. 2, pp. 21-31. 
Kong, K.-L., and Wasserman, G.S., ""Temporal summation in the recep- 
tor potential of the Lirnulus lateral eye: Comparison between retinula 
and eccentric cells,"" Sensory Processes, 1978, Vol. 2, pp. 9-20. (b) 
Michelson, R.P., ""The results of electrical stimulation of the cochlea in 
human sensory deafness,"" Annals of Otology, Rhinology and Laryngol- 
ogy, 1971, Vol. 80, pp. 914-919. 
Mladejovsky, M.G.; Eddington, D.K.; Dobelle, W.H.; and Brackmann, 
D.E., ""Artificial hearing for the deaf by cochlear stimulation: Pitch 
modulation and some parametric thresholds,"" American Society for 
Artificial Internal Organs, Transactions, 1974, Vol. 21, pp. 1-7. 
Miyamoto, R.T.; Gosseft, S.K.; Groom, G.L.; Kienle, M.L.; Pope, M.L.; 
and Shallop, J.K., ""Cochlear implants: An auditory prosthesis for the 
deaf,"" Journal of the Indiana State Medical Association, 1982, Vol. 75, 
pp. 174-177. 
Miyamoto, R.T.; Myres, W.A.; Pope, M.L.; and Carotta, C.A., 
""Cochlear implants for deaf children,"" Laryngoscope, 1986, Vol. 96, pp. 
990-996. 
Pialoux, P.; Chouard, C.H.; Meyer, B.; and Fugain, C., ""Indications 
and results of the multichannel cochlear implant,"" Acta Otolaryngology, 
1979, Vo.. 87, pp. 185-189. 
Robbins, A.M.: Osberger, M.J.; Miyamoto, R.T.; Kienle, M.J.; and 
, � 
Myres, W.A., Speech-tracking performance in single-channel cochlear 
implant subjects,"" Journal of Speech and Hearing Research, 1985, Vol. 
28, pp. 565-578. 
Russell, I.J. and Sellick, P.M., ""The tuning properties of cochlear hair 
cells,"" in E.F. Evans and J.P. Wilson (eds.), Psychophysics and Physiol- 
ogy of Hearing, London: Academic Press, 1977. 
Wasserman, G.S., ""Limulus psychophysics: Temporal summation in the 
ventral eye,"" Journal of Experimental Psychology: General, 1978, Vol. 
107, pp. 276-286. 
789 
[17] 
[19] 
[20] 
Wasserman, G.S., ""Limulus psychophysics: Increment threshold,"" Per- 
ception  Psychophysics, 1981, Vol. 29, pp. 251-260. 
Wasserman, G.S.; Felsten, G.; and Easland, G.S., ""Receptor saturation 
and the psychophysical function,"" Investigative Ophthalmology and 
Visual Science, 1978, Vol. 17, p. 155 (Abstract). 
Wasserman, G.S.; Felsten, G.; and Easland, G.S., ""The psychophysical 
function: Harmonizing Fechner and Stevens,"" Science, 1979, Vol. 204, 
pp. 85-87. 
Wasserman, G.S., ""Cochlear implant codes and speech perception in 
profoundly deaf,"" Bulletin of Psychonomic Society, Vol. (18)3, 1987. 
Wasserman, G.S.; Wang-Bennett, L.T.; and Miyamoto, R.T., ""Tem- 
poral dispersion in natural receptors and pattern discrimination medi- 
ated by artificial receptor,"" Proc. of the Fechner Centennial Sympo- 
sium, Hans Buffart (Ed.), Elsevier/North Holland, Amsterdam, 1987. 
[--  SENSORY CODING DATA- -- 
7 I I 
.5 9 I .513 I 
STIMULUS SIGNAL ANALYSIS BEHAVIOR 
I 11 I 15 
I r .......... � I 
' I 
I  SIGNAL 
, 
i 
17 
Fig. 1. Path of Natural and Prosthetic Signals. 
Sound 
I Microphone I 
I External Coil I 
I Internal Coil I 
I Coc.,ea I 
Central Nervous System 
Fig. 2. The House-Urban Cochlear Implant. 
790 
AMPLIFICATION 
DISPERSION 
..I COMPRESSIVE RECTIFIER 
,..I INTEGRATOR 
""1 
Fig. 3. Receptor Model 
Sound 
[ Microphone 
Bandpass Filter 
Compress;e Rectifier , 
Integrator "" 
I AM Oscillator 
External Coil 
Central Nervous System 
Fig. 4. Modified Implant Model. 
791 
PORTABLE PARAI I EL NEUROCOMPUTER 
FILTERED 
EXTERNAL 
USER CONTROLLED 
PARAMETERS 
16KHz AM 
MODULATED OUTPUT 
Fig. 5. Initial Concept for a SIMD Architecture. 
MICROPHONE 
EXTERNALLY CONTROLLED 
DISPERSION l  
___ NEURON 
MODEL 
.__' NEURON 
MODEL 
AMPLIFICATION 
SORTER 
OF 
N SIGNALS 
Fig. 6. Feedforward Neuron Model Implant. 
792 
$RTER OF n $16NAL$ IN 0!1! 
S, ={0,1} -- 
SIGNALS 
INPUTS 
 FUNCTK)N 
RESHOLD 
SET OF n, 
EXTERNALLY 
CONTROLLED 
THRESHOLD CONTROL: 
SCANNING FUNCTION FROM I.max TO I. min 
I I 
RESET SCANNING 
I i max 
t 
Fig. 7. Signal Sorting Circuit. 
SIGNAL SELECTORS 
S, = {0,1} 
'n l 
S 1 ...... 
01 = 11. S 1 
S n 
OUTPUT SIGNAL 
Fig. 8. Sigma-Pi Units for Signal Composition. 
793 
USER CONTROLLED PARAMETERS 
MICROPHONE 
DISPERSION 
o 
GAIN 
r BEST 
MATCHES 
FILTER PROCESSOR 
BYPASS BYPASS 
SINGLE 
NEURON 
PROCESSING 
Fig. 9. Parameter ControIs for Clinical Studies. 
", neural network improv implant speech percept tenorio electr engin univers increas number deaf patient suffer deaf use cooblear implant sound detect electr stimul peripher auditori nervou although great progress achiev use speech recognit attain either singl multipl channel cooblear evid suggest necessari implant effect coupl natur speech percept system tempor dispers phenomena found natur current implement cooblear present comput model use artifici neural incorpor natur phenomena artifici ann model present seri advantag implement hardwar constraint process taken account togeth develop underlin actual neural total ann sinc abstract natur carri necessari ingredi close map implement necessari sort major could implement local ann model allow function parametr modif softwar varieti opinion permit user freedom system modif allow finer subject fit differ condit oper peripher auditori introduct studi model sensori receptor carri either tri understand natur receptor process incom ms build represent via construct artifici second interest extent counterpart abil replac natur group carri design artifici cochlea seem number differ design tradit make avail widespread use patient deaf caus hair american institut physic surgeri requir perform level matur induc patient seek devic partial acoust inform obtain deaf patient cochlear use pattern speech yet recogniz auditori problem artifici receptor true singl larg section cochlea signal cover larg portion spectrum multi channel stimul specif cochlea specif portion auditori spectrum tackl problem artifici cochlear implant use neurocomput receptor model use develop gerald wasserman sensori code psycholog purdu univers perform richard miyamoto depart indiana univers medic school idea introduc cochlear comput would perform otherwis natur would possibl experiment manipul properti implant measur effect code variat model simpl fast enough comput built flexibl would allow differ part without next review part receptor discuss block diagram section cover associ discuss result obtain singl neuron one feedback section discuss model use feedforward neural advantag cochlear implant neuron model patient can not reliabl recogn randomli chosen spoken implant either multichannel singl channel say inform extract vocabulari reduc limit set patient perform better associ word member type singl channel implant correspond perform better highest multipl perform far one investig differ two type sinc two implant difficult point caus better multipl channel result experi point fact cochlea implant need minor improv abl mediat speech percept sensori code studi suggest solut implant show represent code sensori system task evid came comparison intracellular record taken singl receptor code evid suggest tempor dispers found natur receptor would necessari part present cochlear implant dispers show block diagram repres cochlear acoust signal pick send modul step induc coupl extern intern coil surgic connect pair wire implant insid outsid incorpor tempor dispers model exist devic replic fact natur tempor dispers conjunct oper strongli non oper like select portion figur modifi implant take consider depict ultim goal make detail devic found elsewher import implant would also would receiv feedback integr stage order control characterist result implant model implement patient expos preprocess signal emul easi defin amount feedback system amount time could also paramet variabl across differ anoth varianc experi amount damag among differ paramet determin coupl artifici receptor natur system also physic connect increas risk induct method coupl never limit power concern energi avail coupl use comput receptor model made way fast signal transform comput result clinic studi abl fairli easili without reengin present result implement transfer figur drawn popul describ elsewher given spoken sentenc process simultan coupl word relat one correct patient two one press button correspond correct result shown tabl correct altern msec msec perform msec msec phonem discrimin correct altern msec best perform sentenc comprehens quit lot variat perform differ abl perform better differ dispers amount averag sinc one can not amount damag system patient differ hard predict ideal valu given improv observ undeni valu speech neurocomput model studi implement system yet enough produc look feedforward model possibl want model easili parallel model could expand multichannel environ without compromis speed show initi idea implement devic instruct multipl data implant would similar one describ figur except transfer function receptor would perform two layer forward network sinc way find compress dispers apart clinic even valu chang certain need creat structur flexibl enough modifi program structur simpl also problem would face expand system multichannel neuromorph provid nice paradigm dataflow function program could alter simpl paramet first implement chose use induct drawback method inform compress singl channel reliabl transmiss cross induct coupl critic everi relev inform must pick process given avail coupl suffici provid speech pattern correspond sort signal select highest ad naiv singl processor could multiprocessor depend number signal need scheme sort time would constant number would easili implement analog case becam futur scheme shown figur channel connect threshold whose threshold monoton decreas function scan threshold highest possibl valu output element high correspond valu output sum set disabl scan correspond found highest sort number output threshold unit fed unit signal output unit sum correspond final process signal user full control characterist channel easili number compon allow modul amount dispers channel also individu entir system easili implement analog integr clinic test determin optimum oper shown studi sensori implant enhanc represent scheme use natur sensori implant enhanc significantli effect sensori process transfer function incorpor also shown neuromorph comput paradigm provid easili modifi framework signal process advantag perhap can not offer soon start use first portabl use model provid testb extens trial move parallel possibl move toward analog circuitri rout use neuromorph comput domain use sensori record healthi anim train adapt learn order design implant auditori evalu subject present cochlear subject fit implant auditori annal period pitch stimul multipl tympani electrod deaf american societi intern cochlear annal rhinolog term result electrod electron stimul cochlea annal rhinolog speech processor later eight channel cochlear implant ie biomed novemb respons measur tempor summat receptor spike potenti later sensori summat potenti lirnulu later comparison retinula eccentr sensori result electr stimul cochlea sensori annal rhinolog hear deaf cochlear pitch parametr american societi intern auditori prosthesi journal indiana state medic implant deaf result multichannel cochlear acta perform cochlear journal speech hear tune properti cochlear hair evan wilson psychophys academ tempor summat journal experiment increment satur psychophys investig ophthalmolog psychophys harmon fechner implant code speech percept bulletin psychonom dispers natur receptor pattern discrimin artifici fechner centenni han buffart sensori code signal analysi behavior signal path natur prosthet microphon extern coil intern coil nervou system cochlear compress rectifi integr receptor model microphon filter rectifi oscil coil nervou system modifi implant parai el neurocomput control output initi concept simd control neuron neuron signal feedforward neuron model function min scan max signal sort selector signal unit signal control paramet best processor bypass paramet clinic,2
83,83,"794 
A 'Neural' Network that Learns to Play Backgammon 
G. Tesauro 
Center for Complex Systems Research, University of Illinois 
at Urbana-Champaign, 508 S. Sixth St., Champaign, IL 61820 
T. J. $ejnowski 
Biophysics Dept., Johns Hopkins University, Baltimore, MD 21218 
ABSTRACT 
We describe a class of connectionist networks that have learned to play back- 
gammon at an intermediate-to-advanced level. The networks were trained by a 
supervised learning procedure on a large set of sample positions evaluated by a 
human expert. In actual match play against humans and conventional computer 
programs, the networks demonstrate substantial ability to generalize on the basis of 
expert knowledge. Our study touches on some of the most important issues in net- 
work learning theory, including the development of efficient coding schemes and 
training procedures, scaling, generalization, the use of real-valued inputs and out- 
puts, and techniques for escaping from local minima. Practical applications in 
games and other domains are also discussed. 
INTRODUC'ON 
A potentially quite useful testing ground for studying issues of knowledge representation and 
learning in networks can be found in the domain of game playing. Board games such as chess, go, 
backgammon, and Othello entail considerable sophistication and complexity at the advanced level, 
and mastery of expert concepts and strategies often takes years of intense study and practice for 
humans. However, the complexities in board games are embedded in relatively ""clean"" structured 
tasks with well-defined rules of play, and well-defined criteria for success and failure. This makes 
them amenable to automated play, and in fact most of these games have been extensively studied 
with conventional computer science techniques. Thus, direct comparisons of the results of network 
leaming can be made with more conventional approaches. 
In this paper, we describe an application of network leaming to the game of backgammon. 
Backgammon is a difficult board game which appears to be well-suited to neural networks, because 
the way in which moves are selected is primarily on the basis of pattern-recognition or ""judgemen- 
tal"" reasoning, as opposed to explicit ""look-ahead,"" or tree-search computations. This is due to 
the probabilistic dice rolls in backgammon, which greatly expand the branching faclor m each ply in 
the search (to over 400 in typical positions). 
Our leaming procedure is a supervised one  that requires a database of positions ,and moves 
that have been evaluated by an expert ""teacher."" In contrast, in an unsupervised procedure 2-4 
leaming would be based on the consequences of a given move (e.g., whether it led to a won or lost 
position), and explicit teacher instructions would not be required. However, unsupervised learning 
procedures thus far have been much less efficient at reaching high levels of performance than super- 
vised leaming procedures. In part, this advantage of supervised leaming can be traced to the higher 
� American Institute of Physics 1988 
795 
quantity and quality of information available from the teacher. 
Studying a problem of the scale and complexity of backgammon leads one to confront impor- 
tant general issues in network learning. Amongst the most important are scaling and generalization. 
Most of the problems that have been examined with connectionist leaming algorithms are relatively 
small scale and it is not known how well they will perform on much larger problems. Generalization 
is a key issue in learning to play backgammon since it is estimated that there are 102� possible board 
positions, which is far in excess of the number of examples that can be provided during training. In 
this respect our study is the most severe test of generalization in any connectionist network to date. 
We have also identified in this study a novel set of special techniques for training the network 
which were necessary to achieve good performance. A training set based on naturally occurring or 
random examples was not sufficient to bring the network to an advanced level of performance. 
Intelligent data-base design was necessary. Performance also improved when noise was added to 
the training procedure under some circumstances. Perhaps the most important factor in the success 
of the network was the method of encoding the input information. The best performance was 
achieved when the raw input information was encoded in a conceptually significant way, and a cer- 
tain number of pre-computed features were added to the raw information. These lessons may also 
be useful when connectionist learning algorithms are applied to other difficult large-scale problems. 
NETWORK AND DATA BASE SET-LIP 
Our network is trained to select moves (i.e. to produce a real-valued score for any given 
move), rather than to generate them. This avoids the difficulties of having to teach the network the 
concept of move legality. Instead, we envision our network operating in tandem with a pre- 
processor which would take the board position and roll as input, and produce all legal moves as out- 
put. The network would be trained to score each move, and the system would choose the move with 
the highest network score. Furthermore, the network is trained to produce relative scores for each 
move, rather than an absolute evaluation of each final position. This approach would have greater 
sensitivity in distinguishing between close alternatives, and corresponds more closely to the way 
humans actually evaluate moves. 
The current data base contains a total of 3202 board positions, taken from various sources 5. 
For each position there is a dice roll and a set of legal moves of that roll from that position. The 
moves receive commentary from a human expert in the form of a relative score in the range [- 
100,+100], with +100 representing the best possible move and -100 representing the worst possible 
move. One of us (G.T.) is a strong backgammon player, and played the role of human expert in 
entering these scores. Most of the moves in the data base were 
for a human expert to comment on all possible moves. (The 
data in the training procedure will be discussed in the following 
not scored, because it is not feasible 
handling of these unscored lines of 
section.) 
An important result of our study is that in order to achieve the best performance, the data base 
of examples must be intelligently designed, rather than haphazardly accumulated. If one simply 
accumulates positions which occur in actual game play, for example, one will find that certain prin- 
ciples of play will appear over and over again in these positions, while other important principles 
may be used only rarely. This causes problems for the network, as it tends to ""overlearn"" the com- 
monly used principles, and not learn at all the rarely used principles. Hence it is necessary to have 
both an intelligent selection mechanism to reduce the number of over-represented situations, and an 
intelligent design mechanism to enhance the number of examples which illustrate under-represented 
situations. This process is described in more detail elsewhere 5. 
We use a deterministic, feed-forward network with ,an input layer, ,an output layer, and either 
one or two layers of hidden units, with full connectivity between adjacent layers. (We have tried a 
number of experiments with restricted receptive fields, and generally have not found them to be use- 
ful.) Since the desired output of the network is a single real value, only one output unit is required. 
796 
The coding of the input patterns is probably the most difficult and most important design 
issue. In its current configuration the input layer contains 459 input units. A location-based 
representation scheme is used, in which a certain number of input units are assigned to each of the 
26 locations (24 basic plus White and Black bar) on the board. The input is inverted if necessary so 
that the network always sees a problem in which White is to play. 
An example of the coding scheme used until very recently is shown in Fig. 1. This is essen- 
tially a unary encoding of the number of men at each board location, with a few exceptions as indi- 
cated in the diagram. This representation scheme worked fairly well, but had one peculiar problem 
in that after training, the network tended to prefer piling large numbers of men on certain points, in 
particular White's 5 point (the 20 point in the 1-24 numbering scheme). Fig. 2 illustrates an example 
of this peculiar behavior. In this position White is to play 5-1. Most humans would play 4-5,4-9 in 
this position; however, the network chose the move 4-9,19-20. This is actually a bad move, because 
it reduces White's chances of making further points in his inner board. The fault lies not with the 
data base used to train the network, but rather with the representation scheme used. In Fig. l a, 
notice that unit 12 is turned on whenever the final position is a point, and the number of men is dif- 
ferent from the initial position. For the 20 point in particular, this unit will develop strong excitatory 
weights due to cases in which the initial position is not a point (i.e., the move makes the point). The 
20 point is such a valuable point to make that the excitation produced by turning unit 12 on might 
overwhelm the inhibition produced by the poor distribution of builders. 
--5 -4 -5 --2 -I 
(o) 0 0 0 0 0 
I 2 5 4 5 
6 7 8 9 I0 
4 ->5 
II 12 13 14 15 16 
S-5 -4 -3-<-2 -I 
(b) El B 13 E! 13 
I 2 3 4 5 
6 7 8 9 I0 
II 12 15 14 15 16 17 18 
Figure 1-- Two schemes used to encode the raw position information in the network's input. 
Illustrated in each case is the encoding of two White men present before the move, and three 
White men present after the move. (a) An essentially unary coding of the number of men at a 
particular board location. Units 1-10 encode the initial position, units 11-16 encode the final 
position if there has been a change from the initial position. Units are turned on in the cases 
indicated on top of each unit, e.g., unit 1 is turned on if there are $ or more Black men present, 
etc.. (b) A superior coding scheme with more units used to characterize the type of transition 
from initial to final position. An up arrow indicates an increase in the number of men, a down 
arrow indicates a decrease. Units 11-15 have conceptual interpretations: 11=""clcag,"" 
12=""slotting,"" 13=""breaking,"" 14=""making,"" 15=""stripping"" a point. 
797 
12 11 10 9 8 7 6 5 4 3 2 1 
13 14 15 16 17 18 19 20 21 22 23 24 
Figure 2-- A sample position illustrating a defect of the coding scheme in Fig. la. White is to 
play 5-1. With coding scheme (la), the network prefers 4-9, 19-20. With coding scheme (lb), 
the network prefers 4-9, 4-5. The graphic display was generated on a Sun Microsystems 
workstation using the Gammontool program. 
In conceptual terms, humans would say that unit 12 participates in the representation of two 
different concepts: the concept of making a point, and the concept of changing the number of men 
occupying a made point. These two concepts are unrelated, and there is no point in representing 
them with a common input unit. A superior representation scheme in which these concepts are 
separated is shown in Fig. lb: In this representation unit 13 is turned on only for moves which 
make the point. Other moves which change the number of men on an already-made point do not 
activate unit 13, and thus do not receive any undeserved excitation. With this representation 
scheme the network no longer tends to pile large numbers of men on certain points, and its overall 
performance is significantly better. 
In addition to this representation of the raw board position, we also utilize a number of input 
units to represent certain ""pre-computed"" features of the raw input. The principal god of this 
study has been to investigate network learning, rather than simply to obtain high performance, and 
thus we have resisted the temptation of including sophisticated hand-crafted features in the input 
encoding. However, we have found that a few simple features are needed in practice to obtn 
minimal standards of competent play. With only ""raw"" board information, the order of the desired 
computation (as defined by Minsky and Papert 6) is probably quite high, and the number of examples 
needed to learn such a difficult computation might be intractably large. By giving the network 
""hints"" in the form of pre-computed features, this reduces the order of the computation, and thus 
might make more of the problem leamable in a tractable number of examples. 
798 
TRAINING AND TESTING PROCEDURES 
To train the network, we have used the standard ""back-propagation"" learning algorithm ?-9 
for modifying the connections in a multilayer feed-forward network. (A detailed discussion of 
learning parameters, etc., is provided elsewhereS.) However, our procedure differs from the stan- 
dard procedure due to the necessity of dealing with the large number of uncommented moves in the 
data base. One solution would be simply to avoid presenting these moves to the network. However, 
this would limit the variety of input patterns presented to the network in training, and certain types 
of inputs probably would be eliminated completely. The alternative procedure which we have 
adopted is to skip the uncommented moves most of the time (75% for ordinary rolls and 92% for 
double rolls), and the remainder of the time present the pattem to the network and generate a ran- 
dom teacher signal with a slight negative bias. This makes sense, because if a move has not received 
comment by the human expert, it is more likely to he a bad move than a good move. The random 
teacher signal is chosen uniformly from the interval [-65,+35]. 
We have used the following four measures to assess the network's performance after it has 
been trained: (i) performance on the training data, (ii) performance on a set of test data (1000 posi- 
tions) which was not used to train the network, (iii) performance in actual game play against a con- 
ventional computer program (the program Gammontool of Sun Microsystems Inc.), and (iv) perfor- 
mance in game play against a human expert (G.T.). In the first two measures, we define the perfor- 
mance as the fraction of positions in which the network picks the correct move, i.e., those positions 
for which the move scored highest by the network agrees with the choice of the human expert. In 
the latter two measures, the performance is defined simply as the fraction of games won, without 
considering the complications of counting gammons or backgammons. 
QUANTITATIVE RESULTS 
A summary of our numerical results as measured by performance on the training set and 
against Gammontool is presented in Table 1. The best network that we have produced so far 
appears to defeat Gammontool nearly 60% of the time. Using this as a benchmark, we find that the 
most serious decrease in performance occurs by removing all pre-computed features from the input 
coding. This produces a network which wins at most about 41% of the time. The next most impor- 
tant effect is the removal of noise from the training procedure; this results in a network which wins 
45% of the time. Next in importance is the presence of hidden units; a network without hidden units 
wins about 50% of the games against Gammontool. In contrast, effects such as varying the exact 
number of hidden units, the number of layers, or the size of the training set, results in only a few 
(1-3) percentage point decrease in the number of games won. 
Also included in Table 1 is the result of an interesting experiment in which we removed our 
usual set of pre-computed features and substituted instead the individual terms of the Gammontool 
evaluation function. We found that the resulting network, after being trained on our expert training 
set, was able to defeat the Gammontool program by a small margin of 54 to 46 percent. The purpose 
of this experiment was to provide evidence of the usefulness of network learning as an adjunct to 
standard AI techniques for hand-crafting evaluation functions. Given a set of features to be used in 
an evaluation function which have been designed, for example,' by interviewing a human expert, the 
problem remains as to how to ""tune"" these features, i.e., the relative weightings to associate to 
each feature, and at an advanced level, the context in which each feature is relevant. Little is known 
in general about how to approach this problem, and often the human programmer must resort to 
painstaking trial-and-error tuning by hand. We claim that network learning is a powerful, general- 
purpose, automated method of approaching this problem, and has the potential to produce a tuning 
which is superior to those produced by humans, given a data base of sufficiently high quality, and a 
suitable scheme for encoding the features. The result of our experiment provides evidence to sup- 
port this claim, although it is not firmly established since we do not have highly accurate statistics, 
and we do not know how much human effort went into the tuning of the Gammontool evaluation 
799 
function. More conclusive evidence would be provided if the experiment were repeated with a more 
sophisticated program such as Berliner's BKG �, and similar results were obtained. 
Network rini.g Perf. on Perf. rs. Comments 
size cycles test set Gammontool 
(a) 459-24-24-1 20 .540 .59 4- .03 
(b) 459.-24-1 22 .542 .57 4-.05 
(c) 459.24-! 24 .518 .58 4- .05 
(d) 459.12-1 10 .538 .54 4- .05 
1600 posn. D.B. 
(e) 410-24-12-1 16 .493 .54 4- .03 
(f) 459-1 22 .485 .50 4- .OS 
($) 459-24-12-1 10 .499 .45 4- .03 
(h) 393-24-12-1 12 .488 .41 4- .02 
Gammontool features 
No hidden units 
No traininS noise 
No features 
Table 1-- Summary of performance statistics for various networks. (a) The best network we 
have produced, containing two layers of hidden units, with 24 vnits in each layer. (b) A 
network with only one layer of 24 hidden units. (c) A network with 24 hidden units in a single 
layer, trained on a training set half the normal size. (d) A network with half the number of 
hidden units as in (b). (e) A network with features from the Gammontool evaluation function 
substituted for the normal features. (f) A network without hidden units. (g) A network trained 
with no noise in the training procedure. (h) A network with only a raw board description as 
input. 
QUALITATIVE RESULTS 
Analysis of the weights produced by training a network is an exceedingly difficult problem, 
which we have only been able to approach qualitatively. In Fig. 3 we present a diagram showing the 
connection strengths in a network with 651 input units and no hidden units. The figure shows the 
weights from each input unit to the output unit. (For purposes of illustration, we have shown a cod- 
ing scheme with more units than normal to explicitly represent the transition from initial to final 
position.) Since the weights go directly to the output, the corresponding input units can be clearly 
interpreted as having either an overall excitatory or inhibitory effect on the score produced by the 
network. 
A great deal of columnar structure is apparent in Fig. 3. This indicates that the network has 
learned that a particular number of men at a given location, or a particular type of transition at a 
given location, is either good or bad independent of the exact location on the board where it occurs. 
Furthermore, we can see the importance of each of the pre-computed features in the input coding. 
The most significant features seem to be the number of points made in the network's inner board, 
and the total blot exposure. 
8OO 
features { 
roll { 
bar 
24 
23 
22 
21 
20 
19 
18 
17 
16 
15 
14 
13 
12 
11 
10 
9 
8 
7 
6 
5 
4 
3 
2 
1 
ABCDEF GH I JKLMNOP QRS TUVW 
Figure 3-- A Hinton diagram for a network with 651 input units and no hidden units. Small 
squares indicate weights from a particular input unit to the output unit. White squares indicate 
positive weights, and black squares indicate negative weights. Size of square indicates 
magnitude of weight. First 24 rows from bottom up indicate raw board information. Letting 
x--number of men before the move and y--number of men after the move. the interpretations of 
columns are as follows: A: x<=-5; B: x=-4; C: x=-3; D: x<=-2; E: x=-l: F: x=l; G: x>=2; H: 
x=3: I: x--4: $: x>=5: K: x<l & y=l; L: x<2 & y>=2: M: x<3 & y=3: N: x<4 & y--4: O: x<y & 
y>=5: P: x=l & y=O; Q: x>=2 & y=O: R: x>=2 & y=l: S: x>=3 & y=2: T: x>=4 & y=3: U: 
x>=$ & y--4: V: x>y & y>=$; W: prob. of a White blot at this ocation behg hit (pre- 
computed feature). The next row encodes number of men on White and Black bars. The next 
3 rows encode roll information. Remaining rows encode various pre-computed features. 
Much insight into the basis for the network's judgement of various moves h,xs been gained by 
actually playing games against it. In fact, one of the most revealing tests of what the network has 
and has not learned came from a 20-game match played by G.T. against one of the latest generation 
of networks with 48 hidden units. (A detailed description of the match is given in Ref. 11.) The 
surprising result of this match was that the network actually won, 11 games to 9. However, a 
801 
detailed analysis of the moves played by the network during the match indicates tint the network 
was extromely lucky to have won so many games, and could not reasonably be expected to continue 
to do so well over a large number of games. Out of the 20 games played, thero wero 11 in which 
the network did not make any serious mistakes. The network won 6 out of these 11 games, a rosult 
which is quite roasonable. However, in 9 of the 20 games, the network made one or more serious 
(i.e. potentially fatal) ""blunders."" The seriousness of these mistakes would be equivalently to drop- 
ping a piece in chess. Such a mistake is nearly always fatal in chess against a good opponent; how- 
ever in backgammon thero are still chances due to the element of luck involved. In the 9 games in 
which the network blunderod, it did manage to survive and win 5 of the games due to the element of 
luck. (We are assuming that the mistakes made by the human, if any, wero only minor mistakes.) It 
is highly unlikely that this sort of resuit would be ropeated. A much moro likely result wouid be that 
the network would win only one or two of the games in which it made a serious error. This would 
put the network's expected performance against expert or near-expert humans at about the 35-40% 
level. (This has also been confirmed in play against other networks.) 
We find that the network does act as if it has picked up many of the global concepts and stra- 
tegies of advanced play. The network has also learned many important tactical elements of play at 
the advanced level. As for the specific kinds of mistakes made by the network, we find that they are 
not at all random, senseless mistakes, but instead fall into clear, well-defined conceptual categories, 
and furthermoro, one can understand the roasons why these categories of mistakes are made. We do 
not have space hero to describe these in detail, and rofer the roader instead to Ref. 5. 
To summarize, qualitative analysis of the network's play indicates that it has leamed many 
important strategies and tactics of advanced backgammon. This gives the network very good overall 
performance in typical positions. However, the network's worst case performance leaves a groat 
deal to be desired. The network is capable of making both serious, obvious, ""blunders,"" as well 
moro subtle mistakes, in many different types of positions. Worst case performance is important, 
because the network must make long sequences of moves throughout the course of a game without 
any serious mistakes in order to have a reasonable chance of winning against a skilled opponent. 
The prospects for improving the network's worst case performance appear to be mixed. It seems 
quite likely that many of the current ""blunders"" can be fixed with a reasonable number of hand- 
crafted examples added to the training set. However, many of the subtle mistakes are due to a lack 
of very sophisticated knowledge, such as the notion of timing. It is difficult to imagine that this kind 
of knowledge could be imparted to the network in only a few examples. Probably what is required is 
either an intractably large number of examples, or a major overhaul in either the pre-computed 
featufos or the training paradigm. 
DISCUSSION 
We have seen from both quantitative and qualitative measures that the network has learned a 
great deal about the general principles of backgammon play, and has not simply memorized the 
individual positions in the training set. Quantitatively, the measuro of game performace provides a 
clear indication of the network's ability to generalize, because apart from the first couple of moves 
at the start of each game, the network must operate entirely on generalization. Qualitatively, one can 
see after playing several games against the network that thero are certain characteristic kinds of 
positions in which it does well, and other kinds of positions in which it systematically makes well- 
defined types of mistakes. Due to the network's frequent ""blunders,"" its overall level of play is 
only intermediate level, although it probably is somewhat better than the average intermediate-level 
player. Against the intermediate-level program Gammontool, our best network wins almost 60% of 
the games. However, against a human expert the network would only win about 35-zt0% of the time. 
Thus while the network does not play at expert level, it is sufficiently good to give an expert a hard 
time, and with luck in its favor can actually win a match to a small number of games. 
Our simple supervised learning approach leaves out some very important sources of 
802 
information which are readily available to humans. The network is never told that the underlying 
topological structure of its input space really corresponds to a one-dimensional spatial structure; all 
it knows is that the inputs form a ,59-dimensional hypercube. It has no idea of the object of the 
game, nor of the sense of temporal causality, i.e. the notion that its actions have consequences, and 
how those consequences lead to the achievement of the objective. The teacher signal only says 
whether a given move is good or bad, without giving any indication as to what the teacher's reasons 
are for making such a judgement. Finally, the network is only capable of scoring single moves in 
isolation, without any idea of what other moves are available. These sources of knowledge are 
essential to the ability of humans to play backgammon well, and it seems likely that some way of 
incorporating them into the network learning paradigm will be necessary in order to achieve further 
substantial improvements in performance. 
There are a number of ways in which these additional sources of knowledge might be incor- 
porated, and we shall be exploring some of them in future work. For example, knowledge of alter- 
native moves could be introduced by defining a more sophisticated error signal which takes into 
account not only the network and teacher scores for the current move, but also the network and 
teacher scores for other moves from the same position. However, the more immediate plans involve 
a continuation of the existing strategies of hand-crafting examples and coding scheme modifications 
to eliminate the most serious errors in the network's play. If these errors can be eliminated, and we 
are confident that this can be achieved, then the network would become substantially better than any 
commercially available program, and would be a serious challenge for human experts. We would 
expect 65% performance against Gammontool, and 45% performance against human experts. 
Some of the results of our study have implications beyond backgammon to more general 
classes of difficult problems. One of the limitations we have found is that substantial human effort 
is required both in the design of the coding scheme and in the design of the training set. It is not 
sufficient to use a simple coding scheme and random training patterns, and let the automated net- 
work learning procedure take care of everything else. We expect this to be generally true when 
connectionist learning is applied to difficult problem domains. 
On the positive side, we foresee a potential for combining connectionist learning techniques 
with conventional AI techniques for hand-crafting knowledge to make significant progress in the 
development of intelligent systems. From the practical point of view, network learning can be 
viewed as an ""enhancer"" of traditional techniques, which might produce systems with superior per- 
formance. For this particular application, the obvious way to combine the two approaches is in the 
use of pre-computed features in the input encoding. Any set of hand-crafted features used in a con- 
ventional evaluation function could be encoded as discrete or continuous activity levels of input 
units which represent the current board state along with the units representing the raw information. 
Given a suitable encoding scheme for these features, and a training set of sufficient size and quality 
(i.e., the scores in the training set should be better than those of the original evaluation function), it 
seems possible that the resulting network could outperform the original evaluation function, as evi- 
denced by our experiment with the Gammontool features. 
Network learning might also hold promise as a means of achieving the long-sought goal of 
automated feature discovery 2. Our network certainly appears to have learned a great deal of 
knowledge from the training set which goes far beyond the amount of knowledge that w,xs explicitly 
encoded in the input features. Some of this knowledge (primarily the lowest level components) is 
apparent from the weight diagram when there are no hidden units (Fig. 3). However, much of the 
network's knowledge remains inaccessible. What is needed now is a means of disent,'mgling the 
novel features discovered by the network from either the patterns of activity in the hidden units, or 
from the massive number of connection strengths which characterize the network. This is one our 
top priorities for future research, although techniques for such ""reverse engineering"" of parallel 
networks are only beginning to be developed 2. 
803 
ACKNOWLEDGEMENTS 
This work was inspired by a conference on ""Evolution, Games and Learning"" held at Los 
Alamos National Laboratory, May 20-24, 1985. We thank Sun Microsystems Inc. for providing the 
source code for their Gammontool program, Hans Berliner for providing some of the positions used 
in the data base, Subutai Allmad for writing the weight display graphics package, Bill Bogstad for 
assistance in programming the back-propagation simulator, and Bartlett Mel, Peter Frey, and Scott 
Kirkpalick for critical reviews of the manuscript. G.T. was supported in part by the National 
Center for Supercomputing Applications. T.J.S. was supported by a NSF Presidential Young Inves- 
tigator Award, and by grants from the Seavet Institute and the Lounsbury Foundation. 
REFERENCES 
1. D. E. Rumelart and J. L. McClelland, eds., Parallel Distributed Processing: Explorations in the 
Microstructure of Cognition, Vols. 1 and 2 (Cambridge: MIT Press, 1986). 
2. A. L. Samuel, ""Some studies in machine leaming using the game of checkers."" IBM J. Res. 
Dev. 3, 210--229 (1959). 
3. J. H. Holland, ""Escaping brittleness: the possibilities of general-purpose learning algorithms 
applied to parallel rule-based systems."" In: R. S. Michalski et al. (eds.), Machine learning: an 
artificial intelligence approach, Vol. H (Los Altos CA: Morgan-Kaufman, 1986). 
,. R. S. Sutton, ""Learning to predict by the methods of temporal differences,"" GTE Labs Tech. 
Report TR87-509.1 (1987). 
5. G. Tesauro and T. J. Sejnowski, ""A parallel network that learns to play backgammon."" Univ. of 
Illinois at Urbana-Champaign, Center for Complex Systems Research Technical Report (1987). 
6. M. Minsky and S. Papert, Perceptrons (Cambridge: MIT Press, 1969). 
7. D. E. Rumelhart, G. E. Hinton, and R. J. Williams, ""Leaming representations by back- 
propagating errors."" Nature 323, 533--536 (1986). 
8. Y. Le Cun, ""A learning procedure for asymmetric network."" Proceedings of Cognitiva (Paris) 
85, 599--604 (1985). 
9. D. B. Parker, ""Leaming-logic."" MIT Center for Computational Rese", network learn play backgammon tesauro complex system univers illinoi sixth il john hopkin md describ class connectionist network learn play network train learn procedur larg set sampl posit evalu actual match play human convent comput network demonstr substanti abil gener basi studi touch import issu learn includ develop effici code scheme use input techniqu escap local practic applic domain also potenti quit use test ground studi issu knowledg represent network found domain game board game othello entail consider sophist complex advanc masteri expert concept strategi often take year intens studi practic complex board game embed rel structur rule criteria success make amen autom fact game extens studi convent comput scienc direct comparison result network made convent describ applic network leam game difficult board game appear neural way move select primarili basi oppos explicit due probabilist dice roll greatli expand branch faclor pli search typic leam procedur supervis one requir databas posit move evalu expert unsupervis procedur would base consequ given move whether led lost explicit teacher instruct would unsupervis learn thu far much less effici reach high level perform leam advantag supervis leam trace higher american institut physic qualiti inform avail problem scale complex backgammon lead one confront gener issu network amongst import scale problem examin connectionist leam algorithm rel scale known well perform much larger gener key issu learn play backgammon sinc estim possibl board far excess number exampl provid respect studi sever test gener connectionist network also identifi studi novel set special techniqu train network necessari achiev good train set base natur occur exampl suffici bring network advanc level design perform also improv nois ad train procedur perhap import factor success network method encod input best perform raw input inform encod conceptu signific number featur ad raw lesson may also use connectionist learn algorithm appli difficult data base network train select move produc score given rather gener avoid difficulti teach network move envis network oper tandem would take board posit roll produc legal move network would train score system would choos move highest network network train produc rel score rather absolut evalu final approach would greater distinguish close correspond close way actual evalu current data base contain total board taken variou sourc posit dice roll set legal move roll receiv commentari human expert form rel score rang repres best possibl move repres worst possibl one us strong backgammon play role human expert move data base human expert comment possibl train procedur discuss follow feasibl unscor line import result studi order achiev best data base exampl must intellig rather haphazardli one simpli posit occur actual game one find certain play appear import principl use caus problem tend use learn rare use henc necessari intellig select mechan reduc number design mechan enhanc number exampl illustr process describ detail elsewher use network input output either two layer hidden full connect adjac tri experi restrict recept gener found sinc desir output network singl real one output unit code input pattern probabl difficult import design current configur input layer contain input scheme certain number input unit assign locat basic plu white black input invert necessari network alway see problem white exampl code scheme use recent shown unari encod number men board except represent scheme work fairli one peculiar problem network tend prefer pile larg number men certain point point number illustr exampl peculiar posit white play human would play network chose move actual bad reduc chanc make point inner fault lie base use train rather represent scheme unit turn whenev final posit number men initi point unit develop strong excitatori due case initi posit point move make point valuabl point make excit produc turn unit might inhibit produc poor distribut el two scheme use encod raw posit inform case encod two white men present three men present essenti unari code number men board unit encod initi unit encod final chang initi unit turn case top unit turn black men superior code scheme unit use character type transit initi final arrow indic increas number indic unit conceptu sampl posit illustr defect code scheme white code scheme network prefer code scheme network prefer graphic display gener sun microsystem use gammontool conceptu human would say unit particip represent two concept make concept chang number men made two concept point repres common input superior represent scheme concept shown represent unit turn move move chang number men point unit thu receiv undeserv represent network longer tend pile larg number men certain overal significantli addit represent raw board also util number input repres certain featur raw princip investig network rather simpli obtain high resist temptat includ sophist featur input found simpl featur need practic standard compet board order desir defin minski papert probabl quit number exampl learn difficult comput might intract give network form reduc order thu make problem leamabl tractabl number test procedur train use standard learn algorithm modifi connect multilay detail discuss provid procedur differ procedur due necess deal larg number uncom move one solut would simpli avoid present move would limit varieti input pattern present network certain type input probabl would elimin altern procedur skip uncom move time ordinari roll remaind time present pattem network gener teacher signal slight neg make move receiv human like bad move good random signal chosen uniformli interv use follow four measur assess perform perform train perform set test data use train perform actual game play comput program program gammontool sun microsystem game play human expert first two defin fraction posit network pick correct posit move score highest network agre choic human latter two perform defin simpli fraction game without complic count gammon result summari numer result measur perform train set gammontool present tabl best network produc far defeat gammontool nearli use find seriou decreas perform occur remov featur input produc network win next effect remov nois train result network win next import presenc hidden network without hidden unit game effect vari exact hidden number size train result percentag point decreas number game includ tabl result interest experi remov set featur substitut instead individu term gammontool found result train expert train abl defeat gammontool program small margin purpos experi provid evid use network learn adjunct ai techniqu evalu given set featur use evalu function interview human remain rel weight associ advanc context featur littl known gener approach often human programm must resort tune claim network learn autom method approach potenti produc tune superior produc given data base suffici high scheme encod result experi provid evid although firmli establish sinc highli accur know much human effort went tune gammontool evalu conclus evid would provid experi repeat program bkg similar result comment cycl test set gammontool featur hidden unit nois featur summari perform statist variou best network contain two layer hidden vnit one layer hidden network hidden unit singl train train set half normal network half number unit network featur gammontool evalu function normal network without hidden network train nois train network raw board descript result weight produc train network exceedingli difficult abl approach present diagram show strength network input unit hidden figur show input unit output purpos shown scheme unit normal explicitli repres transit initi final sinc weight go directli correspond input unit clearli either overal excitatori inhibitori effect score produc great deal columnar structur appar indic network particular number men given particular type transit either good bad independ exact locat board see import featur input signific featur seem number point made inner total blot gh jklmnop qr tuvw hinton diagram network input unit hidden small indic weight particular input unit output white squar indic black squar indic neg size squar indic first row bottom indic raw board let men move men interpret white blot hit next row encod number men white black next row encod roll remain row encod variou insight basi judgement variou move gain play game one reveal test network learn came match play one latest gener network hidden detail descript match given result match network actual game analysi move play network match indic tint network extrom lucki mani could reason expect continu well larg number game thero wero network make seriou network rosult quit network made one seriou potenti serious mistak would equival piec mistak nearli alway fatal chess good backgammon thero still chanc due element luck game network manag surviv win game due element assum mistak made wero minor highli unlik sort resuit would much moro like result wouid network would win one two game made seriou would expect perform expert human also confirm play find network act pick mani global concept advanc network also learn mani import tactic element play advanc specif kind mistak made find senseless instead fall conceptu one understand roason categori mistak space hero describ rofer roader instead qualit analysi play indic leam mani strategi tactic advanc give network good overal typic worst case perform leav groat network capabl make well subtl mani differ type worst case perform network must make long sequenc move throughout cours game without seriou mistak order reason chanc win skill prospect improv worst case perform appear seem like mani current fix reason number exampl ad train mani subtl mistak due lack sophist notion difficult imagin kind knowledg could impart network probabl requir intract larg number major overhaul either train seen quantit qualit measur network learn deal gener principl backgammon simpli memor posit train measuro game performac provid indic abil apart first coupl move start network must oper entir one play sever game network thero certain characterist kind kind posit systemat make type due frequent overal level play intermedi although probabl somewhat better averag program best network win almost human expert network would win network play expert suffici good give expert hard luck favor actual win match small number simpl supervis learn approach leav import sourc readili avail network never told underli structur input space realli correspond spatial know input form idea object sens tempor notion action consequ lead achiev teacher signal say given move good without give indic reason make network capabl score singl move without idea move sourc knowledg abil human play backgammon seem like way network learn paradigm necessari order achiev improv number way addit sourc knowledg might shall explor futur knowledg move could introduc defin sophist error signal take network teacher score current also network score move immedi plan involv continu exist strategi exampl code scheme modif elimin seriou error error confid network would becom substanti better avail would seriou challeng human would perform perform human result studi implic beyond backgammon gener difficult one limit found substanti human effort requir design code scheme design train use simpl code scheme random train let autom learn procedur take care everyth expect gener true learn appli difficult problem posit forese potenti combin connectionist learn techniqu convent ai techniqu knowledg make signific progress intellig practic point network learn tradit might produc system superior particular obviou way combin two approach featur input set featur use evalu function could encod discret continu activ level input repres current board state along unit repres raw suitabl encod scheme train set suffici size qualiti score train set better origin evalu possibl result network could outperform origin evalu experi gammontool learn might also hold promis mean achiev goal featur discoveri network certainli appear learn great deal train set goe far beyond amount knowledg explicitli input knowledg lowest level weight diagram hidden unit much knowledg remain need mean featur discov network either pattern activ hidden massiv number connect strength character one prioriti futur although techniqu parallel begin develop work inspir confer game held lo nation may thank sun microsystem provid code gammontool han berlin provid posit use data subutai allmad write weight display graphic bill bogstad program bartlett peter scott critic review support part nation supercomput support nsf presidenti young grant seavet institut lounsburi rumelart parallel distribut explor mit studi machin leam use game ibm possibl learn algorithm parallel michalski et machin intellig alto predict method tempor gte lab tesauro parallel network learn play center complex system research technic report minski perceptron mit represent natur le learn procedur asymmetr proceed cognitiva mit center comput rese,2
84,84,"804 
INTRODUCTION TO A SYSTEM FOR IMPLEMENTING NEURAL NET 
CONNECTIONS ON SIMD ARCHITECTURES 
Sherryl Tomboulian 
Institute for Computer Applications in Science and Engineering 
NASA Langley Research Center, Hampton VA 23665 
ABSTRACT 
Neural networks have attracted much interest recently, and using parallel 
architectures to simulate neural networks is a natural and necessary applica- 
tion. The SIMD model of parallel computation is chosen, because systems of 
this type can be built with large numbers of processing elements. However, 
such systems are not naturally suited to generalized communication. A method 
is proposed that allows an implementation of neural network connections on 
massively parallel SIMD architectures. The key to this system is an algorithm 
that allows the formation of arbitrary connections between the 'neurons '. A 
feature is the ability to add new connections quickly. It also has error recov- 
ery ability and is robust over a variety of network topologies. Simulations of 
the general connection system, and its implementation on the Connection Ma- 
chine, indicate that the time and space requirements are proportional to the 
product of the average number of connections per neuron and the diameter of 
the interconnection network. 
INTRODUCTION 
Neural Networks hold great promise for biological research, artificial intelli- 
gence, and even as general computational devices. However, to study systems 
in a realistic manner, it is highly desirable to be able to simulate a network 
with tens of thousands or hundreds of thousands of neurons. This suggests the 
use of parallel hardware. The most natural method of exploiting parallelism 
would have each processor simulating a single neuron. 
Consider the requirements of such a system. There should be a very large 
number of processing elements which can work in parallel. The computation 
that occurs at these elements is simple and based on local data. The processing 
elements must be able to have connections to other elements. All connections 
in the system must be able to be traversed in parallel. Connections must be 
added and deleted dynamically. 
Given current technology, the only type of parallel model that can be con- 
structed with tens of thousands or hundreds of thousands of processors is an 
SIMD architecture. In exchange for being able to build a system with so many 
processors, there are some inherent limitations. SIMD stands for single instruc- 
tion multiple data  which means that all processors can work in parallel, but 
they must do exactly the same thing at the same time. This machine model 
is sufficient for the computation required within a neuron, however in such a 
system it is difficult to implement arbitrary connections between neurons. The 
Connection Machine 2 provides such a model, but uses a device called the router 
This work was supported by the National Aeronautics and Space Administration under 
NASA Constract No. NASl-18010-7 while the author was in residence at ICASE. 
� American Institute of Physics 1988 
805 
to deliver messages. The router is a complex piece of hardware that uses signif- 
icant chip area, and without the additional hardware for the router, a machine 
could be built with significantly more processors. Since one of the objectives is 
to maximize the number of ""neurons"" it is desirable to eliminate the extra cost 
of a hardware router and instead use a software method. 
Existing software algorithms for forming connections on SIMD machines 
are not sufficient for the requirements of a neural networks. They restrict the 
form of graph (neural network) that can be embedded to permutations s'4 or 
sorts 5'6�""b""d'th?, the methods are network specific, and adding a new connec- 
tion is highly time consuming. 
The software routing method presented here is a unique algorithm which al- 
lows arbitrary neural networks to be embedded in machines with a wide variety 
of network topologies. The advantages of such an approach are numerous: A 
new connection can be added dynamically in the same amount of time that it 
takes to perform a parallel traversal of all connections. The method has error 
recovery ability in case of network failures. This method has relationships with 
natural neural models. When a new connection is to be formed, the two neurons 
being connected are activated, and then the system forms the connection with- 
out any knowledge of the ""address"" of the neuron-processors and without any 
instruction as to the method of forming the connecting path. The connections 
are entirely distributed; a processor only knows that connections pass through 
it - it doesn't know a connection's origin or final destination. 
Some neural network applications have been implemented on massively par- 
allel architectures, but they have run into restrictions due to communication. 
An implementation on the Connection Machine s discovered that it was more 
desirable to cluster processors in groups, and have each processor in a group 
represent one connection, rather than having one processor per neuron, because 
the router is designed to deliver one message at a time from each processor. This 
approach is contrary with the more natural paradigm of having one processor 
represent a neuron. The MPP 9, a massively parallel architecture with proces- 
sors arranged in a mesh, has been used to implement neural nets �, but because 
of a lack of generalized communication software, the method for edge connec- 
tions is a regular communication pattern with all neurons within a specified 
distance. This is not an unreasonable approach, since within the brain neurons 
are usually locally connected, but there is also a need for longer connections 
between groups of neurons. The algorithms presented here can be used on 
both machines to facilitate arbitrary connections with an irregular number of 
connections at each processor. 
MACHINE MODEL 
As mentioned previously, since we desire to build a system with an large 
number of processing elements, the only technology currently available for build- 
ing such large systems is the SIMD architecture model. In the SIMD model 
there is a single control unit and a very large number of slave processors that 
can execute the same instruction stream simultaneously. It is possible to disable 
some processors so that only some execute an instruction, but it is not possible 
to have two processor performing different instructions at the same time. The 
processors have exclusively local memory which is small (only a few thousand 
bits , and facilities for local indirect addressing. In this scheme 
) t. hey have no 
an snstrttctson involves both a particular operation code and the local memory 
8O6 
address. All processors must do this same thing to the same areas of their local 
memory at the same time. 
The basic model of computation is bit-serial - each instruction operates on 
a bit at a time. To perform multiple bit operations, such as integer addition, 
requires several instructions. This model is chosen because it requires less 
hardware logic, and so would allow a machine to be built with a larger number 
of processors than could otherwise be achieved with a standard word-oriented 
approach. Of course, the algorithms presented here will also work for machines 
with more complex instruction abilities; the machine model described satisfies 
the minimal requirements. 
An important requirement for connection formation is that the processors 
are connected in some topology. For instance, the processors might be con- 
nected in a grid so that each processor has a North, South, East, and West 
neighbor. The methods presented here work for a wide variety of network 
topologies. The requirements are: (1) there must be some path between any 
two processors; (2) every neighbor link must be hi-directional, i.e. if A is a 
neighbor of B, then B must be a neighbor of A; (3) the neighbor relations 
between processors must have a consistent invertible labeling. A more pre- 
cise definition of the labeling requirements can be found in n. It suffices that 
most networks a2, including gd, hypercube, cube connected cycles as, shuffle 
exchange , and mesh of trees are admissible under the scheme. Additional 
requirements are that the processors be able to read from or write to their 
neighbors' memories, and that at least one of the processors acts as a serial 
port between the processors and the controller. 
COMPUTATIONAL REQUIREMENTS 
The machine model described here is sufficient for the computational re- 
quirements of a neuron. Adopt the paradigm that each processor represents one 
neuron. While several different models of neural networks exist with slightly 
different features, they are all fairly well characterized by computing a sum or 
product of the neighbors values, and if a certain threshold is exceeded, then 
the processor neuron will fire, i.e. activate other neurons. The machine model 
described here is more efficient at boolean computation, such as described by 
McCulloch and Pitts 6, since it is bit serial. Neural net models using integers 
and floating point arithmetic 7,s will also work but will be somewhat slower 
since the time for computation is proportional to the number of bits of the 
operands. 
The only computational difficulty lies in the fact that the system is SIMD, 
which means that the processes are synchronous. For some neural net models 
this is sufficient xs however others require asynchronous behavior xT. This can 
easily be achieved simply by turning the processors on and off based on a spec- 
ified probability distribution. (For a survey of some different neural networks 
see 19). 
CONNECTION ASSUMPTIONS 
Many models of neural networks assume fully connected systems. This 
model is considered unrealistic, and the method presented here will work better 
for models that contain more sparsely connected systems. While the method 
will work for dense connections, the time and space required is proportional to 
807 
the number of edges, and becomes prohibitively expensive. 
Other than the sparse assumptions, there are no restrictions to the topo- 
logical form of the network being simulated. For example, multiple layered 
systems, slightly irregular structures, and completely random connections are 
all handled easily. The system does function better if there is locality in the 
neural network. These assumptions seem to fit the biological model of neurons. 
THE CONNECTION FORMATION METHOD 
A fundamental part of a neural network implementation is the realization of 
the connections between neurons. This is done using a software scheme first pre- 
sented in n,20. The original method was intended for realizing directed graphs 
in SIMD architectures. Since a neural network is a graph with the neurons 
being vertices and the connections being arcs, the method maps perfectly to 
this system. Henceforth the terms neuron and vertex and the terms arc and 
connection will be used interchangeably. 
The software system presented here for implementing the connections has 
several parts. Each processor will be assigned exactly one neuron. (Of course 
some processors may be free""or unallocated, but even free""processor par- 
ticipate in the routing process.) Each connection will be realized as a path 
in the topology of processors. A labeling of these paths in time and space is 
introduced which allows efficient routing algorithms and a set-up strategy is 
introduced that allows new connections to be added quickly. 
The standard computer science approach to forming the connection would 
be to store the addresses of the processors to which a given neuron is connected. 
Then, using a routing algorithm, messages could be passed to the processors 
with the specified destination. However, the SIMD architecture does not lend 
itself to standard message passing schemes because processors cannot do indi- 
rect addressing, so buffering of values is difficult and costly. 
Instead, a scheme is introduced which is closer to the natural neuron-synapse 
structures. Instead of having an address for each connection, the connection 
is actually represented as a fixed path between the processors, using time as a 
virtual dimension. The path a connection takes through the network of pro- 
cessors is statically encoded in the local memories of the neurons that it passes 
through. To achieve this, the following data structures will be resident at each 
processor. 
ALLOCATED boolean flag indicating 
whether this processor is assigned 
a vertex (neuron) in the graph 
VERTEX LABEL --- label of graph vertex 
HAS_NEIGHBOR[1..neighbor_limit] flag 
indicating the existence of neighbors 
SLOTS[1..T] OF arc path information 
START-- new arc starts here 
DIRECTION ...... direction to send 
{1..neighbor_limit.FREE} 
END arc ends here 
ARC LABEL ..... label of arc 
(neuron) 
808 
The ALLOCATED and VERTEX LABEL field indicates that the processor 
has been assigned a vertex in the graph (neuron). The HAS NEIGHBOR field 
is used to indicate whether a physical wire exists in the particular direction; it 
allows irregular network topologies and boundary conditions to be supported. 
The SLOTS data structure is the key to realizing the connections. It is used 
to instruct the processor where to send a message and to insure that paths are 
constructed in such a way that no collisions will occur. 
SLOTS is an array with T elements. The value T is called the time quantum. 
Traversing all the edges of the embedded graph in parallel will take a certain 
amount of time since messages must be passed along through a sequence of 
neighboring processors. Forming these parallel connections will be considered 
an uninterruptable operation which will take T steps. The SLOTS array is used 
to tell the processors what they should do on each relative time position within 
the time quantum. 
One of the characteristics of this algorithm is that a fixed path is chosen to 
represent the connection between two processors, and once chosen it is never 
changed. For example, consider the grid below. 
--A--B--C--D--E-- 
--F--G--H--T--J-- 
Fig. 1. Grid Example 
If there is an arc between A and H, there are several possible paths: East- 
East-South, East-South-East, and South-East-East. Only one of these paths 
will be chosen between A and H, and that same path will always be used. 
Besides being invariant in space, paths are also invariant in time. As stated 
above, traversal is done within a time quantum T. Paths do no have to start 
on time 1, but can be scheduled to start at some relative offset within the 
time quantum. Once the starting time for the path has been fixed, it is never 
changed. Another requirement is that a message can not be buffered, it must 
proceed along the specified directions without interruption. For example, if 
the path is of length 3 and it starts at time 1, then it will arrive at time 
4. Alternatively, if it starts at time 2 it will arrive at time 5. Further, it is 
necessary to place the paths so that no collisions occur; that is, no two paths 
can be at the same processor at the same instant in time. Essentially time 
adds an extra dimension to the topology of the network, and within this space- 
time network all data paths must be non-conflicting. The rules for constructing 
paths that fulfill these requirements are listed below. 
� At most one connection can enter a processor at a given time, and at 
most one connection can leave a processor at a given time. It is possible 
to have both one coming and one going at the same time. Note that this 
does not mean that a processor can have only one connection; it means 
that it can have only one connection during any one of the T time steps. 
It can have as many as T connections going through it. 
Any path between two processors u,v) representing connection must 
� ( . a 
consist of steps at contiguous times. For example, If the path from pro- 
cessor u to processor v is u,f,g,h,v , then if the arc from u-f is assigned 
time 1, f-g must have time 2, g-h time 3, and h-v time 4. Likewise if u-f 
occurs at time 5, then arc h-v will occur time 8. 
809 
When these rules are used when forming paths, the SLOTS structure can 
be used to mark the paths. Each path �oes throu�h nei�hborin� processors at 
successive time steps. For each of these time steps the DIRECTION field of 
the SLOTS structure is marked, telling the processor which direction it should 
pass a message if it receives it on that time. SLOTS serves both to instruct the 
processors how to send messages, and to indicate that a processor is busy at a 
certain time slot so that when new paths are constructed it can be guaranteed 
that they won't conflict with current paths. 
Consider the following example. Suppose we are given the directed graph 
with vertices A,B,C,D and edges A - > C, B - > C,B - > D, and D - > 
A. This is to be done where A,B,C, and D have been assigned to successive 
elements of a linear array. ( A linear array in not a good network for this 
scheme, but is a convenient source of examples.) 
Logical Connections 
A,B,C,D are successive members in a linear array 
1- - -2-- -3- --4 
A---B---C---D 
First, A ->C can be completed with the map East-East, 
SlotsEAl [1] .direction = E, Slots[B] 52] .direction=E, 
Slots[C] [2] .end = 1 . 
so 
B->C can be done with the map East, it can start at time 
since Slots [B] [1] . direction and Slots [C] [1]. end are free. 
B->D goes through C then to D, its map is East-East. B is 
occupied at time 1 and 2. It is free at time 3, 
so Slots[B][$].direction = E, Slots[C][4].direction = E, 
Slots[D][4].end = 1. 
D->A must go through C,B,A. using map West-West-West. 
D is free on time 1, C is free on time 2, but B is occupied 
on time 3. D is free on time 2, but C is occupied on time 3. 
It can start from D at time 3, Slots[D] [3] .direction = W, 
Slots[C] 54] .direction = , Slots[B] [5] .direction = , 
Slots [A] [5]. end=l 
810 
Every processor acts as a conduit for its neighbors messages. No processor 
knows where any message is going to or coming from, but each processor knows 
what it must do to establish the local connections. 
The use of contiguous time slots is vital to the correct operation of the 
system. If all edge-paths are established according to the above rules, there is 
a simple method for making the connections. The paths have been restricted 
so that there will be no collisions, and paths' directions use consecutive time 
slots. Hence if all arcs at time i send a message to their neighbors, then each 
processor is guaranteed no more than 1 message coming to it. The end of a 
path is specified by setting a separate bit that is tested after each message 
is received. A separate start bit indicates when a path starts. The start bit 
is needed because the SLOTS array just tells the processors where to send a 
message, regardless of how that message arrived. The start array indicates 
when a message originates, as opposed to arriving from a neighbor. 
The following algorithm is basic to the routing system. 
for i 
= time I to T 
FORALL processors 
/* if an arc starts or is passing through at this time*/ 
if SLOT[i] .START = 1 or active = 1 
for j=l to neighbor-limit 
if SLOT[i] .direction= j 
write message bit to in-box 
of neighbor j; 
set active = O; 
FORALL processor that just received a message 
if end [i] 
move in-box to message-destination: 
else 
move in-box to out-box; 
set active bit = 1; 
This code follows the method mentioned above. The time slots are looped 
through and the messages are passed in the appropriate directions as specified 
in the SLOTS array. Two bits, in-box and out-box, are used for message passing 
so that an out-going message won't be overwritten by an in-coming message 
before it gets transferred. The inner loop for ] = 1 to neighbor limit checks 
each of the possible neighbor directions and sends the message to the correct 
neighbor. For instance, in a grid the neighbor limit is 4, for North, South, East, 
and West neighbors. The time complexity of data movement is O(T times 
neighbor-limit). 
SETTING UP CONNECTIONS 
One of the goals in developing this system was to have a method for adding 
new connections quickly. Paths are added so that they don't conflict with any 
previously constructed path. Once a path is placed it will not be re-routed 
811 
by the basic placement algorithm; it will always start at the same spot at the 
same time. The basic idea of the method for placing a connection is to start 
from the source processor and in parallel examine all possible paths outward 
from it that do not conflict with pre-established paths and which adhere to the 
sequential time constraint. As the trial paths are flooding the system, they 
are recorded in temporary storage. At the end of this deluge of trial paths all 
possible paths will have been examined. If the destination processor has been 
reached, then a path exists under the current time-space restrictions. Using 
the stored information a path can be backtraced and recorded in the SLOTS 
structure. This is similar to the Lee-Moore routing algorithm 2,22 for finding a 
path in a system, but with the sequential time restriction. 
For example, suppose that the connection (u,v) is to be added. First it is 
a. ssumed that processors for u and v have already been determined, otherwise 
(as a simplification) assume a random allocation from a pool of free proces- 
sors. A parallel breadth-first search will be performed starting from the source 
processor. During the propagation phase a processor which receives a message 
checks its SLOTS array to see if they are busy on that time step, if not it will 
propagate to its neighbors on the next time step. For instance, suppose a trial 
path starts at time 1 and moves to a neighboring processor, but that neighbor is 
already busy at time 1 (as can be seen by examining the DIRECTION-SLOT.) 
Since a path that would go through this neighbor at this time is not legal, the 
trial path would commit suicide, that is, it stops propagating itself. If the pro- 
cessor slot for time 2 was free, the trial path would attempt to propagate to all 
of its' neighbors at time 3. 
Using this technique paths can be constructed with essentially no knowl- 
edge of the relative locations of the ""neurons"" being connected or the underly- 
ing topology. Variations on the outlined method, such as choosing the shortest 
path, can improve the choice of paths with very little overhead. If the entire net- 
work were known ahead of time, an off-line method could be used to construct 
the paths more efficiently; work on off-line methods is underway. However, the 
simple elegance of this basic method holds great appeal for systems that change 
slowly over time in unpredictable ways. 
PERFORMANCE 
Adding an edge (assuming one can be added), deleting any. set of edges, or 
traversing all the edges in parallel, all have time complexity O(T x neighbor - 
limit). If it is assumed that neighbor limit is a small constant then the com- 
plexity is O(T). Since T is related both to the time and space needed, it is 
a crucial factor in determining the value of the algorithms presented. Some 
analytic bounds on T were presented in , but it is difficult to get a tight bound 
on T for general interconnection networks and dynamically changing graphs. A 
simulator was constructed to examine the behavior of the algorithms. Besides 
the simulated data, the algorithms mentioned were actually implemented for 
the Connection Machine. The data produced by the simulator is consistent 
with that produced by the real machine. The major result is that the size of T 
appears proportional to the average degree of the graph times the diameter of 
the interconnection network 2�. 
812 
FURTHER RESEARCH 
This paper has been largely concerned with a system that can realize the 
connections in a neural network when the two neurons to be joined have been 
activated. The tests conducted have been concerned with the validity of the 
method for implementing connections, rather than with a full simulation of a 
neural network. Clearly this is the next step. 
A natural extension of this method is a system which can form its .own 
connections based solely on the activity of certain neurons, without having 
to explicitly activate the source and destination neurons. This is an exciting 
avenue, and further results should be forthcoming. 
Another area of research involves the formation of branching paths. The 
current method takes an arc in the neural network and realizes it as a unique 
path in space-time. A variation that has similarities to dendritic structure 
would allow a path coming from a neuron to branch and go to several target 
neurons. This extension would allow for a much more economical embedding 
system. Simulations are currently underway. 
CONCLUSIONS 
A method has been outlined which allows the implementation of neural nets 
connections on a class of parallel architectures which can be constructed with 
very large numbers of processing elements. To economize on hardware so as to 
maximize the number of processing element buildable, it was assumed that the 
processors only have local connections; no hardware is provided for communi- 
cation. Some simple algorithms have been presented which allow neural nets 
with arbitrary connections to be embedded in SIMD architectures having a va- 
riety of topologies. The time for performing a parallel traversal and for adding 
a new connection appears to be proportional to the diameter of the topology 
times the average number of arcs in the graph being embedded. In a system 
where the topology has diameter O(logN), and where the degree of the graph 
being embedded is bounded by a constant, the time is apparently O(logN). 
This makes it competitive with existing methods for SIMD routing, with the 
advantages that there are no apriori requirements for the form of the data, and 
the topological requirements are extremely general. Also, with our approach 
new arcs can be added without reconfiguring the entire system. The simplicity 
of the implementation and the flexibility of the method suggest that it could be 
an important tool for using SIMD architectures for neural network simulation. 
BIBLIOGRAPHY 
1. M.J. Flynn, ""Some computer organizations and their effectiveness"", IEEE 
Trans Cornput., vol C-21, no.9, pp. 948-960. 
2. W. Hillis,""The Connection Machine"", MIT Press, Cambridge, Mass, 1985. 
3. D. Nassimi, S. Sahni, ""Parallel Algorithms to Set-up the Benes Permutation 
Network"", Proc. Workshop on Interconnection Networks for Parallel and Dis- 
tributed Processing, April 1980. 
4. D. Nassimi, S. Sahni, ""Benes Network and Parallel Permutation Algorithms"", 
IEEE Transactions on Computers, Vol C-30, No 5, May 1981. 
5. D. Nassimi, S. Sahni, ""Parallel Permutation and Sorting Algorithms and a 
813 
New Generalized Connection Network , JACM, Vol. 29, No. 3, July 1982 pp. 
642-667 
6. K.E. Batchef, ""Sorting Networks and their Applications , The Proceedings 
of AFIPS 1968 SJCC, 1968, pp. 307-314. 
7. C. Thompson, ""Generalized connection networks for parallel processor inter- 
communication , IEEE Tran. Computers, Vol C, No 27, Dec 78, pp. 1119-1125. 
8. Nathan H. Brown, Jr., ""Neural Network Implementation Approaches for the 
Connection Machine"", presented at the 1987 conference on Neural Information 
Processing Systems - Natural and Synthetic. 
9. K.E. Batchef, ""Design of a massively parallel processor"", IEEE Trans on 
Computers, Sept 1980, pp. 836-840. 
10. H.M. Hastings, S. Waner, ""Neural Nets on the MPP"", Frontiers of Massively 
Parallel Scientific Computation, NASA Conference Publication 2478, NASA 
Goddard Space Flight Center, Greenbelt Maryland, 1986. 
11. S. Tomboulian, ""A System for Routing Arbitrary Communication Graphs 
on SIMD Architectures , Doctoral Dissertation, Dept of Computer Science, 
Duke University, Durham NC. 
12. T. Feng, ""A Survey of Interconnection Networks"", Computer, Dec 1981, 
pp.12-27. 
13. F. Preparata and J. Vuillemin, ""The Cube Connected Cycles: a Versatile 
Network for Parallel Computation"", Comm. ACM, Vol 24, No 5 May 1981, pp. 
300-309. 
14. H. Stone, ""Parallel processing with the perfect shuffle , IEEE Trans. Com- 
puters, Vol C, No 20, Feb 1971, pp. 153-161. 
15. T. Leighton, ""Parallel Computation Using Meshes of Trees"", Proc. Inter- 
national Workshop on Graph Theory Concepts in Computer Science, 1983. 
16. W.S. McCulloch, and W. Pitts, ""A Logical Calculus of the Ideas Imminent 
in Nervous Activity,"" Bulletin of Mathematical Biophysics, Vol 5, 1943, pp.115- 
133. 
17. J.J. Hopfield, ""Neural networks and physical systems with emergent col- 
lective computational abilities , Proc. Natl. Aca. Sci., Vol 79, April 1982, pp. 
2554-2558. 
18. T. Kohonen, ""Self-Organization and Associative Memory, Springer-Verlag, 
Berlin, 1984. 
19. R.P. Lippmann, ""An Introduction to Computing with Neural Nets , IEEE 
AASP, April 1987, pp. 4-22. 
20. S. Tomboulian, ""A System for Routing Directed Graphs on SIMD Architec- 
tures , ICASE Report No. 87-14, NASA Langley Research Center, Hampton, 
VA. 
21. C.Y. Lee, ""An algorithm for path connections and its applications , IRE 
Trans Elec Cornput, Vol. EC-10, Sept. 1961, pp. 346-365. 
22. E. F. Moore, ""Shortest path through a maze , Annals of Computation 
Laboratory, vol. 30. Cambridge, MA: Harvard Univ. Press, 1959, pp.285-292. 
", system implement neural net simd architectur tomboulian comput applic scienc engin langley research hampton va network attract much interest use parallel simul neural network natur necessari simd model parallel comput system type built larg number process system natur suit gener method propos allow implement neural network connect parallel simd key system algorithm allow format arbitrari connect abil add new connect also error abil robust varieti network simul gener connect implement connect indic time space requir proport averag number connect per neuron diamet interconnect network hold great promis biolog artifici even gener comput studi system realist highli desir abl simul network ten thousand hundr thousand suggest parallel natur method exploit parallel processor simul singl requir larg process element work comput occur element simpl base local process must abl connect connect system must abl travers connect must delet current type parallel model ten thousand hundr thousand processor exchang abl build system mani inher simd stand singl multipl data mean processor work must exactli thing machin model suffici comput requir within howev difficult implement arbitrari connect machin provid use devic call router work support nation aeronaut space administr constract author resid american institut physic deliv router complex piec hardwar use chip without addit hardwar machin built significantli sinc one object maxim number desir elimin extra cost hardwar router instead use softwar softwar algorithm form connect simd machin suffici requir neural restrict graph embed permut method network ad new highli time softwar rout method present uniqu algorithm arbitrari neural network embed machin wide varieti network advantag approach connect ad dynam amount time perform parallel travers method error abil case network method relationship neural new connect two neuron connect system form connect knowledg without method form connect connect entir processor know connect pass know origin final neural network applic implement massiv run restrict due implement connect machin discov cluster processor processor group one rather one processor per router design deliv one messag time contrari natur paradigm one processor mpp massiv parallel architectur arrang use implement neural net lack gener commun method edg regular commun pattern neuron within specifi unreason sinc within brain neuron usual local also need longer connect group algorithm present use machin facilit arbitrari connect irregular number model mention sinc desir build system larg process technolog current avail larg system simd architectur simd model singl control unit larg number slave processor execut instruct stream possibl disabl processor execut possibl two processor perform differ instruct exclus local memori small thousand facil local indirect scheme hey snstrttctson involv particular oper code local memori processor must thing area local basic model comput instruct oper bit perform multipl bit integ sever model chosen requir less would allow machin built larger number processor could otherwis achiev standard algorithm present also work machin complex instruct machin model describ satisfi minim import requir connect format processor connect processor might grid processor west method present work wide varieti network requir must path everi neighbor link must must neighbor neighbor relat processor must consist invert definit label requir found suffic network includ cube connect cycl shuffl mesh tree admiss addit processor abl read write least one processor act serial processor requir machin model describ suffici comput adopt paradigm processor repres one sever differ model neural network exist slightli fairli well character comput sum neighbor certain threshold processor neuron activ machin model effici boolean describ culloch pitt sinc bit neural net model use integ float point arithmet also work somewhat slower time comput proport number bit comput difficulti lie fact system mean process neural net model suffici xs howev other requir asynchron behavior achiev simpli turn processor base probabl survey differ neural network assumpt model neural network assum fulli connect consid method present work better model contain spars connect method work dens time space requir proport number becom prohibit spars restrict form network multipl layer slightli irregular complet random connect handl system function better local assumpt seem fit biolog model connect format method fundament part neural network implement realiz connect done use softwar scheme first origin method intend realiz direct graph simd sinc neural network graph neuron vertic connect method map perfectli henceforth term neuron vertex term arc use softwar system present implement connect processor assign exactli one cours processor may even rout connect realiz path topolog label path time space allow effici rout algorithm strategi allow new connect ad standard comput scienc approach form connect would store address processor given neuron use rout messag could pass processor specifi simd architectur lend standard messag pass scheme processor can not buffer valu difficult scheme introduc closer natur instead address connect actual repres fix path use time path connect take network static encod local memori neuron pass achiev follow data structur resid boolean flag indic processor assign vertex graph label label graph vertex flag exist neighbor arc path inform new arc start direct send arc end label label arc alloc vertex label field indic processor assign vertex graph neighbor field use indic whether physic wire exist particular irregular network topolog boundari condit slot data structur key realiz use instruct processor send messag insur path way collis array valu call time edg embed graph parallel take certain time sinc messag must pass along sequenc form parallel connect consid uninterrupt oper take slot array use tell processor rel time posit within time characterist algorithm fix path chosen connect two chosen never consid grid grid exampl arc sever possibl one path chosen path alway invari path also invari state travers done within time quantum path start time schedul start rel offset within start time path never anoth requir messag must along specifi direct without path length start time arriv time start time arriv time place path collis two path processor instant essenti time extra dimens topolog within network data path must rule construct fulfil requir list one connect enter processor given one connect leav processor given possibl one come one go note mean processor one mean one connect one time mani connect go path two processor repres connect must step contigu path processor arc assign must time time time likewis time arc occur time rule use form slot structur use mark path processor time time step direct field slot structur tell processor direct messag receiv slot serv instruct send indic processor busi time slot new path construct guarante conflict current follow suppos given direct graph vertic edg done assign success linear linear array good network conveni sourc connect success member linear array complet map eal done map start time slot direct slot end goe map time free time must go use map free time free time occupi time free time occupi time start time processor act conduit neighbor processor messag go come processor know must establish local use contigu time slot vital correct oper establish accord simpl method make path restrict direct use consecut time henc arc time send messag guarante messag come end specifi set separ bit test messag separ start bit indic path start bit need slot array tell processor send regardless messag start array indic messag oppos arriv follow algorithm basic rout time processor arc start pass activ messag bit neighbor activ processor receiv messag end activ bit code follow method mention time slot loop messag pass appropri direct specifi slot two use messag pass messag overwritten messag get inner loop neighbor limit check possibl neighbor direct send messag correct grid neighbor limit west time complex data movement time connect goal develop system method ad connect path ad conflict construct path place basic placement alway start spot basic idea method place connect start sourc processor parallel examin possibl path outward conflict path adher time trial path flood record temporari end delug trial path path destin processor path exist current use store inform path backtrac record slot similar rout algorithm find sequenti time suppos connect first ssume processor alreadi otherwis assum random alloc pool free parallel search perform start sourc propag phase processor receiv messag slot array see busi time neighbor next time suppos trial start time move neighbor neighbor busi time seen examin path would go neighbor time path would commit stop propag slot time trial path would attempt propag neighbor time techniqu path construct essenti rel locat connect variat outlin choos shortest improv choic path littl entir known ahead method could use construct path work method eleg basic method hold great appeal system chang time unpredict edg one delet set edg time complex neighbor assum neighbor limit small constant sinc relat time space crucial factor determin valu algorithm bound present difficult get tight bound gener interconnect network dynam chang construct examin behavior besid simul algorithm mention actual implement connect data produc simul consist produc real major result size proport averag degre graph time diamet interconnect network research paper larg concern system realiz neural network two neuron join test conduct concern valid implement rather full simul clearli next natur extens method system form base sole activ certain without explicitli activ sourc destin excit result area research involv format branch method take arc neural network realiz uniqu variat similar dendrit structur allow path come neuron branch go sever target extens would allow much econom embed simul current method outlin allow implement neural net class parallel architectur construct larg number process econom hardwar number process element assum local hardwar provid simpl algorithm present allow neural net arbitrari connect embed simd architectur time perform parallel travers ad new connect appear proport diamet topolog averag number arc graph system topolog diamet degre graph embed bound time appar make competit exist method simd apriori requir form topolog requir extrem approach arc ad without reconfigur entir simplic implement flexibl method suggest could import tool use simd architectur neural network comput organ ie vol connect mit algorithm bene permut workshop interconnect network parallel april network parallel permut transact vol may permut sort algorithm gener connect network juli network applic proceed afip connect network parallel processor ie vol dec nathan network implement approach present confer neural inform system natur massiv parallel ie tran sept net frontier massiv scientif nasa confer public nasa space flight greenbelt system rout arbitrari commun graph simd architectur doctor dept comput durham survey interconnect dec preparata cube connect versatil parallel vol may process perfect shuffl ie vol feb comput use mesh workshop graph theori concept comput logic calculu idea immin nervou bulletin mathemat vol network physic system emerg comput abil vol april associ introduct comput neural net ie april system rout direct graph simd icas report nasa langley research algorithm path connect applic ire elec path maze annal comput harvard,0
85,85,"814 
NEU1OMO1PHIC NETWORKS BASED 
ON SPARSE OPTICAL ORTHOGONAL CODES 
Mario P. Vecchi and Jawad A. Salehl 
Bell Communications Research 
435 South Street 
Morristown, NJ 07960-1961 
Abstract 
A family of neuromorphic networks specifically designed for communications 
and optical signal processing applications is presented. The information is encoded 
utilizing sparse Optical Orthogonal Code sequences on the basis of unipolar, binary 
(0, 1) signals. The generalized synaptic connectivity matrix is also unipolar, and 
clipped to binary (0, 1) values. In addition to high-capacity associative memory, 
the resulting neural networks can be used to implement general functions, such as 
code filtering, code mapping, code joining, code shifting and code projecting. 
1 Introduction 
Synthetic neural nets [1,2] represent an active and growing research field. Fundamental 
issues, as well as practical implementations with electronic and optical devices are being 
studied. In addition, several learning algorithms have been studied, for example stochas- 
tically adaptive systems[ 3] based on many-body physics optimization concepts[ 4,5]. 
Signal processing in the optical domain has also been an active field of research. 
A wide variety of non-linear all-optical devices are being studied, directed towards ap- 
plications both in optical computating and in optical switching. In particular, the 
development of Optical Orthogonal Codes (OOC) [6] is specifically interesting to opti- 
c01 communications applications, as it has been demonstrated in the context of Code 
Division Multiple Access (CDMA)[ 7]. 
In this paper we present a new class of neuromorphic networks, specifically designed 
for optical signal processing and communications, that encode the information in sparse 
OOC's. In Section 2 we review some basic concepts. The new neuromorphic networks 
are defined in Section 3, and their associative memory properties are presented in Section 
4. In Section 5 other general network functions are discussed. Concluding remarks are 
given in Section 6. 
2 Neural Networks and Optical Orthogonal Codes 
2.1 Neural Network Model 
Neural network are generally based on multiply-threshold-feedback cycles. In the Hop- 
field model[ 2], for instance, a connectivity  matrix stores the M different memory 
elements, labeled m, by the sum of outer products, 
M 
i,J: 
American Institute of Physics 1988 
815 
where the state vectors _u TM represent the memory elements in the bipolar (-1, 1) basis. 
The diagonal matrix elements in the Hopfield model are set to zero, Til - 0. 
For a typical memory recall cycle, an input vector _v i', which is close to a particular 
memory element rn = k, multiplies the  matrix, such that the output vector v �""t is 
given by 
N 
i,j = (2) 
j=l 
and can be seen to reduce to 
(N - + v/(N- 1)(M- 1) 
(3) 
for large N and in the case of randomly coded memory elements u_ TM. 
In the Hopfield model, each output o,t is passed through a thresholding stage 
around zero. The thresholded output signals are then fed back, and the multiply and 
threshold cycle is repeated until a final stable output v_ �""t is obtained. If the input v__ i' is 
sufficiently close to u?, and the number of state vectors is small (i.e. M << N), the final 
output will converge to memory element m = k, that is, _v �""t  _u k. The associative 
memory property of the network is thus established. 
2.2 Optical Orthogonal Codes 
The OOC sequences have been developed [6'7] for optical CDMA systems. Their prop- 
erties have been specifically designed for this purpose, based on the following two con- 
ditions: each sequence can be easily distinguished from a shifted version of itself, and 
each sequence can be easily distinguished from any other shifted or unshifted sequence 
in the set. Mathematically, the above two conditions are expressed in terms of auto- 
and crosscorrelation functions. Because of the non-negative nature of optical signals , 
OOC are based on unipolar (0, 1) signals [7]. 
In general, a family of OOC is defined by the following parameters: 
- F, the length of the code, 
- K, the weight of the code, that is, the number of 1's in the sequence, 
- ), the auto-correlation value for all possible shifts, other than the zero shift, 
- X, the cross-correlation value for all possible shifts, including the zero shift. 
For a given code length F, the maximum number of distinct sequences in a family 
of OOC depends on the chosen parameters, that is, the weight of the code K and the 
allowed overlap and. In this paper we will consider OOC belonging to the minimum 
overlap class,  = . = 1. 
XWe refer to optical intensity signals, and not to detection systems sensitive to phase information. 
816 
3 Neuromorphic Optical Networks 
Our neuromorphic networks are designed to take full advantage of the properties of the 
OOC. The connectivity matrix T is defined as a sum of outer products, by analogy with 
(1), but with the following important modifications: 
The memory vectors are defined by the sequences of a given family of OOC, with a 
basis given by the unipolar, binary pair (0, 1). The dimension of the sparse vectors 
is given by the length of the code F, and the maximum number of available items 
depends on the chosen family of OOC. 
All of the matrix elements Tij are clipped to unipolar, binary (0, 1) values, resulting 
in a sparse and simplified connectivity matrix, without any loss in the functional 
properties defined by our neuromorphic networks. 
3. The diagonal matrix elements Tii are not set to zero, as they reflect important 
information implicit in the OOC sequences. 
4. The threshold value is not zero, but it is chosen to be equal to K, the weight of 
the OOC. 
The connectivity matrix T is generalized to allow for the possibility of a variety 
of outer product options: self-outer products, as in (1), for associative memory, 
but also cross-outer products of different forms to implement various other system 
functions. 
A simplified schematic diagram of a possible optical neuromorphic processor is shown 
in Figure 1. This implementation is equivalent to an incoherent optical matrix-vector 
multiplier [8], with the addition of nonlinear functions. The input vector is clipped using 
an optical hard-limiter with a threshold setting at 1, and then it is anamorphically 
imaged onto the connectivity mask for . In this way, the i h pixel of the input vector 
is imaged onto the i h colunto of the  mask. The light passing through the mask is 
then anamorphically imaged onto a line of optical threshold elements with a threshold 
setting equal to K, such that the jh row is imaged onto the jh threshold element. 
4 Associative Memory 
The associative memory function is defined by a connectivity matrix MEM given by: 
ij =  zz ; i,j - 1,2...F 
(4) 
where each memory element z__ ' corresponds to a given sequence of the OOC family, 
with code length F. The matrix elements of TMEM are all clipped, unipolar values, as 
indicated by the function 6(}, such that, 
(5) 
817 
We will now show that an input vector z_ k, which corresponds to memory element 
m = k, will produce a stable output (equal to the wanted memory vector) in a single 
pass of the multiply and threshold process. 
The multiplication can be written as: 
F 
= j zj 
We remember that the non-linear clipping function {} is to be applied first to obtain 
MEM. Hence, 
(7) 
k = 0, only the second term in (7) contributes, and the pseudo-orthogonality 
For zi 
properties of the OOC allow us to write: 
zj Oiz..  i 
where the cross-correlation value is Ac < K. 
k 1, we again consider the properties of the OOC to obtain for the first term 
For z i = 
of (7): 
F 
Z k k k=Kz 
(9) 
J 
where K is the weight of the O OC. 
Therefore, the result of the multiplication operation given by (7) can be written as: 
o,,t Kz+[valuestrictly] 
i = less than K 
(lO) 
The thresholding operation follows, around the value K as explained in Section 3. 
That is, (10) is thresholded such that: 
v?t _ -- { I if O?t _ K (11) 
0 if O  < K, 
hence, the final output at the end of a single pass will be given by: v t k 
-- gi' 
The result just obtained can be extended to demonstrate the single pass convergence 
when the input vector is close, but not necessarily equal, to a stored memory element. 
We can draw the following conclusions regarding the properties of our neuromorphic 
networks based on OOC: 
� For any given input vector v_ i', the single pass output will correspond to the 
memory vector z__ "" which has the smallest Hamming distance to the input. 
� If the input vector v_ i' is missing a single 1-element from the K 1's of an OOC, 
the single pass output will be the null or zero vector. 
818 
� If the input vector v_/n has the same Hamming distance to two (or more) memory 
vectors z_ "", the single pass output will be the logical sum of those memory vectors. 
The ideas just discussed were tested with a computer simulation. An example of 
associative memory is shown in Table 1, corresponding to the OOC class of length 
F = 21 and weight K = 2. For this case, the maximum number of independent 
sequences is M = 10. The connectivity matrix MEM is seen in Table 1, where one can 
clearly appreciate the simplifying features of our model, both in terms of the sparsity 
and of the unipolar, clipped values of the matrix elements. The computer simulations for 
this example are shown in Table 2. The input vectors a and b show the error-correcting 
memory recovery properties. The input vector c is equally distant to memory vectors 
z s and z_ s, resulting in an output which is the sum (z_ s ( z_s). And finally, input vector 
d is closest to z  but one I is missing, and the output is the zero vector. The mask 
in Figure I shows the optical realization of the Table 1, where the transparent pixels 
correspond to the 1's and the opaque pixels to the O's of the connectivity matrix ME. 
It should be pointed out that the capacity of our network is significant. From the 
previous example, the capacity is seen to be  F/2 for single pass memory recovery. 
This result compares favorably with the capacity of a Hopfield model [9], of  F/4 In F. 
5 General Network Functions 
Our neuromorphic networks, based on OOC, can be generalized to perform functions 
other than associative memory storage by constructing non-symmetrical connectivity 
matrices. The single pass convergence of our networks avoids the possibility of lhnit- 
cycle oscillations. We can write in general: 
= V , 
where each pair defined by m includes two vectors y"" and z_ m, which are not necessarily 
equal. The clipping function (} insures that all matrix elements are binary (0,1) values. 
The possible choice of vector pairs is not completely arbitrary, but there is a wide variety 
of functions that can be implemented for each family of OOC. We will now discuss some 
of the applications that are of particular interest in optical communication systems. 
5.1 Code Filtering (CDMA) 
Figure 2 shows an optical CDMA network in a star configuration. M nodes are inter- 
connected with optical fibers to a passive MxM star coupler that broadcasts the optical 
signals. At each node there is a data encoder that maps each bit of information to the 
OOC sequence corresponding to the user for which the transmission is intended. In 
addition, each node has a filter and decoder that recognizes its specific OOC sequence. 
The optical transmission rate has been expanded by a factor F corresponding to the 
length of the OOC sequence. Within the context of a CDMA communication system [7], 
the filter or decoder must perform the function of recognizing a specific OOC sequence 
in the presence of other interfering codes sent on the common transmission medium. 
819 
We can think, then, of one of our neuromorphic networks as a filter, placed at a given 
receiver node, that will recognize the specific code that it was programmed for. 
We define for this purpose a connectivity matrix as 
CDMA k  . i,j = 1,2...F, (13) 
'ij -- Z i Zj , 
where only one vector z_ k is stored at each node. This symmetric, clipped connectivity 
matrix will give an output equal to z? whenever the input contains this vector, and a 
null or zero output vector otherwise. It is clear by comparing (13) with (4) that the 
CDMA filtering matrix is equivalent to an associative memory matrix with only one 
item imprinted in the memory. Hence the discussion of Section 4 directly applies to the 
understanding of the behaviour of TCDMA. 
In order to evaluate the performance of our neuromorphic network as a CDMA 
filter, computer simulations were performed. Table 3 presents the CDMA matrix for 
a particular node defined by _z k of a CDMA system based on the OOC family F = 21, 
K = 2. The total number of distinct codes for this OOC family is M = 10, hence there 
are 9 additional OOC sequences that interfere with z k, labeled in Table 3 z_  to z 9. 
The performance was simulated by generating random composite sequences from the 
set of codes z  to z__ 9 arbitrarily shifted. All inputs are unipolar and clipped (0,1) signals. 
The results presented in Table 4 give examples of our simulation for the TCDMA matrix 
shown in Table 3. The input a is the (logical) sum of a 1-bit (vector zk), plus interfering 
signals from arbitrarily shifted sequences of z_ z, z_ a, z__ 4, z_ a and z_ 9. The output of the 
neuromorphic network is seen to recover accurately the desired vector z?. The input 
vector _b contains a 0-bit (null vector), plus the shifted sequences of z_  , z_ z, z_ a, z_ a, z ? 
and z_ a, and we see that the output correctly recovers a O-bit. 
As discussed in Section 4, our neuromorphic network will always correctly recognize 
a 1-bit (vector z?) presented to its input. On the other hand 2, there is the possibility of 
making an error when a 0-bit is sent, and the interfering signals from other nodes happen 
to generate the chip positions of z?. This case is shown by input vector c of Table 4, 
which contains a 0-bit (null vector), plus shifted sequences of z_ z, z_ a, z_ 4, z_ s, z_ a, z_ ? and 
z__ a in such a way that the output is erroneously given as a 1-bit. The properties of the 
OOC sequences are specifically chosen to minimize these errors[ 7], and the statistical 
results of our simulation are also shown in Table 4. It is seen that, as expected, when 
a 1-bit is sent it is always correctly recognized. On the other hand, when 0-bits are 
sent, occasional errors occur. Our simulation, yields an overall bit error rate (BER) of 
BER,im = 5.88%, as shown in Table 4. 
These results can be compared with theoretical calculations [7] which yield an esti- 
mate for the BER for the CDMA system described: 
B E Rc,ic   k=0 
(14) 
where q =_ 1 - K For the example of the OOC family F = 21, K = 2, with M = 10, 
2F' 
the above expression yields BERc,I  5.74%. 
2Our channel can be described, then, as a binary Z-channel between each two nodes dynamically 
establishing a communication path 
82O 
It is seen, therefore, that our neuromorphic network approaches the minimum pos- 
� . --GDMA 
sible BER for a given family of OOC. In fact, the results obtmned usm our T 
are equivalent CDMA detection scheme based on ""optical-AND-gates ""[10], which cor- 
responds to the limiting BER determined by the properties of the OOC themselves s. 
The optical mask corresponding to the code filtering function is shown in Figure 3. 
5.2 Other Functions 
As a first example of a non-symmetric T matrix, let us consider the function of mapping 
an input code to a corresponding different output code. We define our mapping matrix 
as; 
Yi zj 
where an input vector z_ TM will produce a different output vector code y_m. 
The function of code joining is defined by a transfer function that takes a given 
input code and produces at the output a chosen combination of two or more codes. 
This function is performed by expressing the general matrix given by 12 as follows: 
where an input vector z_ TM will result in an output that joins several vector codes (_ym  
The code shifting matrix $HIFT will allow for the shift of a given code sequence, 
such that both input and output correspond to the same code, but shifted with respect 
to itself. That is, 
ij = G .z(s)z(O) ; i,j = 1,2...F, (17) 
m 
where we have indicated an unshifted code sequence by z_(0) TM, and its corresponding 
output pair as a shifted version of itself z__(s) "". 
The code projecting function corresponds to processing an input vector that contains 
the logical sum of several codes, and projecting at the output a selected single code 
sequence. The corresponding matrix PRoJ is given by: 
08) 
where each input vector (ym (t) w_ TM (t) ...) will project at the output to a single code 
_z TM. In general, the resulting output code sequence z_ TM could correspond to a code not 
necessarely contained in the input vector. 
The performance and error correcting properties of these, and other, general func- 
tions follow a similar behaviour as discussed in Section 4. 
3The BER for the OOC family shown in this example are far too large for a useful CDMA com- 
munications system. Our choice intended to show computer simulated results within a reasonable 
computation time. 
821 
6 Conclusions 
The neuromorphic networks presented, base d on sparse Optical Orthogonal Code (O O C) 
sequences, have been shown to have a number of attractive properties. The unipolar, 
clipped nature of the synaptic connectivity matrix simplifies the implementation. The 
single pass convergence further allows for general network functions that are expected 
to be of particular interest in communications and signal processing systems. 
The coding of the information, based on OOC, has also been shown to result in high 
capacity associative memories. The combination of efficient associative memory prop- 
erties, plus a variety of general network functions, also suggests the possible application 
of our neuromorphic networks in the implementation of computational functions based 
on optical symbolic substitution. 
The family of neuromorphic networks discussed here emphasizes the importance of 
understanding the general properties of non-negative systems based on sparse codes [11]. 
It is hoped that our results will stimulate further work on the fundamental relationship 
between coding, or representations, and the information processing properties of neural 
nets. 
Acknowledgement 
We thank J. Y. N. Hui and J. Alspector for many useful discussions, and C. A. Brackett for his support 
and encouragement of this research. 
References 
[1] S. Grossberg. In K. Schmitt, editor, Delay and Functional-Differential Equations and Their Ap- 
plications, page 121, Academic Press, New York, NY, 1972. 
[2] J. J. Hopfield. Neural Networks and Physical Systems with Emergent Collective Computational 
Abilities. Proc. Nat. Acad. Sci. USA, 79:2254, 1982. 
[3] D. H. Ackley, G. E. Hinton, and T. J. Sejnowski. A Learning Algorithm for Boltzmann Machines. 
Cogn. Sci., 9:147, 1985. 
[4] S. Kirkpatrick, C. D. Gelatt, and M. P. Vecchi. Optimization by Simulated Annealing. Science, 
220:671, 1983. 
[5] M.P. Vecchi and S. Kirkpatrick. Global Wiring by Simulated Annealing. IEEE Trans. CAD of 
Integrated Circuits and Systems, CAD-2:215, 1983. 
[6] F. R. K. Chung, J. A. Salehi, and V. K. Wei. Optical Orthogonal Codes: Design, Analysis and 
Applications. In IEEE International Symposium on Information Theory, Catalog No. 86CH374-7, 
1986. Accepted for publication in IEEE Trans. on Information Theory. 
[7] J. A. Salehi and C. A. Brackett. Fundamental Principles of Fiber Optics Code Division Multiple 
Access. In IEEE International Conference on Communications, 1987. 
[8] N.H. Farhat, D. Psaltis, A. Prata, and E. Paek. Optical Implementation of the Hopfield Model. 
Appl. Opt., 24:1469, 1985. 
[9] R. J. McEliece, E. C. Posner, E. R. Rodemich, and S.S. Venkatesh. The Capacity of Hopfield 
Associative Memory. IEEE Trans. on Information Theory, IT-33:461, 1987. 
[10] J. A. Salehi. Principles and Applications of Optical AND Gates in Fiber Optics Code Division 
Multiple Access Networks. In preparation, 1987. 
[11] G. Palm. Technical comments. Science, 235:1226, 1987. 
822 
Tsbb I: Assoc,mfi,N Mery. F, ximpl sbo,iq d'i&, d' 10 distinct 
iu O O i O I O O O O O O O O O O O O O O O O 
1 O O O I O O I O O O O O O O O O O O O O O 
t O O O O O I O O O I O O O O O O O  0 O O 
_t* O O O O O O O I O O O O I O O O O O 0 O O 
i"" O O O O O O O O I O O O O O I O O'b' O O O 
i O O O O O O O O O O I O O O O O O I O O O 
is iII I I I I I I I I I I I I i i i I i I I 
i I O O I O I O O O O O O O I O O O 0 O O 
i i O O O O O I I O I O O O O O I O I I O 
O O I O i O O O O O O O O O O O O O O O O' 
O O O I O O i O O O O O O O O O O O O O O 
O O i O I O O O O O O O O i O O O I O O O 
000001000100000100000 
O O O I O O i O O O O O O O 0 O O O O O O 
O O O I O O O I O O O O I O O O O O O O O 
O O I I O O O O I I I I I O i O I I I O O 
I O I I O I O O I I I I O O O O O O 0 O O 
O O O O O O O O O O I O O O O O O I O O O 
O O O O O O O I O O O I O O O I O I 0 I I 
O O O O O O O i O O O O i O O O O O O O O 
O 0 O O I O O O O O O O O i O O O O O O O 
I I 0 I I I I I I I I I I I I I I I i 0 I 
O O O O O I O O O O O O O O O i O O O 0 O 
I I I I I I O I I O 0 I I O I O I I 0 O 
I O O I I I O O O O I I I O O 0 O I O I I 
O O O O O O O I I I I O O O I I I I I I O 
O I O O O O O O O O I O O I O O I I i I 
O O I O O O O O O O I O 0 I O O O I O I OJ 
Code Faterls s 
I OOC Imil, � = it, K = 3 j 
i'je o o o e o e I o o o o o t o o e o e e 
lllllllllllllllllllOl 
llllllllllllllllllllO 
lllllllllllllllllllll 
O I I O O I O O O I I I O I I I O O I I I 
O I I O O O O I O I I O O I I O O I O I 0 
O I I I I I O O O 0 O O O I I O O O O O I 
O O O O O O O I O I I O O O O O O O I I O 
O O O I O O O 0 O I O I O I I O O O I 00 
O O O O O O O O I O O O O O I O O 0 O O O 
O O I 0 I O O O I I I O O O O O I O I I O 
O O O I O O O I I I 0 O I O I O O I 0 I 0 
I I O O O O I O I O O I O O I I O I O I I 
I I I I O O I O I I O O O O O O I I I 0 I 
O I O I O I I O I I I O O I I O I 0 I I O 
O I O O O O I O I I O O O O I O O O I I I 
I I � I O 0 I O O I O O I I I I I I I O I 
I I 0 I O O I O O I O O O O I O I O O I I 
O O I I O O I O I O O O O I I O I I O I O 
O O 0 O O O O O O O O O O O I O O I O I O 
I O I O O 0 O O O O I O O I I O O I O 0 I 
O O I O O O O O I O O I O I 0 O I I O O I 
f] I I I I I I I I I I I I I I I I I I I 0 l 
Is I t I 0 I I I I I I I I I I I I I I I I I 
 O O O O O O O I O O I O O O O O O I O O O 
fflllllllllllllllllllOI 
 O O O O O I O O O O O O O O O I 0 O O O O 
I �'""'"" v"""""" 
I l' III o o o o o o o o o o 
, Outpsd Vc14 
OutPut Vlcted mmw 
i  ]l I O O O I I O t I O O I I I O 0 O O 
I SJt bt J B elMvlom, 
StOI 
11.1'1% st8% 'r 
823 
Figure 1: 
Schematic diagram of an optical neuromorphic pro- 
cessor using sparse Optical Orthogonal Codes. No- 
tice the absence of teedback because of the single-pass 
convergence. The mask shown represents the realiza- 
tion of the content-addressable memory of Table 1. 
Figure 3: 
Optical realization of a code filtering (CDMA) mask 
of Table 3. The l's are represented by the transpar. 
ent pixels, and the 0s by the opaque pixels. 
Figure 2: 
Schematic diagram of a CDMA communications sys- 
tem over an Optical Fiber interconnection network. 
Each node represents one of the M possible distinct 
users in the system. 
", network base spars optic orthogon code vecchi jawad salehl commun research south street nj famili neuromorph network specif design commun optic signal process applic inform encod spars optic orthogon code sequenc basi binari gener synapt connect matrix also binari addit associ result neural network use implement gener code code code shift code introduct neural net repres activ grow research fundament well practic implement electron optic devic sever learn algorithm exampl adapt base physic optim process optic domain also activ field wide varieti devic direct toward optic comput optic optic orthogon code specif interest commun demonstr context code multipl access paper present new class neuromorph specif design optic signal process encod inform spars section review basic new neuromorph network defin section associ memori properti present section section gener network function conclud remark section neural network optic orthogon code neural network model network gener base connect matrix store differ memori label sum outer institut physic state vector tm repres memori element bipolar diagon matrix element hopfield model set til typic memori recal input vector close particular element rn multipli output vector seen reduc larg case randomli code memori element hopfield output pass threshold stage threshold output signal fed multipli cycl repeat final stabl output input close number state vector small final converg memori element associ properti network thu optic orthogon code ooc sequenc develop optic cdma specif design base follow two sequenc easili distinguish shift version sequenc easili distinguish shift unshift sequenc two condit express term crosscorrel natur optic signal base unipolar signal famili ooc defin follow length weight number valu possibl zero valu possibl includ zero given code length maximum number distinct sequenc famili ooc depend chosen weight code overlap paper consid ooc belong minimum refer optic intens detect system sensit phase neuromorph optic network neuromorph network design take full advantag properti connect matrix defin sum outer analog follow import memori vector defin sequenc given famili given binari pair dimens spars vector given length code maximum number avail item chosen famili matrix element tij clip binari result spars simplifi connect without loss function defin neuromorph diagon matrix element tii set reflect import implicit ooc threshold valu chosen equal weight connect matrix gener allow possibl varieti outer product associ also product differ form implement variou system simplifi schemat diagram possibl optic neuromorph processor shown figur implement equival incoher optic addit nonlinear input vector clip use optic threshold set anamorph onto connect mask pixel input vector imag onto colunto light pass mask anamorph imag onto line optic threshold element threshold equal row imag onto threshold associ memori associ memori function defin connect matrix given memori element correspond given sequenc ooc code length matrix element tmem unipolar function show input vector correspond memori element produc stabl output want memori singl multipli threshold multipl written zj rememb clip function appli first obtain second term zi ooc allow us valu ac consid properti ooc obtain first term weight result multipl oper given written less threshold oper around valu explain section threshold final output end singl pass given result obtain extend demonstr singl pass converg input vector necessarili store memori draw follow conclus regard properti neuromorph base given input vector singl pass output correspond vector smallest ham distanc input vector miss singl singl pass output null zero input vector ham distanc two memori singl pass output logic sum memori idea discuss test comput exampl memori shown tabl correspond ooc class length weight maximum number independ connect matrix seen tabl one appreci simplifi featur term sparsiti clip valu matrix comput simul exampl shown tabl input vector show recoveri input vector equal distant memori vector result output sum input vector closest one output zero mask figur show optic realiz tabl transpar pixel opaqu pixel connect matrix point capac network capac seen singl pass memori result compar favor capac hopfield model gener network function neuromorph base gener perform function associ memori storag construct connect singl pass converg network avoid possibl write pair defin includ two vector necessarili clip function insur matrix element binari possibl choic vector pair complet wide varieti function implement famili discuss applic particular interest optic commun code filter show optic cdma network star node optic fiber passiv star coupler broadcast optic node data encod map bit inform sequenc correspond user transmiss node filter decod recogn specif ooc optic transmiss rate expand factor correspond ooc within context cdma commun system filter decod must perform function recogn specif ooc sequenc presenc interf code sent common transmiss one neuromorph network place given recogn specif code program defin purpos connect matrix zj one vector store clip connect give output equal whenev input contain zero output vector clear compar filter matrix equival associ memori matrix one imprint henc discuss section directli appli behaviour order evalu perform neuromorph network cdma comput simul tabl present matrix particular node defin cdma system base ooc famili total number distinct code ooc famili henc addit ooc sequenc interfer label tabl perform simul gener random composit sequenc code arbitrarili input unipolar clip result present tabl give exampl simul tcdma matrix tabl input sum plu interf arbitrarili shift sequenc output network seen recov accur desir vector input contain plu shift sequenc see output correctli recov discuss section neuromorph network alway correctli recogn present hand possibl error interf signal node happen gener chip posit case shown input vector tabl contain plu shift sequenc way output erron given properti sequenc specif chosen minim statist simul also shown tabl seen sent alway correctli occasion error yield overal bit error rate shown tabl result compar theoret calcul yield ber cdma system exampl ooc famili express yield channel binari two node dynam commun path neuromorph network approach minimum ber given famili result obtmn equival cdma detect scheme base limit ber determin properti ooc optic mask correspond code filter function shown figur function first exampl let us consid function map input code correspond differ output defin map matrix zj input vector tm produc differ output vector code function code join defin transfer function take given code produc output chosen combin two function perform express gener matrix given input vector tm result output join sever vector code code shift matrix allow shift given code input output correspond shift respect indic unshift code sequenc correspond pair shift version code project function correspond process input vector contain logic sum sever project output select singl code correspond matrix given input vector tm project output singl code result output code sequenc tm could correspond code contain input perform error correct properti gener follow similar behaviour discuss section ber ooc famili shown exampl far larg use cdma choic intend show comput simul result within reason conclus neuromorph network base spars optic orthogon code shown number attract natur synapt connect matrix simplifi pass converg allow gener network function expect particular interest commun signal process code base also shown result high associ combin effici associ memori plu varieti gener network also suggest possibl applic neuromorph network implement comput function base optic symbol famili neuromorph network discuss emphas import gener properti system base spars code hope result stimul work fundament relationship inform process properti neural thank hui alspector mani use brackett support encourag delay equat page academ new neural network physic system emerg collect comput learn algorithm boltzmann optim simul vecchi global wire simul ie cad circuit optic orthogon analysi ie intern symposium inform catalog accept public ie inform salehi fundament principl fiber optic code divis multipl ie intern confer optic implement hopfield capac hopfield ie inform principl applic optic gate fiber optic code divis access technic distinct ii oj faterl ooc ol oi outpsd put mmw bt oi diagram optic neuromorph use spars optic orthogon absenc teedback mask shown repres memori tabl realiz code filter mask tabl repres opaqu diagram cdma commun optic fiber interconnect node repres one possibl distinct,0
86,86,"824 
SYNCHRONIZATION IN NEURAL NETS 
Jacques J. Vidal 
University of California Los Angeles, Los Angeles, Ca. 90024 
John Haggerty' 
ABSTRACT 
The paper presents an artificial neural network concept (the 
Synchronizable Oscillator Networks) where the instants of individual 
firings in the form of point processes constitute the only form of 
information transmitted between joining neurons. This type of 
communication contrasts with that which is assumed in most other 
models which typically are continuous or discrete value-passing 
networks. Limiting the messages received by each processing unit to 
time markers that signal the firing of other units presents significant 
implementation advantages. 
In our model, neurons fire spontaneously and regularly in the 
absence of perturbation. When interaction is present, the scheduled 
firings are advanced or delayed by the firing of neighboring neurons. 
Networks of such neurons become global oscillators which exhibit 
multiple synchronizing attractors. From arbitrary initial states, 
energy minimization learning procedures can make the network 
converge to oscillatory modes that satisfy multi-dimensional 
constraints Such networks can directly represent routing and 
scheduling problems that consist of ordering sequences of events. 
INTRODUCTION 
Most neural network models derive from variants of Rosenblatt's 
original perceptron and as such are value-passing networks. This is 
the case in particular with the networks proposed by Fukushima 1, 
Hopfield 2, Rumelhart 3 and many others. In every case, the inputs to 
the processing elements are either binary or continuous amplitude 
signals which are weighted by synaptic gains and subsequently 
summed (integrated). The resulting activation is then passed 
through a sigmoid or threshold filter and again produce a continuous 
or quantized output which may become the input to other neurons. 
The behavior of these models can be related to that of living neurons 
even if they fall considerably short of accounting for their complexity. 
Indeed, it can be observed with many real neurons that action 
potentials (spikes) are fired and propagate down the axonal branches 
when the internal activation reaches some threshold and that higher 
John Haggerty is with Interactive Systems Los angeles 
3030 W. 6th St. LA, Ca. 90020 
@ American Institute of Physics 1988 
825 
input rates levels result in more rapid firing. Behind these 
traditional models, there is the assumption that the average 
frequency of action potentials is the carrier of information between 
neurons. Because of integration, the firings of individual neurons are 
considered effective only to the extent to which they contribute to 
the average intensities It is therefore assumed that the activity is 
simply ""frequency coded"". The exact timing of individual firing is 
ignored. 
This view however does not cover some other well known 
aspects of neural communication. Indeed, the precise timing of 
spike arrivals can make a crucial difference to the outcome of some 
neural interactions. One classic example is that of pre-synaptic 
inhibition, a widespread mechanism in the brain machinery. Several 
studies have also demonstrated the occurrence and functional 
importance of precise timing or phase relationship between 
cooperating neurons in local networks 4, 5. 
The model presented in this paper contrasts with the ones just 
mentioned in that in the networks each firing is considered as an 
individual output event. On the input side of each node, the firing of 
other nodes (the presynaptic neurons) either delay (inhibit) or 
advance (excite) the node firing. As seen earlier, this type of 
neuronal interaction which would be called phase-modulation in 
engineering systems, can also find its rationale in experimental 
neurophysiology. Neurophysiological plausibility however is not the 
major concern here. Rather, we propose to explore a potentially 
useful mechanism for parallel distributed computing. The merit of 
this approach for artificial neural networks is that digital pulses are 
used for internode communication instead of analog voltages. The 
model is particularly well suited to the time-ordering and 
sequencing found in a large class of routing and trajectory control 
problems. 
NEURONS AS SYNCHRONIZABLE OSCILLATORS: 
In our model, the processing elements (the ""neurons"") are 
relaxation oscillators with built-in self-inhibition. A relaxation 
oscillator is a dynamic system that is capable of accumulating 
potential energy until some threshold or breakdown point is 
reached. At that point the energy is abruptly released, and a new 
cycle begins. 
The description above fits the dynamic behavior of neuronal 
membranes. A richly structured empirical model of this behavior is 
found in the well-established differential formulation of Hodgkin and 
Huxley 6 and in a simplified version given by Fitzhugh 7. These 
differential equations account for the foundations of neuronal activity 
and are also capable of representing subthreshold behavior and the 
refractoriness that follows each firing. When the membrane 
potential enters the critical region, an abrupt depolarization, i.e., a 
collapse of the potential difference across the membrane occurs 
followed by a somewhat slower recovery. This brief electrical 
826 
shorting of the membrane is called the action potential or ""spike"" 
and constitutes the output event for the neuron. If the causes for the 
initial depolarization are maintained, oscillation (""limit-cycles"") 
develops, generating multiple firings. Depending on input level and 
membrane parameters, the oscillation can be limited to a single 
spike, or may produce an oscillatory burst, or even continually 
sustained activity. 
The present model shares the same general properties but uses 
the much simpler description of relaxation oscillator illustrated on 
Figure 1. 
Activation 
EnergyE{t} 
dtatoly 
Internal 
Eey ln 
Out 
Input perturbation 
u o (t - tO 
Output I 
Figure 1 Relaxation Oscillator with perturbation input 
Firing occurs when the energy level E(t) reaches some critical 
level Ec. Assuming a constant rate of energy influx a, firing will 
occur with the natural period 
Ec. 
T- 
When pre-synaptic pulses impinge on the course of energy 
accumulation, the firing schedule is disturbed. Letting to represent 
the instant of the last firing of the cell and tj, (j = 1,2,...J), the 
intants of impinging arrivals from other cells: 
E(t-to)=a(t-to) + wj..uo(t-ti) ; E<Ec 
where uo(t) represents the unit impulse at t=0. 
The dramatic complexity of synchronization dynamics can be 
appreciated by considering the simplest possible case, that of a 
master slave interaction between two regularly firing oscillator units 
A and B, with natural periods TA and TB. At the instants of firing, 
unit A unidirectionally sends a spike signal to unit B which is 
received at some interval (I) measured from the last time B fired. 
827 
Upon reception the spike is transformed into a quantum of energy 
AE which depends upon the post-firing arrival time (I). The 
relationship AE((I)) can be shaped to represent refractoriness and 
other post-spike properties. Here it is assumed to be a simple ramp 
function. If the interaction is inhibitory, the consequence of this 
arrival is that the next firing of unit B is delayed (with respect to 
what its schedule would have been in absence of perturbation) by 
some positive interval 8 (Figure 2). Because of the shape of AE((I)) , 
the delaying action, nil immediately after firing, becomes longer for 
impinging pre-synaptic spikes that arrive later in the interval. If the 
interaction is excitatory, the delay is negative, i.e. a shortening of the 
natural firing interval. Under very general assumptions regarding the 
function AE((I)), B will tend to synchronize to A. Within a given 
range of coupling gains, the phase (I) will self-adjust until 
equilibrium is achieved. With a given AE((I)) , this equilibrium 
corresponds to a distribution of maximum entropy, i.e., to the point 
where both cells receive the same amouint of activation, during their 
common cycle. 
I 
AE 
) ) Inhibition 
 () Excit:at:ion 
Figure 2 Relationship between phase and delay when input efficiently 
increases linearly in the after-spike interval 
The synchronization dynamics presents an attractor for each 
rational frequency pair. To each ratio is associated a range of stability 
but only the ratios of lowest cardinality have wide zones of phase- 
locking (Figure 3). The wider stability zones correspond to a one to 
one ratio between fA and fB (or between their inverses TA and TB). 
Kohn and Segundo have demonstrated that such phase locking 
occurs in living invertebrate neurons and pointed out the paradoxical 
nature of phase-locked inhibition which, within each stability region, 
828 
takes the appearence of excitation since small increases in input 
firing rate will locally result in increased output rates 8, 5. 
The areas between these ranges of stability have the appearance 
of unstable transitions but in fact, as recently pointed out by Bak 9, 
form an infinity of locking steps known as the Devil's Staircase, 
corresponding to the infinity of intermediate rational palrs (figure 3). 
Bak showed that the staircase is self-similar under scaling and that 
the transitions form a fractal Cantor set with a fractal dimension 
which is a universal constant of dynamic systems. 
!/2 
112 
! 
/' Excitation 
rA rA 
/ 
Inhibitions, 
!/. !/'' / 
Figure 3 Unilateral Synchronization: 
CONSTRAINT SATISFACTION IN OSCILLATOR NETWORKS 
The global synchronization of an interconnected network of 
mutually phase-locking oscillators is a constraint satisfaction 
problem. For each synchronization equilibrium, the nodes fire in 
interlocked patterns that organize inter-spike intervals into integer 
ratios. 
The often cited ""Traveling Salesman Problem"", the archetype 
for a class of important ""hard"" problems, is a special case when the 
ratio must be 1/1; all nodes must fire at the same frequency. Here 
the equilibrium condition is that every node will accumulate the the 
same amount of energy during the global cycle. Furthermore, the 
firings must be ordered along a minimal path. 
Using stochastic energy minimization and simulated annealing, the 
first simulations have demonstrated the feasibility of the approach 
with a limited number of nodes. The TSP is isomorphic to many 
other sequencing problems which involve distributed constraints.and 
fall into the oscfilator array neural net paradigm in a particularly 
natural way. Work is being pursued to more rigorously establish the 
limits of applicability of the model.. 
829 
.1 IiiI I I Iii I I 
I 
' ',,,,,I I ,, ,, 
i I 
i , III Ill I , I I 
Anneah7g 
a- I I I I 
I I I I I 
I I I I 
I I I I 
I I i i 
Figure 4. The Traveling Salesman Probterm In the global 
oscillation of minimal energy each node is constrained to fire at 
the same rate in the order corresponding to the minimal path. 
ACKNOWLEDGENT 
Research supported in part by Aeroiet Electro-Systems under the Aero}et-UCLA Cooperative 
Research Master Agreement No. D841211, and by NASA NAG 2-302. 
REFERENCES 
o 
o 
6. 
7. 
8. 
K. Fukushima, Biol. Cybern. 20, 121 (1975). 
J.J. Hopfield, Proc. Nat. Acad. Sci. 79, 2556 (1982). 
D.E. Rumelhart, G.E. Hinton, and R.J. Williams, Parallel 
Distributed Processing: Explorations in the 
Microstructure of Cognition, (MIT Press, Cambridge, 
MA., 1986) p. 318. 
J.P. Segundo, G.P. Moore, N.J. Stensaas, and T.H. Bullock, J. Exp. 
Biol. 40, 643, (1963). 
J.P. Segundo and A.F. Kohn, Biol Cyber 40, 113 (1981). 
A.L. Hodgkin and A.F. Huxley, J. Physiol. 117, 500 (1952). 
Fitzhugh, Biophysics J., 1, 445 (1961). 
A.F. Kohn, A. Freitas da Rocha, and J.P. Segundo, Biol. Cybem. 
41, 5 (1981). 
P. Bak, Phys. Today (Dec 1986) p. 38 . 
J. Haggerty and J.J. Vidal, UCLA BCI Report, 1975. 
", neural net vidal california lo lo paper present artifici neural network concept oscil instant individu form point process constitut form transmit join type contrast assum typic continu discret limit messag receiv process unit marker signal fire unit present signific neuron fire spontan regularli interact schedul advanc delay fire neighbor neuron becom global oscil exhibit synchron arbitrari initi minim learn procedur make network oscillatori mode satisfi network directli repres rout problem consist order sequenc neural network model deriv variant perceptron case particular network propos fukushima rumelhart mani everi input process element either binari continu amplitud weight synapt gain subsequ result activ pass sigmoid threshold filter produc continu quantiz output may becom input behavior model relat live neuron fall consider short account observ mani real neuron action fire propag axon branch intern activ reach threshold higher haggerti interact system lo angel american institut physic rate level result rapid behind assumpt averag action potenti carrier inform fire individu neuron effect extent contribut averag intens therefor assum activ exact time individu fire view howev cover well known neural precis time arriv make crucial differ outcom one classic exampl widespread mechan brain sever also demonstr occurr function precis time phase relationship neuron local network model present paper contrast one network fire consid output input side fire node presynapt either delay node seen type interact would call also find rational experiment neurophysiolog plausibl howev concern propos explor potenti mechan parallel distribut merit approach artifici neural network digit puls internod commun instead analog particularli well suit found larg class rout trajectori control synchroniz process element oscil relax dynam system capabl accumul energi threshold breakdown point point energi abruptli new descript fit dynam behavior neuron richli structur empir model behavior differenti formul hodgkin simplifi version given fitzhugh equat account foundat neuron activ also capabl repres subthreshold behavior follow membran enter critic abrupt potenti differ across membran occur somewhat slower brief electr membran call action potenti constitut output event caus depolar oscil gener multipl depend input level oscil limit singl may produc oscillatori even continu present model share gener properti use much simpler descript relax oscil illustr perturb relax oscil perturb input occur energi level reach critic assum constant rate energi influx fire natur period puls imping cours energi fire schedul let repres instant last fire cell imping arriv repres unit impuls dramat complex synchron dynam consid simplest possibl slave interact two regularli fire oscil unit natur period ta instant unidirect send spike signal unit interv measur last time recept spike transform quantum energi depend upon arriv time shape repres refractori assum simpl ramp interact consequ next fire unit delay respect schedul would absenc posit interv shape delay nil immedi becom longer spike arriv later delay shorten fire gener assumpt regard tend synchron within given coupl phase given equilibrium distribut maximum point cell receiv amouint inhibit relationship phase delay input effici linearli interv synchron dynam present attractor frequenc ratio associ rang stabil ratio lowest cardin wide zone wider stabil zone correspond one ratio invers ta segundo demonstr phase lock live invertebr neuron point paradox inhibit within stabil appear excit sinc small increas input rate local result increas output rate area rang stabil appear unstabl transit recent point bak infin lock step known infin intermedi ration palr show staircas scale transit form fractal cantor set fractal dimens univers constant dynam excit unilater satisfact oscil network global synchron interconnect network oscil constraint satisfact synchron node fire pattern organ interv integ often cite salesman archetyp class import special case must node must fire equilibrium condit everi node accumul amount energi global must order along minim stochast energi minim simul simul demonstr feasibl approach limit number tsp isomorph mani sequenc problem involv distribut oscfil array neural net paradigm particularli work pursu rigor establish applic ill travel salesman probterm global minim energi node constrain fire rate order correspond minim support part aeroiet cooper master agreement nasa nag parallel explor segundo biol cyber hodgkin biophys freita da today haggerti ucla bci,0
87,87,"83O 
Invariant Object Recognition Using a Distributed Associative Memory 
Harry Wechsler and George Lee Zimmerman 
Department of Electrical Engineering 
University of Minnesota 
Minneapolis, MN 55455 
Abstract 
This paper describes an approach to 2-dimensional object recognition. Complex-log con- 
formal mapping is combined with a distributed associative memory to create a system 
which recognizes objects regardless of changes in rotation or scale. Recalled information 
from the memorized database is used to classify an object, reconstruct the memorized ver- 
sion of the object, and estimate the magnitude of changes in scale or rotation. The system 
response is resistant to moderate amounts of noise and occlusion. Several experiments, us- 
ing real, gray scale images, are presented to show the feasibility of our approach. 
Introduction 
The challenge of the visual recognition problem stems from the fact that the projec- 
tion of an object onto an image can be confounded by several dimensions of variability 
such as uncertain perspective, changing orientation and scale, sensor noise, occlusion, and 
non-uniform illumination. A vision system must not only be able to sense the identity of an 
object despite this variability, but must also be able to characterize such variability -- be- 
cause the variability inherently carries much of the valuable information about the world. 
Our goal is to derive the functional characteristics of image representations suitable for in- 
variant recognition using a distributed associative memory. The main question is that of 
finding appropriate transformations such that interactions between the internal structure 
of the resulting representations and the distributed associative memory yield invariant 
recognition. As Simon [1] points out, all mathematical derivation can be viewed simply as 
a change of representation, making evident what was previously true but obscure. This 
view can be extended to all problem solving. Solving a problem then means transforming it 
so as to make the solution transparent. 
We approach the problem of object recognition with three requirements: 
classification, reconstruction, and characterization. Classification implies the ability to dis- 
tinguish objects that were previously encountered. Reconstruction is the process by which 
memorized images can be drawn from memory given a distorted version exists at the in- 
put. Characterization involves extracting information about how the object has changed 
from the way in which it was memorized. Our goal in this paper is to discuss a system 
which is able to recognize memorized 2-dimensional objects regardless of geometric dis- 
tortions like changes in scale and orientation, and can characterize those transformations. 
The system also allows for noise and occlusion and is tolerant of memory faults. 
The following sections, Invariant Representation and Distributed Associative 
Memory, respectively, describe the various components of the system in detail. The Experi- 
ments section presents the results from several experiments we have performed on real 
data. The paper concludes with a discussion of our results and their implications for future 
research. 
@ American Institute of Physics 1988 
831 
1. Invariant Representation 
The goal of this section is to examine the various components used to produce the 
vectors which are associated in the distributed associative memory. The block diagram 
which describes the various functional units involved in obtaining an invariant image 
representation is shown in Figure 1. The image is complex-log conformally mapped so that 
rotation and scale changes become translation in the transform domain. Along with the 
conformal mapping, the image is also filtered by a space variant filter to reduce the effects 
of aliasing. The conformally mapped image is then processed through a Laplacian in order 
to solve some problems associated with the conformal mapping. The Fourier transform of 
both the conformally mapped image and the Laplacian processed image produce the four 
output vectors. The magnitude output vector 1'11 is invariant to linear transformations of 
the object in the input image. The phase output vector qb 2 contains information concern- 
ing the spatial properties of the object in the input image. 
1.1 Complex-Log Mapping and Space Variant Filtering 
The first box of the block diagram given in Figure 1 consists of two components: 
Complex-log mapping and space variant filtering. Complex-log mapping transforms an 
image from rectangular coordinates to polar exponential coordinates. This transformation 
changes rotation and scale into translation. If the image is mapped onto a complex plane 
then each pixel (x,y) on the Cartesian plane can be described mathematically by z = x + 
jy. The complex-log mapped points w are described by 
w = In(z) = ln(Izl) + jO (1) 
z 
where Iz I =(x 2 +y2) and 0 z =tan-l(y/x). 
Our system sampled 256x256 pixel images to construct 64x64 complex-log mapped 
images. Samples were taken along radial lines spaced 5.6 degrees apart. Along each radial 
line the step size between samples increased by powers of 1.08. These numbers are derived 
from the number of pixels in the original image and the number of samples in the 
complex-log mapped image. An excellent examination of the different conditions involved 
in selecting the appropriate number of samples for a complex-log mapped image is given in 
[2]. The non-linear sampling can be split into two distinct parts along each radial line. To- 
ward the center of the image the samples are dense enough that no anti-aliasing filter is 
needed. Samples taken at the edge of the image are large and an anti-aliasing filter is 
necessary. The image filtered in this manner has a circular region around the center which 
corresponds to an area of highest resolution. The size of this region is a function of the 
number of angular samples and radial samples. The filtering is done, at the same time as 
the sampling, by convolving truncated Bessel functions with the image in the space 
domain. The width of the Bessel functions main lobe is inversely proportional to the eccen- 
tricity of the sample point. 
A problem associated with the complex-log mapping is sensitivity to center 
misalignment of the sampled image. Small shifts from the center causes dramatic distor- 
tions in the complex-log mapped image. Our system assumes that the object is centered in 
the image frame. Slight misalignments are considered noise. Large misalignments are con- 
sidered as translations and could be accounted for by changing the gaze in such a way as 
to bring the object into the center of the frame. The decision about what to bring into the 
center of the frame is an active function and should be determined by the task. An exam- 
ple of a system which could be used to guide the translation process was developed by 
Anderson and Burt [3]. Their pyramid system analyzes the input image at different tern- 
832 
833 
poral and spatial resolution levels. Their smart sensor was then able to shift its fixation 
such that interesting parts of the image (ie. something large and moving) was brought into 
the central part of the frame for recognition. 
1.2 Fourier Transform 
The second box in the block diagram of Figure 1 is the Fourier transform. The 
Fourier transform of a 2-dimensional image f(x,y) is given by 
oo oo 
F(u,v) = f f f(x,y)e -j(ux+vy) dx dy (2) 
and can be described by two 2-dimensional functions corresponding to the magnitude 
IF(u,v)l and phase F(U,V). The magnitude component of the Fourier transform which is 
invariant to translaUon, carries much of the contrast information of the image. The phase 
component of the Fourier transform carries information about how things ar placed in an 
image. Translation of f(x,y) corresponds to the addition of a linear phase cpmponent. The 
complex-log mapping transforms rotation and scale into translation and tile magnitude of 
the Fourier transform is invariant to those translations so that I. I1 vill not change 
significantly with rotation and scale of the object in the image. 
1.3 Laplacian 
The Laplacian that we use is a difference-of-Gaussians (DOG) approximation to the 
V2G function as given by Marr [4]. 
The result of convolving the Laplacian with an image can be viewed as a two step process. 
The image is blurred by a Gaussian kernel of a specified width a. Then the isotropic 
second derivative of the blurred image is computed. The width of the Gaussian kernel is 
chosen such that the conformally mapped image is visible -- approximately 2 pixels in our 
experiments. The Laplacian sharpens the edges of the object in the image and sets any re- 
gion that did not change much to zero. Below we describe the benefits from using the La- 
placian. 
The Laplacian eliminates the stretching problem encountered by the complex-log 
mapping due to changes in object size. When an object is expanded the complex-log 
mapped image will translate. The pixels vacated by this translation will be filled with 
more pixels sampled from the center of the scaled object. These new pixels will not be 
significantly different than the displaced pixels so the result looks like a stretching in the 
complex-log mapped image. The Laplacian of the complex-log mapped image will set the 
new pixels to zero because they do not significantly change from their surrounding pixels. 
The Laplacian eliminates high frequency spreading due to the finite structure of the 
discrete Fourier transform and enhances the differences between memorized objects by ac- 
centuating edges and de-emphasizing areas of little change. 
2. Distributed Associative Memory (DAM) 
The particular form of distributed associative memory that we deal with in this pa- 
per is a memory matrix which modifies the flow of information. Stimulus vectors are asso- 
ciated with response vectors and the result of this association is spread over the entire 
memory space. Distributing in this manner means that information about a small portion 
of the association can be found in a large area of the memory. New associations are placed 
834 
over the older ones and are allowed to interact. This means that the size of the memory 
matrix stays the same regardless of the number of associations that have been memorized. 
Because the associations are allowed to interact with each other an implicit representation 
of structural relationships and contextual information can develop, and as a consequence a 
very rich level of interactions can be captured. There are few restrictions on what vectors 
can be associated there can exist extensive indexing and cross-referencing in the memory. 
Distributed associative memory captures a distributed representation which is context 
dependent. This is quite different from the simplistic behavioral model [5]. 
The construction stage assumes that there are n pairs of m-dimensional vectors that 
are to be associated by the distributed associative memory. This can be written as 
Ms-?. 
= r. for i -- 1,...,n (4) 
I I 
--* .th � --* .th � 
where s. denotes the  stimulus vector and r. denotes the  corresponding response vec- 
 � th � 
tot. We want to construct a memory matrix I such that when the k stimulus vector 
is projected onto the space defined by M the resulting projection will be the correspondin 
response vector r 5. More specifically we want to solve the following equation: 
MS =R (5) 
whereS--[111 1 ...I ]and R-f' ' ' 
- t '1  '2  '"" nn ]' A unique solution for this equa- 
tion does not necessarily exist for any arbitrary group of associations that might be 
chosen. Usually, the number of associations n is smaller than m, the length of the vector to 
be associated, so the system of equations is underconstrained. The constraint used to solve 
for a unique matrix M is that of minimizing the square error, IIMS - PI 2, which results in 
the solution 
M = RS + 
where S + is known as the Moore-Penrose generalized inverse of S [6]. 
The recall operation projects an unknown stimulus vector � onto the memory space 
M. The resulting projection yields the response vector ? 
(7) 
If the memorized stimulus vectors are independent and the unknown stimulus vector  is 
one of the memorized vectors , then the recalled vector will be the associated response 
vector . If the memorized stimulus vectors are dependent, then the vector recalled by 
one of te memorized stimulus vectors will contain the associated response vector and 
some crosstalk from the other stored response vectors. 
The recall can be viewed as the weighted sum of the response vectors. The recall 
begins by assigning weights according to how well the unknown stimulus vector matches 
with the memorized stimulus vector using a linear least squares classifier. The response 
vectors are multiplied by the weights and summed together to build the recalled response 
vector. The recalled response vector is usually dominated by the memorized response vec- 
tor that is closest to the unknown stimulus vector. 
Assume that there are n associations in the memory and each of the associated 
stimulus and response vectors have m elements. This means that the memory matrix has 
2 
m elements. Also assume that the noise that. is added to each element of a memorized 
835 
stimulus vector is independent, zero mean, with a variance of a. 2. The recall from the 
memory is then x 
r = r k + ---- M + = rlt + M (8) 
where v is the input noise vector and U  is the output noise vector. The ratio of the aver- 
I O. 
age output noise variance to the average input noise variance is 
2 2 
ao/a i ---- ITr[T] (9) 
For the autoassociative case this simplifies to 
(0) 
Vo/Vi = -- 1 
m 
This says that when a noisy version of a memorized input vector is applied to the memory 
the recall is improved by a factor corresponding to the ratio of the number of memorized 
vectors to the number of elements in the vectors. For the heteroassoeiative memory ma- 
trix a similar formula holds as long as n is le than m [7]. 
2 2 
= 
m 
Fault tolerance is a byproduet of the distributed nature and error correcting capa- 
bilities of the distributed associative memory. By distributing the information, no single 
memory cell earties a significant portion of the information critical to the overall perfor- 
mance of the memory. 
3. Experiments 
In this section we discuss the result of computer simulations of our system. Images 
of objects are first preprocessed through the subsystem outlined in section 2. The output of 
such a subsystem is four vectors: 1'1 , (I) 1, 1'12, and 2' We construct the memory by associ- 
ating the stimulus vector 1.11 with le response vector (I) 2 .for each object in the database. 
To perform a recall from the memory the. unknown image is preprocessed by the same~sub- 
system to produce the vectors I. I1, (I>l, I*IA, and (I> 2. The resulting stimulus vector 1'1 is 
projected onto the mqmory matrix to produce a respolase vector which is an _estimate 1 of 
the memorized phase (I) 2. The estimated phase vector dp and the magnitude I. I1 ae used 
to reconstruct the memorized object. The difference betveen the estimated phase (I) 2 and 
the unknown phase (I) 2 is used to estimate the amount of rotation and scale experienced by 
the object. 
The database of images consists of twelve objects: four keys, four mechanical parts, 
and four leaves. The objects were chosen for their essentially two-dimensional structure. 
Each object was photographed using a digitizing video camera against a black back- 
ground. We emphasize that all of the images used in creating and testing the recognition 
system were taken at different times using various camera rotations and distances. The im- 
ages are digitized to 256x256, eight bit quantized pixels, and each object covers an area of 
about 40x40 pixels. This small object size relative to the background is necessary due to 
the non-linear sampling of the complex-log mapping. The objects were centered within the 
frame by hand. This is the source of much of the noise and could have been done automat- 
ically using the object's center of mass or some other criteria determined by the task. The 
orientation of each memorized object was arbitrarily chosen such that their major axis 
836 
was vertical. The 2-dimensional images that are the output from the invariant represen- 
tation subsystem are scanned horizontally to form the vectors for memorization. The da- 
tabase used for these experiments is shown in Figure 2. 
s 
Figure 2. The Database of Objects Used in the Experiments 
a) Original 
b) Unknown 
c) Recall: rotated 135 � 
Figure 3. Recall Using a Rotated and scaled key 
d) Memory:6 
SNR: -3.37 Db 
The first example of the operation of our system is shown in Figure 3. Figure 3a) is 
the image of one of the keys as it was memorized. Figure 3b) is the unknown object 
presented to our system. The unknown object in this case is the same key that has been 
rotated by 180 degrees and scaled. Figure 3c) is the recalled, reconstructed image. The 
837 
rounded edges of the recalled image are artifacts of the complex-log mapping. Notice that 
the reconstructed recall is the unrotated memorized key with some noise caused by errors 
in the recalled phase. Figure 3d) is a histogram which graphically displays the 
classification vector which corresponds to Ss. The histogram shows the interplay between 
the memorized images and the unknown image. The ""6"" on the bargraph indicates which 
of the twelve classes the unknown object belongs. The histogram gives a value which is 
the best linear estimate of the image relative to the memorized objects. Another measure, 
the signal-to-noise ratio (SNR), is given at the bottom of the recalled image. SNR com- 
pares the variance of the ideal recall after processing with the variance of the difference 
between the ideal and actual recall. This is a measure of the amount of noise in the recall. 
The SNR does not carry much information about the quality of the recall image because 
the noise measured by the S1NIP is clue to many factors such as misalignment of the center, 
changing reflections, and dependence between other memorized objects -- each affecting, 
quality in a variety of ways. Rotation and scale estimates are made using a vector~D 
corresponding to the dilterence between the unknown vector dp_ and the recalled vector (I> 2. 
2 
In an ideal situation D will be a plane whose gradient indicates the exact amount of rota- 
tion and scale the recalled object has experienced. In our system the recalled vector (I>_ is 
corrupted with noise which means rotationsand scale have to be estim:[ed. The estimat is 
made by letting the first order difference D at each point in the plane vote for a specified 
range of rotation or scale. 
>4 ;:..'  <z..',:..,:,:: , .2%, .;,.'. . 5 ' '''-'.:': .':   ' 
 :.... 
;: -: ./ .; .. 
a) Original b) Unknown c) Recall d) Memory:4 
Figure 4 Recall Using Scaled and Rotated ""S"" with Occlusion 
Figure 4 is an example of occlusion. The unknown object in this case is an ""S"" 
curve which is larger and slightly tilted from the memorized ""S"" curve. A portion of the 
bottom curve was occluded. The resulting reconstruction is very noisy but has filled in the 
missing part of the bottom curve. The noisy recall is reflected in both the SNR and the in- 
terplay between the memories shown by the histogram. 
� :.. -:.:.. 
"" ..: :.... 
: ' :: ..:: -. : . 2.. 
a) Ideal recall 
b) 30% removed 
c) 50% removed 
d) 75% removed 
Figure 5. Recall for Memory Matrix Randomly Set to Zero 
Figure 5 is the result of randomly setting the elements of the memory matrix to 
838 
zero. Figure 5a) shows is the ideal recall. Figure 5b) is the recall after 30 percent of the 
memory matrix has been set to zero. Figure 5c) is the recall for 50 percent and Figure 5d) 
is the recall for 75 percent. Even when 90 percent of the memory matrix has been set to 
zero a faint outline of the pin could still be seen in the recall. This result is important in 
two ways. First, it shows that the distributed associative memory is robust in the presence 
of noise. Second, it shows that a completely connected network is not necessary and as a 
consequence a scheme for data compression of the memory matrix could be found. 
4. Concluzion 
In this paper we demonstrate a computer vision system which recognizes 2- 
dimensional objects invariant to rotation or scale. The system combines an invariant 
representation of the input images with a distributed associative memory such that objects 
can be classified, reconstructed, and characterized. The distributed associative memory is 
resistant to moderate amounts of noise and occlusion. Several experiments, demonstrating 
the ability of our computer vision system to operate on real, grey scale images, were 
presented. 
Neural network models, of which the distributed associative memory is one example, 
were originally developed to simulate biological memory. They are characterized by a 
large number of highly interconnected simple processors which operate in prallel. An ex- 
cellent review of the many neural network models is given in [8]. The distributed associa- 
tive memory we use is linear, and as a result there are certain desirable properties which 
will not be exhibited by our computer vision system. For example, feedback through our 
system will not improve recall from the memory. Recall could be improved if a non-linear 
element, such as a sigmoid func""ion, is introduced into the feedback loop. Non-linear neur- 
al networks, such as those proposed by Hopfield [9] or Anderson et. al. [10], can achieve 
this type of improvement because each memorized pattern is associated with stable points 
in an energy space. The price to be paid for the introduction of non-linearities into a 
memory system is that the system will be difficult to analyze and can be unstable. Imple- 
menting our computer vision system using non-linear distributed associative memory is a 
goal of our future research. 
We are presently extending our work toward 3-dimensional object recognition. Much 
of the present research in 3-dimensional object recognition is limited to polyhedral, non- 
occluded objects-in a clean, highly controlled environment. Most systems are edge based 
and use a generate-and-test paradigm to estimate the position and orientation of recog- 
nized objects. We propose to use an approach based on characteristic views [11] or aspects 
[12] which suggests that the infinite 2-dimensional projections of a 3-dimensional object 
can be grouped into a finite number of topological equivalence classes. An efficient 3- 
dimensional recognition system would require a parallel indexing method to search for ob- 
ject models in the presence of geometric distortions, noise, and occlusion. Our object recog- 
nition system using distributed associative memory can fulfill those requirements with 
respect to characteristic views. 
References
[1] Simon, H. A., (1984), The Science of the Artificial (2nd ed.), MIT Press. 
[2] Massone, L., G. Sandini, and V. Tagliasco (1985), ""Form-invariant"" topological map- 
ping strategy for 2D shape recognition, CVGIP, 30, 169-188. 
[3] Anderson, C. H., P. J. Butt, and G. S. Van Der Wal (1985), Change detection and 
tracking using pyramid transform techniques, Proc. of the SPIE Conference on 
Intelligence, Robots, and Computer Vision, Vol. 579, 72-78. 
839 
[4] Marr, D. (1982), Vision, W. H. Freeman, 1982. 
[5] Hebb, O. D. (1949), The Organization of Behavior, New York: Wiley. 
[6] Kohonen, T. (1984), Self-Organization and Associative-Memories, Springer-Verlag. 
[7] Stiles, G. S. and D. L. Denq (1985), On the effect of noise on the Moore-Penrose gen- 
eralized inverse associative memory, IEEE Trans. on PAMI, 7, 3, 358-360. 
[8] MCClelland, J. L., and D. E. Rumelhart, and the PDP Research Group (Eds.) (1986), 
Parallel Distributed, Processing, Vol. 1, 2, MIT Press. 
[9] Hopfield, J. J. (1982), Neural networks and physical systems with emergent collective 
computational abilities, Proc. Natl. Acad. Scl. USA, 79, April 1982. 
[10] Anderson, J. A., J. W. Silverstein, S. A. Ritz, and R. S. Jones (1977), Distinctive 
features, categorical perception, and probability learning: some applications of a 
neural model, Psychol. Rev., 84,413-451. 
[11] Chakravarty, I., and H. Freeman (1982), Characteristic views as a basis for 3-D object 
recognition, Proc. SPIE on Robot Vision, 336, 37-45. 
[12] Koenderink, J. J., and A. J. Van Doom (1979), Internal representation of solid shape 
with respect to vision, Biol. Cybern., 32,4,211-216. 
", object recognit use distribut associ memori wechsler georg lee zimmerman electr engin minnesota mn paper describ approach object map combin distribut associ memori creat system recogn object regardless chang rotat recal inform memor databas use classifi reconstruct memor estim magnitud chang scale system resist moder amount nois sever gray scale present show feasibl challeng visual recognit problem stem fact object onto imag confound sever dimens variabl uncertain chang orient sensor vision system must abl sens ident despit must also abl character variabl variabl inher carri much valuabl inform goal deriv function characterist imag represent suitabl recognit use distribut associ main question appropri transform interact intern structur result represent distribut associ memori yield invari simon point mathemat deriv view simpli chang make evid previous true extend problem solv problem mean transform make solut approach problem object recognit three classif impli abil object previous reconstruct process imag drawn memori given distort version exist character involv extract inform object chang way goal paper discuss system abl recogn memor object regardless geometr like chang scale character system also allow nois occlus toler memori follow invari represent distribut associ describ variou compon system section present result sever experi perform real paper conclud discuss result implic futur american institut physic invari represent goal section examin variou compon use produc associ distribut associ block diagram describ variou function unit involv obtain invari imag shown figur imag conform map scale chang becom translat transform along imag also filter space variant filter reduc effect conform map imag process laplacian order solv problem associ conform fourier transform conform map imag laplacian process imag produc four magnitud output vector invari linear transform object input phase output vector qb contain inform spatial properti object input map space variant filter first box block diagram given figur consist two map space variant map transform rectangular coordin polar exponenti transform rotat scale imag map onto complex plane pixel cartesian plane describ mathemat map point describ iz system sampl pixel imag construct map sampl taken along radial line space degre along radial step size sampl increas power number deriv number pixel origin imag number sampl map excel examin differ condit involv select appropri number sampl map imag given sampl split two distinct part along radial center imag sampl dens enough filter sampl taken edg imag larg filter imag filter manner circular region around center area highest size region function angular sampl radial filter time convolv truncat bessel function imag space width bessel function main lobe invers proport sampl problem associ map sensit center sampl small shift center caus dramat map system assum object center imag slight misalign consid larg misalign translat could account chang gaze way bring object center decis bring frame activ function determin system could use guid translat process develop burt pyramid system analyz input imag differ spatial resolut smart sensor abl shift fixat interest part imag someth larg brought central part frame fourier transform second box block diagram figur fourier transform imag given oo dx dy describ two function correspond magnitud phase magnitud compon fourier transform carri much contrast inform phase fourier transform carri inform thing place translat correspond addit linear phase map transform rotat scale translat tile magnitud fourier transform invari translat chang rotat scale object laplacian laplacian use approxim function given marr result convolv laplacian imag view two step imag blur gaussian kernel specifi width isotrop deriv blur imag width gaussian kernel conform map imag visibl approxim pixel laplacian sharpen edg object imag set chang much describ benefit use laplacian elimin stretch problem encount due chang object object expand imag pixel vacat translat fill pixel sampl center scale new pixel differ displac pixel result look like stretch map laplacian map imag set pixel zero significantli chang surround laplacian elimin high frequenc spread due finit structur fourier transform enhanc differ memor object edg area littl distribut associ memori particular form distribut associ memori deal memori matrix modifi flow stimulu vector respons vector result associ spread entir distribut manner mean inform small portion associ found larg area new associ place older one allow mean size memori stay regardless number associ associ allow interact implicit represent structur relationship contextu inform consequ rich level interact restrict vector associ exist extens index associ memori captur distribut represent context quit differ simplist behavior model construct stage assum pair vector associ distribut associ written denot stimulu vector denot correspond respons th want construct memori matrix stimulu vector project onto space defin result project vector specif want solv follow uniqu solut necessarili exist arbitrari group associ might number associ smaller length vector system equat constraint use solv uniqu matrix minim squar iim result solut rs known gener invers recal oper project unknown stimulu vector onto memori space result project yield respons vector memor stimulu vector independ unknown stimulu vector memor vector recal vector associ respons memor stimulu vector vector recal memor stimulu vector contain associ respons vector crosstalk store respons recal view weight sum respons recal assign weight accord well unknown stimulu vector match memor stimulu vector use linear least squar respons multipli weight sum togeth build recal respons recal respons vector usual domin memor respons closest unknown stimulu associ memori associ respons vector mean memori matrix also assum nois ad element memor vector zero varianc recal rlt input nois vector output nois ratio output nois varianc averag input nois varianc autoassoci case simplifi say noisi version memor input vector appli memori recal improv factor correspond ratio number memor number element heteroassoei memori similar formula hold long toler byproduet distribut natur error correct distribut associ distribut singl cell earti signific portion inform critic overal experi section discuss result comput simul imag object first preprocess subsystem outlin section output subsystem four construct memori stimulu vector respons vector object perform recal memori unknown imag preprocess produc vector result stimulu vector onto mqmori matrix produc respolas vector memor phase estim phase vector magnitud use reconstruct memor differ estim phase unknown phase use estim amount rotat scale experienc databas imag consist twelv four four mechan four object chosen essenti object photograph use digit video camera black emphas imag use creat test recognit taken differ time use variou camera rotat digit eight bit quantiz object cover area small object size rel background necessari due sampl object center within sourc much nois could done use center mass criteria determin memor object arbitrarili chosen major axi imag output invari subsystem scan horizont form vector use experi shown figur databas object use experi origin unknown rotat recal use rotat scale key db first exampl oper system shown figur figur imag one key figur unknown object unknown object case key degre figur reconstruct edg recal imag artifact notic reconstruct recal unrot memor key nois caus error recal figur histogram graphic display vector correspond histogram show interplay memor imag unknown bargraph indic twelv class unknown object histogram give valu best linear estim imag rel memor anoth ratio given bottom recal snr varianc ideal recal process varianc differ ideal actual measur amount nois snr carri much inform qualiti recal imag nois measur clue mani factor misalign depend memor object varieti rotat scale estim made use dilter unknown vector recal vector ideal situat plane whose gradient indic exact amount scale recal object system recal vector nois mean rotationsand scale let first order differ point plane vote specifi rotat origin unknown recal recal use scale rotat occlus exampl unknown object case larger slightli tilt memor portion curv result reconstruct noisi fill part bottom noisi recal reflect snr memori shown ideal recal remov remov remov recal memori matrix randomli set zero result randomli set element memori matrix figur show ideal figur recal percent matrix set figur recal percent figur recal even percent memori matrix set faint outlin pin could still seen result import show distribut associ memori robust presenc show complet connect network necessari scheme data compress memori matrix could concluzion paper demonstr comput vision system recogn object invari rotat system combin invari input imag distribut associ memori object distribut associ memori moder amount nois sever demonstr abil comput vision system oper grey scale network distribut associ memori one origin develop simul biolog character number highli interconnect simpl processor oper review mani neural network model given distribut memori use result certain desir properti exhibit comput vision feedback improv recal recal could improv sigmoid introduc feedback propos hopfield anderson achiev type improv memor pattern associ stabl point energi price paid introduct system system difficult analyz comput vision system use distribut associ memori futur present extend work toward object much present research object recognit limit highli control system edg base use paradigm estim posit orient propos use approach base characterist view aspect suggest infinit project object group finit number topolog equival effici recognit system would requir parallel index method search model presenc geometr object system use distribut associ memori fulfil requir characterist scienc artifici mit tagliasco topolog strategi shape van der wal chang detect use pyramid transform spie confer comput organ new denq effect nois invers associ ie pdp research group mit neural network physic system emerg collect april jone distinct categor probabl applic freeman characterist view basi object spie robot van doom intern represent solid shape respect,0
88,88,"850 
Strategies for Teaching Layered Networks 
Classification Tasks 
Ben S. Wittner I and John S. Denker 
AT&T Bell Laboratories 
Holmdel, New Jersey 07733 
Abstract 
There is a widespread misconception that the delta-rule is in some sense guaranteed to 
work on networks without hidden units. As previous authors have mentioned, there is 
no such guarantee for classification tasks. We will begin by presenting explicit counter- 
examples illustrating two different interesting ways in which the delta rule can fail. We 
go on to provide conditions which do guarantee that gradient descent will successfully 
train networks without hidden units to perform two-category classification tasks. We 
discuss the generalization of our ideas to networks with hidden units and to multi- 
category classification tasks. 
The Classification Task 
Consider networks of the form indicated in figure 1. We discuss vaxious methods for 
training such a network, that is for adjusting its weight vector, w. If we call the input 
v, the output is g(w. v), where g is some function. 
The classification task we wish to train the network to perform is the following. Given 
two finite sets of vectors, F1 and F2, output a number greater than zero when a vector in 
F1 is input, and output a number less than zero when a vector in F2 is input. Without 
significant loss of generality, we assume that g is odd (i.e. g(-s) - -g(s)). In that case, 
the task can be reformulated as follows. Define 2 
F := F U {-v such that v 6 F2} 
(1) 
and output a number greater than zero when a vector in F is input. The former 
formulation is more natural in some sense, but the later formulation is somewhat more 
convenient for analysis and is the one we use. We call vectors in F, training vectors. 
A Class of Gradient Descent Algorithms 
We denote the solution set by 
W := {w such that g(w. v) > 0 for all v  F}, 
Currently at NYNEX Science and Technology, 500 Westchester Ave., White Plains, NY 10604 
2We use both A := B and B =: A to denote ""A is by definition B"". 
(2) 
American Institute of Physics 1988 
851 
Wl W2 
g(w. v)) 
Figure 1: a simple network 
w 
output 
inputs 
and we are interested in rules for finding some weight vector in W. We restrict our 
attention to rules based upon gradient descent down error functions E(w) of the form 
E(w) = y] h(w. v). (3) 
vEF 
The delta-rule is of this form with 
h(w. v) = hs(w' v):= -(b - g(w. v)) 2 (4) 
for some positive number b called the target (Rumelhart, McClelland, et al.). We call 
the delta rule error function Es. 
Failure of Delta-rule Using Obtainable Targets 
Let g be any function that is odd and differentiable with g'(s) > 0 for all s. In this 
section we assume that the target b is in the range of g. We construct a set F of 
training vectors such that even though W is not empty, there is a local minimum of Es 
not located in W. In order to facilitate visualization, we begin by assuming that g is 
linear. We will then indicate why the construction works for the nonlinear case as well. 
We guess that this is the type of counter-example alluded to by Duda and Hart (p. 151) 
and by Minsky and Papert (p. 15). 
The input vectors are two dimensional. The arrows in figure 2 represent the training 
vectors in F and the shaded region is W. There is one training vector, v , in the second 
quadrant, and all the rest are in the first quadrant. The training vectors in the first 
quadrant are arranged in pairs symmetric about the ray R and ending on the line L. 
The line L is perpendicular to R, and intersects R at unit distance from the origin. 
Figure 2 only shows three of those symmetric pairs, but to make this construction work 
we might need many. The point p lies on R at a distance of g-(b) from the origin. 
We first consider the contribution to Es due to any single training vector, v. The 
contribution is 
(1/2)(b - g(w. v)) , (5) 
and is represented in figure 3 in the z-direction. Since g is linear and since b is in the 
82 
L 
-e no. '='{dYCUla 'bUtion .  {or oh- � 
oa .-  is - tic ,_ 'gets 
Poi � a is t ' the co ,,,e trou_]o ectors , u a lin � 
atp  ,,esu . batrib .... 
� oo it is - ol t% .. ""?oa to t e first o, 'e 'pla- 
Ne, qadratic ratic tro- .error ,. at, then 
_  We _ bowl .,:.. Ughs .,:.. 'Ction 
.uran uaSider  a bott_ta bott 
 qadr..�Y, r ,UScon,_..,rarilv_. tp. Sn? vectors :_ 
a; 'tic bo...; o,e coa,_.- ""'noOtio C*'teep b.- - 
""um _ ..Y ro  .. o  _ .  due _ . .rilv 
Si- be SUci_, s p, b.- qadra,,  
gradien. o s a o.. ,,e p So - e bowl  
' have coafir,,s ev. Q'E.D. etly st t 
� ied the  o Con,. ' . 
C�cepte�es 
853 
y-axis 
Figure 3: Error surface 
We now remove the assumption that g is linear. The key observation is that 
dhs/ds = hs'(s) = (b- #(s))(-#'(s)) 
(6) 
still only has a single zero at g-(b) and so h(s) still has a single minimum at g-(b). 
The contribution to Es due to the training vectors in the first quadrant therefore still 
has a global minimum on the xy-plane at the point p. So, as in the linear case, if there 
are enough symmetric pairs of training vectors in the first quadrant, the value of Eo 
at p can be made arbitrarily lower than the value along some circle in the xy-plane 
centered around p, and Es = Eo + E will have a local minimum arbitrarily near p. 
Q.E.D. 
Failure of Delta-rule Using Unobtainable Targets 
We now consider the case where the target b is greater than any number in the range 
of g. The kind of counter-example presented in the previous section no longer exists, 
but we will show that for some choices of g, including the traditional choices, the delta 
rule can still fail. Specifically, we construct a set F of training vectors such that even 
though W is not empty, for some choices of initial weights, the path traced out by going 
down the gradient of Es never enters W. 
854 
V 1 / 
R ,e 
/ L 
�2 
x-axis 
Figure 4: Counter-example for unobtainable targets 
We suppose that g has the following property. There exists a number r > 0 such that 
)km - 0. (7) 
An example of such a g is 
2 
g(s)- tanh(s) - i + e -2s 1, (8) 
for which any r greater than 1 will do. 
The solid arrows in figure 4 represent the training vectors in F and the more darkly 
shaded region is W. The set F has two elements, 
vl: [-2] and v2: ()() [ ] (9) 
The dotted ray, R lies on the diagonal {y: 
Since 
Es(w) -- hs(w' v x) + hs(w. v2), (10) 
855 
the gradient descent algorithm follows the vector field 
-VE(w) = -h'(w. vl)v 1 - h'(w. v2)v 2. (11) 
The reader can easily verify that for all w on R, 
W' V 1 = --rw' v 2. (12) 
So by equation (7), if we constrain w to move along R, 
lim -h5(w' vl) 
=0. (13) 
w-.o -/zd(w. 
Combining equations (11) and (13) we see that there is a point q somewhere on R such 
that beyond q, -VE(w) points into the region to the right of R, as indicated by the 
dotted arrows in figure 4. 
Let L be the horizontal ray extending to the right from q. Since for all s, 
g'(s) > 0 and b > g(s), (14) 
we get that 
- h6'(s) = (b- g(s))g'(s) > 0. (15) 
So since both v 1 and v 2 have a positive y-component, -VE(w) also has a positive 
y-component for all w. So once the algorithm following -VE enters the region above 
L and to the right of R (indicated by light shading in figure 4), it never leaves. Q.E.D. 
Properties to Guarantee Gradient Descent Learning 
In this section we present three properties of an error function which guarantee that 
gradient descent will not fail to enter a non-empty W. 
We call an error function of the form presented in equation (3) well formed if h is 
differentiable and has the following three properties. 
1. For all s, -h'(s) > 0 (i.e. h does not push in the wrong direction). 
2. There exists some e > 0 such that -h'(s) >  for all s _< 0 (i.e. h keeps pushing 
if there is a misclassification). 
3. h is bounded below. 
Proposition 1 If the error function is well formed, then gradient descent is guaranteed 
to enter W, provided W is not empty. 
856 
The proof proceeds by contradiction. Suppose for some starting weight vector the path 
traced out by gradient descent never enters W. Since W is not empty, there is some 
non-zero w* in W. Since F is finite, 
A := min{w*. v such that v 5 F} >' 0. 
(16) 
Let w(t) be the path traced out by the gradient descent algorithm. So 
w'(t) = -WE(w(t)): y] -a'(w(t). v)v for all t. (17) 
Since we are assuming that at least one training vector is misclassified at all times, by 
properties 1 and 2 and equation (17), 
So 
w*. w'(t) _> , for all t. 
[w'(t)[ > /]w*[ =:  > 0 for all t. 
(18) 
(19) 
By equations (17) and (19), 
dE(w(t))/dt = VE. w'(t)= -w'(t). w'(t) < _2 < 0 for all t. (20) 
This means that 
E(w(t))  -oe as t  oo. (21) 
But property 3 and the fact that F is finite guarantee that E is bounded below. This 
contradicts equation (21) and finishes the proof. 
Consensus and Compromise 
So far we have been concerned with the case in which F is separable (i.e. W is not 
empty). What kind of behavior do we desire in the non-separable case? One might 
hope that the algorithm will choose weights which produce correct results for as many 
of the training vectors as possible. We suggest that this is what gradient descent using 
a well formed error function does. 
From investigations of many well formed error functions, we suspect the following well 
formed error function is representative. Let !/(s) = s, and for some b > 0, let 
(b-s) 2 ifs<b; 
h(s) = 0 otherwise. (22) 
In all four frames of figure 5 there are three training vectors. Training vectors 1 and 2 
are held fixed while 3 is rotated to become increasingly inconsistent with the others. In 
frames (i) and (ii) F is separable. The training set in frame (iii) lies just on the border 
between separability and non-separability, and the one in frame (iv) is in the interior of 
857 
Figure 5: The transition between seperability and non-seperability 
the non-separable regime. Regardless of the position of vector 3, the global minimum 
of the error function is the only minimum. 
In frames (i) and (ii), the error function is zero on the shaded region and the shaded 
region is contained in W. As we move training vector number 3 towards its position in 
frame (iii), the situation remains the same except the shaded region moves arbitrarily 
far from the origin. At frame (iii) there is a discontinuity; the region on which the 
error function is at its global minimum is now the one-dimensional ray indicated by 
the shading. Once training vector 3 has moved into the interior of the non-separable 
regime, the region on which the error function has its global minimum is a point closer 
to training vectors 1 and 2 than to 3 (as indicated by the ""x"" in frame (iv)). 
If all the training vectors can be satisfied, the algorithm does so; otherwise, it tries to 
satisfy as many as possible, and there is a discontinuity between the two regimes. We 
summarize this by saying that it finds a consensus if possible, otherwise it devises a 
compromise. 
Hidden Layers 
For networks with hidden units, it is probably impossible to prove anything like propo- 
sition 1. The reason is that even though property 2 assures that the top layer of weights 
858 
gets a non-vanishing error signal for misclassified inputs, the lower layers might still get 
a vanishingly weak signal if the units above them are operating in the saturated regime. 
We believe it is nevertheless a good idea to use a well formed error function when 
training such networks. Based upon a probabilistic interpretation of the output of the 
network, Baum and Wilczek have suggested using an entropy error function (we thank 
J.J. Hopfield and D.W. Tank for bringing this to our attention). Their error function 
is well formed. Levin, Solla, and Fleisher report simulations in which switching to the 
entropy error function from the delta-rule introduced an order of magnitude speed-up 
of learning for a network with hidden units. 
Multiple Categories 
Often one wants to classify a given input vector into one of many categories. One popular 
way of implementing multiple categories in a feed-forward network is the following. Let 
the network have one output unit for each category. Denote by oy(w) the output of 
the j-th output unit when input v is presented to the network having weights w. The 
network is considered to have classified v as being in the k-th category if 
o(w) > o}'(w) for all j  k. (23) 
The way such a network is usually trained is the generalized delta-rule (Rumelhart, 
McClelland, et al.). Specifically, denote by c(v) the desired classification of v and let 
v / b if j = c(v); (24) 
b :- -b otherwise, 
for some target b > 0. One then uses the error function 
:= - 
This formulation has several bothersome aspects. For one, the error function is not will 
formed. Secondly, the error function is trying to adjust the outputs, but what we really 
care about is the differences between the outputs. A symptom of this is the fact that 
the change made to the weights of the connections to any output unit does not depend 
on any of the weights of the connections to any of the other output units. 
To remedy this and also the other defects of the delta rule we have been discussing, we 
suggest the following. For each v and j, define the relative coordinate 
:= (26) 
859 
What we really want is all the fi to be positive, so use the error function 
(27) 
v 
for some well formed h. In the simulations we have run, this does not always help, but 
sometimes it helps quite a bit. 
We have one further suggestion. Property 2 of a well formed error function (and the 
fact that derivatives are continuous) means that the algorithm will not be completely 
satisfied with positive/; it will try to make them greater than zero by some non-zero 
margin. That is a good thing, because the training vectors are only representatives of 
the vectors one wants the network to correctly classify. Margins are critically important 
for obtaining robust performance on input vectors not in the training set. The problem 
is that the margin is expressed in meaningless units; it makes no sense to use the same 
numerical margin for an output unit which varies a lot as is used for an output unit 
which varies only a little. We suggest, therefore, that for each j and v, keep a running 
estimate of cr(w), the variance of fi(w), and replace/(w) in equation (27) by 
(28) 
Of course, when beginning the gradient descent, it is difficult to have a meaningful 
estimate of cry(w) because w is changing so much, but as the algorithm begins to 
converge, your estimate can become increasingly meaningful. 
References 
1. David Rumelhart, James McClelland, and the PDP Research Group, Parallel Dis- 
tributed Processing, MIT Press, 1986 
2. Richard Duda and Peter Hart, Pattern Classification and Scene Analysis, John 
Wiley & Sons, 1973. 
3. Marvin Minsky and Seymour Papeft, ""On Percepttons"", Draft, 1987. 
4. Eric Baum and Frank Wilczek, these proceedings. 
5. Esther Levin, Sara A. Solla, and Michael Fleisher, private communications. 
", teach layer network task wittner john denker bell laboratori new jersey widespread misconcept sens guarante network without hidden previou author guarante classif begin present explicit illustr two differ interest way delta rule provid condit guarante gradient descent success network without hidden unit perform classif gener idea network hidden unit classif classif task network form indic figur discuss vaxiou method adjust weight call input output classif task wish train network perform given finit set output number greater zero vector output number less zero vector without loss assum odd task reformul defin output number greater zero vector former natur later formul somewhat analysi one call vector train class gradient descent algorithm denot solut set nynex scienc westchest white ny use denot definit institut physic simpl network interest rule find weight vector restrict rule base upon gradient descent error function form ef form posit number call target et call delta rule error function use obtain target function odd differenti assum target rang construct set vector even though local minimum es locat order facilit begin assum indic construct work nonlinear case guess type allud duda hart minski papert input vector two arrow figur repres train shade region one train second rest first train vector first arrang pair symmetr ray end line line perpendicular intersect unit distanc show three symmetr make construct work might need point lie distanc first consid contribut es due singl train repres figur sinc linear sinc ycula ution co batrib oo ol first bowl ugh sider vector ro due bowl error surfac remov assumpt key observ singl zero still singl minimum contribut es due train vector first quadrant therefor still global minimum point linear enough symmetr pair train vector first valu eo made arbitrarili lower valu along circl around es eo local minimum arbitrarili near use unobtain target consid case target greater number rang kind present previou section longer show choic includ tradit delta still construct set train vector even choic initi path trace go gradient es never enter unobtain target suppos follow exist number exampl greater solid arrow figur repres train vector darkli region set two dot lie diagon gradient descent algorithm follow vector field reader easili verifi equat constrain move along equat see point somewher beyond point region right indic arrow figur horizont ray extend right sinc get sinc posit also posit algorithm follow enter region right light shade figur never guarante gradient descent learn section present three properti error function guarante descent fail enter call error function form present equat well form follow three push wrong exist keep push bound error function well gradient descent guarante enter provid proof proce suppos start weight vector path gradient descent never enter sinc sinc path trace gradient descent assum least one train vector misclassifi equat equat mean properti fact finit guarante bound equat finish compromis far concern case separ kind behavior desir one might algorithm choos weight produc correct result mani train vector suggest gradient descent use well form error function investig mani well form error suspect follow well error function let let four frame figur three train train vector held fix rotat becom increasingli inconsist train set frame lie border separ one frame interior transit seper regardless posit vector global minimum error function frame error function zero shade region shade contain move train vector number toward posit situat remain except shade region move arbitrarili frame region function global minimum ray indic train vector move interior region error function global minimum point closer train vector indic frame train vector algorithm tri mani discontinu two say find consensu otherwis devis layer network hidden probabl imposs prove anyth like reason even though properti assur top layer weight error signal misclassifi lower layer might still get vanishingli weak signal unit oper satur believ nevertheless good idea use well form error function base upon probabilist interpret output baum wilczek suggest use entropi error function thank hopfield tank bring error function well fleisher report simul switch error function introduc order magnitud learn network hidden categori one want classifi given input vector one mani one popular implement multipl categori network let network one output unit denot output output unit input present network weight consid classifi categori way network usual train gener et denot desir classif let target one use error function formul sever bothersom error function error function tri adjust realli differ symptom fact chang made weight connect output unit depend weight connect output remedi also defect delta rule defin rel coordin realli want fi use error function well form simul alway help quit one properti well form error function deriv mean algorithm complet tri make greater zero good train vector repres vector one want network correctli margin critic import obtain robust perform input vector train problem margin express meaningless make sens use margin output unit vari lot use output unit vari keep run varianc equat begin gradient difficult meaning chang algorithm begin estim becom increasingli david jame pdp research parallel mit richard duda peter pattern classif scene john marvin minski seymour eric baum frank esther sara michael privat,0
89,89,"860 
A METHOD FOR THE DESIGN OF STABLE LATERAL INHIBITION 
NETWORKS THAT IS ROBUST IN THE PRESENCE 
OF CIRCUIT PARASITICS 
J.L. WYATT, Jr and D.L. STANDLEY 
Department of Electrical Engineering and Computer Science 
Massachusetts Institute of Technology 
cambridge, Massachusetts 02139 
ABSTRACT 
In the analog VLSI implementation of neural systems, it is 
sometimes convenient to build lateral inhibition networks by using 
a locally connected on-chip resistive grid. A serious problem 
of unwanted spontaneous oscillation often arises with these 
circuits and renders them unusable in practice. This paper reports 
a design approach that guarantees such a system will be stable, 
even though the values of designed elements and parasitic elements 
in the resistive grid may be unknown. The method is based on a 
rigorous, somewhat novel mathematical analysis using Tellegen's 
theorem and the idea of Popov multipliers from control theory. It 
is thoroughly practical because the criteria are local in the sense 
that no overall analysis of the interconnected system is required, 
empirical in the sense that they involve only measurable frequency 
response data on the individual cells, and robust in the sense that 
unmodelled parasitic resistances and capacitances in the inter- 
connection network cannot affect the analysis. 
I. INTRODUCT ION 
The term ""lateral inhibition"" first arose in neurophysiology to 
describe a common form of neural circuitry in which the output of 
each neuron in some population is used to inhibit the response of 
each of its neighbors. Perhaps the best understood example is the 
horizontal cell layer in the vertebrate retina, in which lateral 
inhibition simultaneously enhances intensity edges and acts as an 
automatic ain control to extend the dynamic range of the retina 
as a whole . The principle has been used in the design of artificial 
neural system algorithms by Kohonen 2 and others and in the electronic 
design of neural chips by Carver Mead et. al.3, 4. 
In the VLSI implementation of neural systems, it is convenient 
to build lateral inhibition networks by using a locally connected 
on-chip resistive grid. Linear resistors fabricated in, e.g., 
polysilicon, yield a very compact realization, and nonlinear 
resistive grids, made from MOS transistors, have been found useful 
for image segmentation.4, 5 Networks of this type can be divided into 
two classes: feedback systems and feedforward-only systems. In the 
feedforward case one set of amplifiers imposes signal voltages or 
American Institute of Physics 1988 
861 
currents on the grid and another set reads out the resulting response 
for subsequent processing, while the same amplifiers both ""write"" to 
the grid and ""read"" from it in a feedback arrangement. Feedforward 
networks of this type are inherently stable, but feedback networks 
need not be. 
A practical example is one of Carver Mead's retina chips 3 that 
achieves edge enhancement by means of lateral inhibition through a 
resistive grid. Figure 1 shows a single cell in a continuous-time 
version of this chip. Note that the capacitor voltage is affected 
both by the local light intensity incident on that cell and by the 
capacitor voltages on neighboring cells of identical design. Any 
cell drives its neighbors, which drive both their distant neighbors 
and the original cell in turn. Thus the necessary ingredients for 
instability--active elements and signal feedback--are both present 
in this system, and in fact the continuous-time version oscillates 
so badly that the original design is scarcely usable in practice 
with the lateral inhibition paths enabled. 6 Such oscillations can 
 ototrans istor 
incident 
1 igh t 
!similar 
ils 
rout 
Figure 1. This photoreceptor and signal processor circuit, using two 
MOS transconductance amplifiers, realizes lateral inhibition by 
communicating with similar units through a resistive grid. 
readily occur in any resistive grid circuit with active elements and 
feedback, even when each individual cell is quite stable. Analysis 
of the conditions of instability by straightforward methods appears 
hopeless, since any repeated array contains many cells, each of 
which influences many others directly or indirectly and is influenced 
by them in turn, so that the number of simultaneously active feed- 
back loops is enormous. 
This paper reports a practical design approach that rigorously 
guarantees such a system will be stable. The very simplest version 
of the idea is intuitively obvious: design each individual cell so 
that, although internally active, it acts like a passive system as 
seen from the resistive grid. In circuit theory language, the 
design goal here is that each cell's output impedance should be a 
positive-real 7 function. This is sometimes not too difficult in 
practice; we will show that the original network in Fig. 1 satisfies 
this condition in the absence of certain parasitic elements. More 
important, perhaps, it is a condition one can verify experimentally 
862 
by frequency-response measurements. 
It is physically apparent that a collection of cells that 
appear passive at their terminals will form a stable system when 
interconnected through a passive medium such as a resistive grid. 
The research contributions, reported here in summary form, are 
i) a demonstration that this passivity or positive-real condition 
is much stronger than we actually need and that weaker conditions, 
more easily achieved in practice, suffice to guarantee stability of 
the linear network model, and ii) an extension of i) to the nonlinear 
domain that furthermore rules out large-signal oscillations under 
certain conditions. 
II. FIRST-ORDER LINEAR ANALYSIS OF A SINGLE CELL 
We begin with a linear analysis of an elementary model for the 
circuit in Fig. 1. For an initial approximation to the output 
admittance of the cell we simplify the topology (without loss of 
relevant information) and use a naive' model for the transconductance 
amplifiers, as sho in Fig. 2. 
e mk/// 
+ 
( 
(s) 
Figure 2. Simplified network topology and transconductance amplifier 
model for the circuit in Fig. 1. The capacitor in Fig. 1 has been 
absorbed into Co2. 
Straightforward calculations show that the output admittance is 
given by 
- 1 gmlgm2R�l 
Y(s) = [gin2 + Ro2 + s Co2] + . (1) 
(1 + s RolCol) 
This is a positive-real, i.e., passive, admittance since it can always 
be realized by a network of 'the form shown in Fig. 3, where 
-1 -1 -1 
R 1 = (gm2 + Ro2) , R2= (gmlgm2Rol) , and L = Col/gmlgm2. 
Although the original circuit contains no inductors, the 
realization has both capacitors and inductors and thus is capable 
of damped oscillations. Nonetheless, if the transamp model in 
Fig. 2 were perfectly accurate, no network created by interconnecting 
such cells through a resistive grid (with parasitic capacitances) 
could exhibit sustained oscillations. For element values that may 
be typical in practice, the model in Fig. 3 has a lightly damped 
resonance around 1 KHz with a Q = 10. This disturbingly high Q 
suggests that the cell will be highly sensitive to parasitic elements 
not captured by the simple models in Fig. 2. Our preliminary 
863 
L 2 [ 
Y(s) 
Figure 3. Passive network realization of the output admittance (eq. 
(1) of the circuit in Fig. 2. 
analysis of a much more complex model extracted from a physical 
circuit layout created in Carver Mead's laboratory indicates that 
the output impedance will not be passive for all values of the trans- 
amp bias currents. But a definite explanation of the instability 
awaits a more careful circuit modelling effort and perhaps the design 
of an on-chip impedance measuring instrument. 
III. POSITIVE-REAL FUNCTIONS, 8-POSITIVE FUNCTIONS, AND 
STABILITY OF LINEAR NETWORK MODELS 
In the following discussion s = +j is a complex variable, 
H(s) is a rational function (ratio of polynomials) in s with real 
coefficients, and we assume for simplicity that H(s) has no pure 
imaginary poles. The term closed right half plane refers to the set 
of complex numbers s with Re{s} > 0. 
Def. 1 
The function H(s) is said to be positive-real if a) it has no 
poles in the right half plane and b) Re{H(j)} > 0 for all . 
If we know at the outset that H(s) has no right half plane poles, 
then Def. 1 reduces to a simple graphical criterion: HS is positive- 
real if and only if the Nyquist diagram of H(s) (i.e. the plot of 
H(j) for  > 0, as in Fig. 4) lies entirely in the closed right half 
plane. 
Note that positive-real functions are necessarily stable since 
they have no right half plane poles, but stable functions are not 
necessarily positive-real, as Example 1 will show. 
A deep link between positive real functions, physical networks 
and passivity is established by the classical result 7 in linear 
circuit theory which states that H(s) is positive-real if and only if 
it is possible to synthesize a 2-terminal network of positive linear 
resistors, capacitors, inductors and ideal transformers that has H(s) 
as its driving-point impedance or admittance. 
864 
Def. 2 
The function H(s) is said to be 8-positive for a particular value 
of 8(8  0, 8  7), if a) H(s) has no poles in the right half plane, 
and b) the Nyquist plot of H(s) lies strictly to the right of the 
straight line passing through the origin at an angle 8 to the real 
positive axis. 
Note that every 8-positive function is stable and any function 
that is 8-positive with 8 = /2 is necessarily positive-real. 
I {G(j) } 
m 
{G (j) } 
Figure 4. Nyqist diagram for a function that is 8-positive but 
not positive-real. 
Ex.9ple 1 
The function 
G(s) = 
(s+l) (s+40) 
(s+5) (s+6) (S+7) 
(2) 
is 8-positive (for any 8 between about 18 � and 68 �) and stable, but it 
is not positive-real since its Nyquist diagram, shown in Fig. 4, 
crosses into the left half plane. 
The importance of 8-positive functions lies in the following 
observations: 1) an interconnection of passive linear resistors and 
capacitors and cells with stable linear impedances can result in an 
unstable network, b) such an instability cannot result if the 
impedances are also positive-real, c) 8-positive impedances form a 
larger class than positive-real ones and hence 8-positivity is a less 
demanding synthesis goal, and d) Theorem 1 below shows that such an 
instability cannot result if the impedances are 8-positive, even if 
they are not positive-real. 
Theorem 1 
Consider a linear network of arbitrary topology, consisting of 
any number of passive 2-terminal resistors and capacitors of arbitrary 
value driven by any number of active cells. If the output impedances 
865 
of all the active cells are e-positive for some common e, 0<e<-, 
then the network is stable. 
The proof of Theorem 1 relies on Lemma 1 below. 
Lal 
If H(s) is e-positive for some fixed e, then for all s o in the 
closed first quadrant of the complex plane, H(s o) lies strictly to 
the right of the straight line passing through the origin at an angle 
e to the real positive axis, i.e., Re{s o }  0 and Im{s o}  0 ----> 
8-7 <  H(So) < e. 
Proof of Lemma 1 (Outline) 
Let d be the function that assigns to each s in the closed right 
half plane the perpendicular distance d(s) from H(s) to the line 
defined in Def. 2. Note that d(s) is harmonic in the closed right 
half plane, since H is analytic there. It then follows, by application 
of the maximum modulus principle 8 for harmonic functions, that d takes 
its minimum value on the boundary of its domain, which is the 
imaginary axis. This establishes Lemma 1. 
Proof of Theorem 1 (Outline) 
The network is unstable or marginally stable if and only if it 
has a natural frequency in the closed right half plane, and s o is a 
natural frequency if and only if the network equations have a nonzero 
solution at s o . Let {I k} denote the complex branch currents of such 
a solution. By Tellegen's theorethe sum of the complex powers 
absorbed by the circuit elements must vanish at such a solution, i.e., 
[ lZk 12 + [ IZk12/SoCk + Zk(SolZk I= = 0, 
resistances capacitances cell 
terminal pairs 
(3) 
where the second term is deleted in the special case So=O, since the 
complex power into capacitors vanishes at So=0. 
If the network has a natural frequency in the closed right half 
plane, it must have one in the closed first quadrant since natural 
frequencies are either real or else occur in complex conjugate pairs. 
But (3) cannot be satisfied for any s o in the closed first quadrant, 
as we can see by dividing both sides of (3) by [ lIkl 2, where the 
sum is taken over all network branches. After this division, (3) 
asserts that zero is a convex combination of terms of the form Rk, 
terms_of thp for k (CkSo)-l, and terms of the form Zk(So). 
Visualize wnere tnese terms lie in the complex plane: the first set lies 
on the real positive axis, the second set lies in the closed 4-th 
quadrant since s o lies in the closed 1st quadrant by assumption, and 
the third set lies to the right of a line passing through the origin 
at an angle e by Lemma 1. Thus all these terms lie strictly to the 
right of this line, which implies that no convex combination of them 
can equal zero. Hence the network is stable! 
866 
IV. 
STABILITY RESULT FOR NETWORKS WITH NONLINEAR 
RESISTORS AND CAPACITORS 
The previous result for linear networks can afford some limited 
insight into the behavior of nonlinear networks. First the nonlinear 
equations are linearized about an equilibrium point and Theorem 1 is 
applied to the linear model. If the linearized model is stable, then 
the equilibrium point of the original nonlinear network is locally 
stable, i.e., the network will return to that equilibrium point if 
the initial condition is sufficiently near it. But the result in this 
section, in contrast, applies to the full nonlinear circuit model and 
allows one to conclude that in certain circumstances the network 
cannot oscillate even if the initial state is arbitrarily far from 
the equilibrium point. 
Def. 3 
A function H (s) as described in Section III is said to satisfy 
the Popov criterion 10 if there exists a real number r>0 such that 
Re{(l+jr) H(j)} > 0 for all . 
Note that positive real functions satisfy the Popov criterion 
with r=0. And the reader can easily verify that G(s) in Example 1 
satisfies the Popov criterion for a range of values of r. The important 
effect of the term (l+jr) in Def. 3 is to rotate the Nyquist plot 
counterclockwise by progressively greater amounts up to 90 � as  
increases. 
Theorem 2 
Consider a network consisting of nonlinear 2-terminal resistors 
and capacitors, and cells with linear output impedances Zk(S). Suppose 
i) the resistor curves are characterized by continuously 
diffe,rentiable functions i k = gk(Vk) where gk(0) = 0 and 
0 < gk(Vk) < G <  for all values of k and Vk, 
ii) the capacitors are characterized by i k = Ck(vk)$ k with 
0 < C 1 < Ck(V k) < C 2 <  for all values of k and Vk, 
iii) the impedances Zk(S) have no poles in the closed right 
half plane and all satisfy the Popov criterion for some common 
value of r. 
If these conditions are satisfied, then the network is stable in the 
sense that, for any initial condition, 
 i (t) dt <  
0 all branches 
(4) 
The proof, based on Tellegen's theorem, is rather involved. 
will be omitted here and will appear elsewhere. 
It 
867 
ACKNOWLEDGEMENT 
We sincerely thank Professor Carver Mead of Cal Tech for 
enthusiastically supporting this work and for making it possible for 
us to present an early report on it in this conference proceedings. 
This work was supporedbyDefense Advanced Research Projects Agency 
(DoD), through the Office of Naval Research under ARPA Order No. 
3872, Contract No. N00014-80-C-0622 and Defense Advanced Research 
Projects Agency (DARPA) Contract No. N00014-87--0825. 
REFERENCES 
1. F.S. Werblin, ""The Control of Sensitivity on the Retina,"" 
Scientific American, Vol. 228, no. 1, Jan. 1983, pp. 70-79. 
2. T. Kohonen, Self9rganization and Associative Memory, (vol. 8 in 
the Springer Series in Information Sciences), Springer Verlag, 
New York, 1984. 
3. M.A. Sivilotti, M.A. Mahowald, and C.A. Mead, ""Real Time Visual 
Computations Using Analog CMOS Processing Arrays,"" Advanced 
Research in VLSI - Proceedings of the 1987 Stanford Conference, 
P. Losleben, ed., MIT Press, 1987, pp. 295-312. 
4. C.A. Mead, Analog VLSI and Neural Systems, Addison-Wesley, to 
appear in 1988. 
5. J. Hutchinson, C. Koch, J. Luo and C. Mead, ""Computing Motion 
Using Analog and Binary Resistive Networks,"" submitted to IEEE 
Transactions on Computers, August 1987. 
6. M. Mahowald, personal communication. 
7. B.D.O. Anderson and S. Vongpanitlerd, Network Analysis and 
Synthesis - A Modern Systems Theory Approach, Prentice-Ita]l, 
Englewood Cliffs, NJ., 1973. 
8. L.V. Ahlfors, Complex Analysis, McGraw-Hill, New York, 1966, 
p. 164. 
9. P. Penfield, Jr., R. Spence, and S. Duinker, Tellegen's Theorem 
and Electrical Networks, MIT Press, Cambridge, MA, 1970. 
10. M. Vidyasagar, Nonlinear Systems Analysis, Prentice-Hall, 
Englewood Cliffs, NJ, 1970, pp. 211-217. 
", method design stabl later inhibit robust presenc circuit parasit jr standley electr engin comput scienc institut technolog massachusett analog vlsi implement neural conveni build later inhibit network use local connect resist seriou problem unwant spontan oscil often aris render unus paper report design approach guarante system though valu design element parasit element resist grid may method base somewhat novel mathemat analysi use idea popov multipli control thoroughli practic criteria local sens overal analysi interconnect system sens involv measur frequenc data individu robust sens parasit resist capacit network can not affect introduct ion term first aros neurophysiolog common form neural circuitri output neuron popul use inhibit respons perhap best understood exampl cell layer vertebr later simultan enhanc intens edg act control extend dynam rang retina whole principl use design artifici system algorithm kohonen other electron neural chip carver mead vlsi implement neural conveni build later inhibit network use local connect resist linear resistor fabric yield compact nonlinear made mo found use imag network type divid feedback system case one set amplifi impos signal voltag institut physic grid anoth set read result respons subsequ amplifi grid feedback feedforward type inher feedback network practic exampl one carver retina chip edg enhanc mean later inhibit figur show singl cell note capacitor voltag affect local light intens incid cell voltag neighbor cell ident drive drive distant neighbor origin cell thu necessari ingredi element signal present fact version oscil badli origin design scarc usabl practic later inhibit path oscil ototran istor igh photoreceptor signal processor use two transconduct realiz later inhibit similar unit resist occur resist grid circuit activ element even individu cell quit analysi condit instabl straightforward method appear sinc repeat array contain mani influenc mani other directli indirectli influenc number simultan activ loop paper report practic design approach rigor system simplest version idea intuit design individu cell although intern act like passiv system resist circuit theori goal output imped sometim difficult show origin network satisfi condit absenc certain parasit condit one verifi experiment physic appar collect cell passiv termin form stabl system passiv medium resist research report summari demonstr passiv condit much stronger actual need weaker easili achiev suffic guarante stabil linear network extens nonlinear furthermor rule oscil linear analysi singl cell begin linear analysi elementari model initi approxim output cell simplifi topolog loss use model transconduct simplifi network topolog transconduct amplifi circuit capacitor calcul show output admitt admitt sinc alway realiz network form shown origin circuit contain capacitor inductor thu capabl damp transamp model perfectli network creat interconnect cell resist grid parasit exhibit sustain element valu may typic model lightli damp around khz disturbingli high cell highli sensit parasit element captur simpl model preliminari passiv network realiz output admitt circuit much complex model extract physic layout creat carver laboratori indic output imped passiv valu bia definit explan instabl care circuit model effort perhap design imped measur linear network model follow discuss complex ration function real assum simplic pure term close right half plane refer set complex number function said right half plane know outset right half plane reduc simpl graphic nyquist diagram plot lie entir close right half function necessarili stabl sinc right half plane stabl function exampl deep link posit real physic network passiv establish classic result linear theori state possibl synthes network posit linear inductor ideal transform imped function said particular valu pole right half nyquist plot lie strictli right line pass origin angl real everi function stabl function necessarili diagram function function sinc nyquist shown left half import function lie follow interconnect passiv linear resistor cell stabl linear imped result instabl can not result also imped form class one henc less synthesi theorem show can not result imped even linear network arbitrari consist number passiv resistor capacitor arbitrari driven number activ output imped activ cell common network proof theorem reli lemma fix first quadrant complex lie strictli right straight line pass origin angl real posit lemma function assign close right plane perpendicular distanc line note harmon close right sinc analyt applic maximum modulu principl harmon take minimum valu boundari establish lemma theorem network unstabl margin stabl natur frequenc close right half frequenc network equat nonzero let denot complex branch current sum complex power circuit element must vanish zk ck zk capacit cell pair second term delet special case sinc power capacitor vanish network natur frequenc close right half must one close first quadrant sinc natur either real els occur complex conjug can not satisfi close first see divid side ikl taken network zero convex combin term form thp term form wnere tnese term lie complex first set lie real posit second set lie close sinc lie close quadrant third set lie right line pass origin angl lemma thu term lie strictli impli convex combin equal henc network result network nonlinear capacitor previou result linear network afford limit behavior nonlinear first nonlinear linear equilibrium point theorem linear linear model equilibrium point origin nonlinear network local network return equilibrium point initi condit suffici near result appli full nonlinear circuit model one conclud certain circumst network oscil even initi state arbitrarili far equilibrium function describ section said satisfi popov criterion exist real number posit real function satisfi popov criterion reader easili verifi exampl popov criterion rang valu import term rotat nyquist plot progress greater amount network consist nonlinear resistor cell linear output imped suppos resistor curv character continu function valu capacitor character valu imped pole close right plane satisfi popov criterion common condit network stabl initi dt branch base rather omit appear sincer thank professor carver mead cal tech support work make possibl present earli report confer work defens advanc research project agenc offic naval research arpa order contract defens advanc research agenc contract control sensit associ springer seri inform springer time visual use analog cmo process advanc vlsi proceed stanford mit analog vlsi neural luo motion analog binari resist submit ie august person anderson network analysi modern system theori complex new theorem electr mit nonlinear system,2
90,90,"169 
DOES THE NEURON ""LEARN"" LIKE THE SYNAPSE? 
RAOUL TAWEL 
Jet Propulsion Laboratory 
California Institute of Technology 
Pasadena, CA 91109 
Abstract
An improved learning paradigm that offers a significant reduction in com- 
putation time during the supervised lewnlng phase is described. It is based on 
extending the role that the neuron plays in artificial neural systems. Prior work 
has regarded the neuron as a strictly passive, non-linear processing element, and 
the synapse on the other hand as the primary source of information processing and 
knowledge retention. In this work, the role of the neuron is extended insofar as Mlow- 
ing its pararaeters to adaptively participate in the learning phase. The temperature 
of the sigmoid function is an exaraple of such a parameter. During learning, both the 
synaptic interconnection weights w and the neuronal temperatures T/m are opti- 
mized so as to capture the knowledge contained within the training set. The method 
allows each neuron to possess and update its own characteristic local temperature. 
This algorithm has been applied to logic type of problems such as the XOR or parity 
problem, resulting in a significant decrease in the required number of training cycles. 
INTRODUCTION 
One of the current issues in the theory of supervised learning concerns the scal- 
ing properties of neural networks. While low-order neural computations are easily 
handled on sequential or parallel processors, high-order problems prove to be in- 
tractable. The computational burden involved in implementing supervised learning 
algorithms, such as back-propagation, on networks with large connectivity and/or 
large training sets is immense and impractical at present. Therefore the treatment 
of 'real' applications in such areas as image recognition or pattern classification 
require the development of computationally efficient learning rules. This paper 
reports such an algorithm. 
Current neuromorphic models regard the neuron as a strictly passive non-linear 
element, and the synapse on the other hand as the primary source of knowledge 
retention. In these models, information processing is performed by propagating the 
synaptically weighed neuronal contributions in either a feed forward, feed backward, 
or fully recurrent fashion [1]-[3]. Artificial neural networks commonly take the point 
of view that the neuron can be modeled by a simple non-linear 'wire' type of device. 
However, evidence exists that information processing in biological neural net- 
works does occur at the neuronal level [4]. Although neuromorphic nets based on 
simple neurons are useful as a first approximation, a considerable richness is to 
be gained by extending 'learning' to the neuron. In this work, such an extension 
is made. The neuron is then seen to provide an additional or secondary source 
of information processing and knowledge retention. This is achieved by treating 
both the neuronal and synaptic variables as optimization parameters. The temper- 
ature of the sigmoid function is an example of such a neuronal parameter. In much 
170 Tawel 
the same way that the synaptic interconnection weights require optimization to 
reflect the knowledge contained within the training set, so should the temperature 
terms be optimized. It should be emphasized that the method does not optimize a 
global neuronal temperature for the whole network, but rather allows each neuron 
to posses and update its own characteristic local value. 
ADAPTIVE NEURON MODEL 
Although the principle of neuronal optimization is an entirely general concept, 
and therefore applicable to any learning scheme, the popular feed forward back 
propagation (BP) learning rule has been selected for its implementation and per- 
formance evaluation. In this section we develop the mathematical formalism nec- 
cessary to implement the adaptive neuron model (ANM). 
Back propagation is an example of supervised learning where, for each presenta- 
tion consisting of an input vector o p and its associated target vector , the algo- 
rithm attemps to adjust the synaptic weights so as to minimize the sum-squared 
error E over all patterns p. In its simplest form, back propagation treats the inter- 
connection weights as the only variable and consequently executes gradient descent 
in weight space. The error term is given by 
1 
The quantity l F is the i th component of the pth desired output vector pattern 
and o r is the activation of the corresponding neuron in the final layer n. For 
notational ease the summation over p is dropped and a single pattern is considered. 
On completion of learning, the synaptic weights capture the transformation linking 
the input to output variables. In applications other than toy problems, a major 
drawback of this algorithm is the excessive convergence time. 
In this paper it is shown that a significant decrease in convergence time can be 
realized by allowing the neurons to adaptively participate in the learning process. 
This means that each neuron is to be characterized by a set of parameters, such as 
temperature, whose values are optimized according to a rule, and not in a heuris- 
tic fashion as in simulated annealing. Upon training completion, learning is thus 
captured in both the synaptic and neuronal parameters. 
The activation of a unit - say the i h neuron on the mth layer - is given by o. 
This response is computed by a non-linear operation on the weighed responses of 
neurons from the previous layer, as seen in Figure 1. A common function to use is 
the logistic runtion, 
1 
o? = 
1 + e-? 
and T = 1]/ is the temperature of the network. The net weighed input to the 
neuron is found by summing products of the synaptic weights and corresponding 
neuronal ouputs from units on the previous layer, 
Does the Neuron ""Learn"" Like the Synapse? 171 
m 
� O k 
INPU ROM NEURON OUTPUT 
PREVIOUS FROM 
LAYER NEURON 
Figure 1. Each neuron in a network is chara- 
terized by a local, temperature dependent, sig- 
moidal activation function. 
m-1 represent the pairwise connection 
where o?- x represents fan-in units and the 
strength between neuron i in layer m and neuron j in layer m - 1. 
We have investigated several mathematical methods for the determination of the 
optimal neuronal temperatures. In this paper, the rule that was selected to optimize 
these parameters is based on executing gradient descent in the sum squared error 
E in temperature space. The method requires that the incremental change in the 
temperature term be proportional to the negative of the derivative of the error term 
with respect to the temperature. Focussing on the Ita neuron on the ouput layer 
n, we have 
In this expression,  is the temperature learning rate. This equation can be ex- 
pressed as the product of two terms by the chain rule 
OE OE 
0o? - 
Substituting expressions and leaving the explicit functional form of the activation 
function unspecified, i.e. o r = f(T n, ...) we obtain 
OE 0I 
: 
In a similar fashion, the temperature update equation for the previous layer is given 
by, 
OE 
OTk -1 
172 Tawel 
Using the chain rule, this can be expressed as 
OE OE 0o Os 0o -1 
-1 = OoF 1 -1 
l 
Substituting expressions and simplifying reduces the above to 
of 
OT -1 
By repeating the above derivation for the previous layer, i.e. determining the partial 
derivative of E with respect to Tj n-2 etc., a simple recursive relationship emerges 
for the temperature terms. Specifically, the updating scheme for the k h neuronal 
temperature on the rn h layer is given by 
OE 
where 
OE Of 
OTF 
In the above expression, the error signal 5 takes on the value, 
if neuron m lies on an output layer, or 
of 
57 --' E 57+1087+1 wk 
l 
if the neuron lies on a hidden layer. 
SIMULATION RESULTS OF TEMPERATURE OPTIMIZATION 
The new algorithm was applied to logic problems. The network was trained on 
a standard benchmark - the exclusive-or logic problem. This is a classic problem 
requiring hidden units and since many problems involve an XOR as a subproblem. 
As in plain BP, the application of the proposed learning rule involves two passes. 
In the first, an input pattern is presented and propagated forward through the 
network to compute the output values o . This output is compared to its target 
value, resulting in an error signal for each output unit. The second pass involves a 
backward pass through the network during which the error signal is passed along 
the network and the appropriate weight and temperature changes made. Note that 
since the synapses and neurons have their own characteristic learning rate, i.e r/ 
and  respectively, an additional degree of freedom is introduced in the simulation. 
This is equivalent to allowing for relative updating time scales for the weights and 
Does the Neuron earn"" Like the Synapse? 173 
temperatures, i.e. rw and rT respectively. We have now generated a gradient 
descent method for finding weights and temperatures in a feed forward network. 
In deriving the learning rule for temperature optimization in the above section, 
the derivative of the activation function of a neuron played a key role. We have 
used a sigmoidal type of function in our simulations whose explicit form is given 
by, 
1 
and in Figure 2 it is shown to be extremely sensitive to small changes in tempera- 
ture. 
10 
0.8 
o6 
04 
0.2 
5 -3 -1 
$ 
Figure 2. Activation function shown plotted 
for several different temperatures. 
The sigmoid is shown plotted against the net input to a neuron for temperatures 
ranging from 0.2 to 2.0, in increments of 0.2. However, the steepest curve was for 
a temperature of 0.01. The derivative of the activation function taken with respect 
to the temperature is given by 
As shown in Figure 3, the XOR architecture selected has two input units, two 
hidden units, and a single output unit. Each neuron is characterized by a temper- 
ature, and neurons are connected by weights. Prior to training the network, both 
the weights and temperatures were randomized. The initial and final optimization 
parameters for a sample training exercise are shown in Figure 3(a)  (b). Specif- 
ically, Figure 3(a) shows the values of the randomized weights and temperatures 
prior to training, and Figure 3(b) shows their values after training the network for 
1000 iterations. This is a case where the network has reached a global minimum. In 
both figures, the numbers associated with the dashed arrows represent the thresh- 
olds of the neurons, and the numbers written next to the solid arrows represent the 
174 Tawel 
T=0.95,,( 
-0.979 
1.131 
OUT 
I .920 
(a) 
)T=1.039 T=0.628,,( 
0.450 -1.183 
-1.552 1.120 
OUT 
:IT.: 0'047 
0.476 
-1.717 
Figure 3. Architecture of NN for XOR prob- 
lem showing neuronal temperatures and synap- 
tic weights before (a) and after training (b). 
excitatory/inhibitory strengths of the pairwise connections. To fully evaluate the 
convergence speed of the proposed algorithm, a benchmark comparison between 
it and plain BP was made. In both cases the training was started with identical 
initial random synaptic weights lying within the range [-2.0,-t-2.0] and the same 
synaptic weight learning rate r/= 0.1. The temperatures of the neurons in the ANM 
model were randomly selected to lie within the narrow range of [0.9, 1.1] and the 
temperature learning rate  set at 0.1. Figures 4(a) &: (b) summarize the training 
statistics of this comparison. 
100 
10-1 
10-2 
10-3 
10-4 
10-5 
o o2 
lO-1 
lO-2 
\../ 
10'3 I 
10' 7 � � ' � � I , 
ITERATION rTERATION 
Figure 4. Comparison of training statistics 
between the adaptive neuron model and plain 
back propagation. 
Does the Neuron earn""Like the Synapse? !75 
In both figures, the solid lines represent the ANM and the dashed lines represent 
the plain BP model. In Figure 4(a), the error is plotted against the training iteration 
number. In Figure 4(b), the standard deviation of the error over the training set 
is shown plotted against the training iteration. In the first few hundred training 
iterations in Figure 4(a), the performance of BP and the ANM is similar and appears 
as a broad shoulder in the curve. Recall that both the weights and temperatures 
are randomized prior to training, and are therefore far from their final values. As 
a consequence of the low values of the learning rates used, the error is large, and 
will only begin to get smaller when the weights and temperatures begin to fall in 
the right domain of values. In the ANM, the shoulder terminus is marked by a 
phase-transition like discontinuity in both error and standard deviation. For the 
particular example shown, this occured at the 637 th iteration. A several order of 
magnitude drop in the error and standard deviation is observed within the next 10 
iterations. This sharp drop off is followed by a much more gradual decrease in both 
the error and standard deviation. A more detailed analysis of these results will be 
published in a longer paper. 
In leakning the XOR problem using standard BP, it has been observed that the 
network frequently gets trapped in local minima. In Figure 5(a) & (b) we observe 
such a case as shown by the dotted line. In numerous simulations on this problem, 
we have determined that the ANM is much less likely to become trapped in local 
minima. 
10 
10-1 
10-2 
10'6 
101 10 2 
ITERATION 
10-1 
10-2 
10-5 
ITERATION 
Figure 5. Training case where the adaptive 
neuron model escapes a local minima and plain 
back propagation does not. 
CONCLUSIONS 
In this paper we have attempted to upgrade and enrich the model of the neuron 
from a simple static non-linear wire-type construct, to a dynamically reconfigurable 
one. From a purely computational point of view, there are definite advantages in 
such an extension. Recall that if N is the number of neurons in a network then the 
number of synaptic connections typically increases as O(N2). Since the activation 
176 Tawel 
function is extremely sensitive to small changes in temperature and that there are 
far fewer neuronal parameters to update than synaptic weights, suggests that the 
adaptive neuron model should offer a significant reduction in convergence time. 
In this paper we have also shown that the active participation of the neurons 
during the supervised learning phase led to a significant reduction in the number 
of training cycles required to learn logic type of problems. In the adaptive neuron 
model both the synaptic weight interconnection strengths and the neuronal tem- 
perature terms are treated as optimization parameters and have their own updating 
scheme and time scales. This learning rule is based on implementing gradient de- 
scent in the sum squared error E with respect to both the weights wi? and temper- 
atures T/m. Preliminary results indicate that the new algorithm can significantly 
outperform back propagation by reducing the learning time by several orders of 
magnitude. Specifically, the XOR problem was learnt to a very high precision by 
the network in  103 training iterations with a mean square error of  10 -6 versus 
over 106 iterations with a corresponding mean square error of , 10 -3. 
Acknowledgements. 
The work described in this paper was performed by the Jet Propulsion Labora- 
tory, California Institute of Technology, and was supported in parts by the Na- 
tional Aeronautics and Space Administration and the Defense Advanced Research 
Projects Agency through an agreement with the National Aeronautics and Space 
Administration. 
REFERENCES 
1. D. Rummelhart, J. McClelland, ""Parallel Distributed Processing,"" M.I.T. Press, Cambridge, 
MA, 1986. 
2. J. J. Hopfield, Neural Networks as Physical Systems with Emergent Collective Computational 
Abilities, Proceedings of the National Academy of Science USA 79 (1982), 2554-2558. 
3. F. J. Pineda, Generalization O.f Backpropagation To Recurrent and Higher Order Neural 
Networks, in ""Neural Information Processing Systems Proceedings,"" AlP, New York, 1987. 
4. L. R. Carley, Presynaptic Neural In.formation Processing, in ""Neural Information Processing 
Systems Proceedings,"" AIP, New York, 1987. 
", neuron like tawel propuls laboratori institut technolog ca improv learn paradigm offer signific reduct time supervis phase base role neuron play artifici neural prior work regard neuron strictli process synaps hand primari sourc inform process role neuron extend insofar pararaet adapt particip learn temperatur sigmoid function exarapl interconnect weight neuron temperatur captur knowledg contain within train method neuron possess updat characterist local algorithm appli logic type problem xor pariti result signific decreas requir number train current issu theori supervis learn concern properti neural neural comput easili sequenti parallel problem prove comput burden involv implement supervis learn network larg connect train set immens impract therefor treatment applic area imag recognit pattern classif develop comput effici learn paper neuromorph model regard neuron strictli passiv synaps hand primari sourc knowledg inform process perform propag weigh neuron contribut either feed feed fulli recurr fashion artifici neural network commonli take point view neuron model simpl type evid exist inform process biolog neural occur neuron level although neuromorph net base neuron use first consider rich gain extend extens neuron seen provid addit secondari sourc inform process knowledg achiev treat neuron synapt variabl optim sigmoid function exampl neuron much tawel way synapt interconnect weight requir optim knowledg contain within train temperatur emphas method optim neuron temperatur whole rather allow neuron poss updat characterist local neuron model principl neuron optim entir gener therefor applic learn popular feed forward back learn rule select implement section develop mathemat formal implement adapt neuron model propag exampl supervis learn consist input vector associ target vector attemp adjust synapt weight minim pattern simplest back propag treat weight variabl consequ execut gradient descent weight error term given quantiti th compon pth desir output vector pattern activ correspond neuron final layer eas summat drop singl pattern complet synapt weight captur transform link input output applic toy major algorithm excess converg paper shown signific decreas converg time allow neuron adapt particip learn mean neuron character set whose valu optim accord fashion simul upon train learn thu synapt neuron activ unit say neuron mth layer given respons comput oper weigh respons previou seen figur common function use logist temperatur net weigh input found sum product synapt weight correspond ouput unit previou neuron like rom neuron output neuron neuron network temperatur activ repres pairwis connect repres unit neuron layer neuron layer investig sever mathemat method determin neuron rule select optim paramet base execut gradient descent sum squar error temperatur method requir increment chang term proport neg deriv error term respect focuss ita neuron ouput layer temperatur learn equat product two term chain rule oe express leav explicit function form activ obtain similar temperatur updat equat previou layer given tawel chain express oe express simplifi reduc repeat deriv previou determin partial respect tj simpl recurs relationship emerg temperatur updat scheme neuron rn layer given error signal take neuron lie output neuron lie hidden result temperatur optim new algorithm appli logic network train standard benchmark logic classic problem hidden unit sinc mani problem involv xor plain applic propos learn rule involv two input pattern present propag forward comput output valu output compar target result error signal output second pass involv pass network error signal pass along network appropri weight temperatur chang note synaps neuron characterist learn addit degre freedom introduc equival allow rel updat time scale weight neuron like rw gener gradient method find weight temperatur feed forward deriv learn rule temperatur optim deriv activ function neuron play key sigmoid type function simul whose explicit form given figur shown extrem sensit small chang activ function shown plot sever differ sigmoid shown plot net input neuron temperatur increment steepest curv temperatur deriv activ function taken respect temperatur given shown figur xor architectur select two input two singl output neuron character neuron connect prior train weight temperatur initi final optim sampl train exercis shown figur figur show valu random weight temperatur figur show valu train network case network reach global number associ dash arrow repres number written next solid arrow repres tawel architectur nn xor show neuron temperatur weight train strength pairwis fulli evalu speed propos benchmark comparison plain bp case train start ident random synapt weight lie within rang weight learn rate temperatur neuron anm randomli select lie within narrow rang learn rate set figur summar train terat comparison train statist adapt neuron model plain neuron solid line repres anm dash line repres plain bp figur error plot train iter figur standard deviat error train set shown plot train first hundr train figur perform bp anm similar appear broad shoulder recal weight temperatur random prior therefor far final consequ low valu learn rate error begin get smaller weight temperatur begin fall right domain shoulder terminu mark like discontinu error standard exampl occur th sever order drop error standard deviat observ within next sharp drop follow much gradual decreas error standard detail analysi result longer leakn xor problem use standard observ frequent get trap local figur observ case shown dot numer simul determin anm much less like becom trap local train case adapt model escap local minima plain propag paper attempt upgrad enrich model neuron simpl static dynam reconfigur pure comput point definit advantag recal number neuron network synapt connect typic increas sinc activ tawel extrem sensit small chang temperatur fewer neuron paramet updat synapt suggest neuron model offer signific reduct converg paper also shown activ particip neuron supervis learn phase led signific reduct number train cycl requir learn logic type adapt neuron synapt weight interconnect strength neuron term treat optim paramet updat time learn rule base implement gradient sum squar error respect weight preliminari result indic new algorithm significantli back propag reduc learn time sever order xor problem learnt high precis network train iter mean squar error versu iter correspond mean squar error work describ paper perform jet propuls california institut support part aeronaut space administr defens advanc research agenc agreement nation aeronaut space distribut neural network physic system emerg collect comput proceed nation academi scienc usa gener backpropag recurr higher order neural inform process system new presynapt neural inform process new,1
91,91,"CONSTRAINTS ON ADAPTIVE NETWORKS 
FOR MODELING HUMAN GENERALIZATION 
M. Payel 
Mark A. Gluck 
Van Henkle 
Department of Psychology 
Stanford University 
Stanford, CA 94305 
ABSTRACT 
The potential of adaptive networks to learn categorization rules and to 
model human performance is studied by comparing how natural and 
artificial systems respond to new inputs, i.e., how they generalize. Like 
humans, networks can learn a deterministic categorization task by a 
variety of alternative individual solutions. An analysis of the con- 
straints imposed by using networks with the minimal number of hidden 
units shows that this ""minimal configuration"" conslxaint is not 
sufficient to explain and predict human performance; only a few solu- 
tions were found to be shared by both humans and minimal adaptive 
networks. A further analysis of human and network generalizations 
indicates that initial conditions may provide important constraints on 
generalization. A new technique, which we call ""reversed learning"", 
is described for finding appropriate initial conditions. 
INTRODUCTION 
We are investigating the potential of adaptive networks to learn categorization tasks and 
to model human performance. In particular we have studied how both natural and 
artificial systems respond to new inputs, that is, how they generalize. In this paper we 
first describe a computational technique to analyze generalizations by adaptive networks. 
For a given network structure and a given classification problem, the technique 
enumerates all possible network solutions to the problem. We then report the results of 
an empirical study of human categorization learning. The generalizations of human sub- 
jects are compared to those of adaptive networks. A cluster analysis of both human and 
network generalizations indicates. significant differences between human performance 
and possible network behaviors. Finally, we examine the role of the initial state of a net- 
work for biasing the solutions found by the network. Using data on the relations between 
human subjects' initial and final performance during training, we develop a new tech- 
nique, called ""reversed learning"", which shows some potential for modeling human 
learning processes using adaptive networks. The scope of our analyses is limited to gen- 
eralizations in deterministic pattern classification (categorization) tasks. 
Modeling Human Generalization 3 
The basic difficulty in generalization is that there exist many different classification rules 
(""solutions"") that that correctly classify the training set but which categorize novel 
objects differently. The number and diversity of possible solutions depend on the 
language defining the pattern recognizer. However, additional constraints can be used in 
conjunction with many types of pattern categorizers to eliminate some, hopefully 
undesirable, solutions. 
One typical way of introducing additional constraints is to minimize the representation. 
For example minimizing the number of equations and parameters in a mathematical 
expression, or the number of rules in a rule-based system would assure that some 
identification maps would not be computable. In the case of adaptive networks, minimiz- 
ing the size of adaptive networks, which reduces the number of possible encoded func- 
tions, may result in improved generalization performance (Rumelhart, 1988). 
The critical theoretical and applied questions in pattern recognition involve characteriza- 
tion and implementation of desirable constraints. In the first part of this paper we 
describe an analysis of adaptive networks that characterizes the solution space for any 
particular problem. 
ANALYSES OF ADAPTIVE NETWORKS 
Feed-forward adaptive networks considered in this paper will be defined as directed 
graphs with linear threshold units (LTLO as nodes and with edges labeled by real-valued 
weights. The output or activations of a unit is determined by a monotonic nonlinear func- 
tion of a weighted sum of the activation of all units whose edges terminate on that unit. 
There are three types of units within a feed-forward layered architecture: (1) Input units 
whose activity is determined by external input; (2) output units whose activity is taken as 
the response; and (3) the remaining units, called hidden units. For the sake of simplicity 
our discussion will be limited to objects represented by binary valued vectors. 
A fully connected feed-forward network with an unlimited number of hidden units can 
compute any boolean function. Such a general network, therefore, provides no con- 
straints on the solutions. Therefore, additional constraints must be imposed for the net- 
work to prefer one generalization over another. One such constraint is minimizing the 
size of the network. In order to explore the effect of minimizing the number of hidden 
units we first identify the minimal network architecture and then examine its generaliza- 
tions. 
Most of the results in this area have been limited to finding bounds on the expected 
number of possible patterns that could be classified by a given network (e.g. Cover, 1965; 
Volper and Hampson, 1987; Valiant, 1984; Baum & Haussler, 1989). The bounds found 
by these researchers hold for all possible categorizations and are, therefore, too broad to 
be useful for the analysis of particular categorization problems. 
To determine the generalization behavior for a particular network archilecture, a specific 
4 Gluck, Pavel and Henkle 
categorization problem and a training set it is necessary to find find all possible solutions 
and the corresponding generalizations. To do this we used a computational (not a simu- 
lation) procedure developed by Pavel and Moore (1988) for finding minimal networks 
solving specific categorization problems. Pavel and Moore (1988) defined two network 
solutions to be different if at least one hidden unit categorized at least one object in the 
training set differently. Using this definition their algorithm finds all possible different 
solutions. Because finding network solutions is NP-complete (Judd, 1987), for larger 
problems Payel and Moore used a probabilistic version of the algorithm to estimate the 
dislribution of generalization responses. 
One way to characterize the consWaints on generalization is in terms of the number of 
possible solutions. A larger number of possible solutions indicates that generalizations 
will be less predictable. The critical result of the analysis is that, even for minimal net- 
works, the number of different network solutions is often quite large. Moreover, the 
number of solutions increases rapidly with increases in the number of hidden units. The 
apparent lack of consWaints can also be demonstrated by finding the probability that a 
network with a randomly selected hidden layer can solve a given categorization problem. 
That is, suppose that we selgct n different hidden units, each unit representing a linear 
discriminant function. The activations of these random hidden units can be viewed as a 
Uansformation of the input patterns. We can ask what is the probability that an output 
unit can be found to perform the desired dichotomization. A typical example of a result 
of this analysis is shown in Figure 1 for the three-dimensional (3D) parity problem. In 
the minimal configuration involving three hidden units there were 62 different solutions 
to the 3D parity problem. The rapid increase in probability (high slope of the curve in 
Figure 1) indicatea that adding a few more hidden units rapidly increases the probability 
that a random hidden layer will solve the 3D parity problem. 
10o 
HIDDEN UNITS 
Figure I The prolmrfion of solutions to 3D parity problem (solid line) and the 
experimental task (dashed line) as a function of the number of hidden units. 
The results of a more detailed analysis of the generalization performance of the minimal 
networks will be discussed following a description of a categorization experiment with 
Modeling Human Generalization 
human subjects. 
HUMAN CATEGORIZATION EXPERIMENT 
In this experiment human subjects learned to cate objects which were defined by 
four dimensional binary vectors. Of the 2  possible objects, subjects were trained to clas- 
sify a subset of 8 objects into two categories of 4 objects each. The specific assignments 
of objects into categories was patterned after Medin et al. (1982) and is shown in Figure 
2. Eight of the patterns are designated as a training set and the remaining eight comprise 
the test set. The assignment of the patterns in the training set into two categories was 
such that there were many combinations of rules that could be used to correctly perform 
the categorization. For example, the first two dimensions could be used with one other 
dimension. The training patterns could also be categorized on the basis of an exclusive 
or (XOR) of the last two dimensions. The type of solution obtained by a human subject 
could only be determined by examining responses to the test set as well as the training 
seL 
TRAINING SET TEST SET 
X1 110 I 0010 0001 1101 
DIMENSIONS X= 1 1 1 0 0 0 0 1 0 0 1 0 1 1 1 0 
X, 1010 1010 0101 0101 
X 1010 0101 0101 0101 
CATEGORY AAA A B B B B ? ? ? ? ? ? ? ? 
Figure 2. Pattam to b clusified. (Adapted from Medin et al., 1982). 
In the actual experiments, subjects were asked to perform a medical diagnosis for each 
pattern of four symptoms (dimensions). The experimental procure will be described 
here only briefly because the details of this experiment have been described elsewhere in 
detail (Payel, Gluck, Henkle, 1988). Each of the patterns was presented serially in a ran- 
domized order. Subjects responded with one of the categories and then received feed- 
back. The training of each individual continued until he reached a criterion (responding 
correctly to 32 consecutive stimuli) or until each pattern had been presenwat 32 times. 
The data reported here is bas on 78 subjects, half (39) who learned the task to criterion 
and half who did not. 
Following the training phase, subjects were tested using all 16 possible patterns. The 
results of the test phase enabled us to determine the generalizations performed by the 
subjects. Subjects' generalizations were used to estimate the ""functions"" that they may 
have been using. For example, of the 39 criterion subjects, 15 used a solution that was 
consistent with the exclusive-or (XOR) of the dimensions x 3 and x4. 
We use ""response profiles"" to graph responses for an ensemble of functions, in this case 
for a group of subjects. A response profile represents the probability of assigning each 
6 Gluck, Pavel and Henkle 
pattern to category ""A"". For example, the response profile for the XOR solution is 
shown in Figure 3A. For convenience we define the responses to the test set as the ""gen- 
eralization profile"". The response profile of all subjects who reached the criterion is 
shown in Figure 3B. The responses of our criterion subjects to the training set were basi- 
cally identical and correct. The distribution of subjects' generalization profiles reflected 
in the overall generalization profile are indicative of considerable individual differences 
lO01 
o11o 
11Ol 
111o 
loll 
01o0 
o011 
OlOl 
lOlO 
0001 
o01o 
1000 
0111 
11o0 
1111 
oo 
02 04 06 08 
PROPORTION ""A"" 
10 
z 
0110 
1101 
1110 
0100 = - 
o011 
o101 
lOlO 
0001 
o01o 
0111 
11o0 N_ _ 
1111 
o o o!2 o 4 o 6 0'8 1 o 
Figure 3. (A) Reslxmse profile of the XOR olution, and (B) a Woportion of 
the response ""A"" to all patterns for humm subjects (dark bars) and minimal 
networks (light bars). The lowe 8 patterns are from the training set and the 
upper 8 patterns from the test set. 
MODELING THE RESPONSE PROFILF. 
One of our goals is to model subjects' distribution of categorizations as represented by 
the response profile in Figure 3B. We considered three natural approaches to such 
modeling: (1) Statistical/promi models, (2) Minimal disjunctive normal forms 
(DNF), and (3) Minimal two-layer networks. 
The statistical approach is based on the assumption that tbe response profile over subjects 
represents the probability of categorizafions performed by each subject. Our data are not 
consistent with that assumption because each subject appeared to behave deterministi- 
cally. The second approach, using the minimal DNF is also not a good candidate because 
there are only four such solutions and the response profile over those solutions differs 
considerably from that of the subjects. Turning to the adaptive network solutions, we 
found all the solutions using the linear programming technique described above (Payel & 
Moore, 1988). The minimal two-layer adaptive network that was capable of solving the 
training set problem consisted of two hidden units. The proportion of solutions as a 
Modeling Human Generalization 7 
function of the number of hidden units is shown in Figure 1 by the dashed line. 
For the minimal network there were 18 different solutions. These 18 solutions had 8 dif- 
ferent individ_nl generalization profiles. Assuming that each of the 18 network solution 
is equally likely, we computed the generalization profile for minimal network shown in 
Figure 3B. The response profile for the minimal network represents the probability that a 
randomly selected minimal network will assign a given pattern to category ""A"". Even 
without statistical testing we can conclude that the generalization profiles for humans and 
networks are quite different. It is possible, however, that humans and minimal networks 
obtain similar solutions and that the differences in the average responses are due to the 
particular statistical sampling assumption used for the minimal networks (i.e. each solu- 
tion is equally likely). In order to determine the overlap of solutions we examined the 
generalization profiles in more detail. 
CLUSTERING ANALYSIS OF GENERALIZATION PROFILFS 
To analyze the similarity in solutions we defined a metric on generalization profiles. The 
Hamming distance between two profiles is equal to the number of patterns that are 
categorized differently. For example, the distance between generalization profile ""A A 
B A B B B B"" and ""A A B B B B A B"" is equal to two, because the two profiles differ 
on only the fourth and seventh pattern. Figure 4 shows the results of a cluster analysis 
using a hierarchical clustering procedure that maximizes the average distance between 
clusters. 
:: :: : i : ' 
� 
Figure 4. Results of hiersrchical clustering for human (left) and network 
(right) generalization profiles. 
In this graph the average distance between any two clusters is shown by the value of the 
lowest common node in the tree. The clustering analysis indicates that humans and 
8 Gluck, Pavel and Henkle 
networks obtained widely different generalization profiles. Only three generalization 
profiles were found to be common to human and networks. This number of common 
generalizations is to be expecl! by chance if the human and network solutions are 
independent. Thus, even if there exists a learning algorithm that approximates the human 
probability distribution of responses, the minimal network would not be a good model of 
human performance in this task. 
It is clear from the previously described network analysis that somewhat larger networks 
with different constraints could account for human solutions. In order to characterize the 
additional constraints, we examined subjects' individual strategies to find out why indivi- 
dual subjects obtained different solutions. 
ANALYSIS OF HUMAN LARNING STRATEGIES 
Human learning strategies that lead to preferences for particular solutions may best be 
modeled in networks by imposing constraints and providing hints (Abu-Mostafa 1989). 
These include choosing the network architecture and a learning rule, constraining con- 
nectivity, and specifying initial conditions. We will focus on the specifion of initial 
conditions. 
8 
er 
m 
m 
� 10 
z 
XOR HON XOR NO cRrrERION 
SUBJECT TYPES 
Figure $. The number of consistent or non-stable responses (black) and the 
number of stable incorrect responses (light) for XOR, Non-XOR criterion sub- 
jects, and for those who never reached criterion. 
Our effort to examine initial conditions was motivated by large differences in learning 
curves (Pavel et al., 1988) between subjects who obtained the XOR solutions and those 
who did not. The subjects who did not obtain the XOR solutions would perform much 
better on some patterns (e.g. 0001) then the XOR subjects, but worse on other patterns 
(e.g. 1000). We concluded that these subjects during the first few trials discovered rules 
Modeling Human Generalization 9 
that categorized most of the training patterns correctly but failed on one or two training 
patterns. 
We examined the sequences of subjects' responses to see how well they adhered to 
""incorrect"" rules. We designated a response to a pattern as stable if the individo! 
responded the same way to that pattern at least four times in a row. We designated a 
response as consistent if the response was stable and correct. The results of the analysis 
are shown in Figure 5. These results indicate that the subjects who eventually achieved 
the XOR solution were less likely to generate stable incorrect solutions. Another impor- 
tant restfit is that those subjects who never learned the correct responses to the training 
set were not responding randomly. Rather, they were systeanatically using incorrect 
rules. On the basis of these results, we conclude that subjects' initial strategies may be 
important determinants of their final solutions. 
REVERSED LEARNING 
For simplicity we identify subjects' initial conditions by their re.$nses on the first few 
trials. An important theoretical question is whether or not it is possible to find a network 
structure, initial conditions and a learning rule such that the network can represent both 
the initial and final behavior of the subject In order to study this problem we developed 
a technique we call ""reversed learning"". It is based on a perturbation analysis of feed- 
forward networks. We use the fact that the error surface in a small neighborhood of a 
minimum is well approximated by a quadratic surface. Hence, a well behaved trod___ ient 
descent procedure with a starting point in the neighborhood of the minimum will find that 
'minimum. 
The reversed learning proced consists of three phases. (1) A network is trained to a 
final desired state of a particular individual, using both the training and the test patterns. 
(2) Using only the training patterns, the network is then trained to achieve the initial state 
of that individual subject closest to the desired final state (3) The network is trained with 
only the training patterns and the solution is compared to the subject's response profiles. 
Our preliminary results indicate that this procedure leads in many cases to initial condi- 
tions that favor the desired solutions. We are currently investigating conditions for 
finding the optimal initial states. 
CONCLUSION 
The main goal of this study was to examine constraints imposed by humans (experimen- 
tally) and networks (linear programming) on learning of simple binary categorization 
tasks. We characterize the constraints by analyzing responses to novel stimuli. We 
showed that, like the humans, networks learn the deterministic categorization task and 
find many, very different, individual solutions. Thus adaptive networks are better models 
than statistical models and DNF rules. The constraints imposed by minimal networks, 
however, appear to differ from those imposed by human learners in that there are only a 
few solutions shared between human and adaptive networks. After a detailed analysis of 
10 Cluck, Pavel and Henkle 
the human learning process we concluded that initial conditions may provide important 
constraints. In fact we consider the set of initial conditions as .powerful ""hints"" (Abu- 
Mostafa, 1989) which reduces the number of potential solutions, without reducing the 
complexity of the problem. We demonstrm.xl the potential effectiveness of these con- 
straints using a perturbation technique, which we call reversed learning, for finding 
appropriate initial conditions. 
Acknowledgements 
This work was supported by research grants from the National Science Foundation 
(BNS-86-18049) to Gordon Bower and Mark Gluck, and (IST-8511589) to M. Pavel, and 
by a grant from NASA Ames (NCC 2-269) to Stanford University. We thank Steve Slo- 
man and Bob Rehder for useful discussions and their comments on this draft. 
References 
Abu-Mostafa, Y. S. Learning by example with hints. NIPS, 1989. 
Baum, E. B., & Haussler, D. What size net gives valid generalization?. NIPS, 1989. 
Cover, T. (June 1965). Geomeu'ical and statistical properties of systems of linear inequal- 
ities with applications in pattern recognition. IEEE Transactions on Electronic 
Computers, EC-14, 3,326-334. 
Judd, J. S. Complexity of connectionist learning with various node functions. Presented at 
the First IEEE International Conference on Neural Networks, San Diego, June 
1987. 
Medin, D. L., Altom, M. W., Edelson, S. M., & Freko, D. (1982). Correlated symptoms 
and simulated medical classification. Journal of Experimental Psychology: Learn- 
ing, Memory, & Cognition, 8(1), 37-50. 
Pavel, M., Gluck, M. A., & Henkle, V. Generalization by humans and multi-layer adap- 
tive networks. Submitted to Tenth Annual Conference of the Cognitive Science 
Society, August 17-19, 1988. 
Pavel, M., & Moore, R. T. (1988). Computational analysis of solutions of two-layer 
adaptive networks. APL Technical Report, Dept. of Psychology, Stanford Univer- 
sity. 
Valiant, L. G. (1984). A theory of the learnable. Comm. ACM, 27, 11, 1134-1142. 
Volper, D. J., & Hampson, S. E. (1987). Learning and using specific instances. Biological 
Cybernetics, 56,. 
", constraint adapt network model human gener payel gluck henkl psycholog univers ca potenti adapt network learn categor rule human perform studi compar natur system respond new like network learn determinist categor task altern individu analysi impos use network minim number hidden show conslxaint explain predict human found share human minim adapt analysi human network gener initi condit may provid import constraint new call describ find appropri initi investig potenti adapt network learn categor task model human particular studi natur system respond new paper describ comput techniqu analyz gener adapt given network structur given classif techniqu possibl network solut report result empir studi human categor gener human compar adapt cluster analysi human gener signific differ human perform possibl network examin role initi state bias solut found use data relat initi final perform develop new call show potenti model human process use adapt scope analys limit determinist pattern classif human gener basic difficulti gener exist mani differ classif rule correctli classifi train set categor novel number divers possibl solut depend defin pattern addit constraint use mani type pattern categor elimin hope typic way introduc addit constraint minim exampl minim number equat paramet mathemat number rule system would assur map would case adapt size adapt reduc number possibl encod may result improv gener perform critic theoret appli question pattern recognit involv implement desir first part paper analysi adapt network character solut space adapt network adapt network consid paper defin direct linear threshold unit node edg label output activ unit determin monoton nonlinear weight sum activ unit whose edg termin three type unit within layer input unit activ determin extern output unit whose activ taken remain call hidden sake simplic discuss limit object repres binari valu fulli connect network unlimit number hidden unit boolean gener provid addit constraint must impos prefer one gener one constraint minim order explor effect minim number hidden first identifi minim network architectur examin result area limit find bound expect possibl pattern could classifi given network baum bound found research hold possibl categor broad use analysi particular categor determin gener behavior particular network specif pavel henkl problem train set necessari find find possibl solut correspond use comput procedur develop pavel moor find minim network specif categor pavel moor defin two network differ least one hidden unit categor least one object set use definit algorithm find possibl differ find network solut larger payel moor use probabilist version algorithm estim gener way character waint gener term number larger number possibl solut indic gener less critic result analysi even minim number differ network solut often quit solut increas rapidli increas number hidden lack waint also demonstr find probabl randomli select hidden layer solv given categor suppos selgct differ hidden unit repres linear activ random hidden unit view input ask probabl output found perform desir typic exampl result analysi shown figur pariti minim configur involv three hidden unit differ solut pariti rapid increas probabl slope curv indicatea ad hidden unit rapidli increas probabl random hidden layer solv pariti unit prolmrfion solut pariti problem task function number hidden result detail analysi gener perform minim discuss follow descript categor experi human gener categor experi experi human subject learn object defin dimension binari possibl subject train subset object two categori object specif assign object categori pattern medin et shown figur eight pattern design train set remain eight compris test assign pattern train set two categori mani combin rule could use correctli perform first two dimens could use one train pattern could also categor basi exclus last two type solut obtain human subject determin examin respons test set well train set test set pattam medin et actual subject ask perform medic diagnosi four symptom experiment describ briefli detail experi describ elsewher pattern present serial subject respond one categori receiv train individu continu reach criterion consecut pattern presenwat data report half learn task criterion half train subject test use possibl test phase enabl us determin gener perform gener use estim may criterion use solut dimens use graph respons ensembl case group respons profil repres probabl assign pavel henkl categori respons profil xor solut figur conveni defin respons test set respons profil subject reach criterion figur respons criterion subject train set ident distribut gener profil reflect overal gener profil indic consider individu differ ol reslxms profil xor woport respons pattern humm subject minim pattern train set pattern test respons goal model distribut categor repres respons profil figur consid three natur approach minim disjunct normal form minim statist approach base assumpt tbe respons profil subject probabl categorizafion perform data assumpt subject appear behav second use minim dnf also good candid four solut respons profil solut differ turn adapt network solut use linear program techniqu describ minim adapt network capabl solv set problem consist two hidden proport solut human gener number hidden unit shown figur dash minim network differ solut gener assum network solut equal comput gener profil minim network shown respons profil minim network repres probabl select minim network assign given pattern categori even statist test conclud gener profil human quit human minim network similar solut differ averag respons due statist sampl assumpt use minim network equal order determin overlap solut examin profil analysi gener analyz similar solut defin metric gener distanc two profil equal number pattern distanc gener profil equal two profil differ fourth seventh figur show result cluster analysi hierarch cluster procedur maxim averag distanc result hiersrchic cluster human network gener graph averag distanc two cluster shown valu common node cluster analysi indic human pavel henkl obtain wide differ gener three gener found common human number common chanc human network solut even exist learn algorithm approxim human distribut minim network would good model perform clear previous describ network analysi somewhat larger network differ constraint could account human order character examin individu strategi find subject obtain differ human strategi learn strategi lead prefer particular solut may best network impos constraint provid hint includ choos network architectur learn constrain specifi initi focu initi hon xor erion type number consist respons stabl incorrect respons criterion never reach effort examin initi condit motiv larg differ learn et subject obtain xor solut subject obtain xor solut would perform much pattern xor wors pattern conclud subject first trial discov rule human gener categor train pattern correctli fail one two train examin sequenc respons see well adher design respons pattern stabl way pattern least four time design consist respons stabl result analysi shown figur result indic subject eventu achiev xor solut less like gener stabl incorrect anoth restfit subject never learn correct respons train respond systeanat use incorrect basi conclud initi strategi may determin final learn simplic identifi initi condit first import theoret question whether possibl find network initi condit learn rule network repres initi final behavior subject order studi problem develop techniqu call base perturb analysi use fact error surfac small neighborhood well approxim quadrat well behav ient procedur start point neighborhood minimum find revers learn consist three network train desir state particular use train test use train network train achiev initi state individu subject closest desir final state network train train pattern solut compar respons preliminari result indic procedur lead mani case initi favor desir current investig condit optim initi main goal studi examin constraint impos human network learn simpl binari categor character constraint analyz respons novel like network learn determinist categor task individu thu adapt network better model statist model dnf constraint impos minim appear differ impos human learner solut share human adapt detail analysi pavel henkl human learn process conclud initi condit may provid import fact consid set initi condit reduc number potenti without reduc potenti effect use perturb call revers find initi work support research grant nation scienc foundat gordon bower mark grant nasa ame stanford thank steve bob rehder use discuss comment learn exampl size net give valid statist properti system linear applic pattern ie transact electron complex connectionist learn variou node present first ie intern confer neural san june correl symptom simul medic journal experiment gener human submit tenth annual confer cognit scienc august comput analysi solut apl technic stanford theori learn use specif biolog,0
92,92,"11 
AN 
OPTIMALITY PRINCIPLE FOR 
UNSUPERVISED LEARNING 
Terence D. Sanger 
MIT AI Laboratory, NE43-743 
Cambridge, MA 02139 
(tds@wheaties.ai.mit.edu) 
ABSTRACT 
We propose an optimality principle for training an unsu- 
pervised feedforward neural network based upon maximal 
ability to reconstruct the input data from the network out- 
puts. We describe an algorithm which can be used to train 
either linear or nonlinear networks with certain types of 
nonlinearity. Examples of applications to the problems of 
image coding, feature detection, and analysis of random- 
dot stereograms are presented. 
1. INTRODUCTION 
There are many algorithms for unsupervised training of neural networks, each of 
which has a particular optimality criterion as its goal. (For a partial review, see 
(Hinton, 1987, Lippmann, 1987).) We have presented a new algorithm for training 
single-layer linear networks which has been shown to have optimality properties 
associated with the Karhunen-Love expansion (Sanger, 1988b). We now show 
that a similar algorithm can be applied to certain types of nonlinear feedforward 
networks, and we give some examples of its behavior. 
The optimality principle which we will use to describe the algorithm is based on the 
idea of maximizing information which was first proposed as a desirable property of 
neural networks by Linsker (1986, 1988). Unfortunately, measuring the information 
in network outputs can be difficult without precise knowledge of the distribution 
on the input data, so we seek another measure which is related to information 
but which is easier to compute. If instead of maximizing information, we try to 
maximize our ability to reconstruct the input (with minimum mean-squared error) 
given the output of the network, we are able to obtain some useful results. Note 
that this is not equivalent to maximizing information except in some special cases. 
However, it contains the intuitive notion that the input data is being represented 
by the network in such a way that very little of it has been ""lost"". 
12 Sanger 
2. LINEAR CASE 
We now summarize some of the results in (Sanger, 1988b). A single-layer linear 
feedforward network is described by an MxN matrix C of weights such that if x is 
a vector of N inputs and y is a vector of M outputs with M < N, we have y - Cx. 
As mentioned above, we choose an optimality principle defined so that we can best 
reconstruct the inputs to the network given the outputs. We want to minimize the 
mean squared error El(x- )2] where x is the actual input which is zero-mean with 
correlation matrix Q - E[xxT], and k is a linear estimation of this input given the 
output y. The linear least squares estimate (LLSE) is given by 
 = QCT(CQC)-y 
and we will assume that  is computed in this way for any matrix C of weights 
which we choose. The mean-squared error for the LLSE is given by 
E[(x - k)2] = Q - QCT(CQC)-CQ 
and it is well known that this is minimized if the rows of C are a linear combination of 
the first M eigenvectors of the correlation matrix Q. One optimal choice of C is the 
Singular Value Decomposition (SVD) of Q, for which the output correlation matrix 
E[yy T] - CQC T will be the diagonal matrix of eigenvalues of Q. In this case, the 
outputs are uncorrelated and the sum of their variances (traceE[yyT]) is maximal for 
any set of M uncorrelated outputs. We can thus think of the eigenvectors as being 
obtained by any process which maximizes the output variance while maintaining 
the outputs uncorrelated. 
We now define the optimal single-layer linear network as that network whose weights 
represent the first M eigenvectors of the input correlation matrix Q. The optimal 
network thus minimizes the mean-squared approximation error E[(x - )] given 
the shape constraint that M < N. 
2.1 LINEAR ALGORITHM 
We have previously proposed a weight-update rule called the ""Generalized Hebbian 
Algorithm"", and proven that this algorithm causes the rows of the weight matrix C 
to converge to the eigenvectors of the input correlation matrix Q (Sanger, 1988a,b). 
The algorithm is given by: 
C(t -t- 1) = C(t) -t- ? (y(t)x T (t) - LT[y(t)y T (t)]C(t)) 
(1) 
where ? is a rate constant which decreases as l/t, x(t) is an input sample vector, 
y(t) - C(t)x(t), and LT is an operator which makes its matrix argument lower 
triangular by setting all entries above the diagonal to zero. This algorithm can be 
implemented using only a local synaptic learning rule (Sanger, 1988b). 
Since the Generalized Hebbian Algorithm computes the eigenvectors of the input 
correlation matrix Q, it is related to the Singular Value Decomposition (SVD), 
An Optimality Principle for Unsupervised Learning 13 
Figure 1: (a) original image. (b) image coded at .36 bits per picel. (c) masks 
learned by the network which were used for vector quantized coding of 8c8 blocks of 
the image. 
Principal Components Analysis (PCA), and the Karhunen-Love Transform (KLT). 
(For a review of several related algorithms for performing the KLT, see (Oja, 1983).) 
2.2 IMAGE CODING 
We present one example of the behavior of a single-layer linear network. (This 
example appears in (Sanger, 1988b).) Figure 1 shows an original 256x256x8bit 
image which was used for training a network. 8x8 blocks of the image were chosen 
by scanning over the image, and these were used as training inputs to a network with 
64 inputs and 8 outputs. After training, the set of weights for each output (figure 
lc) represents a vector quantizing mask. Each 8x8 block of the input image is then 
coded using the outputs of the network. Each output is quantized with a number of 
bits related to the log of the variance, and the original figure is approximated from 
the quantized outputs. The reconstruction of figure lb uses a total of 23 bits per 8x8 
region, which gives a data rate of 0.36 bits per pixel. The fact that the image could 
be represented using such a low bit rate indicates that the masks that were found 
represent significant features which are useful for recognition. This image coding 
technique is equivalent to block-coded KLT methods common in the literature. 
14 Sanger 
3. NONLINEAR CASE 
In general, training a nonlinear unsupervised network to approximate nonlinear 
functions is very difficult. Because of the large (infinite-dimensional) space of pos- 
sible functions, it is important to have detailed knowledge of the class of functions 
which are useful in order to design an efficient network algorithm. (Several peo- 
ple pointed out to me that the talk implied such knowledge is not necessary, but 
unfortunately such an implication is false.) 
The network structure we consider is a linear layer represented by a matrix C (which 
is perhaps an interior layer of a larger network) followed by node nonlinearities a(Yi) 
where y is the i h linear output, followed by another linear layer (perhaps followed 
by more layers). We assume that the nonlinearities a() are fixed, and that the only 
parameters susceptible to training are the linear weights C. 
If z is the M-vector of outputs after the nonlinearity, then we can write each com- 
ponent z -- (yi) -- (cix) where ci is the i h row of the matrix C. Note that 
the level contours of each function zi are determined entirely by the vector c, and 
that the effect of a 0 is limited to modifying the output value. Intuitively, we thus 
expect that if Yi encodes a useful parameter of the input x, then zi will encode the 
same parameter, although scaled by the nonlinearity a(). 
This can be formalized, and if we choose our optimality principle to again be min- 
imum mean-squared linear approximation of the original input x given the output 
z, the best solution remains when the rows of C are a linear combination of the first 
M eigenvectors of the input correlation matrix Q (Bourlard and Kamp, 1988). 
In two of the simulations, the nonlinearity a() which we use is a rectification non- 
linearity, given by 
y if y>O 
0 if 
Note that at most one of {er(yi), er(-y)} is nonzero at any time, so these two values 
are uncorrelated. Therefore, if we maximize the variance of y (before the nonlin- 
earity) while maintaining the elements of z (after the nonlinearity) uncorrelated, 
we need 2M outputs in order to represent the data available from an M-vector y. 
Note that 2M may be greater than the number of inputs N, so that the ""hidden 
layer"" z can have more elements than the input. 
3.1 NONLINEAR ALGORITHM 
The nonlinear Generalized Hebbian Algorithm has exactly the same form as for 
the linear case, except that we substitute the use of the output values after the 
nonlinearity for the linear values. The algorithm is thus given by: 
C(t + 1)= C()+ ? (z()xT()- LT[z(t)zT(t)lC(t)) (2) 
where the elements of z are given by z() = er(yi()), with y() = C()x(t). 
Although we have not proven that this algorithm converges, a heuristic analysis 
of its behavior (for a rectification nonlinearity and Gaussian input distribution) 
An Optimality Principle for Unsupervised Learning 15 
shows that stable points may exist for which each row of (7 is proportional to 
an eigenvector of Q, and pairs of rows are either the negative of each other or 
orthogonal. In practice, the rows of C are ordered by decreasing output variance, 
and occur in pairs for which one member is the negative of the other. This choice 
of C will maximize the sum of the output variances for uncorrelated outputs, so 
long as the input is Gaussian. It also allows optimal linear estimation of the input 
given the output, so long as both polarities of each of the eigenvectors are present. 
3.2 NONLINEAR EXAMPLES 
3.2.1 Encoder Problem 
We compare the performance of two nonlinear networks which have ]earned to 
perform an identity mapping (the ""encoder"" problem). One is trained by back- 
propagation, (Rumelhart et al., 1986) and the other has two hidden layers trained 
using the unsupervised Hebbian algorithm, while the output layer is trained using 
a supervised LMS algorithm (Widrow and Hoff, 1960). The network has 5 inputs, 
two hidden layers of 3 units each, and 5 outputs. There is a sigmoid nonlinearity at 
each hidden layer, but the thresholds are all kept at zero. The task is to minimize 
the mean-squared difference between the inputs and the outputs. The input is a 
zero-mean correlated Gaussian random 5-vector, and both algorithms are presented 
with the same sequence of inputs. The unsupervised-trained network converged to a 
steady state after 1600 examples, and the backpropagation network converged after 
2400 (convergence determined by no further decrease in average error). The RMS 
error at steady state was 0.42 for both algorithms (this figure should be compared to 
the sum of the variances of the inputs, which was 5.0). Therefore, for this particular 
task, there is no significant difference in performance between backpropagation and 
the Generalized Hebbian Algorithm. This is an encouraging result, since if we can 
use an unsupervised algorithm to solve other problems, the training time will scale 
at most linearly with the number of layers. 
3.2.2 Nonlinear Receptive Fields 
Several investigators have shown that Hebbian algorithms can discover useful image 
features related to the receptive fields of cells in primate visual cortex (see for 
example (Bienenstock et at, 1982, Linsker, 1986, Barrow, 1987)). One of the more 
recent methods uses an algorithm very similar to the one proposed here to find the 
principal component of the input (Linsker, 1986). We performed an experiment to 
find out what types of nonlinear receptive fields could be learned by the Generalized 
Hebbian Algorithm if provided with similar input to that used by Linsker. 
We used a single-layer nonlinear network with 4096 inputs arranged in a 64x64 
grid, and 16 outputs with a rectification nonlinearity. The input data consisted of 
images of low-pass filtered white Gaussian noise multiplied by a Gaussian window. 
After 5000 samples, the 16 outputs ]earned the masks shown in figure 2. These 
masks possess qualitative similarity to the receptive fields of cells found in the visual 
cortex of cat and monkey (see for example (Andrews and Pollen, 1979)). They are 
equivalent to the masks learned by a purely linear network (Sanger, 1988b), except 
that both positive and negative polarities of most mask shapes are present here. 
16 Sanger 
Figure �: Nonlinear receptive fields ordered from left-to-right and top-to-bottom. 
3.2.3 Stereo 
We now show how the nonlinear Generalized Hebbian Algorithm can be used to 
train a two-layer network to detect disparity edges. The network has 128 inputs, 
8 types of unit in the hidden layer with a rectification non]inearity, and 4 types of 
output unit. A 128x128 pixel random-dot stereo pair was generated in which the 
left half had a disparity of two pixels, and the right half had zero disparity. The 
image was convolved with a vertically-oriented elliptical Gaussian mask to remove 
high-frequency vertical components. Corresponding 8x8 blocks of the ]eft and right 
images (64 pixels from each image) were multiplied by a Gaussian window function 
and presented as input to the network, which was allowed to learn the first layer 
according to the unsupervised algorithm. After 4000 iterations, the first layer had 
converged to a set of 8 pairs of masks. These masks were convolved with the images 
(the left mask was convolved with the left image, and the right mask with the right 
image, and the two results were summed and rectified) to produce a pattern of 
activity at the hidden layer. (Although there were only 8 types of hidden unit, we 
now allow one of each type to be centered at every input image location to obtain a 
pattern of total activity.) Figure 3 shows this activity, and we can see that the last 
four masks are disparity-sensitive since they respond preferentially to either the 2 
pixel disparity or the zero disparity region of the image. 
An Optimality Principle for Unsupervised Learning 17 
Figure 3: Hidden layer response for a two-layer nonlinear network trained on stereo 
images. The left half of the input random dot image has a � pixel disparity, and the 
right half has zero disparity. 
Figure d: Output layer response for a two-layer nonlinear network trained on stereo 
images. 
Since we were interested in disparity, we trained the second layer using only the last 
four hidden unit types. The second layer had 1024 (=4x16x16) inputs organized as 
a 16x16 receptive field in each of the four hidden unit ""planes"". The outputs did not 
have any nonlinearity. Training was performed by scanning over the hidden unit 
activity pattern (successive examples overlapped by 8 pixels) and 6000 iterations 
were used to produce the second-layer weights. The masks that were learned were 
then convolved with the hidden unit activity pattern to produce an output unit 
activity pattern, shown in figure 4. 
The third output is clearly sensitive to a change in disparity (a depth edge). If we 
generate several different random-dot stereograms and average the output results, 
18 Sanger 
Figure 5: Output layer response averaged over ten stereograms with a central � pixel 
disparity square and zero disparity surround. 
we see that the other outputs are also sensitive (on average) to disparity changes, but 
not as much as the third. Figure 5 shows the averaged response to 10 stereograms 
with a central 2 pixel disparity square against a zero disparity background. Note 
that the ability to detect disparity edges requires the rectification nonlinearity at 
the hidden layer, since no linear function has this property. 
4. CONCLUSION 
We have shown that the unsupervised Generalized Hebbian Algorithm can produce 
useful networks. The algorithm has been proven to converge only for single-layer 
linear networks. However, when applied to nonlinear networks with certain types 
of nonlinearity, it appears to converge to good results. In certain cases, it operates 
by maintaining the outputs uncorrelated while maximizing their variance. We have 
not investigated its behavior on nonlinearities other than rectification or sigmoids, 
so we can make no predictions about its general utility. Nevertheless, the few 
examples presented for the nonlinear case are encouraging, and suggest that further 
investigation of this algorithm will yield interesting results. 
Acknowledgement s 
I would like to express my gratitude to the many people at the NIPS conference 
and elsewhere whose comments, criticisms, and suggestions have increased my un- 
derstanding of these results. In particular, thanks are due to Ralph Linsker for 
pointing out to me an important error in the presentation and for his comments on 
the manuscript, as well as to John Denker, Steve Nowlan, Rich Sutton, Tom Breuel, 
and my advisor Tomaso Poggio. 
This report describes research done at the MIT Artificial Intelligence Laboratory, 
and sponsored by a grant from the Office of Naval Research (ONR), Cognitive 
and Neural Sciences Division; by the Alfred P. Sloan Foundation; by the National 
Science Foundation; by the Artificial Intelligence Center of Hughes Aircraft Cor- 
poration (S1-801534-2); and by the NATO Scientific Affairs Division (0403/87). 
Support for the A. I. Laboratory's artificial intelligence research is provided by the 
An Optimality Principle for Unsupervised Learning 19 
Advanced Research Projects Agency of the Department of Defense under Army con- 
tract DACA76-85-C-0010, and in part by ONR contract N00014-85-K-0124. The 
author was supported during part of this research by a National Science Foundation 
Graduate fellowship, and later by a Medical Scientist Training Program grant. 
References 
Andrews B. W., Pollen D. A., 1979, Relationship between spatial frequency selec- 
tivity and receptive field profile of simple cells, J. Physiol., 287:163-176. 
Barrow H. G., 1987, Learning receptive fields, In Proc. IEEE 1st Ann. Conference 
on Neural Networks, volume 4, pages 115-121, San Diego, CA. 
Bienenstock E. L., Cooper L. N., Munro P. W., 1982, Theory for the development 
of neuron selectivity: Orientation specificity and binocular interaction in visual 
cortex, J. Neuroscience, 2(1):32-48. 
Bourlard H., Kamp Y., 1988, Auto-association by multilayer perceptrons and sin- 
gular value decomposition, Biological Cybernetics, 59:291-294. 
Hinton G. E., 1987, Connectionist learning procedures, CMU Tech. Report CS-87- 
115. 
Linsker R., 1986, From basic network principles to neural architecture, Proc. Natl. 
Acad. Sci. USA, 83:7508-7512. 
Linsker R., 1988, Self-organization in a perceptual network, Compuler, 21(3):105- 
117. 
Lippmann R. P., 1987, An introduction to computing with neural nets, IEEE ASSP 
Magazine, pages 4-22. 
Oja E., 1983, Subspace Methods of Pattern Recognition, Research Studies Press, 
UK. 
Rumelhart D. E., Hinton G. E., Williams R. J., 1986, Learning representations by 
back-propagating errors, Nature, 323(9):533-536. 
Sanger T. D., 1988a, Optimal unsupervised learning, Neural Networks, 1(S1):127, 
Proc. 1st Ann. INNS meeting, Boston, MA. 
Sanger T. D., 1988b, Optimal unsupervised learning in a single-layer linear feedfor- 
ward neural network, submitted to Neural Networks. 
Widrow B., Hoff M. E., 1960, Adaptive switching circuits, In IRE WESCON Cony. 
Record, Part ., pages 96-104. 
", principl learn sanger ai propos optim principl train feedforward neural network base upon maxim reconstruct input data network describ algorithm use train linear nonlinear network certain type exampl applic problem featur analysi stereogram introduct mani algorithm unsupervis train neural particular optim criterion partial see present new algorithm train linear network shown optim properti expans show similar algorithm appli certain type nonlinear feedforward give exampl optim principl use describ algorithm base maxim inform first propos desir properti network linsker measur inform network output difficult without precis knowledg distribut input seek anoth measur relat inform easier instead maxim tri abil reconstruct input minimum output abl obtain use note equival maxim inform except special contain intuit notion input data repres network way littl sanger linear case summar result linear network describ matrix weight vector input vector output mention choos optim principl defin best input network given want minim squar error actual input matrix linear estim input given linear least squar estim given assum comput way matrix weight error llse given well known minim row linear combin first eigenvector correl matrix one optim choic valu decomposit output correl matrix cqc diagon matrix eigenvalu uncorrel sum varianc maxim set uncorrel thu think eigenvector process maxim output varianc maintain output defin optim linear network network whose weight first eigenvector input correl matrix optim thu minim approxim error given shape constraint linear algorithm previous propos rule call hebbian proven algorithm caus row weight matrix converg eigenvector input correl matrix algorithm given rate constant decreas input sampl oper make matrix argument lower set entri diagon algorithm use local synapt learn rule gener hebbian algorithm comput eigenvector input matrix relat singular valu decomposit optim principl unsupervis learn origin imag code bit per mask network use vector quantiz code block compon analysi transform review sever relat algorithm perform see imag code present one exampl behavior linear appear figur show origin use train block imag chosen scan use train input network input set weight output repres vector quantiz block input imag use output output quantiz number relat log origin figur approxim quantiz reconstruct figur lb use total bit per give data rate bit per fact imag could repres use low bit rate indic mask found signific featur use imag code equival klt method common sanger nonlinear case train nonlinear unsupervis network approxim nonlinear larg space import detail knowledg class function use order design effici network point talk impli knowledg implic network structur consid linear layer repres matrix perhap interior layer larger follow node nonlinear linear follow anoth linear layer follow assum nonlinear suscept train linear weight output write ci row matrix note level contour function zi determin entir vector effect limit modifi output thu yi encod use paramet input zi encod although scale nonlinear choos optim principl linear approxim origin input given output best solut remain row linear combin first eigenvector input correl matrix two nonlinear use rectif given one nonzero two valu maxim varianc maintain element need output order repres data avail may greater number input element nonlinear algorithm nonlinear gener hebbian algorithm exactli form linear except substitut use output valu linear algorithm thu given element given proven algorithm heurist analysi behavior rectif nonlinear gaussian input optim principl unsupervis learn stabl point may exist row proport eigenvector pair row either neg row order decreas output occur pair one member neg choic maxim sum output varianc uncorrel input also allow optim linear estim input long polar eigenvector nonlinear exampl encod problem compar perform two nonlinear network ident map one train et two hidden layer train unsupervis hebbian output layer train use supervis lm algorithm network hidden layer unit sigmoid nonlinear hidden threshold kept task minim differ input input correl gaussian random algorithm present sequenc network converg state backpropag network converg determin decreas averag rm steadi state algorithm figur compar sum varianc particular signific differ perform backpropag gener hebbian encourag sinc unsupervis algorithm solv train time scale linearli number nonlinear recept field investig shown hebbian algorithm discov use imag relat recept field cell primat visual cortex et one method use algorithm similar one propos find compon input perform experi type nonlinear recept field could learn gener algorithm provid similar input use use nonlinear network input arrang output rectif input data consist filter white gaussian nois multipli gaussian output mask shown figur possess qualit similar recept field cell found visual cat monkey exampl mask learn pure linear network except posit neg polar mask shape present sanger nonlinear recept field order stereo show nonlinear gener hebbian algorithm use network detect dispar network type unit hidden layer rectif type pixel stereo pair gener half dispar two right half zero convolv ellipt gaussian mask remov vertic correspond block right pixel multipli gaussian window function present input allow learn first layer unsupervis first layer set pair mask convolv imag left mask convolv left right mask right two result sum produc pattern hidden type hidden allow one type center everi input imag locat obtain total figur show see last mask sinc respond preferenti either dispar zero dispar region optim principl unsupervis learn hidden layer respons nonlinear network train stereo left half input random dot imag pixel half zero output layer respons nonlinear network train stereo interest train second layer use last hidden unit second layer input organ recept field four hidden unit output train perform scan hidden unit pattern exampl overlap iter use produc mask learn convolv hidden unit activ pattern produc output unit shown figur third output clearli sensit chang dispar depth sever differ stereogram averag output sanger output layer respons averag ten stereogram central pixel squar zero dispar see output also sensit dispar much figur show averag respons stereogram central pixel dispar squar zero dispar note abil detect dispar edg requir rectif nonlinear hidden sinc linear function conclus shown unsupervis gener hebbian algorithm produc algorithm proven converg appli nonlinear network certain type appear converg good certain oper maintain output uncorrel maxim investig behavior nonlinear rectif make predict gener present nonlinear case suggest algorithm yield interest would like express gratitud mani peopl nip confer elsewher whose suggest increas thank due ralph linsker import error present comment well john steve rich tom advisor tomaso report describ research done mit artifici intellig sponsor grant offic naval research cognit neural scienc alfr sloan nation artifici intellig center hugh aircraft nato scientif affair divis artifici intellig research provid optim principl unsupervis learn research project agenc depart defens armi part onr contract support part research nation scienc foundat later medic scientist train program pollen relationship spatial frequenc recept field profil simpl learn recept ie confer neural volum page san cooper munro theori develop neuron orient specif binocular interact visual kamp multilay perceptron valu biolog connectionist learn cmu report basic network principl neural perceptu introduct comput neural ie assp page subspac method pattern research studi hinton william learn represent optim unsupervis neural inn optim unsupervis learn linear neural submit neural hoff adapt switch ire wescon part page,2
93,93,"2O 
ASSOCIATIVE LEARNING 
VIA INHIBITORY SEARCH 
David H. Ackley 
Bell Communications Research 
Cognitive Science Research Group 
ABSTRACT 
ALVIS is a reinforcement-based connectionist architecture that 
learns associative maps in continuous multidimensional environ- 
ments. The discovered locations of positive and negative rein- 
forcements are recorded in ""do be"" and ""don't be"" subnetworks, 
respectively. The outputs of the subnetworks relevant to the cur- 
rent goal are combined and compared with the current location to 
produce an error vector. This vector is backpropagated through 
a motor-perceptual mapping network to produce an action vec- 
tor that leads the system towards do-be locations and away from 
don't-be locations. ALVIS is demonstrated with a simulated robot 
posed a target-seeking task. 
INTRODUCTION 
The ""backpropagatlon algorithm"" or generalized delta rule (Rumelhart, Hinton, & 
Williams, 1986) is sometimes criticized on the grounds that it is a ""supervised"" 
learning algorithm, which requires a ""teacher"" to provide correct outputs, and 
apparently leaves open the question of how the teacher learned the right answers. 
However, work by Rumelhart (personal communication, 1987) and Miyata (1988) 
has shown how the environment that a system is embedded in can serve as the 
""teacher."" If, as in this paper, a backpropagation network is posed the task of 
mapping from a vector t of robot arm joint angles to the resulting vector X of 
arm coordinates in space (the 'forward kinematics problem""), then input-output 
training data can be obtained by supplying sets of joint angles to the arm and 
observing the resulting configurations. 
Although this ""environment as teacher"" strategy shows how a ""teacher"" can come to 
possess useful information without an infinite regress learning it, it is not a complete 
solution. There are problems for which the ""laws of physics"" of an environment 
do not suffice to determine the solution. Suppose, for example, that a robot is 
posed the problem of learning to reach for different positions in space depending 
on which of a set of signals is currently presented, and that the only feedback 
available from the environment is success or failure information about the current 
arm configuration. 
Associative Learning via Inhibitory Search 21 
c b 
d a 
Figure 1. A ""trunk"" robot. 
What is needed in such a case is a mechanism to search through the space of possi- 
ble arm configurations, recording the successful configurations associated with the 
various inputs. A�VIS  Associative Learning Via Inhibitory Search -- provides 
one such mechanism. The next section applies backpropagation to the t? -- X map- 
ping and shows how the resulting network can sometimes be used to solve X -- t 
problems. The third section, ""Self-supervision and inhibitory search,"" integrates 
that network into the overall A�VIS algorithm. The final section contains some 
discussion and conclusions. An expanded version of this paper may be found in 
Acldey (1988). 
FORWARD AND INVERSE KINEMATICS 
The inverse kinematics problem in controlling an arm is the problem of determining 
what joint angles are needed to produce a specific position and orientation of a hand. 
In the general case it is a difficult problem. An itch on your back suggests the kinds 
of questions that arise. Which hand should you use? Should you go up from around 
your waist, or down from over your shoulders? Can you be sure you know what 
will work without actually trying it? 
From a computational standpoint, forward kinematics  deciding where your limbs 
will end up given a set of joint angles -- is an easier problem. 
Figure 1 depicts the planar ""robot"" that was used in this work. I call it the ""trunk"" 
robot. (The work discussed in Ackley (1988) also used a two-handed ""pincer"" 
robot.) Of course, the trunk is a far cry from a real robot, and the only significant 
constraint is that the possible joint angles are limited, but this suffices to pose 
non-trivial kinematics problems. The trunk has five joints, and each joint angle is 
limited to a range of 4 � to 176 � with respect to the previous limb. 
I simulated a backpropagation network with five real-valued input units (the joint 
angles), sixty hidden units in a single layer, and twelve linear output units (the 
Cartesian joint positions). Joint angles were expressed in radians, so the range of 
input unit values was from about 0.07 to about 3.07. The configuration vector X 
was represented by twelve output units corresponding to six pairs of (,//) coordi- 
22 Ackley 
Figure 2. A ""logarithmic strobe"" display of the trunk's asymptotic convergence on 
a specified position and orientation. The arm position is displayed after iterations 
1,2,4, 8,... ,256. 
nates, one pair for each joint a through f. With the trunk robot (though not with 
the ""pincer"") f and fy have constant values, since they end up being part of the 
""anchor."" The state of an output unit equals the sum of its inputs, and the error 
propagated out of an output unit equals the error propagated into it. 
Errors were defined by the difference between the predicted configuration and the 
actual configuration, and after extensive training on the trunk robot forward kine- 
matics problem, the network achieved high accuracy over most of the joint ranges. 
In typical backpropagation applications, once the desired mapping has been learned, 
the backward ""error channels"" in the network are no longer used. However, suppose 
some other error computation, different from that used to train the weights, was 
then incorporated. Those errors can be propagated from the outputs of the trained 
network all the way back to the inputs. The goal is no longer to change weights 
in the network -- since they already represent a useful mapping -- but to use the 
trained network to translate output-space errors, however defined, into errors at 
the inputs to the network. 
Figure 2 illustrates one use of this process, showing how a trained forward kine- 
matics network can be used to perform a cheap kind of inverse kinematics. The 
figure shows superimposed outputs of the trained network under the influence of 
a task-specific error computation; in this case the trunk is trying to reduce the 
distances between the front and back of a ""target arrow"" and the front and back 
of its first arm section. The target arrow is defined by a head (h, hy) and a tail 
(t,ty). The errors for output units a and % are defined by e(a) = h-a and 
e(%) = by-%, the errors for output units b and by are defined by e(b) = t-b 
and e(by) -- ty - by, and the errors at all other outputs are set to zero. 
The algorithm used to generate this behavior has the following steps: 
1. Compute errors for one or more output units based on the current positions 
of the joints and the desired positioning and orienting information. If ""close 
Associative Learning via Inhibitory Search 23 
Figure 3. The trunk kinking itself. 
enough"" to the target, exit, otherwise, store these errors on the selected 
output units, and set the other error terms to zero. 
2. Backpropagate the errors all the way through the network to the input 
units. This produces an error term e(i) for each joint angle t i. Produce 
new joint angles: t; - t i -- ke(ti) where k is a scaing constant. Clip the 
joint angles against their minimum and maximum values. 
3. Forward propagate through the network bosed on the new joint angles, to 
produce new current positions for the joints. Go to step 1. 
Whereos the training phose has forward propagation of activations (states) followed 
by back propagation of errors, this usage reverses the order. Backpropagation of 
errors is followed by changes in inputs followed by forward propagation of activa- 
tions. This is a general gradient descent technique usable when a backpropagation 
network can learn to map from a control space t to an error or evaJuation space X. 
Figure 3 illustrates how gradient descent's familiar limitation can manifest itself: 
The tazget is reachable but the robot fails to reach it. The initiaJ configuration 
was such that while approaching the target, the trunk kinked itself too short to 
reach. If the robot had ""thought""to open t3 instead of closing it, it could have 
succeeded. In that sense, the problem arises because the error computation only 
specified errors for the tip of the trunk, and not for the rest of the arm. If, instead, 
there were indications where a//of the joints were to be placed, failures due to local 
minima could be greatly reduced. 
SELF-SUPERVISION AND INHIBITORY SEARCH 
The feedback control network of the previous section locally minimizes joint position 
errors -- however they are generated -- by translating them into joint angle space 
and moving downhill. A�VI$ uses the feedback control network for arm control; 
this section shows how A�VI$ learns to generate appropriate joint position space 
errors given only a reinforcement signal. There are two key points. The first is 
this: Once an action producing a positive reinforcement hos somehow been found, 
24 Ackley 
the problem reduces to associative mapping between the input and the discovered 
correct output. In ALVI$, ""do-be units"" are used to record such successes. The 
second point is this: When negative reinforcement occurs, the current configuration 
can be associated with the input in a behavior-reversed fashion -- as a place to 
avoid in the future. In ALVI$, ""don't-be units"" are used to record such failures. 
The overall idea, then, is to perform inhibitory search by remembering failures as 
they occur and avoiding them in the future, and to perform associative learning 
by remembering successful configurations as the search process uncovers them and 
recreating them in the future. In effect, ALVIS constructs input-dependent ""attrac- 
tors""at arm configurations associated with success and ""repellots"" at configurations 
associated with failure. Figure 4 summarizes the algorithm. A few points to note 
are these: 
The do-be and don't-be units use the spherical non-linear function explored by 
Burr & Hanson (1987). The response of a spherical unit is may..imal and equal to 
one when the input vector and the weight vector are identical. The response of 
the unit decreases monotonically with the Euclidean distance between the two 
vectors, and the roAius r governs the rate of decay. 
The don't-be units of each subnetwork (i.e., relevant to one goal) are in a com- 
petitive network (see, e.g., Feldman 1982). The don't-be unit with the largest 
activation value (which is a function of both the distance from the current posi- 
tion and the radius) is the only don't-be unit that has effects on the rest of the 
system. In the simulations reported here, I used rn - 4 don't-be units per goal. 
In addition to the parameters associated with spherical units, each do-be and 
don't-be unit has a strength parameter s that specifies how much influence the 
unit has over the behavior of the arm. Do-be strength (st + ) grows logarithmi- 
cally with positive reinforcement and shrinks linearly with negative; don't-be 
strength (s) grows logarithmically with negative reinforcement and shrinks lin- 
early with positive. 
Figure 5 illustrates a situation from early in a run of the system. From left to right, 
the three displays show the state of the relevant do-be unit, the relevant don't-be 
subnetwork, and the current configuration of the arm. Since this particular goal 
has never been achieved before, the do-be map provides no useful information -- 
its weight vector contains small random values (as it happens, the origin is below 
and right of the display) and its strength is zero. The display of the don't-be map 
shows the positions of all four relevant don't-be units, with the currently selected 
don't-be (unit number 3) drawn somewhat darker. The don't-be units are spread 
around configuration space, creating ""hills"" that push away the arm if it comes 
too close. As the arm moves about without reaching the target, different don't-be 
units win the competition and take control. Negative reinforcement accrues, and 
the winning don't-be consequently moves toward the various current configurations 
and gets stronger, until the arm is pushed elsewhere. 
Figure 6 illustrates the behavior of the system after more extensive learning. The 
Associative Learning via Inhibitory Search 25 
Figure 4. A�VIS 
O. (Initialize) Given: a space X of h dimensions, a backpropagation network 
trained on 0 --* X, a set O of goals and a mapping from O to regions of 
space. Create an A�VIS network with n = IOl goal units 91,-.-, g,, n do- 
be/don't-be subnetworks consisting of one do-be unit df and m don't-be 
units d,...,d-m, and h current position units Zl,...zh. Create modi- 
fiable connections wi from z's to d's, wi from d's to z's, and a modi- 
fiable strength s for each d. Set all do-be strengths st + and all don't-be 
strengths st'  to zero. Set all weights wzi and wiz to small random values. 
Set 0 to a random legal vector and produce a current configuration X. 
1. (New stimulus) Choose t at random from 1... 
2. (Do's/Don'ts) Compute activations for do-he's and don't-he's using the 
spherical function: d = 1/ 1 + /-i=l(zi - we:i) 2 . In subnetwork t, 
let d/. be the unit with the largest activation. 
3. (Errors) Let w. + denote the weights from dt+ and w:- denote the weights 
from d,, and similarly for strengths s + and st' . Compute errors for each 
component of X: e() = s+(w+ - z) + s?.( - w). 
4. (Move) Backpropagate to produce e(0). Generate angle changes: A0 i = 
min(q,max(-q,k,.e(Oi))), with parameters q and k,.. Generate new an- 
gles respecting the maximum v/+ and minimum v- possible joint angles: 
O = min(vi+,max(v-,Oi + AOi) ). Forward propagate to produce a new 
configuration X'. 
5. (Positive reint'orcement) Determine whether X' satisfies goal t. If it does 
not, go to step 6. Otherwise, 
+ ' and 
5.1 Fori-1,...,h, letw =:i we:- 
5.2 Let s+'= rain (5, s + + p+/(1 + s+)), for positive reinf p+ > O. 
5.3 Let '+ = :o/max(.1, s+'), with parameter :o. 
-' max(O, -p+),and- ko/max(.X,-' 
-- -- - ' $ti )' 
5.4 For i 1, ..., m, let sti sti 
5.5 Go to step 1. 
6. (Negative reinforcement) Perform the following: 
_ _ _, _ +(+ 
6.1 For i - 1,...,h, let wi' - Wie: + r(z- w) and wi - we: * 
r(z' i - w+i) with parameter r, where  is a uniform random variable 
between +0.01. 
6.2 Let s-'- min (5, s- + p-/(1 + s-)), for negative reinf p-  0. 
6.$ Let q- = o/max(.1, -'). 
.a Uet +'= m(0, +-p-), ad + = o/m(0., ?'). 
6.5 Go to step 2. 
26 Ackley 
Do Be: 0.000000 
Don't B: 3 1.294703 Be 
Figure 5. A display of the internal state of the trunk robot in the process of 
learning to sociate a set of twelve arbitrary stimuli with specified positions in 
space. The current signal (though the system h not discovered this yet) means 
""touch 5"" 
Do Be: .998667 
Don't Be: 3 0.007976 Be 
Figure 6. A display of the internal state of the same trunk robot later in the 
learning process. The previous goal w ""touch *"" and the current goal is ""touch 
3.  
do-be map now contains an accurate image of a successful configuration for the 
""touch 3  goal, and its strength is high. The strength of the selected don't-be 
unit is low. The current configuration map in Figure 6 shows each iteration of the 
algorithm between the time it achieved its previous goal and the time it achieved 
the current goal. 
Finally, Figure 7 displays the average time-per-goal  a function of the number of 
goals achieved. For 75 repetitions, the trunk network w initialized and run until 
500 goals had been achieved, and the resulting time-per-goal data w averaged to 
produce the graph. 
The average time-per-goal declines rapidly as goals are presented, then seems to 
rise slightly, and then stabilizes around an average value of about $00. To have 
some kind of standard of comparison, albeit unsophisticated, if the joint angles are 
simply changed by uniform random values between q and -q (see Figure 4) on each 
iteration, the average time-per-goal is observed to be about 490. 
Associative Learning via Inhibitory Search 27 
2700 
2400 
2100 
1800 
1500 
1200 
900 
600 
300 
0 
0 I100 EO0 00 I00 500 
Figure 7. A graph of the average time taken per goM as a function of the number 
of goals achieved. The horizontM line shows the average performance of random 
joint changes. 
DISCUSSION 
ALVIS is a preliminary, exploratory system. Of course, the ALVIS environment 
is but a pole shadow of the real world, but even granting the limited scope of the 
problem formulation, several pects of ALVIS are incompletely satisfying and in 
need of improvement. 
To my eye, the biggest drawback of the current implementation is the loc goal 
representation -- which essentially requires that the set of go,xls be enumerable at 
network definition time. Related problems include the inability to share information 
between one goal and another and the inability to pursue more than one goal 
simultaneously. To determine behavior, the constraints of goals must be integrated 
with the possibilities of the current situation. In ALVIS this is done  a strictly 
two-step process: the gooJ selects a subnetwork, and the current situation selects 
units within the subnetwork. Work such  Jordan (1986) and Miyata (1988) shows 
how goal information and context information can be integrated by supplying both 
as inputs to a single network. 
A LVI$ is a pure feedback control model, and can suffer from the traditional problem 
of that approach: when the errors are small, the resulting joint angle changes are 
small, and the arm converges only slowly. If the gin at the joints is increded 
to speed convergence, overshoot and oscillation become more likely. However, in 
ALVI$ oscillations gradually die out, as don't-be units shift positions under the 
negative reinforcement, and sometimes such temporary oscillations actually help 
with the search, causing the tip of the arm to explore a variety of different points. 
28 Ackley 
The aspect of ALVIS behavior that I find most irritating reveals something about 
the approach in general. In some cases -- usually on more ""peripheral""targets 
 ALVIS learns to hit the very edge of the target region. While approaching 
such targets, ALVIS experiences negative reinforcement, and the don't-be units, 
consequently, gain a little strength. The resulting interference occasionally causes 
a very long search for a goal that had previously been rapidly achieved. ALVIS 
has a representation only for its own body; a better system would also be able to 
represent other objects in the world, and useful relations on the expanded set. The 
""mostly motor""emphasis evident in the present system needs to be balanced by 
more sophistication on the perceptual side. 
Though limited in scope, ALVIS demonstrates three ideas I think worth highlight- 
ing: 
� The reuse of the error channel of a backpropagation network, after training, for 
translating arbitrary output-space gradients into input-space gradients. 
� The recording of previous actual outputs to be used as future desired outputs. 
� The use of ""repellots""(don't-be units) as well as attractors in defining errors, and 
the resulting process of search-by-inhibition generated by negative reinforcement. 
Characterizing the behavior of a machine in terms of attractor dynamics is a familiar 
notion, but ""repellot dynamics""seems to be largely unknown territory. Indeed, in 
ALVIS there is an ephemeral quality to the don't-be units: When all answers have 
been discovered, all strength accrues to the do-be's, good performances become 
routine, and ALVIS behavior is essentially attractor-based. In watching such a 
""grown-up"" ALVIS, it is easy to forget how it was in the beginning, when the world 
was big and answers were scarce, and ALVIS was doing well just to discover a new 
mistake. 
References 
Acldey, D.H. (1988). Associative learning via inhibitory search. Technical memorandum TM 
AHH-012509, Morristown, N J: Bell Communications Hesearch. 
Burr, D.J., & Hanson, S.J. (1987). Knowledge representation in connection/st networks. Technical 
memorandum TM-AHH-008733, Morristown, N J: Bell Communications Hesearch. 
Feldman, J.A. (1982). Dynamic connections in neural networks. Biological Cybernetics, 36, 193- 
202. 
Jordan, M.I. (1986). Serial order: A parallel, distributed processing approach. Technical report 
ICS-8604. La Jolla, CA: University of California, Institute for Cognitive Science. 
Miyata, Y. (1988). The learning and planning of actions. Unpublished doctoral dissertation in 
psychology, University of California San Diego. 
Rumelhart, D.E., Hinton, G.E., & Williams, Rl. (1986). Learning representations by back- 
propgatlng errors. Nature, 323, 533-536. 
Humelhart, D.E. (personal commun/catlon, 1987). Also cited as personal communication/n Miy- 
ata (lSS). 
", learn inhibitori search ackley commun research scienc research group connectionist architectur associ map continu multidimension discov locat posit neg record output subnetwork relev goal combin compar current locat error vector backpropag map network produc action lead system toward locat away alvi demonstr simul robot gener delta rule sometim critic ground requir provid correct leav open question teacher learn right work rumelhart miyata shown environ system embed serv backpropag network pose task vector robot arm joint angl result vector coordin space kinemat data obtain suppli set joint angl arm result strategi show come use inform without infinit regress learn complet problem environ suffic determin robot problem learn reach differ posit space depend set signal current feedback environ success failur inform current learn via inhibitori search need case mechan search space arm record success configur associ associ learn via inhibitori search provid next section appli backpropag show result network sometim use solv third inhibitori integr network overal final section contain expand version paper may found invers kinemat invers kinemat problem control arm problem determin joint angl need produc specif posit orient gener case difficult itch back suggest kind question hand go around sure know work without actual tri comput forward kinemat decid limb end given set joint angl easier depict planar use call work discuss ackley also use trunk far cri real signific possibl joint angl suffic pose kinemat trunk five joint angl rang respect previou simul backpropag network five input unit joint sixti hidden unit singl twelv linear output unit joint joint angl express rang unit valu configur vector repres twelv output unit correspond six pair ackley display asymptot converg specifi posit arm posit display iter one pair joint trunk robot fy constant sinc end part state output unit equal sum error output unit equal error propag defin differ predict configur extens train trunk robot forward network achiev high accuraci joint typic backpropag desir map backward network longer suppos error differ use train error propag output train way back goal longer chang weight network sinc alreadi repres use map use network translat howev error input illustr one use show train forward network use perform cheap kind invers show superimpos output train network influenc error case trunk tri reduc front back front back first arm target arrow defin head tail error output unit defin error output unit defin ty error output set algorithm use gener behavior follow comput error one output unit base current posit joint desir posit orient learn via inhibitori search trunk kink store error select set error term backpropag error way network input produc error term joint angl produc joint clip angl minimum maximum forward propag network bose new joint new current posit go step train phose forward propag activ follow back propag usag revers backpropag follow chang input follow forward propag gener gradient descent techniqu usabl backpropag learn map control space error juation space illustr gradient familiar limit manifest tazget reachabl robot fail reach configur approach trunk kink short robot open instead close could problem aris error comput error tip rest indic joint failur due local could greatli inhibitori search feedback control network previou section local minim joint posit howev gener translat joint angl space move use feedback control network arm section show learn gener appropri joint posit space given reinforc two key first action produc posit reinforc ho somehow ackley problem reduc associ map input discov use record point neg reinforc current configur associ input fashion place use record overal perform inhibitori search rememb failur occur avoid perform associ learn rememb success configur search process uncov alvi construct arm configur associ success configur figur summar point note unit use spheric function explor hanson respons spheric unit equal input vector weight vector respons unit decreas monoton euclidean distanc two aiu govern rate unit subnetwork relev one network feldman unit largest valu function distanc current unit effect rest simul report use rn unit per addit paramet associ spheric unit strength paramet specifi much influenc behavior strength grow posit reinforc shrink linearli grow logarithm neg reinforc shrink illustr situat earli run left three display show state relev relev current configur sinc particular goal never achiev map provid use inform weight vector contain small random valu origin right strength display map posit four relev current select number drawn somewhat unit spread configur creat push away arm come arm move without reach differ win competit take neg reinforc win consequ move toward variou current configur get arm push illustr behavior system extens learn via inhibitori search space backpropag network set goal map region creat network iol goal unit subnetwork consist one unit df current posit unit creat connect strength set strength st set weight wzi wiz small random random legal vector produc current configur choos random comput activ use subnetwork unit largest let denot weight denot weight similarli strength comput error backpropag produc gener angl paramet gener new respect maximum minimum possibl joint forward propag produc new determin whether satisfi goal go step letw let rain posit reinf let paramet let sti sti go step perform let paramet uniform random variabl let min neg reinf let uet go step ackley display intern state trunk robot process set twelv arbitrari stimuli specifi posit current signal system discov mean display intern state trunk robot later previou goal current goal map contain accur imag success configur strength strength select current configur map figur show iter time achiev previou goal time achiev current figur display averag function number trunk network initi run goal result data averag averag declin rapidli goal seem stabil around averag valu kind standard albeit joint angl chang uniform random valu figur averag observ learn via inhibitori search graph averag time taken per function number goal line show averag perform random exploratori alvi environ pole shadow real even grant limit scope sever alvi incomplet satisfi biggest drawback current implement goal essenti requir set enumer definit relat problem includ inabl share inform one goal anoth inabl pursu one goal determin constraint goal must integr possibl current alvi done strictli select current situat select within work jordan miyata show goal inform context inform integr suppli input singl pure feedback control suffer tradit problem error result joint angl chang arm converg joint incred speed overshoot oscil becom oscil gradual die unit shift posit sometim temporari oscil actual help caus tip arm explor varieti differ ackley aspect alvi behavior find irrit reveal someth approach case usual alvi learn hit edg target approach alvi experi neg gain littl result interfer occasion caus long search goal previous rapidli alvi represent better system would also abl object use relat expand evid present system need balanc sophist perceptu limit alvi demonstr three idea think worth reus error channel backpropag arbitrari gradient record previou actual output use futur desir use well attractor defin result process gener neg behavior machin term attractor dynam familiar larg unknown ephemer qualiti answer strength accru good perform becom alvi behavior essenti watch easi forget world big answer alvi well discov new associ learn via inhibitori technic memorandum tm bell commun knowledg represent technic bell commun dynam connect neural biolog serial distribut process technic report la univers institut cognit learn plan unpublish doctor dissert univers california san learn represent also cite person,2
94,94,"29 
""FAST LEARNING IN 
MULTI-RESOLUTION HIERARCHIES"" 
John Moody 
Yale Computer Science, P.O. Box 2158, New Haven, CT 06520 
Abstract 
A class of fast, supervised learning algorithms is presented. They use lo- 
cal representations, hashing, aild multiple scales of resolution to approximate 
functions which are piece-wise continuous. Inspired by Albus's CMAC model, 
the algorithms learn orders of magnitude more rapidly than typical imple- 
mentations of back propagation, while often achieving comparable qualities of 
generalization. Furthermore, unlike most traditional function approximation 
methods, the algorithms are well suited for use in real time adaptive signal 
processing. Unlike simpler adaptive systems, such as linear predictive cod- 
ing, the adaptive linear combinet, and the Kalman filter, the new algorithms 
are capable of efficiently capturing the structure of complicated non-linear 
systems. As an illustration, the algorithm is applied to the prediction of a 
chaotic timeseries. 
1 Introduction 
A variety of approaches to adaptive information processing have been developed 
by workers in disparate disciplines. These include the large body of literature on 
approximation and interpolation techniques (curve and surface fitting), the linear, 
real-time adaptive signal processing systems (such as the adaptive linear combiner 
and the Kalman filter), and most recently, the reincarnation of non-linear neural 
network models such as the multilayer perceptron. 
Each of these methods has its strengths and weaknesses. The curve and surface 
fitting techniques are excellent for off-line data analysis, but are typically not formu- 
lated with real-time applications in mind. The linear techniques of adaptive signal 
processing and adaptive control are well-characterized, but are limited to applica- 
tions for which linear descriptions are appropriate. Finally, neural network learning 
models such as back propagation have proven extremely versatile at learning a wide 
variety of non-linear mappings, but tend to be very slow computationally and are 
not yet well characterized. 
The purpose of this paper is to present a general description of a class of su- 
pervised learning algorithms which combine the ability of the conventional curve 
30 Mdy 
fitting and multilayer perceptron methods to precisely learn non-linear mappings 
with the speed and flexibility required for real-time adaptive application domains. 
The algorithms are inspired by a simple, but often overlooked, neural network 
model, Albus's Cerebellar Model Articulation Controller (CMAC) [2,1], and have 
a great deal in common with the standard techniques of interpolation and approx- 
imation. The algorithms ""learn from examples"", generalize well, and can perform 
efficiently in real time. Furthermore, they overcome the problems of precision and 
generalization which limit the standard CMAC model, while retaining the CMAC's 
speed. 
2 System Description 
The systems are designed to rapidly approximate mappings g � a7 -. 7 from multi- 
dimensional input spaces   $inrt, t to multidimensional output spaces ff  $ot, trt, t. 
The algorithms can be applied to any problem domain for which a metric can be de- 
fined on the input space (typically the Euclidean, Hamming, or Manhattan metric) 
and for which the desired learned mapping is (to a close approximation) piece-wise 
continuous. (Discontinuities in the desired mapping, such as those at classifica- 
tion boundaries, are approximated continuously.) Important general classes of such 
problems include approximation of real-valued functions 7 n - 7 rn (such as those 
found in signal processing), classification problems 7  -* B m (such as phoneme 
classification), and boolean mapping problems B"" -. B "" (such as the NETtalk 
problem [20]). Here, 7 are the reals and B is {0, 1}. This paper focuses on real- 
valued mappings; the formulation and application of the algorithms to boolean 
problem domains will be presented elsewhere. 
In order to specify the complete learning system in detail, it is easiest to start 
with simple special cases and build the description from the bottom up-  
2.1 A Simple Adaptive Module 
The simplest special case of the general class under consideration is described as 
follows. The input space is overlayed with a lattice of points � a local function 
value or ""weight"" � is assigned to every possible lattice point. The output of the 
system for a given input is: 
(1) 
where NO (a) is a neighborhood function for the 3 ta lattice point such that NO = 1 
if 0 is the lattice point closest to the input vector a7 and NO = 0 otherwise. 
More generally, the neighborhood functions N can overlap and the sum in equa- 
tion (1) can be replaced by an average. This results in a greater ability to generalize 
when training data is sparse, but at the cost of losing fine detail. 
Fast Learning in Multi-Resolution Hierarchies  31 
Learning is accomplished by varying the  to minimize the squared error of 
the system output on a set of training data: 
1 Z(idesired 
= - , 
i 
(2) 
where the sum is over all exemplars { i, i desired } in the training set. The de- 
termination of 17 is easily formulated as a real time adaptive algorithm by using 
gradient descent to minimize an instantaneous estimate E(t) of the error: 
dV __dZ(0 
dt =-rr dV 
(3) 
2.2 Saving Memory with Hashing: The CMAC 
The approach of the previous section encounters serious difficulty when the dimen- 
sion of the input space becomes large and the distribution of data in the input space 
becomes highly non-uniform. In such cases, allocating a separate function value for 
each possible lattice point is extremely wasteful, because the majority of lattice 
points will have no training data within a local neighborhood. 
As an example, suppose that the input space is four dimensional, but that all 
input data lies on a fuzzy two dimensional subspace. (Such a situation [projected 
onto 3-dimensions] is shown in figure [2A].) Furthermore, suppose that the input 
space is overlayed with a rectangular lattice with K nodes per dimension. The 
complete lattice will contain K 4 nodes, but only O(K ) of those nodes will have 
training data in their local neighborhoods Thus, only O(K ) of the weights V will 
have any meaning. The remaining O(K 4) weights will be wasted. (This assumes 
that the lattice is not too fine. If K is too large, then only O(P) of the lattice points 
will have training data nearby, where P is the number of training data.) 
An alternative approach is to have only a small number of weights and to allo- 
cate them to only those regions of the input space which are populated with training 
data. This allocation can be accomplished by a dimensionality-reducing mapping 
from a virtual lattice in the input space onto a lookup table of weights or function 
values. In the absence of any a priori information about the distribution of data in 
the input space, the optimal mapping is a random mapping, for example a universal 
hashing function [8]. The random nature of such a function insures that neighbor- 
hood relationships in the virtual lattice are not preserved. The average behavior 
of an ensemble of universal hashing functions is thus to access all elements of the 
lookup table with equal probability, regardless of the correlations in the input data. 
The many-to-one hash function can be represented here as a matrix H 'p of O's 
and 1's with one I per column, but many 1's per row. With this notation, the 
system response function is: 
T N 
z-'() = Z Z Ir nr/ N(T ) (4) 
r=l fi=l 
32 Moody 
A Hash Table B 
'- Resolution  
L 
Figure 1: (A) A simple CMAC module. (B) The computation of errors for a multi- 
resolution hierarchy. 
The CMAC model of Albus is obtained when a distributed representation of 
the input space is used and the neighborhood functions N() are overlapping. 
In this case, the sum over 3 is replaced by an average. Note that, as specified 
by equation (4), hash table collisions are not resolved. This introduces ""collision 
noise"", but the effect of this noise is reduced by 1/v/B), where B is the number 
of neighborhood functions which respond to a given input. Collision noise can be 
completely eliminated if standard collision resolution techniques are used. 
A few comments should be made about efficiency. In spite of the costly formal 
sums in equation (4), actual implementations of the algorithm are extremely fast. 
The set of non-zero N (Z) on the virtual lattice, the hash function value for each 
vertex, and the set of corresponding lookup table values r given by the hash 
function are easily determined on the fly. The entire hash function H rts is never 
pre-computed, the sum over the index 3 is limited to a few lattice points neighboring 
the input Z, and since each lattice point is associated with only one lookup table 
value, the formal sum over r disappears. 
The CMAC model is shown schematically in figure [1A]. 
2.3 
Interpolation: Neighborhood Functions with Graded 
Pesponse 
One serious problem with the formulations discussed so far is that the neighborhood 
functions are constant in their regions of support. Thus, the system response is dis- 
continuous over neighborhood boundaries. This problem can be easily remedied by 
using neighborhood functions with graded response in order to perform continuous 
interpolation between lattice points. 
""Fast Learning in Multi-Resolution Hierarchies  33 
The normalized system response function is then: 
The functions R ( are the graded neighborhood response functions associated 
with each lattice point �. They are intended to have local support on the'input 
space Sinrut, thus being non-zero only in a local neighborhood of their associated 
lattice point /. Each function R/(a) attains its maximum value at lattice point 
/ and drops off monotonically to zero as the distance Ila - xl increases. Note 
that R is not necessarily isotropic or symmetric. 
Certain classes of localized response functions R defined on certain lattices are 
self-normalized, meaning that: 
] R() - 1, for any . (6) 
In this case, the equation (5) simplifies to: 
(7) 
One particularly important and useful class of of response functions are the B- 
splines. However, it is not easy to formulate B-splines on arbitrary lattices in high 
dimensional spaces. 
2.4 Multi-Resolution Interpolation 
The final limitation of the methods described so far is that they use a lattice at 
only one scale of resolution. Without detailed a priori knowledge of the distribu- 
tion of data in the input space, it is difficult to choose an optimal lattice spacing. 
Furthermore, there is almost always a trade-off between the ability to generalize 
and the ability to capture fine detail. When a single coarse resolution is used, gen- 
eralization is good, but fine details are lost. When a single fine resolution is used, 
fine details are captured in those regions which contain dense data, but no general 
picture emerges for those regions in which data is sparse. 
Good generalization and fine detail can both be captured by using a multi- 
resolution hierarchy. 
A hierarchical system with L levels represents functions g �  -. 7 in the follow- 
ing way: 
L 
-- = (8) 
where ' is a mapping as described in equation(5) for the A-th level in the hierarchy. 
The coarsest scale is A = 1 and the finest is A = L. 
34 Moodr 
The multi-resolution system is trained such that the finer scales learn corrections 
to the total output of the coarser scales. This is accomplished by using a hierarchy 
of error functions. For each level in the hierarchy ,, the output for that level !7 is 
defined to be the partial sum 
(Note that ffx+l = ff + '+ .) The error for level , is defined to be 
a = a(i) , 
i 
where the error associated with the ita exemplar is: 
1 
(i) = .i(i'""- ff(e)) 
The learning or training procedure for level A involves varying the lookup table 
values V)[ for that level to minimize E. Note that the lookup table values V 
for previous or subsequent levels (n : A) are held fixed during the minimization 
of Ex. Thus, the lookup table values for each level are varied to minimize only 
the error defined for that level. This hierarchical learning procedure guarantees 
that the first level mapping zl is the best possible at that level, the second level 
mapping z2 constitutes the best possible corrections to the first level, and the A-th 
level mapping z constitutes the best possible corrections to the total contributions 
of all previous levels. The computation of error signals is shown schematically in 
figure [lB]. 
It should be noted that multi-resolution approaches have been successfully used 
in other contexts. Examples are the well-known multigrid methods for solving 
differential equations and the pyramid architectures used in machine vision [6,7]. 
3 Application to Timeseries Prediction 
The multi-resolution hierarchy can be applied to a wide variety of problem domains 
as mentioned earlier. Due to space limitations, we consider only one test problem 
here, the prediction of a chaotic timeseries. 
As it is usually formulated, the prediction is accomplished by finding a real- 
valued mapping f: 7 n  7 which takes a sequence of n recent samples of the 
timeseries and predicts the value at a future moment. Typically, the state space 
imbedding in 7"" is x-'It I : (x[t],x[t- Al,x[t- 2Al,x[t- 3/Xl) , where A is the 
sampling parameter, and the correct prediction for prediction time T is x[t + . 
For the purposes of testing various non-parametric prediction methods, it is sumed 
that the underlying process which generates the timeseries is unknown. 
The particular timeseries studied here results from integrating the Mackey-Gls 
differentiM-delay equation [14]: 
_ dt- 1 
dz[t] -b z[t] + a 
dt - 1 + [ - 10 () 
'Fast Learning in Multi-Resolution Hierarchies  35 
0.0 
-1.5 
:l 
Figure 2: (A) Imbedding in three dimensions of 1000 successive points of the 
Mackey-Glass chaotic timeseries with delay parameter r = 17 and sampling pa- 
rameter A = 6. (B) Normalized Prediction Error rs. Number of Training Data. 
Squares are runs with the multi-resolution hierarchy runs. The circle is the back 
propagation benchmark. The horizontal line is included for visual reference only 
and is not intended to imply a scaling law for back propagation. 
The solid lines in figure [3] show the resulting timeseries for r --- 17, a = 0.2, 
and b = 0.1; note that it is cyclic, but not periodic. The characteristic time of 
the series, given by the inverse of the mean of the power spectrum, is tcaa,  
50. Classical techniques like linear predictive coding and Gabor-Volterra-Wiener 
polynomial expansions typically do no better than chance when predicting beyond 
tchar [10]. 
For purposes of comparison, the sampling parameter and prediction time are 
chosen to be A = 6 and T = 85 > t,h respectively. Figure [2A] shows a projection 
of the four dimensional state space imbedding onto three dimensions. The orbits of 
the series lie on a fuzzy two dimensional subspace which is a strange attractor of 
fractal dimension 2.1. 
This problem has been studied by both conventional data analysis techniques 
and by neural network methods. 
It was first studied by Farmer and Sidorowich who locally fitted linear and 
quadratic surfaces directly to the data. [11,10]. The exemplars in the imbedding 
space were stored in a k-d tree structure in order to allow rapid determination of 
proximity relationships [3,4,19]. The local surface fitting method is extremely ef- 
ficient computationally. This kind of approach has found wide application in the 
statistics community [5]. Casdagli has applied the method of radial basis functions, 
which is an exact interpolation method and also depends on explicit storage of the 
data. [9]. The radial basis functions method is a global method and becomes corn- 
36 Moody 
putationally expensive when the number of exemplars is large, growing as O(Pa). 
Both approaches yield excellent results when used as off-line algorithms, but do not 
seem to be well suited to real-time application domains. 
For real-time apphcations, little a priori knowledge about the data can be as- 
sumed, large amounts of past data can't be stored, the function being learned may 
vary with time, and computing speed is essentiM. 
Three different neural network techniques have been applied to the timeseries 
prediction problem, back propagation [13], self-organized, locally-tuned processing 
units [18,17], and an approach based on the GMDH method and simulated an- 
neMing [21]. The first two approaches can in principle be applied in real time, 
because they don't require explicit storage of past data and can adapt continuously. 
Back propagation yields better predictions since it is completely supervised, but 
the locally-tuned processing units learn substantially faster. The GMDH approach 
yields excellent results, but is computationally intensive and is probably limited to 
off-line use. 
The multi-resolution hierarchy is intended to offer speed, precision, and the 
ability to adapt continuously in real time. Its application to the Mackey-Glass 
prediction problem is demonstrated in two different modes of operation: off-line 
learning and real-time learning. 
3.1 Off- Line Learning 
In off-line mode, a five level hierarchy was trained to predict the future values. At 
each level, a regular rectangular lattice was used, with each lattice having A intervals 
and therefore A + 1 nodes per dimension. The lattice resolutions were chosen to 
be (A = 4, A2 = 8, As = 16, A4 '- 32, A5 = 64). The corresponding number of 
vertices in each of the virtual 4-dimensional lattices was therefore (M1 = 625, M2 = 
6,561, M3 = 83,521, M4 = 1,185,921, M5 = 17,850,625). The corresponding 
lookup table sizes were (T1 = 625, T2 = 4096, T3 = 4096, T4 = 4096, T, = 4096). 
Note that T = Mi, so hashing was not required for the first layer. For all other 
layers, Tx < M,, so hashing was used. For layers 3, 4, and 5, Tx << M,, so 
hashing resulted in a dramatic reduction in the memory required. The neighborhood 
response function R(a7) was a B-spline with support in the 16 cells adjacent to each 
lattice point Z. Hash table collisions were not resolved. 
The learning method used was simple gradient descent. The lookup table values 
were updated after the presentation of each exemplar. At each level, the training 
set was presented repeatedly until a convergence criterion was satisfied. The levels 
were trained sequentially: level 1 was trained until it converged, followed by level 
2, and so on. 
The performance of the system as a function of training set size is shown in fig- 
are [2l- The normalized error is defined as [rms error]/[a], where a is the standard 
deviation of the timeseries. For each run, a different segment of the timeseries was 
used. In all cases, the performance was measured on an independent test sequence 
consisting of the 500 exemplars immediately following the training sequence. The 
prediction error initially drops rapidly as the number of training data are increased, 
'Fast Learnir in Multi-Resolution Hierarchies' 37 
but then begins to level out. This leveling out is most likely caused by collision 
noise in the hash tables. Collision resolution techniques should improve the results, 
but have not yet been implemented. 
For training sets with 500 exemplars, the multi-resolution hierarchy achieved 
prediction accuracy equivalent to that of a back propagation network trained by 
Lapedes and Farber [13]. Their network had four linear inputs, one linear output, 
and two internal layers, each containing 20 sigmoidal units. The layers were fully 
connected yielding 541 adjustable parameters (weights and thresholds) total. They 
trained their network in off-line mode using conjugate gradient, which they found 
to be significantly faster than gradient descent. 
The multi-resolution hierarchy converged in about 3.5 minutes on a Sun 3/60 for 
the 500 exemplar runs. Lapedes estimates that the back propagation network re- 
quired probably 5 to 10 minutes of Cray X/MP time running at about 90 Mflops [12]. 
This would correspond to about 4,000 to 8,000 minutes of Sun 3/60 time. Hence, 
the multi-resolution hierarchy converged about three orders of magnitude faster that 
the back propagation network. This comparison should not be taken to be univer- 
sal, since many implementations of both back propagation and the multi-resolution 
hierarchy are possible. Other comparisons could easily vary by factors of ten or 
more. 
It is interesting to note that the training time for the multi-resolution hierarchy 
increased sub-linearly with training set size. This is because the lookup table values 
were varied after the presentation of each exemplar, not after presentation of the 
whole set. A similar effect should be observable in back propagation nets. In fact, 
training after the presentation of each exemplar could very likely increase the overall 
rate of convergence for a back propagation net. 
3.2 Real-Time Learning 
Unlike most standard curve and surface fitting methods, the multi-resolution hi- 
erarchy is extremely well-suited for real-time applications. Indeed, the standard 
CMAC model has been applied to the real-time control of robots with encouraging 
success [16,15]. 
Figure [3] illustrates a two level hierarchy (with 5 and 9 nodes per dimension) 
learning to predict the timeseries for T = 50 from an initial tabula rasa configuration 
(all lookup table values set to zero). The solid line is the actual timeseries data, while 
the dashed line are the predicted values. The predicted values lead the actual values 
in the graphs. Notice that the system discovers the intrinsically cyclic nature of the 
series almost immediately. At the end of a single pass through 9,900 exemplars, 
the normalized prediction error is below 5% and the fit looks very good to the eye. 
On a Sun 3/50, the algorithm required 1.4 rnsec per level to respond to and 
learn from each exemplar. At this rate, the two level system was able to process 
300 exemplars (over 7 cycles of the timeseries) per second. This rate would be 
considered phenomenal for a typical back propagation network running on a Sun 
3/50. 
38 Moody 
1.0 m 
0.8 
. 
0.6 
0.4 
0.2 
0.0 I a-' 
1.0 
0.8 
0.6 
0.4 
0.2 
0.0 
0 100 200 300 400 9500 9600 9700 9800 9900 
Time ( = # of Exemplars ) 
Time ( = # of exemplars) 
Figure 3: An example of learning to predict the Mackey-Glass chaotic timeseries in 
real time with a two-stage multi-resolution hierarchy. 
4 Discussion 
There are two reasons that the multi-resolution hierarchy learns much more quickly 
than back propagation. The first is that the hierarchy uses local representations 
of the input space and thus requires evaluation and modification of only a few 
lookup table values for each exemplar. In contrast, the complete back propagation 
net must be evaluated and modified for each exemplar. Second, the learning in 
the multi-resolution hierarchy is cast as a purely quadratic optimization procedure. 
In contrast, the back propagation procedure is non-linear and is plagued with a 
multitude of local minima and plateaus which can significantly retard the learning 
process. 
In these respects, the multi-resolution hierarchy is very similar to the local sur- 
face fitting techniques exploited by Farmer and Sidorowich. The primary difference, 
however, is that the hierarchy, with its multi-resolution architecture and hash table 
data structures offers the flexibility needed for real time problem domains and does 
not require the explicit storage of past data or the creation of data structures which 
depend on the distribution of data. 
Acknowledgements 
I gratefully acknowledge helpful comments from Chris Darken, Doyne Farmer, Alan 
Lapedes, Tom Miller, Terry Sejnowski, and John Sidorowich. I am especially 
grateful for support from ONR grant N00014-86-K-0310, AFOSR grant F40620- 
88-C0025, and a Purdue Army subcontract. 
Fast Learning in Multi-Resolution Hierarchies"" 39 
References 
[1] J.S. Albns. Brain, Behavior and Robotics. Byte Books, 1981. 
[2] J.S. Albns. A new approach to manipulator control: the cerebellar model articulation con- 
troller (CMAC). J. Dyn. Sys. Mess., Contr., 97:220, 1975. 
[3] Jon L. Bentley. Multidimensional binary search trees in database applications. IEEE Trans. 
on Software Engineering, SE-5:333, 1979. 
[4] Jon L. Bentley. Multidimensional divide and conquer. Communications of the A CM, 23:214, 
1980. 
[5] L. BreAman, J.H. Friedman, R.A. Olshen, and C.J. Stone. Classification and Regression 
Trees. Wadsworth, Monterey, CA, 1984. 
[6] Peter J. Burr and Edward H. Adelson. The laplacian pyramid as a compact image code. 
IEEE Trans. Communications, COM-31:532, 1983. 
[7] Peter J. Burr and Edward H. Adelson. A multiresolution spline with application to image 
mosaics. A CM Trans. on Graphics, 2:217, 1983. 
[8] J.L. Carter and M.N. Wegman. Universal classes of hash functions. In Proceedings of the 
Ninth Annual SIGA CT Conference, 1977. 
[9] M. Casdagli. Nonlinear Prediction of Chaotic Time Series. Technical Report, Queen Mary 
College, London, 1988. 
[10] J.D. Farmer and J.J. Sidorowich. Exploiting Chaos to Predict the Future and Reduce Noise. 
Technical Report, Los Alamos National Laboratory, Los Alamos, New Mexico, 1988. 
[11] J.D. Farmer and J.J. Sidorowich. Predicting chaotic time series. Physical Review Letters, 
59:845, 1987. 
[12] A. Lapedes. 1988. Personal communication. 
[13] A.S. Lapedes and R. Farber. Nonlinear Signal Processing Using Neural Networks: Prediction 
and System Modeling. Technical Report, Los Alamos National Laboratory, Los Alamos, New 
Mexico, 1987. 
[14] M.C. Mackey and L. Glass. Oscillation and chaos in physiological control systems. Science, 
197:287. 
[15] W.T. Miller, F. H. Glanz, and L. G. Kraft. Application of a general learning algorithm to the 
control of robotic manipulators. International Journal of Robotics Research, 6(2):84, 1987. 
[16] W. Thomas Miller. Sensor-based control of robotic manipulators using a general learning 
algorithm. IEEE Journal of Robotics and Automation, RA-3(2):157, 1987. 
[17] J. Moody and C. Darken. Fast learning in networks of locally-tuned processing units. Neural 
Computation, 1989. To Appear. 
[18] J. Moody and C. Darken. Learning with localized receptive fields. In Touretzky, Hinton, and 
Sejnowski, editors, Proceedings of the 1988 Connectionist Models Summer School, Morgan 
Kaufmann, Publishers, 1988. 
[19] S. Omohundro. Efficient algorithms with neural network behavior. Complex Systems, 1:273. 
[20] T. Sejnowski and C. Rosenberg. Parallel networks that learn to pronounce English text. 
Complex Systems, 1:145, 1987. 
[21] M.F. Tenorio and W.T. Lee. Self-organized neural networks for the identification problem. 
Poster paper presented at the Neural Information Processing Systems Conference, 1988. 
", learn moodi comput box new ct class supervis learn algorithm use aild multipl scale resolut approxim inspir cmac algorithm learn order magnitud rapidli typic back often achiev compar qualiti unlik tradit function approxim algorithm well suit use real time adapt signal unlik simpler adapt linear predict adapt linear kalman new algorithm capabl effici captur structur complic algorithm appli predict introduct varieti approach adapt inform process develop worker dispar includ larg bodi literatur interpol techniqu surfac adapt signal process system adapt linear combin kalman reincarn neural model multilay method strength curv surfac techniqu excel data typic applic linear techniqu adapt signal adapt control limit linear descript neural network learn back propag proven extrem versatil learn wide tend slow comput yet well purpos paper present gener descript class learn algorithm combin abil convent curv mdi multilay perceptron method precis learn map speed flexibl requir adapt applic algorithm inspir often neural network cerebellar model articul control great deal common standard techniqu interpol algorithm gener perform real overcom problem precis limit standard cmac retain system descript system design rapidli approxim map input space multidimension output space ff algorithm appli problem domain metric input space manhattan desir learn map close desir approxim import gener class includ approxim function rn signal classif problem phonem boolean map problem nettalk real paper focus formul applic algorithm boolean domain present order specifi complet learn system easiest start simpl special case build descript bottom simpl adapt modul simplest special case gener class consider describ input space overlay lattic point local function assign everi possibl lattic output given input neighborhood function ta lattic point lattic point closest input vector neighborhood function overlap sum replac result greater abil gener train data cost lose fine learn hierarchi accomplish vari minim squar error system output set train sum exemplar desir train easili formul real time adapt algorithm use descent minim instantan estim save memori cmac approach previou section encount seriou difficulti input space becom larg distribut data input space highli alloc separ function valu possibl lattic point extrem major lattic train data within local suppos input space four data lie fuzzi two dimension situat shown figur suppos input overlay rectangular lattic node per lattic contain node data local neighborhood weight remain weight assum lattic lattic point train data number train altern approach small number weight region input space popul train alloc accomplish map virtual lattic input space onto lookup tabl weight function absenc priori inform distribut data input optim map random exampl univers function random natur function insur relationship virtual lattic averag behavior ensembl univers hash function thu access element tabl equal regardless correl input hash function repres matrix one per mani per respons function moodi hash tabl resolut simpl cmac comput error cmac model albu obtain distribut represent input space use neighborhood function sum replac note specifi equat hash tabl collis introduc effect nois reduc number neighborhood function respond given collis nois elimin standard collis resolut techniqu comment made spite costli formal equat actual implement algorithm extrem set virtual hash function valu set correspond lookup tabl valu given hash easili determin entir hash function rt never sum index limit lattic point neighbor input sinc lattic point associ one lookup tabl formal sum cmac model shown schemat figur neighborhood function grade seriou problem formul discuss far neighborhood constant region system respons neighborhood problem easili remedi neighborhood function grade respons order perform continu lattic learn hierarchi normal system respons function function grade neighborhood respons function associ lattic point intend local support thu local neighborhood associ point function attain maximum valu lattic point drop monoton zero distanc note necessarili isotrop class local respons function defin certain lattic mean equat simplifi particularli import use class respons function easi formul arbitrari lattic high interpol final limit method describ far use lattic one scale without detail priori knowledg data input difficult choos optim lattic almost alway abil gener abil captur fine singl coars resolut fine detail singl fine resolut detail captur region contain dens gener emerg region data gener fine detail captur use hierarch system level repres function map describ level coarsest scale finest moodr system train finer scale learn correct total output coarser accomplish use hierarchi error level hierarchi output level partial sum error level defin error associ ita exemplar learn train procedur level involv vari lookup tabl level minim note lookup tabl valu previou subsequ level held fix minim lookup tabl valu level vari minim error defin hierarch learn procedur guarante first level map zl best possibl second level constitut best possibl correct first map constitut best possibl correct total contribut previou comput error signal shown schemat note approach success use exampl multigrid method solv equat pyramid architectur use machin vision applic timeseri predict hierarchi appli wide varieti problem domain mention due space consid one test problem predict chaotic usual predict accomplish find map take sequenc recent sampl predict valu futur state space correct predict predict time purpos test variou predict underli process gener timeseri particular timeseri studi result integr equat learn hierarchi imbed three dimens success point chaotic timeseri delay paramet sampl normal predict error number train run hierarchi circl back horizont line includ visual refer intend impli scale law back solid line figur show result timeseri note characterist time given invers mean power classic techniqu like linear predict code expans typic better chanc predict beyond purpos sampl paramet predict time figur show project four dimension state space imbed onto three orbit seri lie fuzzi two dimension subspac strang attractor dimens problem studi convent data analysi techniqu neural network first studi farmer sidorowich local fit linear surfac directli exemplar imbed store tree structur order allow rapid determin relationship local surfac fit method extrem kind approach found wide applic commun casdagli appli method radial basi exact interpol method also depend explicit storag radial basi function method global method becom moodi expens number exemplar grow approach yield excel result use well suit applic littl priori knowledg data larg amount past data function learn may comput speed differ neural network techniqu appli timeseri back propag process approach base gmdh method simul ming first two approach principl appli real requir explicit storag past data adapt propag yield better predict sinc complet process unit learn substanti gmdh approach excel comput intens probabl limit hierarchi intend offer adapt continu real applic problem demonstr two differ mode line learn five level hierarchi train predict futur regular rectangular lattic lattic interv therefor node per lattic resolut chosen correspond number virtual lattic therefor correspond tabl size hash requir first tx hash layer tx result dramat reduct memori neighborhood function support cell adjac point hash tabl collis learn method use simpl gradient lookup tabl valu updat present train present repeatedli converg criterion level train level train follow level perform system function train set size shown normal error defin standard differ segment timeseri perform measur independ test sequenc exemplar immedi follow train error initi drop rapidli number train data begin level level like caus collis hash collis resolut techniqu improv yet train set hierarchi achiev accuraci equival back propag network train farber network four linear one linear two intern contain sigmoid layer fulli yield adjust paramet network mode use conjug found significantli faster gradient hierarchi converg minut sun exemplar laped estim back propag network probabl minut cray time run mflop would correspond minut sun hierarchi converg three order magnitud faster back propag comparison taken sinc mani implement back propag comparison could easili vari factor ten interest note train time hierarchi train set lookup tabl valu vari present present similar effect observ back propag present exemplar could like increas overal converg back propag learn standard curv surfac fit extrem standard model appli control robot encourag illustr two level hierarchi node per predict timeseri initi tabula rasa configur lookup tabl valu set solid line actual timeseri dash line predict predict valu lead actual valu notic system discov intrins cyclic natur almost end singl pass normal predict error fit look good sun algorithm requir rnsec per level respond two level system abl process exemplar cycl per rate would phenomen typic back propag network run sun moodi exemplar exampl learn predict chaotic timeseri time discuss two reason hierarchi learn much quickli back first hierarchi use local represent input space thu requir evalu modif tabl valu complet back propag must evalu modifi learn hierarchi cast pure quadrat optim back propag procedur plagu local minima plateau significantli retard learn hierarchi similar local fit techniqu exploit farmer primari architectur hash tabl structur offer flexibl need real time problem domain requir explicit storag past data creation data structur distribut grate acknowledg help comment chri doyn alan tom terri john especi support onr grant afosr grant purdu armi learn behavior byte new approach manipul cerebellar model articul jon multidimension binari search tree databas ie softwar jon multidimension divid commun classif regress peter burr edward laplacian pyramid compact imag peter burr edward multiresolut spline applic imag cm carter univers class hash proceed annual siga ct nonlinear predict chaotic time technic queen mari farmer exploit chao predict futur reduc lo alamo nation lo new farmer predict chaotic time physic review person laped nonlinear signal process use neural predict system technic lo alamo nation lo new mackey oscil chao physiolog control applic gener learn algorithm robot intern journal robot thoma control robot manipul use gener learn ie journal robot moodi fast learn network process neural moodi learn local recept proceed connectionist model summer morgan effici algorithm neural network complex sejnowski parallel network learn pronounc english tenorio neural network identif paper present neural inform process system,0
95,95,"4O 
EFFICIENT PARALLEL LEARNING 
ALGORITHMS FOR NEURAL NETWORKS 
Alan H. Kramer and A. Sangiovanni-Vincentelli 
Department of EECS 
U.C. Berkeley 
Berkeley, CA 94720 
ABSTRACT 
Parallelizable optimization techniques are applied to the problem of 
learning in feedforward neural networks. In addition to having supe- 
rior convergence properties, optimization techniques such as the Polak- 
Ribiere method are also significantly more efficient than the Back- 
propagation algorithm. These results are based on experiments per- 
formed on small boolean learning problems and the noisy real-valued 
learning problem of hand-written character recognition. 
INTRODUCTION 
The problem of learning in feedforward neural networks has received a great deal 
of attention recently because of the ability of these networks to represent seemingly 
complex mappings in an efficient parallel architecture. This learning problem can 
be characterized as an optimization problem, but it is unique in several respects. 
Function evaluation is very expensive. However, because the underlying network is 
parallel in nature, this evaluation is easily parallelizable. In this paper, we describe 
the network learning problem in a numerical framework and investigate parallel 
algorithms for its solution. Specifically, we compare the performance of several 
parallelizable optimization techniques to the standard Back-propagation algorithm. 
Experimental results show the clear superiority of the numerical techniques. 
2 NEURAL NETWORKS 
A neural network is characterized by its architecture, its node functions, and its 
interconnection weights. In a learning problem, the first two of these are fixed, so 
that the weight values are the only free parameters in the system. when we talk 
about ""weight space"" we refer to the parameter space defined by the weights in a 
network, thus a ""weight vector"" w is a vector or a point in weightspace which defines 
the values of each weight in the network. We will usually index the components of 
a weight vector as wij, meaning the weight value on the connection from unit i to 
unit j. Thus N(w, r), a network function with n output units, is an n-dimensional 
vector-valued function defined for any weight vector w and any input vector r: 
N(w, r)--[o(w,r),o2(w,r),...,o,(w,r)] T 
Efficient Parallel Learning Algorithms 
where oi is the ith output unit of the network. Any node j in the network has input 
ii(w,r) = ,Efanin o,(w,r)w, and output o(w,r) - f(i(w,r)), where f0 is 
the node function. The evaluation of N() is inherently parallel and the time to 
evaluate N() on a single input vector is O(#layers). If pipelining is used, multiple 
input vectors can be evaluated in constant time. 
3 LEARNING 
The ""learning"" problem for a neural network refers to the problem of finding a 
network function which approximates some desired ""target"" function T0, defined 
over the same set of input vectors as the network function. The problem is simplified 
by asking that the network function match the target function on only a finite set of 
input vectors, the ""training set"" R. This is usually done with an error measure. The 
most common measure is sum-squared error, which we use to define the ""instance 
error"" between N(w, r) and T(r) at weight vector w and input vector r: 
eN,T(w,r) -  � (T/(r) - �i(w,r)) 2- �liT(r)- N(w,r)ll 2. 
iEoutputs 
We can now define the ""error function"" between N 0 and T() over R as a function 
of w: 
EN,T,R(w) =  eN,T(w,r)' 
r6R 
The learning problem is thus reduced to finding a w for which EN,T,R(w) is min- 
imized. If this minimum value is zero then the network function approximates the 
target function exactly on all input vectors in the training set. Henceforth, for no- 
tational simplicity we will write e 0 and E 0 rather than eN,T0 and. EN,T,s0. 
4 OPTIMIZATION TECHNIQUES 
As we have framed it here, the learning problem is a classic problem in optimization. 
More specifically, network learning is a problem of function approximation, where 
the approximating function is a finite parameter-based system. The goal is to find 
a set of parameter values which minimizes a cost function, which in this case, is a 
measure of the error between the target function and the approximating function. 
Among the optimization algorithms that can be used to solve this type of problem, 
gradient-based algorithms have proven to be effective in a variety of applications 
{Avriel, 1976}. These algorithms are iterative in nature, thus wk is the weight 
vector at the kh iteration. Each iteration is characterized by a search direction 
and a step c. The weight vector is updated by taking a step in the search direction 
as below: 
for(k=o; evaluate(w) != CONVERGED; ++k) { 
d = determine_search_direction(); 
k = deermine_sep(); 
Wk+ 1 = W k + Otkd k; 
} 
42 Kramer and Sangiovanni-Vincentelli 
If d is a direction of descent, such as the negative of the gradient, a sufficiently 
small step will reduce the value of E0. Optimization algorithms vary in the way 
they determine c and d, but otherwise they are structured as above. 
5 CONVERGENCE CRITERION 
The choice of convergence criterion is important. An algorithm must terminate 
when E 0 has been sufficiently minimized. This may be done with a threshold on 
the value of E(), but this alone is not sufficient. In the case where the error surface 
contains ""bad"" local minirod, it is possible that the error threshold will be unattain- 
able, and in this case the algorithm will never terminate. Some researchers have 
proposed the use of an iteration limit to guarantee termination despite an unattain- 
able error threshold {Fahlman, 1989}. Unfortunately, for practical problems where 
this limit is not known a priori, this approach is inapplicable. 
A necessary condition for w* to be a minimum, either local or global, is that the 
gradient g(w*) = VE(w*) = 0. Hence, the most usual convergence criterion for 
optimization algorithms is [[g(w)[ I < e where e is a sufficiently small gradient 
threshold. The downside of using this as a convergence test is that, for successful 
trials, learning times will be longer than they would be in the case of an error thresh- 
old. Error tolerances are usually specified in terms of an acceptable bit error, and 
a threshold on the mazimum bit error (MBE) is a more appropriate representation 
of this criterion than is a simple error threshold. For this reason we have chosen 
a convergence criterion consisting of a gradient threshold and an MBE threshold 
(r), terminating when ][g(w)][ < e or MBE(w) _< r, where MBE() is defined as: 
MBE(w) =max ( max (�(Ti(r) -oi(w,r)))) . 
rcR k,i�outputs 
6 STEEPEST DESCENT 
Steepest Descent is the most classical gradient-based optimization algorithm. In 
this algorithm the search direction dk is always the negative of the gradient - the 
direction of steepest descent. For network learning problems the computation of 
g(w), the gradient of E(w), is straightforward: 
where 
where for output units 
while for all other units 
g(w) = rE(w) 
w(w,) 
0e(w,r) 
Owij 
51(w, r) 
6j(w, r) 
d (w,) =  W(w,), 
= 
rER 
_ [O(w, r) O(w, ) O(w, ) T 
 , ,o'', � 
Ow Ow2 Ow.m 
-- oi(w,r)Sj(w,r), 
/j(i(w,,))(o(w, ,)- 3 (r)), 
yj(i(w,,))  (w,,)w}. 
k E fanout 
Efficient Parallel Learning Algorithms 43 
The evaluation of g is thus almost dual to the evaluation of N; while the latter feeds 
forward through the net, the former feeds back. Both computations are inherently 
parallelizable and of the same complexity. 
The method of Steepest Descent determines the step (: by inexact linesearch, mean- 
ing that it minimizes E(w - (dk). There are many ways to perform this com- 
putation, but they are all iterative in nature and thus involve the evaluation of 
E(w - ( d) for several values of (. As each evaluation requires a pass through 
the entire training set, this is expensive. Curve fitting techniques are employed to 
reduce the number of iterations needed to terminate a linesearch. Again, there are 
many ways to curve fit . We have employed the method of false position and used 
the Wolfe Test to terminate a linesearch {Luenberger, 1986). In practice we find 
that the typical linesearch in a network learning problem terminates in 2 or 3 iter- 
ations. 
7 PARTIAL CONJUGATE GRADIENT METHODS 
Because linesearch guarantees that E(w+) < E(w), the Steepest Descent algo- 
rithm can be proven to converge for a large class of problems {Luenberger, 1986). 
Unfortunately, its convergence rate is only linear and it suffers from the problem 
of ""cross-stitching"" {Luenberger, 1986), so it may require a large number of iter- 
ations. One way to guarantee a faster convergence rate is to make use of higher 
order derivatives. Others have investigated the performance of algorithms of this 
class on network learning tasks, with mixed results {Becker, 1989). We are not 
interested in such techniques because they are less parallelizable than the methods 
we have pursued and because they are more expensive, both computationally and 
in terms of storage requirements. Because we are implementing our algorithms on 
the Connection Machine, where memory is extremely limited, this last concern is 
of special importance. We thus confine our investigation to algorithms that require 
explicit evaluation only of g, the first derivative. 
Conjugate gradient techniques take advantage of second order information to avoid 
the problem of cross-stitching without requiring the estimation and storage of the 
Hessian (matrix of second-order partials). The search direction is a combination of 
the current gradient and the previous search direction: 
dk+ -- -g+ + fid. 
There are various rules for determining/?; we have had the most success with the 
Polak-Ribiere rule, where/? is determined from g+ and g according to 
(g+l -- gk) T � g+i 
As in the Steepest Descent algorithm, a is determined by linesearch. With a sim- 
ple reinitialization procedure partial conjugate gradient techniques are as robust as 
the method of Steepest Descent {Powell, 1977); in practice we find that the Polak- 
Ribiere method requires far fewer iterations than Steepest Descent. 
44 Kramer and Sangiovanni-Vincentelli 
8 BACKPROPAGATION 
The Btch Back-propagation algorithm {Rumelhart, 1986} can be described in 
terms of our optimization framework. Without momentum, the algorithm is very 
similar to the method of Steepest Descent in that dk = -gk. Rather than being 
determined by a linesearch, c, the ""learning rate"", is a fixed user-supplied constant. 
With momentum, the algorithm is similar to a partial conjugate gradient method, 
as d}+ - -g+ +/?}d}, though again , the ""momentum term"", is fixed. On-line 
Back-propagation is a variation which makes a change to the weight vector following 
the presentation of each input vector: d} = V'e(wk, rk). 
Though very simple, we can see that this algorithm is numerically unsound for sev- 
eral reasons. Because /5 is fixed, dk may not be a descent direction, and in this 
case any e will increase E(). Even if d} is a direction of descent (as is the case 
for Batch Back-propagation without momentum), e may be large enough to move 
from one wall of a ""valley"" to the opposite wall, again resulting in an increase in 
E(). Because the algorithm can not guarantee that E 0 is reduced by successive 
iterations, it cannot be proven to converge. In practice, finding a value for e which 
results in fast progress and stable behavior is a black art, at best. 
9 WEIGHT DECAY 
One of the problems of performing gradient descent on the ""error surface"" is that 
minima may be at infinity. (In fact, for boolean learning problems all minima 
are at infinity.) Thus an algorithm may have to travel a great distance through 
weightspace before it converges. Many researchers have found that weight decay is 
useful for reducing learning times {Hinton, 1986}. This technique can be viewed as 
adding a term corresponding to the length of the weight vector to the cost function; 
this modifies the cost surface in a way that bounds all the minima. Rather than 
minimizing on the error surface, minimization is performed on the surface with cost 
function 
C(w) = E(w)+ 
where 7, the relative weight cost, is a problem-specific parameter. The gradient for 
this cost function is g(w) = V'C(w) = VE(w) + 7w, and for any step c, the effect 
of 7 is to ""decay"" the weight vector by a factor of (1 - 
w+l -- wk -- -- w(1 - - ckVE(w). 
10 PARALLEL IMPLEMENTATION ISSUES 
We have emphasized the parallelism inherent in the evaluation of E() and g(). To 
be efficient, any learning algorithm must exploit this parallelism. Without momen- 
tum, the Back-propagation algorithm is the simplest gradient descent technique, as 
it requires the storage of only a single vector, g. Momentum requires the storage of 
only one additional vector, d_. The Steepest Descent algorithm also requires the 
storage of only a single vector more than Back-propagation without momentum: 
Efficient Parallel Learning Algorithms 45 
d, which is needed for linesearch. In addition to d, the Polak-Ribiere method 
requires the storage of two additional vectors: d_  and g_ . The additional stor- 
age requirements of the optimization techniques are thus minimal. The additional 
computational requirements are essentially those needed for linesearch - a single dot 
product and a single broadcast per iteration. These operations are parallelizable 
(log time on the Connection Machine) so the additional computation required by 
these algorithms is also minimal, especially since computation time is dominated 
by the evaluation of E 0 and g0. Both the Steepest Descent and Polak-Ribiere 
algorithms are easily parallelizable. We have implemented these algorithms, as well 
as Back-propagation, on a Connection Machine {Hillis, 1986). 
11 EXPERIMENTAL RESULTS - BOOLEAN LEARNING 
We have compared the performance of the Polak-Ribiere (P-R), Steepest Descent 
(S-D), and Batch Back-propagation (B-B) algorithms on small boolean learning 
problems. In all cases we have found the Polak-Ribiere algorithm to be significantly 
more efficient than the others. All the problems we looked at were based on three- 
layer networks (1 hidden layer) using the logistic function for all node functions. 
Initial weight vectors were generated by randomly choosing each component from 
(+r,-r). 7 is the relative weight cost, and e and 7' define the convergence test. 
Learning times are measured in terms of epochs (sweeps through the training set). 
The encoder problem is easily scaled and has no bad local minima (assuming suf- 
ficient hidden units: log(#inputs)). All Back-propagation trials used a = 1 and 
/5 = 0; these values were found to work about as well as any others. Table 1 sum- 
marizes the results. Standard deviations for all data were insignificant (< 25%). 
TABLE 1. Encoder Results 
Encoder hum Parameter Values Average Epochs to Convergence 
Problem trials r I 7 [ 7' [ e P-R I S-D[ B-B 
10-5-1 ""0 100 1.0 le-4 le-1 le-8 63.71 109'.06 196.93 
10-5-10 100 1.0 le'4 2e-2 le-8 71.27 14:.31 299.55 
10-5-10 100 1.0 le-4 7e-4 le-8 104.70 431.4'3 3286.20 ' 
10-5-10 100' 1.0 le-4 0.0"" le-4 279.52 1490.00 13117.00 
10-5-10 100 1.0 1'e-4 0.0 le-6 353.30 2265.00 2'1910.00 
10-5'-10 i00 1.0 le-4 0'.0"" le-8 417.90 2863.00 ""35260.'06' 
4-2-4 100 1.0 le-4 0.1 le-8 36.92 56.90 179'.95 
8'3-8 100 1.0 le-4 0.1 le-8 67.63 194.80 ' 594176 
16-4-16 100 1.0 le-4 0.1 ' le-8 121.30 572'.80 990.33 
32-5-32 25 1.0 le-4 0.1 ' '1-8 208.60 1379.40 1826.15 
64-6-64 25 1.0 le-4 0.1 le-8 405.60 4187130 > 10000 
46 ' Kramer and Sangiovanni-Vincentelli 
The parity problem is interesting because it is also easily scaled and its weightspace 
is known to contain bad local minima To report learning times for problems with 
bad local minima, we use expected epochs to solution, EES. This measure makes 
sense especially if one considers an algorithm with a restart procedure: if the algo- 
rithm terminates in a bad local rninima it can restart from a new random weight 
vector. EES can be estimated from a set of independent learning trials as the 
ratio of total epochs to successful trials. The results of the parity experiments are 
summarized in table 2. Again, the optimization techniques were more efficient than 
Back-propagation. This fact is most evident in the case of bad trials. All trials used 
r = 1, 7 = le -- 4, r = 0.1 and e = le - 8. Back-propagation used e = I and f] -- 0. 
TABLE 2. Parity Results 
I1 Parity l alg l trials avg, (s.d.) aVgun, (s.d.) EES II 
2-2-1 P-R 100 72% 73 (43) 232 (54) 163 
S-D 100 80% 95 (115) 3077 (339) 864 
B-B 100 78% 684 (1460) 47915 (5505) 14197 
4-4-1 P:R 100 61%""' 352 (122) 453 (117) 641 
s-D 100 99% 2052 (1753) 18512 (-) 2324 
B-B 100 71% 8704 (8339) 95345 (11930) 48430 
8-8-1 P-R 16 50% 1716 (748) 953 (355) 2669 
S-D 6 >10000 >10000 >10000 
B:B 2 >100000 >100000 >100000 
12 LETTER RECOGNITION 
One criticism of batch-based gradient descent techniques is that for large real-world, 
real-valued learning problems, they will be be less efficient than On-line Back- 
propagation. The task of characterizing hand drawn examples of the 26 capital 
letters was chosen as a good problem to test this, partly because others have used 
this problem to demonstrate that On-line Back-propagation is more efficient than 
Batch Back-propagation {Le Cun, 1986}. The experimental setup was as follows: 
Characters were hand-entered in a 80 x 120 pixel window with a 5 pixel-wide brush 
(mouse controlled). Because the objective was to have many noisy examples of the 
same input pattern, not to learn scale and orientation invariance, all characters were 
roughly centered and roughly the full size of the window. Following character entry, 
the input window was symbolically gridded to define 100 8 x 12 pixel regions. Each 
of these regions was an input and the percentage of ""on"" pixels in the region was 
its value. There were thus 100 inputs, each of which could have any of 96 (8 x 12) 
distinct values. 26 outputs were used to represent a one-hot encoding of the 26 
letters, and a network with a single hidden layer containing 10 units was chosen. 
The network thus had a 100-10-26 architecture; all nodes used the logistic function. 
Efficient Parallel Learning Algorithms 47 
A training set consisting of 64 distinct sets of the 26 upper case letters was created 
by hand in the manner described. 25 ""A"" vectors are shown in figure 1. This 
large training set was recursively split in half to define a series of 6 successively 
larger training sets; Ro to Ra, where Ro is the smallest training set consisting 
of 1 of each letter and Ri contains /?4- and 2 i-1 new letter sets. A testing set 
consisting of 10 more sets of hand-entered characters was also created to measure 
network performance. For each /t4, we compared naive learning to incremehtal 
learning, where naive learning means initializing W(o i) randomly and incremental 
(i-) (the solution weight vector to the learning 
learning means setting w(0 i) to w, 
problem based on Ri-l). The incremental epoch count for the problem based on 
Ri was normalized to the number of epochs needed starting from w(, i- 1) plus  the 
number of epochs taken by the problem based on Ri- (since ]Ri-i] = �]Ri[). This 
normalized count thus reflects the total number of relative epochs needed to get 
from a naive network to a solution incrementally. 
Both Polak-Ribiere and On-line Back-propagation were tried on all problems. Table 
3 contains only results for the Polak-Ribiere method because no combination of 
weight-decay and learning rate were found for which Back-propagation could find a 
solution after 1000 times the number of iterations taken by Polak-Ribiere, although 
values of 7 from 0.0 to 0.001 and values for a from 1.0 to 0.001 were tried. All 
problems had r -- 1, 7 - 0.01, 7' - le - 8 and e = 0.1. Only a single trial was done 
for each problerm Performance on the test set is shown in the last column. 
FIGURE 1. 25 ""A""s 
TABLE 3. Letter Recognition 
prob Learning Time (epochs) Test 
� I I % 
R0 95 95 95 53.5 
R1 83 130 85 69.2 
R2 63 128 271 80.4 
R3 14 78 388 83.4 
R4 191 230 1129 92.3 
R5 153 268 1323 98.1 
R6 46 180 657 99.6 
The incremental learning paradigm was very effective at reducing learning times. 
Even non-incrementally, the Polak-Ribiere method was more efficient than on-line 
Back-propagation on this problem. The network with only 10 hidden units was 
sufficient, indicating that these letters can be encoded by a compact set of features. 
13 CONCLUSIONS 
Describing the computational task of learning in feedforward neural networks as 
an optimization problem allows exploitation of the wealth of mathematical pro- 
gramming algorithms that have been developed over the years. We have found 
48 Kramer and Sang/ovanni-Vincentelli 
that the Polak-Ribiere algorithm offers superior convergence properties and signif- 
icant speedup over the Back-propagation algorithm. In addition, this algorithm is 
well-suited to parallel implementation on massively parallel computers such as the 
Connection Machine. Finally, incremental learning is a way to increase the efficiency 
of optimization techniques when applied to large real-world learning problems such 
as that of handwritten character recognition. 
Acknowledgments 
The authors would like to thank Greg Sotkin for helpful discussions. This work was 
supported by the Joint Services Educational Program grant #482427-25304. 
References 
{Avriel, 1976) Mordecai Avriel. Nonlinear Programming, Analysis and Methods. 
Prentice-Hall, Inc., Englewood Cliffs, New Jersey, 1976. 
{Becker, 1989) Sue Becker and Yan Le Cun. Improving the Convergence of Back- 
Propagation Learning with Second Order Methods. In Proceedings of the 1988 
Connectionist Models Summer School, pages 29-37, Morgan Kaufmann, San 
Mateo Calif., 1989. 
{Fahlman, 1989) Scott E. Fahlman. Faster Learning Variations on Back-Propagation: 
An Empirical Study. In Proceedings of the 1988 Connectionist Models Sum- 
mer School, pages 38-51, Morgan Kaufmann, San Mateo Calif., 1989. 
{Hillis, 1986) William D. Hillis. The Connection Machine. MIT Press, Cambridge, 
Mass, 1986. 
{Hinton, 1986) G. E. Hinton. Learning Distributed Representations of Concepts. 
In Proceedings of the Cognitive Science Society, pages 1-12, Erlbaum, 1986. 
(Kramer, 1989) Alan H. Kramer. Optimization Techniques for Neural Networks. 
Technical Memo # UCB-ERL-M89-1, U.C. Berkeley Electronics Research L ab- 
oratory, Berkeley Calif., Jan. 1989. 
{Le Cun, 1986} Yan Le Cun. HLM: A Multilayer Learning Network. In Pro- 
ceedings of the 1986 Connectionist Models Summer School, pages 169-177, 
Carnegie-Mellon University, Pittsburgh, Penn., 1986. 
{Luenberger, 1986) David G. Luenberger. Linear and Nonlinear Programming. 
Addison-Wesley Co., Reading, Mass, 1986. 
(Powell, 1977) M. J. D. Powell. ""Restart Procedures for the Conjugate Gradient 
Method"", Mathematical Programming 12 (1977) 241-254 
{Rumelhart, 1986) David E Rumelhart, Geoffrey E. Hinton, and R. J. Williams. 
Learning Internal Representations by Error Propagation. In Parallel Dis- 
tributed Processing: Ezplorations in the Microstructure. of Cognition. Vol 1: 
Foundations, pages 318-362, MIT Press, Cambridge, Mass., 1986 
", parallel learn neural network kramer eec berkeley ca optim techniqu appli problem feedforward neural addit converg optim techniqu method also significantli effici result base experi small boolean learn problem noisi problem charact problem learn feedforward neural network receiv great deal attent recent abil network repres seemingli map effici parallel learn problem character optim uniqu sever evalu underli network evalu easili describ network learn problem numer framework investig parallel compar perform sever optim techniqu standard result show clear superior numer neural network neural network character node learn first two weight valu free paramet talk refer paramet space defin weight thu vector point weightspac defin valu weight usual index compon weight vector mean weight valu connect unit thu network function output function defin weight vector input vector parallel learn algorithm oi ith output unit node network input output node evalu inher parallel time singl input vector pipelin multipl vector evalu constant learn problem neural network refer problem find function approxim desir function defin set input vector network problem simplifi ask network function match target function finit set usual done error common measur use defin weight vector input vector eoutput defin function learn problem thu reduc find minimum valu zero network function approxim function exactli input vector train simplic write rather optim techniqu frame learn problem classic problem network learn problem function approxim function finit goal find set paramet valu minim cost error target function approxim optim algorithm use solv type algorithm proven effect varieti applic algorithm iter thu wk weight iter character search direct step weight vector updat take step search direct otkd kramer direct neg suffici step reduc valu optim algorithm vari way determin otherwis structur converg criterion choic converg criterion algorithm must termin suffici may done threshold valu alon case error surfac local possibl error threshold case algorithm never research use iter limit guarante termin despit error threshold practic problem limit known approach necessari condit either local usual converg criterion algorithm suffici small gradient downsid use converg test success learn time longer would case error error toler usual specifi term accept bit threshold mazimum bit error appropri represent criterion simpl error reason chosen converg criterion consist gradient threshold mbe threshold termin defin max steepest descent descent classic optim algorithm search direct dk alway neg gradient steepest network learn problem comput gradient output unit unit er parallel learn algorithm evalu thu almost dual evalu latter feed former feed comput inher method steepest descent determin step inexact minim mani way perform iter natur thu involv evalu sever valu evalu requir pass entir train curv fit techniqu employ number iter need termin way curv fit employ method fals posit use wolf test termin linesearch practic find typic linesearch network learn problem termin partial conjug gradient method linesearch guarante steepest descent proven converg larg class problem converg rate linear suffer problem may requir larg number one way guarante faster converg rate make use higher other investig perform algorithm network learn mix result techniqu less paralleliz method pursu comput term storag implement algorithm connect memori extrem last concern special thu confin investig algorithm requir evalu first gradient techniqu take advantag second order inform avoid problem without requir estim storag search direct combin current gradient previou search variou rule success determin accord steepest descent determin reiniti procedur partial conjug gradient techniqu robust method steepest descent practic find method requir far fewer iter steepest kramer backpropag algorithm describ optim without algorithm method steepest descent dk rather fix algorithm similar partial conjug gradient though variat make chang weight vector follow present input see algorithm numer unsound dk may descent increas even direct descent case batch without may larg enough move one wall opposit result increas algorithm guarante reduc success can not proven find valu fast progress stabl behavior black weight decay problem perform gradient descent may boolean learn problem minima thu algorithm may travel great distanc mani research found weight decay reduc learn time techniqu view term correspond length weight vector cost modifi cost surfac way bound rather error minim perform surfac cost rel weight gradient cost function step effect weight vector factor wk parallel implement issu emphas parallel inher evalu learn algorithm must exploit without algorithm simplest gradient descent requir storag singl momentum requir storag one addit steepest descent algorithm also requir singl vector without parallel learn algorithm need addit method storag two addit addit requir optim techniqu thu addit requir essenti need linesearch singl dot singl broadcast per oper paralleliz time connect addit comput requir algorithm also especi sinc comput time domin evalu steepest descent easili implement well connect machin experiment result boolean learn compar perform steepest descent batch algorithm small boolean learn case found algorithm significantli effici problem look base network hidden use logist function node weight vector gener randomli choos compon rel weight defin converg time measur term epoch train encod problem easili scale bad local minima hidden trial use valu found work well tabl standard deviat data insignific encod result hum paramet valu averag epoch converg trial kramer pariti problem interest also easili scale weightspac known contain bad local report learn time problem local use expect epoch measur make especi one consid algorithm restart termin bad local rninima restart new random weight ee estim set independ learn trial total epoch success result pariti experi tabl optim techniqu effici fact evid case bad trial use le le use pariti result pariti alg trial ee ii letter recognit critic gradient descent techniqu larg learn less effici task character hand drawn exampl capit chosen good problem test partli other use problem demonstr effici experiment setup pixel window brush object mani noisi exampl input learn scale orient charact center roughli full size follow charact input window symbol grid defin pixel region input percentag pixel region thu could output use repres encod network singl hidden layer contain unit network thu node use logist parallel learn algorithm train set consist distinct set upper case letter creat hand manner vector shown figur train set recurs split half defin seri success train ro ro smallest train set consist letter ri contain new letter test set set charact also creat measur compar naiv learn incremeht naiv learn mean initi randomli increment solut weight vector learn mean set base increment epoch count problem base normal number epoch need start plu epoch taken problem base count thu reflect total number rel epoch need get naiv network solut tri tabl contain result method combin learn rate found could find time number iter taken although valu le singl trial done problerm perform test set shown last letter recognit learn time test increment learn paradigm effect reduc learn method effici network hidden unit indic letter encod compact set conclus comput task learn feedforward neural network optim problem allow exploit wealth mathemat algorithm develop found kramer algorithm offer superior converg properti speedup algorithm parallel implement massiv parallel comput increment learn way increas effici optim techniqu appli larg learn problem handwritten charact author would like thank greg sotkin help work joint servic educ program grant mordecai nonlinear analysi englewood new sue becker yan le improv converg learn second order proceed model summer page morgan san scott faster learn variat empir proceed connectionist model page morgan san mateo william connect mit learn distribut represent proceed cognit scienc page alan optim techniqu neural memo berkeley electron research berkeley yan le multilay learn connectionist model summer page david linear nonlinear procedur conjug gradient mathemat program david geoffrey intern represent error parallel ezplor vol page mit,2
96,96,"Mapping Classifier Systems 
Into Neural Networks 
Lawrence Davis 
BBN Laboratories 
BBN Systems and Technologies Corporation 
l0 Moulton Street 
Cambridge, MA 02238 
January 16, 1989 
Abstract
Classifier systems are machine learning systems incorporating a genetic al- 
gorithm as the learning mechanism. Although they respond to inputs that neural 
networks can respond to, their intemal structure, representation formalisms, and 
learning mechanisms differ markedly from those employed by neural network re- 
searchers in the same sorts of domains. As a result, one might conclude that these 
two types of machine learning formalisms are intrinsically different. This is one 
of two papers that, taken together, prove instead that classifier systems and neural 
networks are equivalent. In this paper, half of the equivalence is demonstrated 
through the description of a transformation procedure that will map classifier 
systems into neural networks that are isomorphic in behavior. Several alterations 
on the commonly-used paradigms employed by neural network researchers are 
required in order to make the transformation work. These alterations are noted 
and their appropriateness is discussed. The paper concludes with a discussion of 
the practical import of these results, and with comments on their extensibility. 
1 Introduction 
Classifier systems are machine learning systems that have been developed since the 
1970s by John Holland and, more recently, by other members of the genetic algorithm 
research community as well . Classifier systems are varieties of genetic algorithms 
-- algorithms for optimization and learning. Genetic algorithms employ techniques 
inspired by the process of biological evolution in order to ""evolve"" better and better 
1This paper has benefited from discussions with Wayne Mesard, Rich Sutton, Ron Williams, Stewart 
Wilson, Craig Shaefer, David Montana, Gii Syswerda and other members of BARGAIN, the Boston Area 
Research Group in Genetic Algorithms and Inductive Networks. 
50 Das 
individuals that are taken to be solutions to problems such as optimizing a function, 
traversing a maze, etc. (For an explanation of genetic algorithms, the reader is 
referred to [Goldberg 1989].) Classifier systems receive messages from an external 
source as inputs and organize themselves using a genetic algorithm so that they will 
""learn"" to produce responses for internal use and for interaction with the external 
SOUrce. 
This paper is one of two papers exploring the question of the formal relationship 
between classifier systems and neural networks. As normally employed, the two sorts 
of algorithms are probably distinct, although a procedure for translating the operation 
of neural networks into isomorphic classifier systems is given in [Belew and Gherrity 
1988]. The technique Belew and Gherrity use does not include the conversion of the 
neural network learning procedure into the classifier system framework, and it appears 
that the technique will not support such a conversion. Thus, one might conjecture that 
the two sorts of machine learning systems employ learning techniques that cannot be 
reconciled, although if there were a subsumption relationship, Belew and Gherrity's 
result suggests that the set of classifier systems might be a superset of the set of 
neural networks. 
The reverse conclusion is suggested by consideration of the inputs that each sort 
of learning algorithm processes. When viewed as ""black boxes"", both mechanisms 
for learning receive inputs, carry out self-modifying procedures, and produce outputs. 
The class of inputs that axe traditionally processed by classifier systems -- the class 
of bit strings of a fixed length -- is a subset of the class of inputs that have been 
traditionally processed by neural networks. Thus, it appears that classifier systems 
operate on a subset of the inputs that neural networks can process, when viewed as 
mechanisms that can modify their behavior. 
In fact, both these impressions are correct. One can translate classifier systems 
into neural networks, preserving their learning behavior, and one can translate neural 
networks into classifier systems, again preserving learning behavior. In order to do 
so, however, some specializations of each sort of algorithm must be made. This 
paper deals with the translation from classifier systems to neural networks and with 
those specializations of neural networks that are required in order for the translation 
to take place. The reverse translation uses quite different techniques, and is treated 
in [Davis 1989]. 
The following sections contain a description of classifier systems, a description of 
the transformation operator, discussions of the extensibility of the proof, comments 
on some issues raised in the course of the proof, and conclusions. 
2 Classifier Systems 
A classifier system operates in the context of an environment that sends messages to 
the system and provides it with reinforcement based on the behavior it displays. A 
classifier system has two components -- a message list and a population of rule-lilce 
entities called classifiers. Each message on the message list is composed of bits, and 
Mapping Classifier Systems Into Neural Networks 51 
each has a pointer to its source (messages may be generated by the environment or 
by a classifier.) Each classifier in the population of classifiers has three components: 
a match sty'rig made up of the characters 0,1, and # (for ""don't care""); a message 
made up of the characters 0 and 1; and a strength. The top-level description of a 
classifier system is that it contains a population of production rules that attempt to 
match some condition on the message list (thus ""classifying"" some input) and post 
their message to the message list, thus potentially affecting the environment or other 
classifiers. Reinforcement from the environment is used by the classifier system to 
modify the strengths of its classifiers. Periodically, a genetic algorithm is invoked 
to create new classifiers, which replace certain members of the classifier set. (For 
an explanation of classifier systems, their potential as machine learning systems, and 
their formal properties, the reader is referred to [Holland et al 1986].) 
Let us specify these processing stages more precisely. A classifier system operates 
by cycling through a fixed list of procedures. In order, these procedures are: 
Message List Processing. 1. Clear the message list. 2. Post the environmental 
messages to the message list. 3. Post messages to the message list from classifiers 
in the post set of the previous cycle. 4. Implement environmental reinforcement by 
analyzing the messages on the message list and altering the strength of classifiers in 
the post set of the previous cycle. 
Form the Bid Set. 1. Determine which classifiers match a message in the 
message list. A classifier matches a message if each bit in its match field matches its 
corresponding message bit. A 0 matches a 0, a I matches a 1, and a # matches either 
bit. The set of all matching classifiers forms the current bid set. 2. Implement bid 
taxes by subtracting a portion of the strength of each classifier � in the bid set. Add 
the strength taken from � to the strength of the classifier or classifiers that posted 
messages matched by � in the prior step. 
Form the Post Set. 1. If the bid set is larger than the maximum post set size, 
choose classifiers stochastically to post from the bid set, weighting them in proportion 
to the magnitude of their bid taxes. The set of classifiers chosen is the post set. 
Reproduction Reproduction generally does not occur 'on every cycle. When it 
does occur, these steps are carried out: 1. Create n children from parents. Use 
crossover and/or mutation, choosing parents stochastically but favoring the strongest 
ones. (Crossover and mutation are two of the operators used in genetic algorithms.) 
2. Set the strength of each child to equal the average of the strength of that child's 
parents. (Note: this is one of many ways to set the strength of a new classifier. 
The transformation will work in analogous ways for each of them.) 3. Remove n 
members of the classifier population and add the n new children to the classifier 
population. 
3 Mapping Classifiers Into Classifier Networks 
The mapping operator that I shall describe maps each classifier into a classifier 
network. Each classifier network has links to environmental input units, links to 
52 Das 
other classifier networks, and match, post, and message units. The weights on the 
links leading to a match node and leaving a post node are related to the fields in 
the match and message lists in the classifier. An additional link is added to provide 
a bias term for the match node. (Note: it is assumed here that the environment 
posts at most one message per cycle. Modifications to the transformation operator to 
accommodate multiple environmental messages are described in the final comments 
of this paper.) 
Given a classifier system CS with n classifiers, each matching and sending mes- 
sages of length m, we can construct an isomorphic neural network composed of r 
classifier networks in the following way. For each classifier � in CS, we construct its 
corresponding classifier network, composed of r match nodes, I post node, and rn 
message nodes. One match node (the environmental match node) has links to inputs 
from the environment. Each of the other match nodes is linked to the message and 
post node of another classifier network. The reader is referred to Figure 2 for an 
example of such a transformation. 
Each match node in a classifier network has rn + 1 incoming links. The weights 
on the first m links are derived by applying the following transformation to the m 
elements of c's match field: 0 is associated with weight -1, 1 is associated with 
weight 1, and # is associated with weight 0. The weight. of the final link is set to 
rn + I - l, where I is the number of links with weight = 1. Thus, a classifier with 
match field (1 0 # 0 1) would have an associated network with weights on the links 
leading to its match nodes of 1, -1, 0, -1, 1, and 4. A classifier with match field (1 
0 #) would have weights of 1, -1, 0, and 3. 
The weights on the links to each message node in the classifier network are set 
to equal the corresponding element of the classifier's message field. Thus, if the 
message field of the classifier were (0 I 0), the weights on the links leading to the 
three message nodes in the corresponding classifier network would be 0, 1, and 0. 
The weights on all other links in the classifier network are set to 1. 
Each node in a classifier network uses a threshold function to determine its acti- 
vation level. Match nodes have thresholds = rn + .9. All other nodes have thresholds 
= .9. If a node's threshold is exceeded, the node's activation level is set to 1. If not, 
it is set to 0. 
Each classifier network has an associated quantity called strength that may be 
altered when the network is run, during the processing cycle described below. 
A cycle of processing of a classifier system CS maps onto the following cycle of 
processing in a set of classifier networks: 
Message List Processing. 1. Compute the activation level of each message 
node in CS. 2. If the environment supplies reinforcement on this cycle, divide that 
reinforcement by the number of post nodes that are currently active, plus I if the 
environment posted a message on the preceding cycle, and add the quotient to the 
strength of each active post node's classifier network. 3. If there is a message on this 
cycle from the environment, map it onto the first rn environment nodes so that each 
node associated with a 0 is off and each node associated with a 1 is on. Turn the final 
environmental node on. If there is no environmental message, turn all environmental 
Mapping Classifier Systems Into Neural Networks 53 
nodes off. 
Form the Bid Set. 1. Compute the activation level of each match node in 
each classifier network. 2. Compute the activation level of each bid node in each 
classifier network (the set of classifier networks with an active bid node is the bid 
set). 3. Subtract a fixed proportion of the strength of each classifier network cn in 
the bid set. Add this amount to the strength of those networks connected to an active 
match node in cn. (Strength given to the environment passes out of the system.) 
Form the Post Set. 1. If the bid set is larger than the maximum post set size, 
choose networks stochastically to post from the bid set, weighting them in proportion 
to the magnitude of their bid taxes. The set of networks chosen is the post set. (This 
might be viewed as a stochastic n-winners-take-all procedure). 
Reproduction. If this is a cycle on which reproduction would occur in the 
classifier system, carry out its analog in the neural network in the following way. 
1. Create r children from parents. Use crossover and/or mutation, choosing parents 
stochastically but favoring the strongest ones. The ternary alphabet composed of -1, 
1, and 0 is used instead of the classifier alphabet of 0, 1, and #. After each operator 
is applied, the final member of the match list is set to rn + 1 - I. 2. Write over the 
weights on the match links and the message links of r classifier networks to match 
the weights in the children. Choose networks to be re-weighted stochastically, so that 
the weakest ones are most likely to be chosen. Set the strength of each re-weighted 
classifier network to be the average of the strengths of its parents. 
It is simple to show that a classifier network match node will match a message 
in just those cases in which its associated classifier matched a message. There are 
three cases to consider. If the original match character was a #, then it matched any 
message bit. The corresponding link weight is set to 0, so the state of the node it 
comes from will not affect the activation of the match node it goes to. If the original 
match character was a 1, then its message bit had to be a I for the message to be 
matched. The corresponding link weight is set to 1, and we see by inspection of the 
weight on the final link, the match node threshold, and the fact that no other type 
of link has a positive weight, that every link with weight 1 must be connected to an 
active node for the match node to be activated. Finally, the link weight corresponding 
to a 0 is set to -1. If any of these links is connected to a node that is active, then the 
effect is that of turning off a node connected to a link with weight 1, and we have 
just seen that this will cause the match node to be inactive. 
Given this correspondence in matching behavior, one can verify that a set of 
classifier networks associated with a classifier system has the following properties: 
During each cycle of processing of the classifier system, a classifier is in the bid set 
in just those cases in which its associated network has an active bid node. Assuming 
that both systems use the same randomizing technique, initialized in the same way, 
the classifier is in the post set in just those cases when the network is in the post 
set. Finally, the parents that are chosen for reproduction are the transformas of those 
chosen in the classifier system, and the children produced are the transformations of 
the classifier system parents. The two systems are isomorphic in operation, assuming 
that they use the same random number generator. 
54 Davis 
CLASSIFIER NETWORK 1 
strength = 49,3 
CLASSIFIER NETWORK 2 
strength = 21.95 
MESSAGE 
NODES 
TH = .9 
POST 
NODES 
TH = .9 
-1 
MATCH 
NODES 
TH = 3,9 
ENVIRONMENT 
INPUT 
NODES 
Figure 1: Result of mappinga classifier system 
witfl two classifiers into a neural network, 
Classifier 1 has match field(O 1 ), message field(1 1 0), 
and strength 49,3, Classifier2 has match field(1 1 ), 
message field(O 1 1), and strength 21.95, 
Mapping Classifier Systems Into Neural Networks 55 
4 Concluding Comments 
The transformation procedure described above will map a classifier system into a 
neural network that operates in the same way. There are several points raised by the 
techniques used to accomplish the mapping. In closing, let us consider four of them. 
First, there is some excess complexity in the classifier networks as they are shown 
here. In fact, one could eliminate all non-environmental match nodes and their 
links, since one can determine whenever a classifier network is reweighted whether it 
matches the message of each other classifier network in the system. If so, one could 
introduce a link directly from the post node of the other classifier network to the post 
node of the new network. The match nodes to the environment are necessary, as 
long as one cannot predict what messages the environment will post. Message nodes 
are necessary as long as messages must be sent out to the environment. If not, they 
and theix incoming links could be eliminated as well. These simplifications have not 
been introduced here because the extensions discussed next require the complexity 
of the current architecture. 
Second, on the genetic algorithm side, the classifier system considered here is an 
extremely simple one. There are many extensions and refinements that have been 
used by classifier system researchers. I believe that such refinements can be handled 
by expanded mapping procedures and by modifications of the architecture of the 
classifier networks. To give an indication of the way such modifications would go, 
let us consider two sample cases. The first is the case of an environment that may 
produce multiple messages on each cycle. To handle multiple messages, an additional 
link must be added to each environmental match node with weight set to the match 
node's threshold. This link will latch the match node. An additional match node 
with links to the environment nodes must be added, and a latched counting node 
must be attached to it. Given these two architectural modifications, the cycle is 
modified as follows: During the message matching cycle, a series of subcycles is 
carried out, one for each message posted by the environment. In each subcycle, an 
environmental message is input and each environmental match node computes its 
activation. The environmental match nodes are latched, so that each will be active 
if it matched any environmental message. The count nodes will record how many 
were matched by each classifier network. When bid strength'is paid from a classifier 
network to the posters of messages that it matched, the divisor is the number of 
environmental messages matched as recorded by the count node, plus the number 
of other messages matched. Finally, when new weights are written onto a classifier 
network's links, they are written onto the match node connected to the count node 
as well. A second sort of complication is that of pass-through bits -- bits that 
are passed from a message that is matched to the message that is posted. This 
sort of mechanism can be implemented in an obvious fashion by complicating the 
structure of the classifier network. Similar complications are produced by considering 
multiple-message matching, negation, messages to effectors, and so forth. It is an 
open question whether all such cases can be handled by modifying the architecture 
and the mapping operator, but I have not yet found one that cannot be so handled. 
56 Davis 
Third, the classifier networks do not use the sigmoid activation functions that sup- 
port hill-climbing techniques such as back-propagution. Further, they are recurrent 
networks ra{her than strict feed-forward networks. Thus, one might wonder whether 
the fact that one can carry out such transformations should affect the behavior of 
researchers in the field. This point is one that is taken up at greater length in the 
companion paper. My conclusion there is that several of the techniques imported into 
the neural network domain by the mapping appear to improve the performance of neu- 
ral networks. These include tracking strength in order to guide the learning process, 
using genetic operators to modify the network makeup, and using population-level 
measurements in order to determine what aspects of a network to use in reproduction. 
The reader is referred to [Montana and Davis 1989] for an example of the benefits 
to he gained by employing these techniques. 
Finally, one might wonder what the import of this proof is intended to be. In 
my view, this proof and the companion proof suggest some exciting ways in which 
one can hybridize the learning techniques of each field. One such approach and its 
successful application to a real-world problem is characterized in [Montana and Davis 
1989]. 
References 
[1] Belew, Richard K. and Michael Gherrity, ""Back Propagation for the Classifier 
System"", in preparation. 
[2] Davis, Lawrence, ""Mapping Neural Networks into Classifier Systems"", submit- 
ted to the 1989 International Conference on Genetic Algorithms. 
[3] Goldberg, David E. Genetic Algorithms in Search, Optimization, and Machine 
Learning, Addison Wesley 1989. 
[4] Holland, John H, Keith J. Holyoak, Richard E. Nishett, and Paul R. Thagard, 
Induction, MIT Press, 1986. 
[5] 
Montana, David J. and Lawrence Davis, ""Training Feedforward Neural Net- 
works Using Genetic Algorithms"", submitted to the 1989 International Joint 
Conference on Artificial Intelligence. 
", map classifi system neural network davi laboratori system technolog corpor moulton street system machin learn system incorpor genet learn although respond input neural respond intem represent mechan differ markedli employ neural network sort one might conclud type machin learn formal intrins one two paper taken prove instead classifi system neural half equival demonstr descript transform procedur map classifi neural network isomorph sever alter paradigm employ neural network research order make transform alter note appropri paper conclud discuss practic import comment introduct system machin learn system develop sinc john holland member genet algorithm commun well classifi system varieti genet algorithm algorithm optim genet algorithm employ techniqu process biolog evolut order better better paper benefit discuss wayn rich ron stewart craig david gii syswerda member boston area group genet algorithm induct taken solut problem optim explan genet reader classifi system receiv messag extern input organ use genet algorithm produc respons intern use interact extern paper one two paper explor question formal relationship classifi system neural normal two sort algorithm probabl although procedur translat oper neural network isomorph classifi system given gherriti techniqu belew gherriti use includ convers network learn procedur classifi system appear techniqu support one might conjectur two sort machin learn system employ learn techniqu can not although subsumpt belew suggest set classifi system might superset set revers conclus suggest consider input sort learn algorithm view mechan learn receiv carri produc class input axe tradit process classifi system class bit string fix length subset class input process neural appear classifi system subset input neural network view modifi impress one translat classifi system neural preserv learn one translat neural classifi preserv learn order special sort algorithm must deal translat classifi system neural network special neural network requir order translat take revers translat use quit differ treat follow section contain descript classifi descript transform discuss extens comment issu rais cours classifi system classifi system oper context environ send messag system provid reinforc base behavior system two compon messag list popul call messag messag list compos classifi system neural network pointer sourc may gener environ classifi popul classifi three match made charact messag charact descript system contain popul product rule attempt condit messag list post messag messag thu potenti affect environ reinforc environ use classifi system strength genet algorithm invok creat new replac certain member classifi explan classifi potenti machin learn formal reader refer et al us specifi process stage classifi system oper cycl fix list procedur list clear messag post environment messag post messag messag list classifi post set previou implement environment reinforc messag messag list alter strength classifi post set previou bid determin classifi match messag classifi match messag bit match field match messag match match match either set match classifi form current bid implement bid subtract portion strength classifi bid add strength taken strength classifi classifi post match prior post bid set larger maximum post set classifi stochast post bid weight proport magnitud bid set classifi chosen post reproduct gener occur everi step carri creat children use choos parent stochast favor strongest mutat two oper use genet set strength child equal averag strength one mani way set strength new transform work analog way remov classifi popul add new children classifi map classifi classifi network map oper shall describ map classifi classifi classifi network link environment input link classifi messag weight lead match node leav post node relat field match messag list addit link ad provid bia term match assum environ one messag per modif transform oper multipl environment messag describ final comment classifi system cs match send length construct isomorph neural network compos network follow classifi construct classifi compos match post rn one match node environment match link input match node link messag node anoth classifi reader refer figur match node classifi network rn incom weight first link deriv appli follow transform match associ weight associ associ weight final link set number link weight classifi field would associ network weight link match node classifi match field would weight weight link messag node classifi network set equal correspond element messag field classifi weight link lead messag node correspond classifi network would weight link classifi network set node classifi network use threshold function determin match node threshold rn node threshold threshold activ level set set classifi network associ quantiti call strength may network process cycl describ cycl process classifi system cs map onto follow cycl set classifi list comput activ level messag environ suppli reinforc divid number post node current plu post messag preced add quotient activ post classifi messag map onto first rn environ node associ node associ turn final node environment turn environment classifi system neural network bid comput activ level match node classifi comput activ level bid node network set classifi network activ bid node bid subtract fix proport strength classifi network cn bid add amount strength network connect activ node given environ pass post bid set larger maximum post set network stochast post bid weight proport magnitud bid set network chosen post view stochast cycl reproduct would occur carri analog neural network follow creat children use crossov choos parent favor strongest ternari alphabet compos use instead classifi alphabet oper final member match list set rn write match link messag link classifi network match weight choos network weakest one like set strength network averag strength simpl show classifi network match node match messag case associ classifi match case origin match charact match correspond link weight set state node affect activ match node goe origin charact messag bit messag correspond link weight set see inspect final match node fact type link posit everi link weight must connect node match node link weight correspond set link connect node turn node connect link weight seen caus match node correspond match one verifi set network associ classifi system follow cycl process classifi classifi bid set case associ network activ bid assum system use random initi classifi post set case network post parent chosen reproduct transforma classifi children produc transform classifi system two system isomorph assum use random number davi network network result mappinga classifi system two classifi neural match messag strength match strength classifi system neural network conclud comment transform procedur describ map classifi system network oper sever point rais use accomplish let us consid four excess complex classifi network shown one could elimin match node sinc one determin whenev classifi network reweight whether messag classifi network one could link directli post node classifi network post new match node environ one can not predict messag environ messag node necessari long messag must sent theix incom link could elimin simplif introduc extens discuss next requir complex current genet algorithm classifi system consid simpl mani extens refin classifi system believ refin handl expand map procedur modif architectur give indic way modif would us consid two sampl first case environ may multipl messag handl multipl addit must ad environment match node weight set match link latch match addit match node link environ node must latch count node attach given two architectur cycl messag match seri subcycl one messag post messag input environment match node comput environment match node activ match environment count node record mani match classifi bid paid classifi poster messag divisor number messag match record count plu number messag new weight written onto classifi written onto match node connect count node second sort complic bit bit pass messag match messag mechan implement obviou fashion complic classifi similar complic produc consid messag question whether case handl modifi architectur map yet found one can not davi classifi network use sigmoid activ function techniqu recurr strict one might wonder whether fact one carri transform affect behavior point one taken greater length conclus sever techniqu import neural network domain map appear improv perform includ track strength order guid learn genet oper modifi network use order determin aspect network use reader refer davi exampl benefit gain employ one might wonder import proof intend proof companion proof suggest excit way hybrid learn techniqu one approach applic problem character davi richard michael propag classifi neural network classifi intern confer genet david genet algorithm machin addison wesley john keith richard paul mit david lawrenc feedforward neural use genet submit intern joint artifici,1
97,97,"57 
Self Organizing Neural Networks for the 
Identification Problem 
Manoel Fernando Tenorio 
School of Electrical Engineering 
Purdue University 
W. Lafayette, IN. 47907 
tenorio@ ee.ecn.purdue.edu 
Wei-Tsih Lee 
School of Electrical Engineering 
Purdue University 
W. Lafayette, IN. 47907 
lwl@ ed.ecn.purdue.edu 
ABSTRACT 
This work introduces a new method called Self Organizing 
Neural Network (SONN) algorithm and demonstrates its use in a 
system identification task. The algorithm constructs the network, 
chooses the neuron functions, and adjusts the weights. It is compared to 
the Back-Propagation algorithm in the identification of the chaotic time 
series. The results shows that SONN constructs a simpler, more 
accurate model, requiring less training data and epochs. The algorithm 
can be applied and generalized to appilications as a classifier. 
I. INTRODUCTION 
1.1 THE SYSTEM IDENTIFICATION PROBLEM 
In various engineering applications, it is important to be able to estimate, interpolate, 
and extrapolate the behavior of an unknown system when only its input-output pairs are 
available. Algorithms which produce an estimation of the system behavior based on these 
pairs fall under the category of system identification techniques. 
1.2 SYSTEM IDENTIFICATION USING NEURAL 
NETWORKS 
A general form to represent systems, both linear and nonlinear, is the Kolmogorov- 
Garbor polynomial [Garbor, 1961 ] shown below: 
y = a0 + Z aixi + X E aijxixj +'"" 
i i j (1) 
58 Tenorio and Lee 
where the y is the output, and x the input to the system. [Garbor ,1961] proposed a 
learning method that adjuswat the coefficient of (1) by minimizing the mean square error 
between each desired output sample and the actual output. 
This paper describes a supervised learning algorithm for structure construction and 
adjustment. Here, systems which can be described by (1) are presented. The computation 
of the function for each neuron performs a choice from a set of possible functions 
previously assigned to the algorithm, and it is general enough to accept a wide range of 
both continuous and discrete functions. In this work, the set is taken from variants of the 
2-input quadratic polynomial for simplicity, although there is no requirement making it 
so. This approach abandons the simplistic mean-square error for performance measure in 
favor of a modified Minimum Description Length (MDL) criterion [Rissanen,1975], with 
provisions to measure the complexity of the model generated. The algorithm searches for 
the simplest model which generates the best estimate. The modified MDL, from hereon 
named the Structure Estimation Criterion (SEC), is applied hierarchically in the selection 
of the optimal neuron transfer function from the function set, and then used as an optimal 
criterion to guide the construction of the structure. The connectivity of the resulting 
structure is.arbitrary, and under the correct conditions [Geman&Geman, 84] the estimation 
of the structure is optimal in terms of the output error and low function complexity. This 
approach shares the same spirit of GMDH-type algorithms. However, the concept of 
parameter estimation from Information Theory, combined with a stochastic search 
algorithm - Simulated Annealing, was used to create a new tool for system identification. 
This work is organized as follows: section II presents the problem formulation and the 
Self Organizing Neural Network (SONN) algorithm description; section III describes the 
results of the application of SONN to a well known problem tested before using other 
neural network algorithms [Lapedes&Farber, 1987; Moody, 1988]; and finally, section IV 
presents a discussion of the results and future directions for this work. 
II. THE SELF ORGANIZING NEURAL NETWORK 
ALGORITHM 
II.1 SELF ORGANIZING STRUCTURES 
The Self Organizing Neural Network (SONN) algorithm performs a search on the model 
space by the construction of hypersurfaces. A network of nodes, each node representing a 
hypersurface, is organized to be an approximate model of the real system. SONN can be 
fully characterized by three major components, which can be modified to incorporate 
knowledge about the process: (1) a generating rule of the primitive neuron transfer 
functions, (2) an evaluation method which accesses the quality of the model, and, (3) a 
structure search strategy. Below, the components of SONN are discussed. 
II.2 THE ALGORITHM STRUCTURE 
Self Organizing Neural Networks 59 
II.2.1 The Generating Rule 
Given a set of observations S: 
S = {(Xl, Y1),(X2, Y2),...,(Xl, Vl)} 
Yi = f(Xi) + 1 
(2) 
where f(.) is represented by a Kolmogorov-Garbor polynomial, and the random variable 
'1 is normally distributed, N(O,1). The dimensions of Y is m, and the dimensions of X is 
n. Every component Yk of Y forms a hypersufface Yk = fk(X) in the space of dim (X) + 
1. The problem is to find f(.), given the observations S, which is a corrupted version of 
the desired function. In this work, the model which estimates f(.) is desired to be as 
accurate and simple (small number of parameters, and low degree of non linearity) as 
possible. 
The approach taken here is to estimate the simplest model which best describes f(.) by 
generating optimal functions for each neuron, which can be viewed as the construction of 
a hypersurface based on the observed data. It can be described as follows: given a set of 
observations S; use p components of the n dimensional space of X to create a 
hypersurface which best describes Yk = f(X), through a three step process. First, given X 
= [x 1, x 2, x 3, ..., x n] and Yk' and the mapping t'n: [x 1, x2, x3, ..., Xn] -> [xt,(1), 
xt,(2 ), xt,(3 ), ..., xt,(n)], construct the hypersurface hl(Xt,(1), xt,(2), xt,(3), ..., 
xt,(n)) (h i after the first iteration) of p+l dimensions, where t' n is a projection from n 
dimensions to p dimensions. The elements of the domain of t' n are called terminals. 
Second, If the global optimality criterion is reached by the construction of hi(xt,(l ), 
xt,(2 ), xt,(3 ), ..., xt,(n)), then stop, otherwise continue to the third step. Third, 
generate from [x 1, x 2, x 3, ..., xn,hl(Xt,(1), xt,(2), xt,(3), ..., xt,(n)) ] a new p+l 
dimensional hypersurface hi+ 1 through the extended mapping t'n+l(. ), and reapply the 
second step. The resulting model is a multilayered neural network whose topology is 
arbitrarily complex and creawxi by a stochastic search guided by a structure estimation 
criterion. For simplicity in this work, the set of prototype functions (F) is reslricWxl to be 
2-input quadratic surfaces or smaller, with only four possible types: 
y = ao+alxl+a2x2 (3) 
y = ao+alxl+a2x2+a3xlx2 (4) 
Y = ao+alxl+a2x21 (5) 
Y = ao+alxl+a2x2+a3xlx2+a4x21+asx (6) 
II.2.2 Evaluation of the Model Based on the MDL Criterion 
The selection rule (T) of the neuron transfer function was based on a modification of the 
Minimal Description Length (MDL) information criterion. In [Rissanen, 1975] the 
principle of minimal description for statistical estimation was developed. The MDL 
provides a wade-off between the accuracy and the complexity of the model by including 
the structure estimation term of the final model. The final model (with the minimal 
60 Tenorio and Lee 
MDL) is optimum in the sense of being a consistent estimate of the number of 
parameters while achieving the minimum error [Rissanen, 1980]. Given a sequence of 
observation x10t20t3,...,x N from the random variable X, the dominant term of the MDL 
in [Rissanen, 1975] is: 
MDL = - log f(xl0) + 0.5 k log N 
where f(x10) is the estimated probability density function of the model, k is the number 
of parameters, and N is the number of observations. The first term is actually the negative 
of the maximum likelihood (ML) with respect to the estimated parameter. The second 
term describes the structure of the models and it is used as a penalty for the complexity of 
the model. In the case of linear polynomial regression, the MDL is: 
MDL = - 0.5 N log S2n + 0.5 k log N 
where k is the number of coefficients in the model selected. 
In the SONN algorithm, the MDL criterion is modified to operate both recursively and 
hierarchically. First, the concept of the MDL is applied to each candidate prototype 
surface for a given neuron. Second, the acceptance of the node, based on Simulated 
Annealing, uses the MDL measure as the system energy. However, since the new neuron 
is generateA from terminals which can be the output of other neurons, the original 
definition of the MDL is unable to compute the true number of system parameters of the 
final function. Recall that due to the arbitrary connectivity, feedback loops and other 
configurations it is non trivial to compute the number of parameters in the entire 
structure. In order to reflect the hierarchical nature of the model, a modified MDL called 
Structure Estimation Criterion (SEC) is used in conjunction with an heuristic estimator 
of the number of parameters in the system at each stage of the algorithm. A 
computationally efficient heuristic for the estimation of the number of parameters in the 
model is based on the fact that SONN creates a tree-like structure with multiple roots at 
the input terminals. Then k, in expression (8), can be estimated recursively by: 
k = kL + kR + (no. of parameters of the current node) (9) 
where kL and kR are the estimated number of parameters of the left and right parents of 
the current node, respectively. This heuristic estimator is neither a lower bound nor an 
upper bound of the true number of parameter in the model. 
II.2.3 The SONN Algorithm 
To explain the algorithm, the following definitions are necessary: Node - neuron and the 
associated function, connections, and SEC; BASIC NODE - A node for the system input 
variable; FRONT NODE - A node without children; INTERMIDIATE NODE - The nodes 
that are neither front or basic nodes; STATE - The collection of nodes, and the 
configuration of their interconnection; INITIAL STATE (SI) - The state with only basic 
nodes; PARENT AND CHILD STATE - The child state is equal to the parent state except 
for f a new node and its interconnection generated on the parent state structure; 
NEIGHBOR STATE - A state that is either a child or a parent state of another; ENERGY 
Self Organizing Neural Networks 6! 
OF THE STATE (SEC-Si) - The energy of the state is defined as the minimum SEC of 
all the front nodes in that state. 
In the SONN algorithm, the search for fie correct model structure is done via Simulated 
Annealing. Therefore the algorithm at times can accept partial structures that look less 
than ideal. In the same way, it is able to discard partially constructed substructures in 
search for better results. The use of this algorithm implies that the node accepting rule 
(R) varies at run-time according to a cooling temperature (T) schedule. The SONN 
algorithm is as follows: 
Initialize T, and SI 
Repeat 
Repeat 
Sj = generate (Si), - application of P. 
If accept ( SEC_Sj, SEC_Si, T) then Si = S j, - application of R. 
until the number of new neurons is greater than N. 
Decrease the temperature T. 
until The temperature T is smaller than Ten d (Terminal temperature for Simulated 
Annealing). 
Each neuron output and the system input variables are called terminals. Terminals are 
viewed as potential dimensions from which a new hypersurface can be constructed. Every 
terminal represents the best tentative to approximate the srstem function with the 
available infation, and are therefore treateA equally. 
HI. EXAMPLE - THE CHAOTIC TIME SERIES 
In the following results, the chaotic time series generated by the Mackay-Glass 
differential equations was used. The SONN with fle $EC, and its heuristic variant were 
used to obtain the approximate model of the system. The result is compared with those 
obtained by using the nonlinear signal processing method [Lapedes&Farber, 1987]. The 
advantages and disadvantages of both approaches are analyzed in the next section. 
III. 1 Structure of the Problem 
The MacKay-Glass differential equation used here can be described as: 
)x(t___) _ a x(t- :) - b x(t) 
t 1 + x�(t- x) (10) 
By setting a = 0.2, b = 0.1, and  = 17, a chaotic time series with a'strange attractor of 
fractal dimension about 3.5 will be produced [Lapedes&Farber, 1987]. To compare the 
accuracy of prediction the normalized root mean square error is used as a performance 
index: 
62 Tenorio and Lee 
normalized RMSE = RMSE 
Standard Deviation 
(11) 
III.2. SONN WITH THE HEURISTIC SEC (SONN-H) 
In the following examples, a modified heuristic version of the SEC is used. The estimator 
of the number of parameters is given by (9), and the f'mal configuraion is shown in figure 
1. 
III.2.1 Node 19 
In this subsection, SONN is allowed to generate up to the 19th accepted node. In this 
first version of the algorithm, all neurons have the same number of interconnections, and 
therefore draw their transfer function from the same pool of functions.. Generalizations of 
the algorithm can be easily made to accommodate multiple input functions, and neuron 
transfer function assignment being drawn from separate pools. In this example, the first 
one hundred points of the time series was used for training, and samples 101 through 400 
used for prediction testing. The total number of weights in the network is 27. The 
performance index average 0.07. The output of the network is overlapped in the figure 2 
with the original time series. 
For comparison purposes, a GDR network with the structure used in [Lapedes&Farber, 
1987] is trained for 6500 epochs. The training data consisted of the first 500 points of the 
time series, and the testing data ran from the 501st sample to the 832nd. The total 
number of weights is 165, and the final performance index equal to 0.12. This was done 
to give both algorithms similar computational resources. Figure 3 shows the original 
time series overlapped with the GDR network output. 
IH.2.2 NODE 37 
In this subsection, the model chosen was formed by the 37 th accepted node. The network 
was Wained in a similar manner to the first example, since it is part of the same run. The 
final number of weights is 40, and the performance index 0.018. Figure 4 shows the 
output of the network overlapped with the original time series. Figure 5 shows the GDR 
with 11,500 epochs. Notice that in both cases, the GDR network demands 150 
connections and 150 weights, as compared to 12 connections and 27 weights for the first 
example and 10 connections and 40 weights for the second example. The comparison of 
the performance of different models is listed in figure 6. 
IV. Conclusion and Future Work 
In this study, we proposed a new approach for the identification problem based on a 
flexible, self-organizing neural network (SONN) structure. The variable structure provides 
the opportunity to search and construct the optimal model based on input-output 
observations. The hierarchical version of the MDL, called the structure estimation criteria, 
Self Organizing Neural Networks 63 
was used to guide the trade-off between the model complexity and the accuracy of tim 
estimation. The SeNN approach demonstrates potential usefulness as a tool for system 
identification through the example of modeling a chaotic time series. 
REFERENCES
Garber, D., et. al. ,""A universal nonlinear filter, predicator and simulator which 
optimizes irsekf by a learning process,"" IEE Proc.,18B, pp. 422-438, 1961 
Rissanenj. ""Modeling by shortest dam description,"" Automatica, vol. 14, pp. 465- 
471,1975 
Gemen, S, and Gemen D., ""Stochastic relaxation, gibbs deisribution, and the bayesian 
restoration of images,"" IEEE PAMI., PAMI-6,pp.721-741, 1984 
Lapedes,A. and Farber, R. ,""Nonlinear signal processing using neural networks: 
Predicaon and system modeling,"" TR. LA-UR-87-2662, 1987 
Moody, I. This volume 
Rissanen:,j. ""Consistent order estimation of autoregressive processing by shortest 
description of data,"" Analysis and optimization of stochastic system, .l'acobs et. al. Eds. 
N.Y. Academic, 1980 
Figure 1. The 37th State Generated 
5�ll I0.. SONNimoO 
Figure 2. SONN 19th Model, P.I. = 0.06 
6 Tenorio and Lee 
SvilIiII IO 
' .y 
r 
Figure 3. GDR after 6,500 Epochs, P.I. = 0.12 
-3vslem 0.. 'ONN mode 373 
Figure 4. SONN 37th Model, P.I. = 0.038 
"":;vlle I0.. Jecl( Pfe)Daqet.k)n w,ln  I 500 Pocns 
Figure 5. GDR after 11,500 Epochs, P.I. = 0.018 
Comparison ol the Perlormace hlex 
O. t2'  
O. tO - 
008 .- .,- -'""'- 
O 06 ......... ' ....... "" 
O 02 , .'---.------'-' '--'""""-' -'--/""'""' 
Figure 6. Performance Index 
Versus the Number of Predicted Points 
", organ neural network problem fernando tenorio electr engin univers lee electr engin univers work introduc new method call self organ network algorithm demonstr use identif algorithm construct neuron adjust compar algorithm identif chaotic time result show sonn construct requir less train data algorithm appli gener appil introduct system identif problem variou engin import abl extrapol behavior unknown system pair algorithm produc estim system behavior base fall categori system identif system identif use neural gener form repres linear polynomi shown aixi aijxixj tenorio lee input propos method adjuswat coeffici minim mean squar error desir output sampl actual paper describ supervis learn algorithm structur construct system describ comput function neuron perform choic set possibl function assign gener enough accept wide rang continu discret set taken variant quadrat polynomi although requir make approach abandon simplist error perform measur modifi minimum descript length criterion measur complex model algorithm search simplest model gener best modifi hereon structur estim criterion appli hierarch select optim neuron transfer function function use optim guid construct connect result correct condit estim structur optim term output error low function share spirit concept estim inform combin stochast search simul use creat new tool system work organ section ii present problem formul organ neural network algorithm section describ applic sonn well known problem test use network algorithm section iv discuss result futur direct self organ neural network self organ structur self organ neural network algorithm perform search model construct network node repres organ approxim model real sonn character three major modifi incorpor gener rule primit neuron transfer evalu method access qualiti search compon sonn algorithm structur organ neural network gener rule set observ repres random variabl normal dimens dimens everi compon yk form hypersuffac yk space dim problem find given observ corrupt version desir model estim desir simpl number low degre non approach taken estim simplest model best describ optim function view construct hypersurfac base observ describ given set use compon dimension space creat best describ yk three step given map construct hypersurfac first project element domain call global optim criterion reach construct otherwis continu third new hypersurfac extend map reappli result model multilay neural network whose topolog complex creawxi stochast search guid structur estim simplic set prototyp function wxl quadrat surfac four possibl evalu model base mdl criterion select rule neuron transfer function base modif descript length inform minim descript statist estim mdl accuraci complex model includ structur estim term final final model minim tenorio lee optimum sens consist estim number achiev minimum error given sequenc random variabl domin term mdl log log estim probabl densiti function number number first term actual neg maximum likelihood respect estim second describ structur model use penalti complex case linear polynomi mdl log log number coeffici model sonn mdl criterion modifi oper recurs concept mdl appli candid prototyp given accept base simul use mdl measur system sinc new neuron termin output origin mdl unabl comput true number system paramet recal due arbitrari feedback loop non trivial comput number paramet entir order reflect hierarch natur modifi mdl call estim criterion use conjunct heurist estim number paramet system stage effici heurist estim number paramet base fact sonn creat structur multipl root input express estim recurs paramet current estim number paramet left right parent current heurist estim neither lower bound bound true number paramet sonn algorithm explain follow definit node neuron basic node node system input front node node without intermidi node node neither front basic state collect initi state state basic parent child state child state equal parent state except new node interconnect gener parent state state state either child parent state energi organ neural network state energi state defin minimum sec front node sonn search correct model structur done via simul therefor algorithm time accept partial structur look less abl discard partial construct substructur better use algorithm impli node accept rule vari accord cool temperatur sonn si gener applic accept si applic number new neuron greater temperatur temperatur smaller ten temperatur simul neuron output system input variabl call termin potenti dimens new hypersurfac everi repres best tent approxim function therefor exampl chaotic time seri follow chaotic time seri gener equat sonn heurist variant obtain approxim model result compar use nonlinear signal process method disadvantag approach analyz next structur problem differenti equat use describ set chaotic time seri attractor dimens produc compar predict normal root mean squar error use perform tenorio lee rmse rmse deviat sonn heurist sec follow modifi heurist version sec estim number paramet given configuraion shown figur node sonn allow gener accept version neuron number draw transfer function pool gener algorithm easili made accommod multipl input neuron function assign drawn separ first hundr point time seri use sampl predict total number weight network index averag output network overlap figur origin time comparison gdr network structur use train train data consist first point test data ran sampl total weight final perform index equal done give algorithm similar comput figur show origin seri overlap gdr network node model chosen form th accept network wain similar manner first sinc part number weight perform index figur show network overlap origin time figur show gdr notic gdr network demand compar connect weight first connect weight second comparison perform differ model list figur conclus futur work propos new approach identif problem base neural network variabl structur provid opportun search construct optim model base hierarch version call structur estim organ neural network use guid model complex accuraci tim nn approach demonstr potenti use tool system exampl model chaotic time univers nonlinear predic simul irsekf learn iee shortest dam gemen gibb bayesian ie signal process use neural system volum order estim autoregress process shortest analysi optim stochast state gener sonn tenorio lee ii io gdr sonn gdr ol perform index number predict point,2
98,98,"65 
LINEAR LEARNING: LANDSCAPES AND ALGORITHMS 
Pierre Baldi 
Jet Propulsion Laboratory 
California Institute of Technology 
Pasadena, CA 91109 
Abstract
What follows extends some of our results of [1] on learning from ex- 
amples in layered feed-forward networks of linear units. In particu- 
lar we examine what happens when the number of layers is large or 
when the connectivity between layers is local and investigate some 
of the properties of an autoassociative algorithm. Notation will be 
as in [1] where additional motivations and references can be found. 
It is usual to criticize linear networks because ""linear functions do 
not compute"" and because several layers can always be reduced to 
one by the proper multiplication of matrices. However this is not the 
point of view adopted here. It is assumed that the architecture of the 
network is given (and could perhaps depend on external constraints) 
and the purpose is to understand what happens during the learning 
phase, what strategies are adopted by a synaptic weights modifying 
algorithm,... [see also Cottrell et al. (1988) for an example of an ap- 
plication and the work of Linsker (1988) on the emergence of feature 
detecting units in linear networks]. 
Consider first a two layer network with n input units, n output units 
and p hidden units (p < n). Let (xl,yl),...,(xr, yr) be the set of 
centered input-output training patterns. The problem is then to find 
two matrices of weights A and B minimizing the error function E: 
= IlY,- AB,112. 
l<t<T 
66 Bald 
Let Exx, Ex�, E��, Eyx denote the usual covariance matrices. The 
main result of [1] is a description of the landscape of E, characerised 
by a multiplicity of saddle points and an absence of local minima. 
More precisely, the following four facts are true. 
Fact 1: For any fixed n x p matrix A the function E(A, B) is convex 
in the coefficients of B and attains its minimum for any B satisfying 
the equation 
AABExx = AEyx. (2) 
If in addition Exx is invertible and A is of full rank p, then E is 
strictly convex and has a unique minimum reached when 
B = 1)(A) = (A'A)-iA'SyxSc. 
(a) 
Fact 2: For any fixed p x n matrix B the function E(A, B) is convex 
in the coefficients of A and attains its minimum for any A satisfying 
the equation 
ABSxxB= SyxB . (4) 
If in addition Sxx is invertible and B is of full rank p, then E is 
strictly convex and has a unique minimum reached when 
A = .2.(B)= SyxB'(BSxxB') -. 
(5) 
Fact 3: Assume that Sxx is invertible. If two matrices A and B 
define a critical point of E (i.e. a point where OE/Oaii = OE/Obii = 
0) then the global map W = AB is of the form 
(6) 
where PA denotes the matrix of the orthogonal projection onto the 
subspace spanned by the columns of A and A satisfies 
PAS = PASPA = SPA (7) 
Linear Learning: Landscapes and Algorithms 67 
with E = EyxE]xEx�. If A is of full rank p, then A and B define 
a critical point of E if and only if A satisfies (7) and B =/)(A), or 
equivalently if and only if A and W satisfy (6) and (7). Notice that 
in (6), the matrix Eyx E is the slope matrix for the ordinary least 
square regression of Y on X. 
Fact 4: Assume that E is full rank with n distinct eigenvalues A > 
... > X,. If Z = {i,...,ip}(1 < i < ... < ip < n)is any or- 
dered p-index set, let Uz = [ui,...,ui,] denote the matrix formed 
by the orthonormal eigenvectors of E associated with the eigenvalues 
Ai,..., Alp. Then two full rank matrices A and B define a critical 
point of E if and only if there exist an ordered p-index set 27 and an 
invertible p x p matrix C such that 
A= UzC' (8) 
B = C-1U5'],yxS'],. 
For such a critical point we have 
W = PU:rEYXE: 
(10) 
(11) 
Therefore a critical point of W of rank p is always the product of the 
ordinary least squares regression matrix followed by an orthogonal 
projection onto the subspace spanned by p eigenvectors of E. The map 
W associated with the index set {1,2,...,p} is the unique local and 
global minimum of E. The remaining () - 1 p-index sets correspond 
to saddle points. All additional critical points defined by matrices 
A and B which are not of full rank are also saddle points and can 
be characerized in terms of orthogonal projections onto subspaces 
spanned by q eigenvectors with q < p. 
68 Bsldi 
Deep Networks 
Consider now the case of a deep network with a first layer of n input 
units, an (rn + 1)-th layer of n output units and rn- 1 hidden layers 
with an error function given by 
E(AI,...,An) -  [lY' - A1AI...Arax, I[ . 
l<t<T 
(12) 
It is worth noticing that, as in fact I and 2 above, if we fix any rn - 1 
of the rn matrices A1, ..., A,, then E is convex in the remaining matrix 
of connection weights. Let p (p < n) denote the number of units in 
the smallest layer of the network (several hidden layers may have p 
units). In other words the network has a bottleneck of size p. Let i 
be the index of the corresponding layer and set 
A = AAa...Am-i+ 
B = Am-i+2...Am 
(13) 
When we let A,..., A, vary, the only restriction they impose on A 
and B is that they be of rank at most p. Conversely, any two ma- 
trices A and B of rank at most p can always be decomposed (and 
in many ways) in products of the form of (13). It results that any 
local minirod of the error function of the deep network should yield a 
local minirod for the corresponding ""collapsed"" .three layers network 
induced by (13) and vice versa. Therefore E(A,...,A,,) does not 
have any local minima and the global minimal map W* = A A2...A,, 
is unique and given by (10) with index set {1,2,...,p}. Notice that 
of course there is a large number of ways of decomposing W* into 
a product of the form AA2...A,. Also a saddle point of the error 
function E(A, B) does not necessarily generate a saddle point of the 
corresponding E(A,..., A,,) for the expressions corresponding to the 
two gradients are very different. 
Linear Larning: Landscapes and Algorithms 69 
Forced Connections. Local Connectivity 
Assume now an error function of the form 
= Ilu,- 
l<t<T 
for a two layers network but where the value of some of the entries 
of A may be externally prescribed. In particular this includes the 
case of local connectivity described by relations of the form aij ---- 0 
for any output unit i and any input unit j which are not connected. 
Clearly the error function E(A) is convex in A. Every constraint of 
the form aij --cst defines an hyperplane in the space of all possible A. 
The intersection of all these constraints is therefore a convex set. Thus 
minimizing E under the given constraints is still a convex optimization 
problem and so there are no local minima. It should be noticed that, 
in the case of a network with even only three constrained layers with 
two matrices A and B and a set of constraints of the form aij --cst 
on A and bet --cst for B, the set of admissible matrices of the form 
W = AB is, in general, not convex anymore. It is not unreasonable 
to conjecture that local minima may then arise, though this question 
needs to be investigated in greater detail. 
Algorithmic Aspects 
One of the nice features of the error landscapes described so far is 
the absence of local minima and the existence, up to equivalence, 
of a unique global minimum which can be understood in terms of 
principal component analysis and least square regression. However 
the landscapes are also characterized by a large number of saddle 
points which could constitute a problem for a simple gradient descent 
algorithm during the learning phase. The proof in [1] shows that 
the lower is the E value corresponding to a saddle point, the more 
difficult it is to escape from it because of a reduction in the possible 
number of directions of escape (see also [Chauvin, 1989] in a context of 
Hebbian learning). To assert how relevant these issues are for practical 
implementations requires further simulation experiments. On a more 
7O Bsld 
speculative side, it remains also to be seen whether, in a problem 
of large size, the number and spacing of saddle points encountered 
during the first stages of a descent process could not be used to ""get 
a feeling"" for the type of terrain being descented and as a result to 
adjust the pace (i.e. the learning rate). 
We now turn to a simple algorithm for the auto-associative case in a 
three layers network, i.e. the case where the presence of a teacher 
can be avoided by setting /t: xt and thereby trying to achieve a 
compression of the input data in the hidden layer. This technique 
is related to principal component analysis, as described in [1]. If 
yt: xt, it is easy to see from equations (8) and (9) that, if we take 
the matrix C to be the identity, then at the optimum the matrices 
A and B are transpose of each other. This heuristically suggests a 
possible fast algorithm for auto-association, where at each iteration a 
gradient descent step is applied only to one of the connection matrices 
while the other is updated in a symmetric fashion using transposition 
and avoiding to back-propagate the error in one of the layers (see 
[Williams, 1985] for a similar idea). More formally, the algorithm 
could be concisely described by 
A(O) = random 
(o) = '(o) 
A(k + 1) = A(k) - r I OA 
B(k+l)=A'(k+l) 
(15) 
Obviously a similar algorithm can be obtained by setting B(k + 1) = 
B(k) - rlc9E/OB and A(k + 1) = B'(k + 1). It may actually even be 
better to alternate the gradient step, one iteration with respect to A 
and one iteration with respect to B. 
A simple calculation shows that (15) can be rewritten as 
A(k + 1) = A(k) + rl(I- W(k))ExxA(k) 
( + l) = (k) + V()Sxx(t- W(k)) 
(16) 
Linear Learning: Landscapes and Algorithms 71 
where W(k) -- A(k)B(k). It is natural from what we have already 
seen to examine the behavior of this algorithm on the eigenvectors of 
I]xx. Assume that u is an eigenvector of both I]xx and W(k) with 
eigenvalues A and p(k). Then it is easy to see that u is an eigenvector 
of W(k + 1) with eigenvalue 
p(k + 1) = p(k)[1 + r/(1 - p(k))] 2. 
For the algorithm to converge to the optimal W, p(k q- 1) must con- 
verge to 0 or 1. Thus one has to look at the iterates of the func- 
tion f(x) = /[1 q-r/(1- x)] 2. This can be done in detail and 
we shall only describe the main points. First of all, f'(x) = 0 iff 
x = 0 or x = xa = 1 q- (1/r/A) or x = Xb = 1/3 + (1/3r/A) and 
f""(x) = 0 iff x = xc = 2/3 + (2/3r/,X) = 2Xb. For the fixed points, 
f(x) = x iff x = 0, x = 1 or x = Xd = 1 + (2/r/,X). Notice also 
that f(xa) = 0 and f(1 + (l/,lA)) = (1 + (//r/,X)(1 - l) a. Points cor- 
responding to the values 0,1, Xa,Xd of the x variable can readily be 
positioned on the curve of f but the relative position of xb (and 
depends on the value assumed by r/,X with respect to 1/2. Obviously 
if/(0) = 0, 1 or xd then/(k) = 0, 1 or x, if/(0) < 0/(k) --+ 
and if p(k) > x p(k) -4 +oc. Therefore the algorithm can converge 
only for 0 < p(0) < x. When the learning rate is too large, i.e. 
when > 1/2 then even if p(0) is in the interval (0, x) one can see 
that the algorithm does not converge and may even exhibit complex 
oscillatory behavior. However when r/,X < 1/2, if 0 </(0) < xa then 
/(k) --+ 1, if p(0) = xa then = 0 and if xa < /(0) < xd then 
In conclusion, we see that if the algorithm is to be tested, the 
learning rate should be chosen so that it does not exceed 1/2,X, where 
,X is the largest eigenvalue of Exx. Even more so than back propaga- 
tion, it can encounter problems in the proximity of saddle points. 
Once a non-principal eigenvector of Exx is learnt, the algorithm 
rapidly incorporates a projection along that direction which cannot 
be escaped at later stages. Simulations are required to examine the 
effects of ""noisy gradients"" (computed after the presentation of only 
a few training examples), multiple starting points, variable learning 
rates, momentum terms, and so forth. 
72 Bd 
Aknowledgement 
Work supported by NSF grant DMS-8800323 and in part by ONR 
contract 411P006 01. 
References 
(1) Baldi, P. and Hornik, K. (1988) Neural Networks and Principal 
Component Analysis: Learning from Examples without Local Min- 
ima. Neural Networks, Vol. 2, No. 1. 
(2) Chauvin, Y. (1989) Another Neural Model as a Principal Compo- 
nent Analyzer. Submitted for publication. 
(3) Cottrell, G. W., Munro, P. W. and Zipser, D. (1988) Image Com- 
pression by Back Propagation: a Demonstration of Extensional Pro- 
gramming. In: Advances in Cognitive Science, Vol. 2, Sharkey, N. E. 
ed., Norwood, NJ Abbex. 
(4) Linsker, R. (1988) Self-Organization in a Perceptual Network. 
Computer 21 (3), 105-117. 
(5) Williams, R. J. (1985) Feature Discovery Through Error-Correction 
Learning. ICS Report 8501, University of California, San Diego. 
", landscap algorithm baldi propuls laboratori institut technolog ca follow extend result learn layer network linear examin happen number layer larg connect layer local investig properti autoassoci notat addit motiv refer usual critic linear network function sever layer alway reduc proper multipl howev view adopt assum architectur given could perhap depend extern purpos understand happen learn strategi adopt synapt weight modifi also cottrel et exampl work linsker emerg featur unit linear first two layer network input output unit hidden unit let set train problem find matric weight minim error function eyx denot usual covari result descript landscap characeris multipl saddl point absenc local follow four fact fix matrix function convex coeffici attain minimum satisfi equat addit exx invert full rank convex uniqu minimum reach fix matrix function convex coeffici attain minimum satisfi equat addit sxx invert full rank convex uniqu minimum reach assum sxx two matric critic point point global map ab form pa denot matrix orthogon project onto span column satisfi paspa spa landscap algorithm full rank defin critic point satisfi satisfi notic matrix eyx slope matrix ordinari least regress assum full rank distinct eigenvalu ip let uz denot matrix form orthonorm eigenvector associ eigenvalu two full rank matric defin critic exist order set matrix critic point critic point rank alway product least squar regress matrix follow orthogon onto subspac span eigenvector map associ index set uniqu local minimum remain set correspond saddl addit critic point defin matric full rank also saddl point characer term orthogon project onto subspac eigenvector bsldi network case deep network first layer input layer output unit hidden layer error function given worth notic fact fix rn rn matric convex remain matrix connect let denot number unit smallest layer network hidden layer may word network bottleneck size let index correspond layer set let restrict impos rank two rank alway decompos mani product form result minirod error function deep network yield minirod correspond layer network vice therefor local minima global minim map uniqu given index set notic cours larg number way decompos product form also saddl point error necessarili gener saddl point express correspond gradient landscap algorithm local connect error function form two layer network valu entri may extern particular includ local connect describ relat form aij output unit input unit error function convex everi constraint form aij defin hyperplan space possibl intersect constraint therefor convex thu given constraint still convex optim local notic case network even three constrain layer matric set constraint form aij bet set admiss matric form ab convex unreason conjectur local minima may though question investig greater aspect nice featur error landscap describ far absenc local minima uniqu global minimum understood term compon analysi least squar howev landscap also character larg number saddl could constitut problem simpl gradient descent learn proof show lower valu correspond saddl escap reduct possibl direct escap also context assert relev issu practic requir simul remain also seen problem larg number space saddl point encount first stage descent process could use type terrain descent result pace learn turn simpl algorithm case layer case presenc teacher avoid set xt therebi tri achiev input data hidden techniqu relat princip compon describ easi see equat take matrix optimum matric transpos heurist suggest fast algorithm iter descent step appli one connect matric updat symmetr fashion use transposit avoid error one layer similar algorithm concis describ random oa similar algorithm obtain set may actual even altern gradient one iter respect one iter respect simpl calcul show rewritten landscap algorithm natur alreadi examin behavior algorithm eigenvector assum eigenvector easi see eigenvector eigenvalu algorithm converg optim must thu one look iter done detail shall describ main first iff xa xb iff xc fix iff xd notic also point valu variabl readili curv rel posit xb valu assum respect obvious xd therefor algorithm converg learn rate even interv one see algorithm converg may even exhibit complex howev xa xa xa xd see algorithm rate chosen exceed largest eigenvalu even back encount problem proxim saddl eigenvector algorithm incorpor project along direct can not escap later simul requir examin present train multipl start variabl learn momentum support nsf grant part onr neural network princip learn exampl without local neural anoth neural model princip submit imag back demonstr extension advanc cognit nj perceptu featur discoveri ic report univers san,2
99,99,"73 
LEARNING BY CHOICE 
OF INTERNAL PEPPESENTATIONS 
Tal Grossman, Ronny Meir and Eytan Domany 
Department of Electronics, Weizmann Institute of Science 
Rehovot 76100 Israel 
ABSTRACT 
We introduce a learning algorithm for multilayer neural net- 
works composed of binary linear threshold elements. Whereas ex- 
isting algorithms reduce the learning process to minimizing a cost 
function over the weights, our method treats the internal repre- 
sentations as the fundamental entities to be determined. Once a 
correct set of internal representations is arrived at, the weights are 
found by the local ahd biologically plausible Perceptton Learning 
Rule (PLR). We tested our learning algorithm on four problems: 
adjacency, symmetry, parity and combined symmetry-parity. 
I. INTRODUCTION 
Consider a network of binary linear threshold elements i, whose state $i - 4-1 
is determined according to the rule 
$i - sign(-. wi$ + Oi) (1) 
Here wij is the (unidirectional) weight assigned to the connection from unit j to 
i; 0i is a local bias. We focus our attention on feed-forward networks in which N 
units of the inpu layer determine the states of H units of a hidden layer; these, in 
turn, feed one or more output elements. 
For a typical A vs B classificalion task such a network needs a single output, 
with Sour _ +1 (or -1) when the input layer is set in a state that belongs to category 
A (or B) of input space. The basic problem of learning is to find an algorithm, that 
produces weights which enable the network to perform this task. In the absence 
of hidden units learning can be accomplished by the PLR [Rosenblatt 1962], which 
we now briefly describe. Consider j = 1, ..., N source units and a single target unit 
i. When the source units are set in any one of p - 1, ..M patterns, i.e. $j - , 
we require that the target unit (determined using (1)) takes preassigned values . 
Learning takes place in the course of a training session. Starting from any arbitrary 
initial guess for the weights, an input  is presented, resulting in the output taking 
some value $. Now modify every weight according to the rule 
V V V V 
wij --* wij + r(1 - $ i )i j , (2) 
74 Grossman, Meir and Domany 
where r/  0 is a parameter ( = I is used to modify the bias 0). Another 
input pattern is presented, and so on, until all inputs draw the correct output. 
The Perceptton convergence lheorera states [Rosenblatt 1962, Minsky and Paperr 
1969] that the PLR will find a solution (if one exists), in a finite number of steps. 
However, of the 22r possible partitions of input space only a small subset (less than 
2N2]N!) is linearly separable [Lewis and Coates 1967], and hence soluble by single- 
layer perceptrons. To get around this, hidden units are added. Once a single hidden 
layer (with a large enough number of units) is inserted beween input and output, 
every classification problem has a solution. But for such architectures the PLR 
cannot be implemented; when the network errs, it is not clear which connection is 
to blame for the error, and what corrective action is to be taken. 
Back-propagation [Pumelhart et al 1986] circumvents this ""credit-assignment"" 
problem by dealing only with networks of continuous valued units, whose response 
function is also continuous (sigmoid). ""Learning"" consists of a gradient-descent 
type minimization of a cost function that measure the deviation of actual outputs 
from the required ones, in the space of weights Wij , 0 i. A new version of BP, ""back 
propagation of desired states"", which bears some similarity to our algorithm, has 
recently been introduced [Plaut 1987]. See also le Cun [1985] and Widrow and 
Winter [1988] for related methods. 
Our algorithm views the internal representations associated with various inputs 
as the basic independent variables of the learning process. This is a conceptually 
plausible assumption; in the course of learning a biological )r artificial system should 
form maps and representations of the external world. Once such representations 
are formed, the weights can be found by simple and local Hebbian learning rules 
such as the PLR. Hence the problem of learning becomes one of searching for proper 
internal representations, rather than one of minimization. Failure of the PLR to 
converge to a solution is used as an indication that the current guess of internal 
representations needs to be modified. 
II. THE ALGORITHM 
If we know the internal representations (e.g. the states taken by the hidden 
layer when patterns from the training set are presented), the weights can be found 
by the PLR. This way the problem of learning becomes one of choosing proper 
internal representations, rather than of minimizing a cost function by varying the 
values of weights. To demonstrate our approache, consider the classification prob- 
lem with output values, $out, = out,, required in response to/ = 1, ..., M input 
patterns. If a solution is found, it first maps each input onto an internal represen- 
tation generated on the hidden layer, which, in turn, produces the correct output. 
Now imagine that we are not supplied with the weights that solve the problem; 
however the correct internal representations are revealed. That is, we are given a 
table with M rows, one for each input. Every row has H bits /', for i - 1, ..H, 
specifying the state of the hidden layer obtained in response to input pattern y. 
One can now view each hidden-layer cell i as the target cell of the PLR, with the 
N inputs viewed as source. Given sufficient time, the PLP will converge to a set 
Learning by Choice of Internal Representations 75 
of weights Wi,j, connecting input unit j to hidden unit i, so that indeed the input- 
output association that appears in column i of our table will be realized. In a 
similar fashion, the PLR will yield a set of weights wi, in a learning process that 
uses the hidden layer as source and the output unit as target. Thus, in order to 
solve the problcm of learning, all one needs is a search procedure in the space of 
possible internal representations, for a table that can be used to generate a solution. 
Updating of weights can be done in parallel for the two layers, using the current 
table of internal representations. In the present algorithm, however, the process is 
broken up into four distinct stages: 
1. SETINREP: Generate a table of internal representations {/a,v} by presenting 
each input pattern from the training set and calculating the state on the hidden 
layer,using Eq.(la), with the existing couplings Wij and 0i. 
2. LEARN23: The hidden layer cells are used as source, and the output as the 
target unit of the PLR. The current table of internal representations is used as 
the training set; the PLR tries to find appropriate weights wi and 0 to obtain the 
desired outputs. If a solution is found, the problem has been solved. Otherwise 
stop after I23 learning sweeps, and keep the current weights, to use in INREP. 
3. INREP: Generate a new table of internal representations, which, when used in 
(lb), yields the correct outputs. This is done by presenting the table sequentially, 
row by row, to the hidden layer. If for row y the wrong output is obtained, the 
internal representation h,v is changed. Having the wrong output means that the 
""field"" produced by the hidden layer on the output unit, h �ut, = j wj ' is 
either too large or too small. We then randomly pick a site j of the hidden layer, 
and try to flip the sign of '; if h �ut, changes in the right direction, we replace 
the entry of our table, i.e. 
We keep picking sites and changing the internal representation of pattern y until 
the correct output is generated. We always generate the correct output this way, 
provided j Iwjl > ]O�utl (as is the case for our learning process in LEARN23). 
This procedure ends with a modified table which is our next guess of internal 
representations. 
4. LEA1ZN12: Apply the PLR with the first layer serving as source, treating 
every hidden layer site separately as target. Actually, when an input from the 
training set is presented to the first layer, we first check whether the correct result 
is produced on the outpu! unit of the network. If we get wrong overall output, we 
use the PLR for every hidden unit i, modifying weights incident on i according 
to (2), using column i of the table as the desired states of this unit. If input y 
does yield the correct output, we insert the current state of the hidden layer as the 
internal representation associated with pattern y, and no learning steps are taken. 
We sweep in this manner the training set, modifying weights Wij, (between input 
and hidden layer), hidden-layer thresholds Oi, and, as explained above, internal 
76 Grossman, Meir and Domany 
representations. If the network has achieved error-free performance for the entire 
training set, learning is completed. If no solution has been found after I12 sweeps 
of the training set, we abort the PLR stage, keep the present values of wij, Oi, and 
start SETINttEP again. 
This is a fairly complete account of our procedure (see also Grossman et al 
[1988]). There are a few details'that need to be added. 
a) The ""impatience"" parameters: I12 and I23, which are rather arbitrary, are 
introduced to guarantee that the PLR stage is aborted if no solution is found. This 
is necessary since it is not clear that a solution exists for the weights, given the 
current table of internal representations. Thus, if the PLR stage does not converge 
within the time limit specified, a new table of internal representations is formed. 
The parameters have to be large enough to allow the PLR to find a solution (if 
one exists) with sufficiently high probability. On the other hand, too large values 
are wasteful, since they force the algorithm to execute a long search even when 
no solution exists. Therefore the best values of the impatience parameters can be 
determined by optimizing the performance of the network; our experience indicates, 
however, that once a ""reasonable"" range of values is found, performance is fairly 
insensitive to the precise choice. 
b) Integer weights: In the PLR correction step, as given by Eq.2, the size of 
AW is constant. Therefore, when using binary units, it can be scaled to unity (by 
setting r/= 0.5) and one can use integer tVi,j's without any loss of generality. 
c) Optimization: The algorithm described uses several parameters, which should 
be optimized to get the best performance. These parameters are: I1 and I3 - see 
section (a) above; Ima - time limit, i.e. an upper bound to the total number of 
training sweeps; and the PLR training parameters - i.e the increment of the weights 
and thresholds during the PLR stage. In the PLR we used values of r/_ 0.1 [see 
Eq. (2) ] for the weights, and r/_ 0.05 for thresholds, whereas the initial (random) 
values of all weights were taken from the interval (-0.5,0.5), and thresholds from 
(-0.05,0.05). In the integer weights program, described above, these parameters are 
not used. 
d) Treating Multiple Outputs: In the version of inrep described above, we 
keep flipping the internal representations 'until we find one that yields the correct 
output, i.e. zero error for the given pattern. This is not always possible when using 
more than one output unit. Instead, we can allow only for a pre-specified number 
of attempted flips, Ii,, and go on to the next pattern even if vanishing error was 
not achieved. In this modified version we also introduce a slightly different, and less 
""restrictive"" criterion for accepting or rejecting a flip. Having chosen (at random) 
a hidden unit i, we check the effect of flipping the sign of /a,v on the total output 
error, i.e. the number of wrong bits (and not on the output field, as described 
above). If the output error is not increased, the flip is accepted and the table of 
internal representations is changed accordingly. 
This modified algorithm is applicable for multiple-output networks. ttesults of 
preliminary experiments with this version are presented in the next section. 
Learning by Choice of Internal Representations 77 
III. PERFORMANCE OF THE ALGORITHM 
The ""time"" parameter that we use for measuring performance is the number of 
sweeps through the training set of M patterns needed in order to find the solution. 
Namely, how many times each pattern was presented to the network. In each cycle 
of the algorithm there are I12 + 123 such sweeps. For each problem, and each 
parameter choice, an ensemble of many independent runs, each starting with a 
different random choice of initial weights, is created. In general, when applying a 
learning algorithm to a given problem, there are cases in which the algorithm fails 
to find a solution within the specified time limit (e.g. when BP get stuck in a local 
minimum), and it is impossible to calculate the ensemble average of learning times. 
Therefore we calculate, as a performance measure, either the median number of 
sweeps, tin, or the ""inverse average rate"", r, as defined in Tesauro and Janssen 
[1988]. 
The first problem we studied is contiguity: the system has to determine whether 
the number of clumps (i.e. contiguous blocks) of +1's in the input is, say, equal to 
2 or 3. This is called [Denker et al 1987] the ""2 versus 3"" clumps predicate. We 
used, as our training set, all inputs that have 2 or 3 clumps, with learning cycles 
parametrized by 112 -- 20 and I23 - 5. Keeping N - 6 fixed, we varied H; 500 
cases were used for each data point of Fig. 1. 
t m 
400 
300 
20O 
lOO 
0 
I [ I I I I I I Ili I I i I 1 !'1 I I I""1 I I 1 I I I 
X � BP 
o � CHIR 
A 
3 4 5 6 7 8 
H 
Figure 1. Median number of sweeps tin, needed to train a network of N - 6 
input units, over an exhaustive training set, to solve the ""2 vs 3"" clumps predicate, 
plotted against the number of hidden units H. Results for back-propagation [Denker 
et al 1987] (x) and this work (Q) are shown. 
78 rosman, Meir and Domany 
In the next problem, symmetry, one requires Sour = 1 for reflection-symmetric 
inputs and -1 otherwise. This can be solved with H >_ 2 hidden units. Fig. 2 
presents, for H = 2, the median number of exhaustive training sweeps needed to 
solve the problem, vs input size N. At each point 500 cases were run, with 112 -- 10 
and I23 = 5. We always found a solution iwless than 200 cycles. 
10 3 
{3171 
10 2 
lo 1 
Illl 
Figure 2. Median number of sweeps lrn, needed to train networks on 
symmetry (with H = 2). 
In the Parity problem one requires S �ut = 1 for an even number of +1 bits in 
the input, and -1 otherwise. In order to compare performance of our algorithm to 
that of BP, we studied the Parity problem, using networks with an architecture of 
N: 2N: 1, as chosen by Tesauro and Janssen [1988]. 
We used the integer version of our algorithm, briefly described above. In this 
version of the algorithm the weights and thresholds are integers, and the increment 
size, for both thresholds and weights, is unity. As an initial condition, we chose 
them to be +1 or -1 randomly. In the simulation of this version, all possible input 
patterns were presented sequentially in a fixed order (within the perceptton learning 
sweeps). The results are presented in Table 1. For all choices of the parameters 
( I12, I23 ), that are mentioned in the table, our success rate was 100%. Namely, the 
algorithm didn't fail even once to find a solution in less than the maximal number 
of training cycles Irnaa: specified in the table. Results for BP, r(BP) (from Tesauro 
and Janssen 1988) are also given in the table. Note that BP does get caught in 
local minima, but the percentage of such occurrences was not reported. 
Learning by Choice of Internal Representations 79 
For testing the multiple output version of the algorithm we usel the combined 
parity and symmetry problem; the network has two output units, both connected to 
all hidden units. The first output unit performs the parity predicate on the input, 
and the second performs the symmetry predicate. The network architecture was 
N:2N:2 and the results for N-4..7 are given in Table 2. The choice of parameters 
is also given in that table. 
N (I2, I2) Imam: tra r(CHIR) r(BP) 
3 (8,4) 10 3 3 35 
4 (9,3)(6,6) 20 4 4 75 
5 (12,4)(9,6) 40 8 6 130 
6 (12,4)(10,5) 120 19 9 31q 
7 (12,4)(15,5) 240 290 30 800,, 
8 (20,10) 900 2900 150 200 
9 (20,10) 900 2400 1300 - 
Table 1. Parity with N:2N:I architecture. 
N I12 I23 Iin Imax tm r 
4 12 8 7 40 50 33 
5 14 7 7 400 900 350 
6 18 9 7 900 5250 925 
7 40 20 7 900 6000 2640 
Table 2. Parity and Symmetry with N:2N:2 architecture. 
IV. DISCUSSION 
We have presented a learning algorithm for two-layer percepttons, that searches 
for internal representations of the training set, and determines the weights by the 
local, Hebbian perceptton learning rule. Learning by choice of internal represen- 
tation may turn out to be most useful in situations where the ""teacher"" has some 
information about the desired internal representations. 
We demonstrated that our algorithm works well on four typical problems, and 
studied the manner in which training time varies with network size. Comparisons 
with back-propagation were also made. it should be noted that a training sweep 
involves much lcss computations than that of back-propagation. We also presented 
a generalization of the algorithm to networks with multiple outputs, and found 
that it functions well on various problems of the same kind as discussed above. It 
appears that the modification needed to deal with multiple outputs also enables us 
to solve the learning problem for network architectures with more than one hidden 
layer. 
80 Grossman, Meir and Domany 
At this point we can offer only very limited discussion of the interesting ques- 
tion - why does our algorithm work at all? That is, how come it finds correct 
internal representations (e.g. ""tables"") while these constitute only a small fraction 
of the total possible number (2H2N)? The main reason is that our procedure ac- 
tually does not search this entire space of tables. This large space contains a small 
subspace, T, of ""target tables"", i.e. those that can be obtained, for all possible 
choices of w[j and Oi, by rule (1), in response to presentation of the input patterns. 
Another small subspace S, is that of the tables that can potentially produce the 
required output. Solutions of the learning problem constitute the space T f3 S. 
Our algorithm iterates between T and S, executing also a ""walk"" (induced by the 
modification of the weights due to the PLR) within each. 
An appealing feature of our algorithm is that it can be implemented in a 
manner that uses only integer-valued weights and thresholds. This discreteness 
makes the analysis of the behavior of the network much easier, since we know 
the exact number of bits used by the system in constructing its solution, and do 
not have to worry about round-off errors. From a technological point of view, for 
hardware implementation it may also be more feasible to work with integer weights. 
We are extending this work in various directions. The present method needs, in 
the learning stage, MH bits of memory: internal representations of all M training 
patterns are stored. This feature is biologically implausible and may be techno- 
logically limiting; we are developing a method that does not require such memory. 
Other directions of current study include extensions to networks with continuous 
variables, and to networks with feed-back. 
References 
Denker J., Schwartz D., Wittner B., Solla S., Hopfield J.J., Howard R. and Jackel 
L. 1987, Complea: Systems 1,877-922 
Grossman T., Meir R. and Domany E. 1988, Cornplea: Systems in press. 
Itebb D.O. 1949, The organization of Behavior, J. Wiley, N.Y 
Le Cun Y. 
Lewis P.M 
Minsky M. 
Plaut D.C. 
Rosenblatt 
Rumelhart 
Tesauro G. 
Widrow B. 
1985, Proc. Cogniliva 85,593 
� and Coates C.L. 1967, Threshold Logic. (Wiley, New York) 
and Paperr S. 1988, Percepttons. (MIT, Cambridge). 
, Nowlan S.J. and Hinton G.E. 1987, Tech. Report CMU-CS-86-126 
F. Principles of neurodynamics. (Spartan, New York, 1962) 
D.E., Hinton G.E. and Williams R.J. 1986, Nature 323, 533-536 
and Janssen H. 1988, Complez Systems 2, 39 
and Winter R. 1988, Computer 21, No.3, 25 
", choic intern peppesent ronni meir eytan domani weizmann institut scienc israel introduc learn algorithm multilay neural compos binari linear threshold wherea algorithm reduc learn process minim cost method treat intern fundament entiti set intern represent arriv weight local ahd biolog plausibl perceptton learn test learn algorithm four pariti combin introduct network binari linear threshold element whose state determin accord rule wij weight assign connect unit local focu attent network layer determin state unit hidden feed one output typic vs classificalion task network need singl sour input layer set state belong categori input basic problem learn find weight enabl network perform absenc hidden unit learn accomplish plr briefli consid sourc unit singl target unit sourc unit set one requir target unit use take preassign valu take place cours train start arbitrari guess input result output take valu modifi everi weight accord rule wij meir domani paramet use modifi bia anoth pattern input draw correct perceptton converg lheorera state minski paperr plr find solut one finit number possibl partit input space small subset linearli separ coat henc solubl get around hidden unit singl hidden larg enough number insert beween input classif problem architectur plr network clear connect blame correct action et al circumv deal network continu valu whose respons also continu consist minim cost function measur deviat actual output requir space weight wij new version desir bear similar introduc see also le cun widrow relat algorithm view intern represent associ variou input basic independ variabl learn conceptu cours learn biolog artifici system map represent extern represent weight found simpl local hebbian learn rule henc problem learn becom one search proper rather one failur plr solut use indic current guess intern need algorithm know intern represent state taken hidden pattern train set weight found way problem learn becom one choos proper rather minim cost function vari demonstr consid classif output requir respons input solut first map input onto intern gener hidden produc correct imagin suppli weight solv correct intern represent given one everi row bit state hidden layer obtain respons input pattern view cell target cell input view given suffici converg set choic intern represent weight connect input unit hidden unit inde associ appear column tabl plr yield set weight learn process hidden layer sourc output unit order problcm one need search procedur space intern tabl use gener weight done parallel two use current intern present process four distinct gener tabl intern represent present input pattern train set calcul state hidden exist coupl wij hidden layer cell use output unit current tabl intern represent use train plr tri find appropri weight wi obtain solut problem otherwis learn keep current use gener new tabl intern use yield correct done present tabl hidden row wrong output represent wrong output mean produc hidden layer output larg randomli pick site hidden tri flip sign chang right replac entri keep pick site chang intern represent pattern correct output alway gener correct output iwjl case learn process procedur end modifi tabl next guess intern appli plr first layer serv treat hidden layer site separ input set present first first check whether correct result produc unit get wrong overal plr everi hidden unit modifi weight incid accord use column tabl desir state input yield correct insert current state hidden layer represent associ pattern learn step sweep manner train modifi weight input hidden threshold explain intern meir domani network achiev perform entir learn solut found sweep train abort plr keep present valu ep fairli complet account procedur also grossman et al need rather guarante plr stage abort solut necessari sinc clear solut exist given tabl intern plr stage converg time limit new tabl intern represent paramet larg enough allow plr find solut suffici high larg valu sinc forc algorithm execut long search even solut therefor best valu impati paramet optim perform experi rang valu perform fairli precis integ plr correct given size use binari scale uniti one use integ without loss algorithm describ use sever optim get best paramet see time upper bound total number plr train paramet increment weight threshold plr plr use valu wherea initi weight taken interv threshold integ weight describ paramet treat multipl version inrep describ flip intern represent find one yield correct zero error given alway possibl use one output allow number attempt go next pattern even vanish error modifi version also introduc slightli less criterion accept reject chosen hidden unit check effect flip sign total output number wrong bit output describ output error flip accept tabl represent chang modifi algorithm applic ttesult experi version present next choic intern represent perform algorithm paramet use measur perform number train set pattern need order find mani time pattern present cycl algorithm ensembl mani independ start random choic initi appli algorithm given case algorithm fail find solut within specifi time limit bp get stuck local imposs calcul ensembl averag learn perform either median number averag defin tesauro janssen first problem studi system determin whether number clump contigu input equal call et al versu clump train input learn cycl keep vari use data point oo ili bp chir median number sweep need train network exhaust train solv vs clump number hidden unit result al work meir domani next one requir sour solv hidden median number exhaust train sweep need vs input size point case alway found solut iwless median number sweep need train network pariti problem one requir even number bit order compar perform algorithm studi pariti use network architectur chosen tesauro janssen use integ version briefli describ algorithm weight threshold increment threshold initi chose simul possibl input present sequenti fix order perceptton learn result present tabl choic paramet mention success rate fail even find solut less maxim number train cycl specifi result tesauro janssen also given note bp get caught percentag occurr choic intern represent test multipl output version algorithm combin symmetri network two output connect hidden first output unit perform pariti predic second perform symmetri network architectur result given tabl choic paramet also given tra pariti iin imax tm pariti symmetri discuss present learn algorithm search intern represent train determin weight hebbian perceptton learn learn choic intern may turn use situat desir intern demonstr algorithm work well four typic manner train time vari network comparison also note train sweep much lcss comput also present gener algorithm network multipl found function well variou problem kind discuss modif need deal multipl output also enabl us solv learn problem network architectur one hidden meir domani point offer limit discuss interest algorithm work come find correct represent constitut small fraction total possibl number main reason procedur search entir space larg space contain small possibl rule respons present input small subspac tabl potenti produc solut learn problem constitut space algorithm iter execut also weight due within appeal featur algorithm implement use weight discret analysi behavior network much sinc know exact number bit use system construct worri technolog point implement may also feasibl work integ extend work variou present method learn mh bit intern represent train featur biolog implaus may develop method requir direct current studi includ extens network continu network schwartz wittner solla hopfield howard jackel system meir domani system organ cun cogniliva coat threshold new paperr nowlan hinton report principl new hinton william natur janssen complez system winter comput,0
